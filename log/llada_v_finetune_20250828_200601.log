[2025-08-28 20:06:18,922] torch.distributed.run: [WARNING] 
[2025-08-28 20:06:18,922] torch.distributed.run: [WARNING] *****************************************
[2025-08-28 20:06:18,922] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2025-08-28 20:06:18,922] torch.distributed.run: [WARNING] *****************************************
[2025-08-28 20:06:26,703] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-28 20:06:26,706] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-28 20:06:26,706] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Please install pyav to use video processing functions.
Please install pyav to use video processing functions.
Please install pyav to use video processing functions.
/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
OpenCLIP not installed
OpenCLIP not installed
OpenCLIP not installed
[2025-08-28 20:06:44,326] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-08-28 20:06:44,329] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-08-28 20:06:44,329] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-08-28 20:06:44,382] [INFO] [comm.py:637:init_distributed] cdb=None
You are using a model of type llava_llada to instantiate a model of type llada. This is not supported for all configurations of models and can yield errors.
Rank 0:  Overwriting config with {'use_pos_skipping': False, 'pos_skipping_range': 4096, 'mm_spatial_pool_mode': 'bilinear'}
You are using a model of type llava_llada to instantiate a model of type llada. This is not supported for all configurations of models and can yield errors.
You are using a model of type llava_llada to instantiate a model of type llada. This is not supported for all configurations of models and can yield errors.
Rank 0:  Loading vision tower: google/siglip2-so400m-patch14-384
[2025-08-28 20:06:54,737] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 1035, num_elems = 16.48B
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  5.34it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:01,  4.58it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00,  5.07it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00,  4.90it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:05<00:07,  2.38s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:05<00:07,  2.38s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:08<00:40,  8.18s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:13<00:09,  4.75s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:13<00:09,  4.74s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:15<00:31,  7.78s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:19<00:05,  5.28s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:20<00:05,  5.29s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:21<00:20,  6.96s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:28<00:13,  6.74s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:35<00:07,  7.15s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:39<00:00, 10.05s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:39<00:00,  6.55s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:39<00:00, 10.05s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:39<00:00,  6.55s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:41<00:00,  6.46s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:41<00:00,  6.84s/it]
Rank 0:  Adding LoRA adapters...
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Rank 0:  Prompt version: llava_llada
Rank 0:  google/siglip2-so400m-patch14-384 is already loaded, `load_model` called again, skipping.
Rank 0:  Total parameters: ~8613.17 MB)
Rank 0:  Trainable parameters: ~189.28 MB)
Rank 0:  Loading data using traditional JSON format
Rank 0:  Loading /hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/dataset/vpp_sft_ready/vpp_sft_bbox_llava.json
Rank 0:  Loaded 1186414 samples from /hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/dataset/vpp_sft_ready/vpp_sft_bbox_llava.json
Rank 0:  Loaded 1186414 samples from /hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/dataset/vpp_sft_ready/vpp_sft_bbox_llava.json
Rank 0:  Formatting inputs...Skip in lazy mode
Rank 0:  Setting NCCL timeout to INF to avoid running errors.
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Parameter Offload: Total persistent parameters: 663456 in 331 params
  0%|          | 0/24716 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
TOKENIZERS_PARALLELISM=(true | false)
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  0%|          | 1/24716 [01:10<484:18:30, 70.54s/it]                                                     {'loss': 1.2555, 'grad_norm': 4.195617198619076, 'learning_rate': 1.3477088948787063e-07, 'epoch': 0.0}
  0%|          | 1/24716 [01:10<484:18:30, 70.54s/it]  0%|          | 2/24716 [02:20<481:14:53, 70.10s/it]                                                     {'loss': 1.3349, 'grad_norm': 4.4043717788115755, 'learning_rate': 2.6954177897574125e-07, 'epoch': 0.0}
  0%|          | 2/24716 [02:20<481:14:53, 70.10s/it][2025-08-28 20:12:35,732] [WARNING] [stage3.py:1949:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  0%|          | 3/24716 [03:09<415:23:43, 60.51s/it]                                                     {'loss': 1.3407, 'grad_norm': 3.57786179744834, 'learning_rate': 4.043126684636119e-07, 'epoch': 0.0}
  0%|          | 3/24716 [03:09<415:23:43, 60.51s/it]  0%|          | 4/24716 [03:50<362:01:58, 52.74s/it]                                                     {'loss': 1.3707, 'grad_norm': 5.501476743476846, 'learning_rate': 5.390835579514825e-07, 'epoch': 0.0}
  0%|          | 4/24716 [03:50<362:01:58, 52.74s/it]  0%|          | 5/24716 [04:39<354:24:59, 51.63s/it]                                                     {'loss': 1.4436, 'grad_norm': 5.273484676866429, 'learning_rate': 6.738544474393532e-07, 'epoch': 0.0}
  0%|          | 5/24716 [04:39<354:24:59, 51.63s/it]  0%|          | 6/24716 [05:30<352:45:44, 51.39s/it]                                                     {'loss': 1.4181, 'grad_norm': 10.062813083808626, 'learning_rate': 8.086253369272238e-07, 'epoch': 0.0}
  0%|          | 6/24716 [05:30<352:45:44, 51.39s/it]  0%|          | 7/24716 [06:18<344:27:57, 50.19s/it]                                                     {'loss': 1.2022, 'grad_norm': 3.4791126913397226, 'learning_rate': 9.433962264150943e-07, 'epoch': 0.0}
  0%|          | 7/24716 [06:18<344:27:57, 50.19s/it]  0%|          | 8/24716 [07:01<328:00:13, 47.79s/it]                                                     {'loss': 1.3417, 'grad_norm': 3.955238484534636, 'learning_rate': 1.078167115902965e-06, 'epoch': 0.0}
  0%|          | 8/24716 [07:01<328:00:13, 47.79s/it]  0%|          | 9/24716 [07:46<322:18:38, 46.96s/it]                                                     {'loss': 1.602, 'grad_norm': 4.334200283242227, 'learning_rate': 1.2129380053908356e-06, 'epoch': 0.0}
  0%|          | 9/24716 [07:46<322:18:38, 46.96s/it]  0%|          | 10/24716 [08:29<313:14:03, 45.64s/it]                                                      {'loss': 1.2125, 'grad_norm': 4.337110322181506, 'learning_rate': 1.3477088948787064e-06, 'epoch': 0.0}
  0%|          | 10/24716 [08:29<313:14:03, 45.64s/it]  0%|          | 11/24716 [09:13<310:10:14, 45.20s/it]                                                      {'loss': 1.1838, 'grad_norm': 3.485515436738613, 'learning_rate': 1.482479784366577e-06, 'epoch': 0.0}
  0%|          | 11/24716 [09:13<310:10:14, 45.20s/it]  0%|          | 12/24716 [10:08<330:11:10, 48.12s/it]                                                      {'loss': 1.2346, 'grad_norm': 4.66163644278487, 'learning_rate': 1.6172506738544475e-06, 'epoch': 0.0}
  0%|          | 12/24716 [10:08<330:11:10, 48.12s/it]  0%|          | 13/24716 [11:00<338:22:31, 49.31s/it]                                                      {'loss': 1.2078, 'grad_norm': 3.5191738045174756, 'learning_rate': 1.752021563342318e-06, 'epoch': 0.0}
  0%|          | 13/24716 [11:00<338:22:31, 49.31s/it]  0%|          | 14/24716 [12:01<363:28:32, 52.97s/it]                                                      {'loss': 1.3253, 'grad_norm': 4.196188620937315, 'learning_rate': 1.8867924528301887e-06, 'epoch': 0.0}
  0%|          | 14/24716 [12:01<363:28:32, 52.97s/it]  0%|          | 15/24716 [12:39<332:29:40, 48.46s/it]                                                      {'loss': 1.2851, 'grad_norm': 3.711587747024758, 'learning_rate': 2.0215633423180592e-06, 'epoch': 0.0}
  0%|          | 15/24716 [12:39<332:29:40, 48.46s/it]  0%|          | 16/24716 [13:28<334:03:14, 48.69s/it]                                                      {'loss': 1.1956, 'grad_norm': 4.135599955703352, 'learning_rate': 2.15633423180593e-06, 'epoch': 0.0}
  0%|          | 16/24716 [13:28<334:03:14, 48.69s/it]  0%|          | 17/24716 [14:21<343:07:26, 50.01s/it]                                                      {'loss': 1.1711, 'grad_norm': 9.03933405178484, 'learning_rate': 2.291105121293801e-06, 'epoch': 0.0}
  0%|          | 17/24716 [14:21<343:07:26, 50.01s/it]  0%|          | 18/24716 [15:03<326:20:01, 47.57s/it]                                                      {'loss': 1.1519, 'grad_norm': 3.313709992105675, 'learning_rate': 2.425876010781671e-06, 'epoch': 0.0}
  0%|          | 18/24716 [15:03<326:20:01, 47.57s/it]  0%|          | 19/24716 [15:58<340:33:32, 49.64s/it]                                                      {'loss': 1.426, 'grad_norm': 3.9306336341782186, 'learning_rate': 2.560646900269542e-06, 'epoch': 0.0}
  0%|          | 19/24716 [15:58<340:33:32, 49.64s/it][2025-08-28 20:26:22,224] [WARNING] [stage3.py:1949:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  0%|          | 20/24716 [16:55<357:13:21, 52.07s/it]                                                      {'loss': 1.1704, 'grad_norm': 4.152223436656684, 'learning_rate': 2.6954177897574127e-06, 'epoch': 0.0}
  0%|          | 20/24716 [16:55<357:13:21, 52.07s/it]  0%|          | 21/24716 [17:51<363:48:12, 53.03s/it]                                                      {'loss': 0.9548, 'grad_norm': 2.6803588539412586, 'learning_rate': 2.830188679245283e-06, 'epoch': 0.0}
  0%|          | 21/24716 [17:51<363:48:12, 53.03s/it]  0%|          | 22/24716 [18:38<351:05:43, 51.18s/it]                                                      {'loss': 1.1866, 'grad_norm': 7.633310324191476, 'learning_rate': 2.964959568733154e-06, 'epoch': 0.0}
  0%|          | 22/24716 [18:38<351:05:43, 51.18s/it]  0%|          | 23/24716 [19:36<365:03:02, 53.22s/it]                                                      {'loss': 1.1976, 'grad_norm': 5.979551667362414, 'learning_rate': 3.0997304582210242e-06, 'epoch': 0.0}
  0%|          | 23/24716 [19:36<365:03:02, 53.22s/it]  0%|          | 24/24716 [20:37<382:40:12, 55.79s/it]                                                      {'loss': 1.0592, 'grad_norm': 3.7095720558672225, 'learning_rate': 3.234501347708895e-06, 'epoch': 0.0}
  0%|          | 24/24716 [20:37<382:40:12, 55.79s/it]  0%|          | 25/24716 [21:35<387:13:13, 56.46s/it]                                                      {'loss': 1.2282, 'grad_norm': 4.467028341806351, 'learning_rate': 3.3692722371967654e-06, 'epoch': 0.0}
  0%|          | 25/24716 [21:35<387:13:13, 56.46s/it]  0%|          | 26/24716 [22:29<382:10:10, 55.72s/it]                                                      {'loss': 1.3239, 'grad_norm': 4.290054243283002, 'learning_rate': 3.504043126684636e-06, 'epoch': 0.0}
  0%|          | 26/24716 [22:29<382:10:10, 55.72s/it]  0%|          | 27/24716 [23:32<397:03:41, 57.90s/it]                                                      {'loss': 1.1548, 'grad_norm': 3.92916313234526, 'learning_rate': 3.6388140161725074e-06, 'epoch': 0.0}
  0%|          | 27/24716 [23:32<397:03:41, 57.90s/it]  0%|          | 28/24716 [24:22<380:06:51, 55.43s/it]                                                      {'loss': 1.2456, 'grad_norm': 7.010176671062869, 'learning_rate': 3.7735849056603773e-06, 'epoch': 0.0}
  0%|          | 28/24716 [24:22<380:06:51, 55.43s/it]  0%|          | 29/24716 [25:13<370:24:53, 54.02s/it]                                                      {'loss': 1.3131, 'grad_norm': 4.7666554403737775, 'learning_rate': 3.908355795148248e-06, 'epoch': 0.0}
  0%|          | 29/24716 [25:13<370:24:53, 54.02s/it]  0%|          | 30/24716 [26:10<376:12:26, 54.86s/it]                                                      {'loss': 1.0016, 'grad_norm': 2.735519081650681, 'learning_rate': 4.0431266846361185e-06, 'epoch': 0.0}
  0%|          | 30/24716 [26:10<376:12:26, 54.86s/it]  0%|          | 31/24716 [26:49<345:25:35, 50.38s/it]                                                      {'loss': 1.112, 'grad_norm': 3.462172304388777, 'learning_rate': 4.17789757412399e-06, 'epoch': 0.0}
  0%|          | 31/24716 [26:49<345:25:35, 50.38s/it]  0%|          | 32/24716 [27:33<331:11:07, 48.30s/it]                                                      {'loss': 1.2889, 'grad_norm': 4.121038629834463, 'learning_rate': 4.31266846361186e-06, 'epoch': 0.0}
  0%|          | 32/24716 [27:33<331:11:07, 48.30s/it]  0%|          | 33/24716 [28:26<341:17:40, 49.78s/it]                                                      {'loss': 1.5317, 'grad_norm': 10.638102914092373, 'learning_rate': 4.44743935309973e-06, 'epoch': 0.0}
  0%|          | 33/24716 [28:26<341:17:40, 49.78s/it]  0%|          | 34/24716 [29:16<341:41:51, 49.84s/it]                                                      {'loss': 1.0812, 'grad_norm': 4.255092069906917, 'learning_rate': 4.582210242587602e-06, 'epoch': 0.0}
  0%|          | 34/24716 [29:16<341:41:51, 49.84s/it]  0%|          | 35/24716 [30:10<349:18:17, 50.95s/it]                                                      {'loss': 0.9135, 'grad_norm': 3.2747719578761894, 'learning_rate': 4.716981132075472e-06, 'epoch': 0.0}
  0%|          | 35/24716 [30:10<349:18:17, 50.95s/it]  0%|          | 36/24716 [31:05<358:24:34, 52.28s/it]                                                      {'loss': 0.921, 'grad_norm': 3.806335374777542, 'learning_rate': 4.851752021563342e-06, 'epoch': 0.0}
  0%|          | 36/24716 [31:05<358:24:34, 52.28s/it]  0%|          | 37/24716 [31:52<347:04:39, 50.63s/it]                                                      {'loss': 0.7289, 'grad_norm': 3.291645922509252, 'learning_rate': 4.9865229110512135e-06, 'epoch': 0.0}
  0%|          | 37/24716 [31:52<347:04:39, 50.63s/it]  0%|          | 38/24716 [32:35<331:24:30, 48.35s/it]                                                      {'loss': 0.7466, 'grad_norm': 2.561250672496079, 'learning_rate': 5.121293800539084e-06, 'epoch': 0.0}
  0%|          | 38/24716 [32:35<331:24:30, 48.35s/it]  0%|          | 39/24716 [33:33<352:06:12, 51.37s/it]                                                      {'loss': 0.86, 'grad_norm': 5.951889417548075, 'learning_rate': 5.256064690026954e-06, 'epoch': 0.0}
  0%|          | 39/24716 [33:33<352:06:12, 51.37s/it]  0%|          | 40/24716 [34:15<331:49:01, 48.41s/it]                                                      {'loss': 0.7892, 'grad_norm': 4.01611325550179, 'learning_rate': 5.3908355795148255e-06, 'epoch': 0.0}
  0%|          | 40/24716 [34:15<331:49:01, 48.41s/it]  0%|          | 41/24716 [35:04<332:32:22, 48.52s/it]                                                      {'loss': 0.9376, 'grad_norm': 4.554597108626959, 'learning_rate': 5.525606469002696e-06, 'epoch': 0.0}
  0%|          | 41/24716 [35:04<332:32:22, 48.52s/it]  0%|          | 42/24716 [35:49<325:44:37, 47.53s/it]                                                      {'loss': 0.6763, 'grad_norm': 2.3412842058843157, 'learning_rate': 5.660377358490566e-06, 'epoch': 0.0}
  0%|          | 42/24716 [35:49<325:44:37, 47.53s/it]  0%|          | 43/24716 [36:43<339:46:26, 49.58s/it]                                                      {'loss': 0.4966, 'grad_norm': 2.467492067595195, 'learning_rate': 5.7951482479784366e-06, 'epoch': 0.0}
  0%|          | 43/24716 [36:43<339:46:26, 49.58s/it]  0%|          | 44/24716 [37:20<312:43:40, 45.63s/it]                                                      {'loss': 0.7851, 'grad_norm': 3.968526168737731, 'learning_rate': 5.929919137466308e-06, 'epoch': 0.0}
  0%|          | 44/24716 [37:20<312:43:40, 45.63s/it]  0%|          | 45/24716 [38:03<307:58:46, 44.94s/it]                                                      {'loss': 0.5822, 'grad_norm': 2.7926447353490262, 'learning_rate': 6.064690026954178e-06, 'epoch': 0.0}
  0%|          | 45/24716 [38:03<307:58:46, 44.94s/it]  0%|          | 46/24716 [38:49<310:17:14, 45.28s/it]                                                      {'loss': 0.4804, 'grad_norm': 2.749167801520117, 'learning_rate': 6.1994609164420485e-06, 'epoch': 0.0}
  0%|          | 46/24716 [38:49<310:17:14, 45.28s/it]  0%|          | 47/24716 [39:21<283:52:56, 41.43s/it]                                                      {'loss': 0.4417, 'grad_norm': 1.768846399726953, 'learning_rate': 6.334231805929919e-06, 'epoch': 0.0}
  0%|          | 47/24716 [39:21<283:52:56, 41.43s/it]  0%|          | 48/24716 [40:19<317:04:41, 46.27s/it]                                                      {'loss': 0.4374, 'grad_norm': 1.4317548651067682, 'learning_rate': 6.46900269541779e-06, 'epoch': 0.0}
  0%|          | 48/24716 [40:19<317:04:41, 46.27s/it]  0%|          | 49/24716 [41:02<310:44:17, 45.35s/it]                                                      {'loss': 0.4789, 'grad_norm': 3.170254848396601, 'learning_rate': 6.60377358490566e-06, 'epoch': 0.0}
  0%|          | 49/24716 [41:02<310:44:17, 45.35s/it]  0%|          | 50/24716 [42:09<354:55:34, 51.80s/it]                                                      {'loss': 0.5571, 'grad_norm': 1.970078861799026, 'learning_rate': 6.738544474393531e-06, 'epoch': 0.0}
  0%|          | 50/24716 [42:09<354:55:34, 51.80s/it]  0%|          | 51/24716 [43:03<359:18:18, 52.44s/it]                                                      {'loss': 0.4355, 'grad_norm': 1.641811490340807, 'learning_rate': 6.873315363881402e-06, 'epoch': 0.0}
  0%|          | 51/24716 [43:03<359:18:18, 52.44s/it]  0%|          | 52/24716 [43:50<348:24:55, 50.86s/it]                                                      {'loss': 0.3306, 'grad_norm': 1.2287070362273689, 'learning_rate': 7.008086253369272e-06, 'epoch': 0.0}
  0%|          | 52/24716 [43:50<348:24:55, 50.86s/it]  0%|          | 53/24716 [44:32<329:12:55, 48.05s/it]                                                      {'loss': 0.8045, 'grad_norm': 5.874864311506006, 'learning_rate': 7.142857142857143e-06, 'epoch': 0.0}
  0%|          | 53/24716 [44:32<329:12:55, 48.05s/it]  0%|          | 54/24716 [45:27<343:59:49, 50.21s/it]                                                      {'loss': 0.3504, 'grad_norm': 1.3401989834582504, 'learning_rate': 7.277628032345015e-06, 'epoch': 0.0}
  0%|          | 54/24716 [45:27<343:59:49, 50.21s/it]  0%|          | 55/24716 [46:25<360:58:28, 52.69s/it]                                                      {'loss': 0.4954, 'grad_norm': 1.920710589764337, 'learning_rate': 7.412398921832884e-06, 'epoch': 0.0}
  0%|          | 55/24716 [46:25<360:58:28, 52.69s/it]  0%|          | 56/24716 [47:02<328:26:52, 47.95s/it]                                                      {'loss': 0.3678, 'grad_norm': 1.41298831598371, 'learning_rate': 7.547169811320755e-06, 'epoch': 0.0}
  0%|          | 56/24716 [47:02<328:26:52, 47.95s/it]  0%|          | 57/24716 [47:50<328:14:05, 47.92s/it]                                                      {'loss': 0.4007, 'grad_norm': 3.0678567852755365, 'learning_rate': 7.681940700808626e-06, 'epoch': 0.0}
  0%|          | 57/24716 [47:50<328:14:05, 47.92s/it]  0%|          | 58/24716 [48:45<342:51:05, 50.06s/it]                                                      {'loss': 0.2677, 'grad_norm': 1.6840973139705104, 'learning_rate': 7.816711590296496e-06, 'epoch': 0.0}
  0%|          | 58/24716 [48:45<342:51:05, 50.06s/it]  0%|          | 59/24716 [49:21<314:10:35, 45.87s/it]                                                      {'loss': 0.3852, 'grad_norm': 2.5878747721895228, 'learning_rate': 7.951482479784367e-06, 'epoch': 0.0}
  0%|          | 59/24716 [49:21<314:10:35, 45.87s/it]  0%|          | 60/24716 [50:12<325:04:01, 47.46s/it]                                                      {'loss': 0.3287, 'grad_norm': 1.533117504763498, 'learning_rate': 8.086253369272237e-06, 'epoch': 0.0}
  0%|          | 60/24716 [50:12<325:04:01, 47.46s/it]  0%|          | 61/24716 [51:01<328:01:45, 47.90s/it]                                                      {'loss': 0.4349, 'grad_norm': 1.4681343768648984, 'learning_rate': 8.221024258760109e-06, 'epoch': 0.0}
  0%|          | 61/24716 [51:01<328:01:45, 47.90s/it]  0%|          | 62/24716 [51:59<347:09:12, 50.69s/it]                                                      {'loss': 0.4461, 'grad_norm': 1.6483718085804453, 'learning_rate': 8.35579514824798e-06, 'epoch': 0.0}
  0%|          | 62/24716 [51:59<347:09:12, 50.69s/it]  0%|          | 63/24716 [52:49<345:41:52, 50.48s/it]                                                      {'loss': 0.3365, 'grad_norm': 2.159255261686731, 'learning_rate': 8.49056603773585e-06, 'epoch': 0.0}
  0%|          | 63/24716 [52:49<345:41:52, 50.48s/it]  0%|          | 64/24716 [53:39<345:21:13, 50.43s/it]                                                      {'loss': 0.3725, 'grad_norm': 1.599801915649256, 'learning_rate': 8.62533692722372e-06, 'epoch': 0.0}
  0%|          | 64/24716 [53:39<345:21:13, 50.43s/it]  0%|          | 65/24716 [54:24<334:11:53, 48.81s/it]                                                      {'loss': 0.4726, 'grad_norm': 1.572752860860673, 'learning_rate': 8.76010781671159e-06, 'epoch': 0.0}
  0%|          | 65/24716 [54:24<334:11:53, 48.81s/it]  0%|          | 66/24716 [55:19<346:14:06, 50.57s/it]                                                      {'loss': 0.3989, 'grad_norm': 3.389311758243154, 'learning_rate': 8.89487870619946e-06, 'epoch': 0.0}
  0%|          | 66/24716 [55:19<346:14:06, 50.57s/it]  0%|          | 67/24716 [56:01<329:05:48, 48.06s/it]                                                      {'loss': 0.3995, 'grad_norm': 8.644659257531972, 'learning_rate': 9.029649595687333e-06, 'epoch': 0.0}
  0%|          | 67/24716 [56:01<329:05:48, 48.06s/it]  0%|          | 68/24716 [56:58<348:10:18, 50.85s/it]                                                      {'loss': 0.2712, 'grad_norm': 1.2934244413388607, 'learning_rate': 9.164420485175203e-06, 'epoch': 0.0}
  0%|          | 68/24716 [56:58<348:10:18, 50.85s/it]  0%|          | 69/24716 [57:49<348:44:25, 50.94s/it]                                                      {'loss': 0.2488, 'grad_norm': 1.2754720868496163, 'learning_rate': 9.299191374663074e-06, 'epoch': 0.0}
  0%|          | 69/24716 [57:49<348:44:25, 50.94s/it]  0%|          | 70/24716 [58:47<362:01:09, 52.88s/it]                                                      {'loss': 0.3903, 'grad_norm': 2.2815888534396414, 'learning_rate': 9.433962264150944e-06, 'epoch': 0.0}
  0%|          | 70/24716 [58:47<362:01:09, 52.88s/it]  0%|          | 71/24716 [59:43<368:27:29, 53.82s/it]                                                      {'loss': 0.399, 'grad_norm': 0.9641832036533091, 'learning_rate': 9.568733153638814e-06, 'epoch': 0.0}
  0%|          | 71/24716 [59:43<368:27:29, 53.82s/it]  0%|          | 72/24716 [1:00:32<359:12:06, 52.47s/it]                                                        {'loss': 0.3392, 'grad_norm': 3.64512174873021, 'learning_rate': 9.703504043126685e-06, 'epoch': 0.0}
  0%|          | 72/24716 [1:00:32<359:12:06, 52.47s/it]  0%|          | 73/24716 [1:01:30<371:09:20, 54.22s/it]                                                        {'loss': 0.2973, 'grad_norm': 1.2535590475834564, 'learning_rate': 9.838274932614555e-06, 'epoch': 0.0}
  0%|          | 73/24716 [1:01:30<371:09:20, 54.22s/it]  0%|          | 74/24716 [1:02:29<380:44:19, 55.62s/it]                                                        {'loss': 0.34, 'grad_norm': 1.4617211574165, 'learning_rate': 9.973045822102427e-06, 'epoch': 0.0}
  0%|          | 74/24716 [1:02:29<380:44:19, 55.62s/it]  0%|          | 75/24716 [1:03:20<371:50:04, 54.32s/it]                                                        {'loss': 0.3716, 'grad_norm': 1.2385111026559814, 'learning_rate': 1.0107816711590297e-05, 'epoch': 0.0}
  0%|          | 75/24716 [1:03:20<371:50:04, 54.32s/it]  0%|          | 76/24716 [1:04:18<378:14:11, 55.26s/it]                                                        {'loss': 0.334, 'grad_norm': 1.7482327062700753, 'learning_rate': 1.0242587601078168e-05, 'epoch': 0.0}
  0%|          | 76/24716 [1:04:18<378:14:11, 55.26s/it]  0%|          | 77/24716 [1:05:03<356:32:08, 52.09s/it]                                                        {'loss': 0.278, 'grad_norm': 1.1098860181993944, 'learning_rate': 1.0377358490566038e-05, 'epoch': 0.0}
  0%|          | 77/24716 [1:05:03<356:32:08, 52.09s/it]  0%|          | 78/24716 [1:05:53<352:13:27, 51.47s/it]                                                        {'loss': 0.2692, 'grad_norm': 1.4202058301627085, 'learning_rate': 1.0512129380053909e-05, 'epoch': 0.0}
  0%|          | 78/24716 [1:05:53<352:13:27, 51.47s/it]  0%|          | 79/24716 [1:06:49<362:28:16, 52.96s/it]                                                        {'loss': 0.305, 'grad_norm': 1.7737962087601364, 'learning_rate': 1.0646900269541779e-05, 'epoch': 0.0}
  0%|          | 79/24716 [1:06:49<362:28:16, 52.96s/it]  0%|          | 80/24716 [1:07:46<371:18:54, 54.26s/it]                                                        {'loss': 0.3229, 'grad_norm': 1.0311907029799245, 'learning_rate': 1.0781671159029651e-05, 'epoch': 0.0}
  0%|          | 80/24716 [1:07:46<371:18:54, 54.26s/it]  0%|          | 81/24716 [1:08:34<356:49:13, 52.14s/it]                                                        {'loss': 0.2871, 'grad_norm': 1.2859984394008293, 'learning_rate': 1.0916442048517521e-05, 'epoch': 0.0}
  0%|          | 81/24716 [1:08:34<356:49:13, 52.14s/it]  0%|          | 82/24716 [1:09:28<360:44:30, 52.72s/it]                                                        {'loss': 0.3576, 'grad_norm': 3.0663786095694734, 'learning_rate': 1.1051212938005392e-05, 'epoch': 0.0}
  0%|          | 82/24716 [1:09:28<360:44:30, 52.72s/it]  0%|          | 83/24716 [1:10:18<356:44:53, 52.14s/it]                                                        {'loss': 0.2891, 'grad_norm': 0.8830654926273718, 'learning_rate': 1.1185983827493262e-05, 'epoch': 0.0}
  0%|          | 83/24716 [1:10:18<356:44:53, 52.14s/it]  0%|          | 84/24716 [1:11:05<344:58:35, 50.42s/it]                                                        {'loss': 0.2751, 'grad_norm': 3.5981074981119243, 'learning_rate': 1.1320754716981132e-05, 'epoch': 0.0}
  0%|          | 84/24716 [1:11:05<344:58:35, 50.42s/it]  0%|          | 85/24716 [1:11:50<333:14:19, 48.71s/it]                                                        {'loss': 0.2654, 'grad_norm': 1.5218115598042532, 'learning_rate': 1.1455525606469003e-05, 'epoch': 0.0}
  0%|          | 85/24716 [1:11:50<333:14:19, 48.71s/it]  0%|          | 86/24716 [1:12:39<334:00:54, 48.82s/it]                                                        {'loss': 0.2783, 'grad_norm': 2.3523241125029313, 'learning_rate': 1.1590296495956873e-05, 'epoch': 0.0}
  0%|          | 86/24716 [1:12:39<334:00:54, 48.82s/it]  0%|          | 87/24716 [1:13:42<363:41:51, 53.16s/it]                                                        {'loss': 0.2934, 'grad_norm': 1.813721959859503, 'learning_rate': 1.1725067385444745e-05, 'epoch': 0.0}
  0%|          | 87/24716 [1:13:42<363:41:51, 53.16s/it]  0%|          | 88/24716 [1:14:27<347:58:16, 50.86s/it]                                                        {'loss': 0.2726, 'grad_norm': 1.8401638164829235, 'learning_rate': 1.1859838274932616e-05, 'epoch': 0.0}
  0%|          | 88/24716 [1:14:27<347:58:16, 50.86s/it]  0%|          | 89/24716 [1:15:05<320:34:16, 46.86s/it]                                                        {'loss': 0.3157, 'grad_norm': 4.336184594314384, 'learning_rate': 1.1994609164420486e-05, 'epoch': 0.0}
  0%|          | 89/24716 [1:15:05<320:34:16, 46.86s/it]  0%|          | 90/24716 [1:16:08<353:45:59, 51.72s/it]                                                        {'loss': 0.3052, 'grad_norm': 1.369637235838392, 'learning_rate': 1.2129380053908356e-05, 'epoch': 0.0}
  0%|          | 90/24716 [1:16:08<353:45:59, 51.72s/it]  0%|          | 91/24716 [1:16:52<336:58:42, 49.26s/it]                                                        {'loss': 0.2867, 'grad_norm': 0.8583866949693649, 'learning_rate': 1.2264150943396227e-05, 'epoch': 0.0}
  0%|          | 91/24716 [1:16:52<336:58:42, 49.26s/it]  0%|          | 92/24716 [1:17:37<329:58:15, 48.24s/it]                                                        {'loss': 0.2334, 'grad_norm': 0.6393723600369605, 'learning_rate': 1.2398921832884097e-05, 'epoch': 0.0}
  0%|          | 92/24716 [1:17:37<329:58:15, 48.24s/it]  0%|          | 93/24716 [1:18:15<307:21:45, 44.94s/it]                                                        {'loss': 0.2572, 'grad_norm': 0.8917914646403778, 'learning_rate': 1.2533692722371967e-05, 'epoch': 0.0}
  0%|          | 93/24716 [1:18:15<307:21:45, 44.94s/it]  0%|          | 94/24716 [1:19:00<309:08:16, 45.20s/it]                                                        {'loss': 0.4444, 'grad_norm': 4.157904238735689, 'learning_rate': 1.2668463611859838e-05, 'epoch': 0.0}
  0%|          | 94/24716 [1:19:00<309:08:16, 45.20s/it]  0%|          | 95/24716 [1:19:44<306:01:47, 44.75s/it]                                                        {'loss': 0.3463, 'grad_norm': 1.8055133361708182, 'learning_rate': 1.2803234501347711e-05, 'epoch': 0.0}
  0%|          | 95/24716 [1:19:44<306:01:47, 44.75s/it]  0%|          | 96/24716 [1:20:43<334:43:58, 48.95s/it]                                                        {'loss': 0.2939, 'grad_norm': 0.7844914485435929, 'learning_rate': 1.293800539083558e-05, 'epoch': 0.0}
  0%|          | 96/24716 [1:20:43<334:43:58, 48.95s/it]  0%|          | 97/24716 [1:21:29<329:46:52, 48.22s/it]                                                        {'loss': 0.2984, 'grad_norm': 1.4532233631420761, 'learning_rate': 1.307277628032345e-05, 'epoch': 0.0}
  0%|          | 97/24716 [1:21:29<329:46:52, 48.22s/it]  0%|          | 98/24716 [1:22:16<325:59:14, 47.67s/it]                                                        {'loss': 0.278, 'grad_norm': 2.724742642883496, 'learning_rate': 1.320754716981132e-05, 'epoch': 0.0}
  0%|          | 98/24716 [1:22:16<325:59:14, 47.67s/it]  0%|          | 99/24716 [1:23:17<353:23:15, 51.68s/it]                                                        {'loss': 0.252, 'grad_norm': 2.3486011570054495, 'learning_rate': 1.3342318059299191e-05, 'epoch': 0.0}
  0%|          | 99/24716 [1:23:17<353:23:15, 51.68s/it]  0%|          | 100/24716 [1:24:04<344:58:02, 50.45s/it]                                                         {'loss': 0.3026, 'grad_norm': 0.7005393102683746, 'learning_rate': 1.3477088948787062e-05, 'epoch': 0.0}
  0%|          | 100/24716 [1:24:04<344:58:02, 50.45s/it]  0%|          | 101/24716 [1:25:04<363:14:17, 53.12s/it]                                                         {'loss': 0.3476, 'grad_norm': 1.2647554177301013, 'learning_rate': 1.3611859838274935e-05, 'epoch': 0.0}
  0%|          | 101/24716 [1:25:04<363:14:17, 53.12s/it]  0%|          | 102/24716 [1:26:02<373:00:47, 54.56s/it]                                                         {'loss': 0.3989, 'grad_norm': 1.2302873824060063, 'learning_rate': 1.3746630727762804e-05, 'epoch': 0.0}
  0%|          | 102/24716 [1:26:02<373:00:47, 54.56s/it]  0%|          | 103/24716 [1:26:47<353:46:07, 51.74s/it]                                                         {'loss': 0.3383, 'grad_norm': 1.058640954207278, 'learning_rate': 1.3881401617250674e-05, 'epoch': 0.0}
  0%|          | 103/24716 [1:26:47<353:46:07, 51.74s/it][2025-08-28 21:37:10,174] [WARNING] [stage3.py:1949:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  0%|          | 104/24716 [1:27:43<363:35:43, 53.18s/it]                                                         {'loss': 0.3408, 'grad_norm': 2.1209916368685637, 'learning_rate': 1.4016172506738545e-05, 'epoch': 0.0}
  0%|          | 104/24716 [1:27:43<363:35:43, 53.18s/it]  0%|          | 105/24716 [1:28:26<341:55:00, 50.01s/it]                                                         {'loss': 0.3008, 'grad_norm': 1.2913414969857893, 'learning_rate': 1.4150943396226415e-05, 'epoch': 0.0}
  0%|          | 105/24716 [1:28:26<341:55:00, 50.01s/it]  0%|          | 106/24716 [1:29:18<346:36:38, 50.70s/it]                                                         {'loss': 0.2996, 'grad_norm': 0.8388284645959435, 'learning_rate': 1.4285714285714285e-05, 'epoch': 0.0}
  0%|          | 106/24716 [1:29:18<346:36:38, 50.70s/it]  0%|          | 107/24716 [1:30:03<334:15:28, 48.90s/it]                                                         {'loss': 0.2228, 'grad_norm': 1.5206144337859882, 'learning_rate': 1.4420485175202156e-05, 'epoch': 0.0}
  0%|          | 107/24716 [1:30:03<334:15:28, 48.90s/it]  0%|          | 108/24716 [1:30:51<332:21:11, 48.62s/it]                                                         {'loss': 0.3248, 'grad_norm': 1.9885549556236533, 'learning_rate': 1.455525606469003e-05, 'epoch': 0.0}
  0%|          | 108/24716 [1:30:51<332:21:11, 48.62s/it]  0%|          | 109/24716 [1:31:32<317:01:43, 46.38s/it]                                                         {'loss': 0.3211, 'grad_norm': 1.0760840334206054, 'learning_rate': 1.4690026954177898e-05, 'epoch': 0.0}
  0%|          | 109/24716 [1:31:32<317:01:43, 46.38s/it]  0%|          | 110/24716 [1:32:20<320:04:17, 46.83s/it]                                                         {'loss': 0.322, 'grad_norm': 1.1554843795992262, 'learning_rate': 1.4824797843665769e-05, 'epoch': 0.0}
  0%|          | 110/24716 [1:32:20<320:04:17, 46.83s/it]  0%|          | 111/24716 [1:33:07<321:14:10, 47.00s/it]                                                         {'loss': 0.3139, 'grad_norm': 1.562763355081178, 'learning_rate': 1.4959568733153639e-05, 'epoch': 0.0}
  0%|          | 111/24716 [1:33:07<321:14:10, 47.00s/it]  0%|          | 112/24716 [1:33:57<326:21:20, 47.75s/it]                                                         {'loss': 0.3116, 'grad_norm': 1.3371040242445393, 'learning_rate': 1.509433962264151e-05, 'epoch': 0.0}
  0%|          | 112/24716 [1:33:57<326:21:20, 47.75s/it]  0%|          | 113/24716 [1:34:54<346:17:37, 50.67s/it]                                                         {'loss': 0.3269, 'grad_norm': 1.2703852573977783, 'learning_rate': 1.522911051212938e-05, 'epoch': 0.0}
  0%|          | 113/24716 [1:34:54<346:17:37, 50.67s/it]  0%|          | 114/24716 [1:35:44<343:27:32, 50.26s/it]                                                         {'loss': 0.3368, 'grad_norm': 1.6473826129063613, 'learning_rate': 1.5363881401617252e-05, 'epoch': 0.0}
  0%|          | 114/24716 [1:35:44<343:27:32, 50.26s/it]  0%|          | 115/24716 [1:36:29<333:49:18, 48.85s/it]                                                         {'loss': 0.314, 'grad_norm': 0.8025575917693835, 'learning_rate': 1.5498652291105122e-05, 'epoch': 0.0}
  0%|          | 115/24716 [1:36:29<333:49:18, 48.85s/it]  0%|          | 116/24716 [1:37:26<350:40:33, 51.32s/it]                                                         {'loss': 0.315, 'grad_norm': 1.3308060134674413, 'learning_rate': 1.5633423180592992e-05, 'epoch': 0.0}
  0%|          | 116/24716 [1:37:26<350:40:33, 51.32s/it]  0%|          | 117/24716 [1:38:26<367:47:06, 53.82s/it]                                                         {'loss': 0.3729, 'grad_norm': 0.9851309303990926, 'learning_rate': 1.5768194070080863e-05, 'epoch': 0.0}
  0%|          | 117/24716 [1:38:26<367:47:06, 53.82s/it]  0%|          | 118/24716 [1:39:27<381:55:30, 55.90s/it]                                                         {'loss': 0.3224, 'grad_norm': 1.263615401260271, 'learning_rate': 1.5902964959568733e-05, 'epoch': 0.0}
  0%|          | 118/24716 [1:39:27<381:55:30, 55.90s/it]  0%|          | 119/24716 [1:40:19<374:23:06, 54.79s/it]                                                         {'loss': 0.3116, 'grad_norm': 1.2640522974141788, 'learning_rate': 1.6037735849056604e-05, 'epoch': 0.0}
  0%|          | 119/24716 [1:40:19<374:23:06, 54.79s/it]  0%|          | 120/24716 [1:41:02<350:56:05, 51.36s/it]                                                         {'loss': 0.3739, 'grad_norm': 1.6157432512387855, 'learning_rate': 1.6172506738544474e-05, 'epoch': 0.0}
  0%|          | 120/24716 [1:41:02<350:56:05, 51.36s/it]  0%|          | 121/24716 [1:42:01<366:48:15, 53.69s/it]                                                         {'loss': 0.3023, 'grad_norm': 1.7893904614713343, 'learning_rate': 1.6307277628032348e-05, 'epoch': 0.0}
  0%|          | 121/24716 [1:42:01<366:48:15, 53.69s/it]  0%|          | 122/24716 [1:42:42<340:49:01, 49.89s/it]                                                         {'loss': 0.384, 'grad_norm': 1.567302874453468, 'learning_rate': 1.6442048517520218e-05, 'epoch': 0.0}
  0%|          | 122/24716 [1:42:42<340:49:01, 49.89s/it]  0%|          | 123/24716 [1:43:26<328:08:03, 48.03s/it]                                                         {'loss': 0.3166, 'grad_norm': 1.819268770217635, 'learning_rate': 1.657681940700809e-05, 'epoch': 0.0}
  0%|          | 123/24716 [1:43:26<328:08:03, 48.03s/it]  1%|          | 124/24716 [1:44:18<336:13:48, 49.22s/it]                                                         {'loss': 0.338, 'grad_norm': 1.2310859406843084, 'learning_rate': 1.671159029649596e-05, 'epoch': 0.01}
  1%|          | 124/24716 [1:44:18<336:13:48, 49.22s/it]  1%|          | 125/24716 [1:45:21<363:59:58, 53.29s/it]                                                         {'loss': 0.3365, 'grad_norm': 1.0007946077874794, 'learning_rate': 1.684636118598383e-05, 'epoch': 0.01}
  1%|          | 125/24716 [1:45:21<363:59:58, 53.29s/it]  1%|          | 126/24716 [1:46:03<341:19:14, 49.97s/it]                                                         {'loss': 0.262, 'grad_norm': 0.8653496812245581, 'learning_rate': 1.69811320754717e-05, 'epoch': 0.01}
  1%|          | 126/24716 [1:46:03<341:19:14, 49.97s/it]  1%|          | 127/24716 [1:46:59<353:47:40, 51.80s/it]                                                         {'loss': 0.3496, 'grad_norm': 1.7622610241561203, 'learning_rate': 1.711590296495957e-05, 'epoch': 0.01}
  1%|          | 127/24716 [1:46:59<353:47:40, 51.80s/it]  1%|          | 128/24716 [1:47:55<362:57:34, 53.14s/it]                                                         {'loss': 0.2675, 'grad_norm': 1.1592714511676305, 'learning_rate': 1.725067385444744e-05, 'epoch': 0.01}
  1%|          | 128/24716 [1:47:55<362:57:34, 53.14s/it]  1%|          | 129/24716 [1:48:58<382:45:53, 56.04s/it]                                                         {'loss': 0.2136, 'grad_norm': 0.8568874731349052, 'learning_rate': 1.738544474393531e-05, 'epoch': 0.01}
  1%|          | 129/24716 [1:48:58<382:45:53, 56.04s/it]  1%|          | 130/24716 [1:49:58<390:06:38, 57.12s/it]                                                         {'loss': 0.3008, 'grad_norm': 1.2317858350300257, 'learning_rate': 1.752021563342318e-05, 'epoch': 0.01}
  1%|          | 130/24716 [1:49:58<390:06:38, 57.12s/it]  1%|          | 131/24716 [1:50:43<365:02:39, 53.45s/it]                                                         {'loss': 0.336, 'grad_norm': 0.8709833013893603, 'learning_rate': 1.765498652291105e-05, 'epoch': 0.01}
  1%|          | 131/24716 [1:50:43<365:02:39, 53.45s/it]  1%|          | 132/24716 [1:51:43<378:49:09, 55.47s/it]                                                         {'loss': 0.3334, 'grad_norm': 1.888165387279196, 'learning_rate': 1.778975741239892e-05, 'epoch': 0.01}
  1%|          | 132/24716 [1:51:43<378:49:09, 55.47s/it]  1%|          | 133/24716 [1:52:44<389:40:52, 57.07s/it]                                                         {'loss': 0.2721, 'grad_norm': 0.826508490170429, 'learning_rate': 1.7924528301886792e-05, 'epoch': 0.01}
  1%|          | 133/24716 [1:52:44<389:40:52, 57.07s/it]  1%|          | 134/24716 [1:53:19<345:14:12, 50.56s/it]                                                         {'loss': 0.2771, 'grad_norm': 1.3710137210391933, 'learning_rate': 1.8059299191374666e-05, 'epoch': 0.01}
  1%|          | 134/24716 [1:53:19<345:14:12, 50.56s/it]  1%|          | 135/24716 [1:54:08<342:04:15, 50.10s/it]                                                         {'loss': 0.2544, 'grad_norm': 0.9455955363528005, 'learning_rate': 1.8194070080862536e-05, 'epoch': 0.01}
  1%|          | 135/24716 [1:54:08<342:04:15, 50.10s/it]  1%|          | 136/24716 [1:54:56<337:16:32, 49.40s/it]                                                         {'loss': 0.3137, 'grad_norm': 0.753010672364863, 'learning_rate': 1.8328840970350406e-05, 'epoch': 0.01}
  1%|          | 136/24716 [1:54:56<337:16:32, 49.40s/it]  1%|          | 137/24716 [1:56:01<369:46:54, 54.16s/it]                                                         {'loss': 0.2722, 'grad_norm': 3.636099716332063, 'learning_rate': 1.8463611859838277e-05, 'epoch': 0.01}
  1%|          | 137/24716 [1:56:01<369:46:54, 54.16s/it]  1%|          | 138/24716 [1:56:41<341:08:48, 49.97s/it]                                                         {'loss': 0.3057, 'grad_norm': 0.774734112764647, 'learning_rate': 1.8598382749326147e-05, 'epoch': 0.01}
  1%|          | 138/24716 [1:56:41<341:08:48, 49.97s/it]  1%|          | 139/24716 [1:57:20<318:15:32, 46.62s/it]                                                         {'loss': 0.2789, 'grad_norm': 1.101062440176765, 'learning_rate': 1.8733153638814018e-05, 'epoch': 0.01}
  1%|          | 139/24716 [1:57:20<318:15:32, 46.62s/it]  1%|          | 140/24716 [1:58:08<320:51:33, 47.00s/it]                                                         {'loss': 0.517, 'grad_norm': 6.96221977207509, 'learning_rate': 1.8867924528301888e-05, 'epoch': 0.01}
  1%|          | 140/24716 [1:58:08<320:51:33, 47.00s/it]  1%|          | 141/24716 [1:58:58<326:22:45, 47.81s/it]                                                         {'loss': 0.2599, 'grad_norm': 1.1791628637414477, 'learning_rate': 1.9002695417789758e-05, 'epoch': 0.01}
  1%|          | 141/24716 [1:58:58<326:22:45, 47.81s/it]  1%|          | 142/24716 [1:59:51<337:34:19, 49.45s/it]                                                         {'loss': 0.3137, 'grad_norm': 1.4392100596674515, 'learning_rate': 1.913746630727763e-05, 'epoch': 0.01}
  1%|          | 142/24716 [1:59:51<337:34:19, 49.45s/it]  1%|          | 143/24716 [2:00:37<329:29:09, 48.27s/it]                                                         {'loss': 0.3454, 'grad_norm': 1.8742599353877196, 'learning_rate': 1.92722371967655e-05, 'epoch': 0.01}
  1%|          | 143/24716 [2:00:37<329:29:09, 48.27s/it]  1%|          | 144/24716 [2:01:34<348:35:33, 51.07s/it]                                                         {'loss': 0.2817, 'grad_norm': 1.182340154705171, 'learning_rate': 1.940700808625337e-05, 'epoch': 0.01}
  1%|          | 144/24716 [2:01:34<348:35:33, 51.07s/it]  1%|          | 145/24716 [2:02:28<354:27:45, 51.93s/it]                                                         {'loss': 0.3087, 'grad_norm': 1.2902599836978497, 'learning_rate': 1.954177897574124e-05, 'epoch': 0.01}
  1%|          | 145/24716 [2:02:28<354:27:45, 51.93s/it]  1%|          | 146/24716 [2:03:16<345:29:49, 50.62s/it]                                                         {'loss': 0.2544, 'grad_norm': 0.901309795687106, 'learning_rate': 1.967654986522911e-05, 'epoch': 0.01}
  1%|          | 146/24716 [2:03:16<345:29:49, 50.62s/it]  1%|          | 147/24716 [2:04:04<340:11:10, 49.85s/it]                                                         {'loss': 0.277, 'grad_norm': 1.6281928238417798, 'learning_rate': 1.9811320754716984e-05, 'epoch': 0.01}
  1%|          | 147/24716 [2:04:04<340:11:10, 49.85s/it]  1%|          | 148/24716 [2:04:50<332:28:18, 48.72s/it]                                                         {'loss': 0.2841, 'grad_norm': 2.87747950608255, 'learning_rate': 1.9946091644204854e-05, 'epoch': 0.01}
  1%|          | 148/24716 [2:04:50<332:28:18, 48.72s/it]  1%|          | 149/24716 [2:05:35<324:48:33, 47.60s/it]                                                         {'loss': 0.2786, 'grad_norm': 0.657995615906564, 'learning_rate': 2.0080862533692725e-05, 'epoch': 0.01}
  1%|          | 149/24716 [2:05:35<324:48:33, 47.60s/it]  1%|          | 150/24716 [2:06:20<319:48:46, 46.87s/it]                                                         {'loss': 0.2717, 'grad_norm': 1.110770073083395, 'learning_rate': 2.0215633423180595e-05, 'epoch': 0.01}
  1%|          | 150/24716 [2:06:20<319:48:46, 46.87s/it]  1%|          | 151/24716 [2:06:58<300:56:08, 44.10s/it]                                                         {'loss': 0.3342, 'grad_norm': 0.93724022518934, 'learning_rate': 2.0350404312668465e-05, 'epoch': 0.01}
  1%|          | 151/24716 [2:06:58<300:56:08, 44.10s/it]  1%|          | 152/24716 [2:07:46<310:32:31, 45.51s/it]                                                         {'loss': 0.3021, 'grad_norm': 0.7960519853707861, 'learning_rate': 2.0485175202156336e-05, 'epoch': 0.01}
  1%|          | 152/24716 [2:07:46<310:32:31, 45.51s/it]  1%|          | 153/24716 [2:08:40<326:21:14, 47.83s/it]                                                         {'loss': 0.3613, 'grad_norm': 1.157111541544725, 'learning_rate': 2.0619946091644206e-05, 'epoch': 0.01}
  1%|          | 153/24716 [2:08:40<326:21:14, 47.83s/it]  1%|          | 154/24716 [2:09:27<325:50:13, 47.76s/it]                                                         {'loss': 0.2344, 'grad_norm': 0.9643144722311469, 'learning_rate': 2.0754716981132076e-05, 'epoch': 0.01}
  1%|          | 154/24716 [2:09:27<325:50:13, 47.76s/it]  1%|          | 155/24716 [2:10:19<333:32:27, 48.89s/it]                                                         {'loss': 0.3166, 'grad_norm': 1.45631640506768, 'learning_rate': 2.0889487870619947e-05, 'epoch': 0.01}
  1%|          | 155/24716 [2:10:19<333:32:27, 48.89s/it]  1%|          | 156/24716 [2:11:04<325:34:20, 47.72s/it]                                                         {'loss': 0.3688, 'grad_norm': 1.0751835695581298, 'learning_rate': 2.1024258760107817e-05, 'epoch': 0.01}
  1%|          | 156/24716 [2:11:04<325:34:20, 47.72s/it]  1%|          | 157/24716 [2:12:00<342:24:32, 50.19s/it]                                                         {'loss': 0.2747, 'grad_norm': 0.6783501182014705, 'learning_rate': 2.1159029649595687e-05, 'epoch': 0.01}
  1%|          | 157/24716 [2:12:00<342:24:32, 50.19s/it]  1%|          | 158/24716 [2:12:45<331:37:25, 48.61s/it]                                                         {'loss': 0.2455, 'grad_norm': 1.366525454088805, 'learning_rate': 2.1293800539083558e-05, 'epoch': 0.01}
  1%|          | 158/24716 [2:12:45<331:37:25, 48.61s/it]  1%|          | 159/24716 [2:13:24<312:56:38, 45.88s/it]                                                         {'loss': 0.2718, 'grad_norm': 0.7945048246208665, 'learning_rate': 2.1428571428571428e-05, 'epoch': 0.01}
  1%|          | 159/24716 [2:13:24<312:56:38, 45.88s/it]  1%|          | 160/24716 [2:14:14<321:26:58, 47.13s/it]                                                         {'loss': 0.3061, 'grad_norm': 0.706848724367751, 'learning_rate': 2.1563342318059302e-05, 'epoch': 0.01}
  1%|          | 160/24716 [2:14:14<321:26:58, 47.13s/it]  1%|          | 161/24716 [2:15:21<361:41:02, 53.03s/it]                                                         {'loss': 0.273, 'grad_norm': 0.9814260951292564, 'learning_rate': 2.1698113207547172e-05, 'epoch': 0.01}
  1%|          | 161/24716 [2:15:21<361:41:02, 53.03s/it]  1%|          | 162/24716 [2:16:16<365:26:31, 53.58s/it]                                                         {'loss': 0.2826, 'grad_norm': 0.6103223151015343, 'learning_rate': 2.1832884097035043e-05, 'epoch': 0.01}
  1%|          | 162/24716 [2:16:16<365:26:31, 53.58s/it]  1%|          | 163/24716 [2:17:08<361:44:16, 53.04s/it]                                                         {'loss': 0.3008, 'grad_norm': 0.8007351936471517, 'learning_rate': 2.1967654986522913e-05, 'epoch': 0.01}
  1%|          | 163/24716 [2:17:08<361:44:16, 53.04s/it]  1%|          | 164/24716 [2:17:56<351:59:03, 51.61s/it]                                                         {'loss': 0.2368, 'grad_norm': 0.7637821106648383, 'learning_rate': 2.2102425876010783e-05, 'epoch': 0.01}
  1%|          | 164/24716 [2:17:56<351:59:03, 51.61s/it]  1%|          | 165/24716 [2:19:02<381:40:10, 55.97s/it]                                                         {'loss': 0.2962, 'grad_norm': 0.781482765524858, 'learning_rate': 2.2237196765498654e-05, 'epoch': 0.01}
  1%|          | 165/24716 [2:19:02<381:40:10, 55.97s/it]  1%|          | 166/24716 [2:19:55<375:10:10, 55.01s/it]                                                         {'loss': 0.2452, 'grad_norm': 0.9147943850716566, 'learning_rate': 2.2371967654986524e-05, 'epoch': 0.01}
  1%|          | 166/24716 [2:19:55<375:10:10, 55.01s/it]  1%|          | 167/24716 [2:20:57<389:55:20, 57.18s/it]                                                         {'loss': 0.3339, 'grad_norm': 0.8952399640781658, 'learning_rate': 2.2506738544474394e-05, 'epoch': 0.01}
  1%|          | 167/24716 [2:20:57<389:55:20, 57.18s/it]  1%|          | 168/24716 [2:21:49<379:38:15, 55.67s/it]                                                         {'loss': 0.3062, 'grad_norm': 0.8358855707874223, 'learning_rate': 2.2641509433962265e-05, 'epoch': 0.01}
  1%|          | 168/24716 [2:21:49<379:38:15, 55.67s/it]  1%|          | 169/24716 [2:22:43<375:57:25, 55.14s/it]                                                         {'loss': 0.281, 'grad_norm': 0.9938845581053728, 'learning_rate': 2.2776280323450135e-05, 'epoch': 0.01}
  1%|          | 169/24716 [2:22:43<375:57:25, 55.14s/it]  1%|          | 170/24716 [2:23:41<380:43:23, 55.84s/it]                                                         {'loss': 0.3787, 'grad_norm': 1.524672801272594, 'learning_rate': 2.2911051212938006e-05, 'epoch': 0.01}
  1%|          | 170/24716 [2:23:41<380:43:23, 55.84s/it]  1%|          | 171/24716 [2:24:32<372:36:36, 54.65s/it]                                                         {'loss': 0.2262, 'grad_norm': 0.8589620953166776, 'learning_rate': 2.3045822102425876e-05, 'epoch': 0.01}
  1%|          | 171/24716 [2:24:33<372:36:36, 54.65s/it]  1%|          | 172/24716 [2:25:19<356:38:48, 52.31s/it]                                                         {'loss': 0.2772, 'grad_norm': 1.3089205385564309, 'learning_rate': 2.3180592991913746e-05, 'epoch': 0.01}
  1%|          | 172/24716 [2:25:19<356:38:48, 52.31s/it]  1%|          | 173/24716 [2:26:13<359:44:02, 52.77s/it]                                                         {'loss': 0.2867, 'grad_norm': 0.69526078259299, 'learning_rate': 2.331536388140162e-05, 'epoch': 0.01}
  1%|          | 173/24716 [2:26:13<359:44:02, 52.77s/it]  1%|          | 174/24716 [2:27:02<352:28:13, 51.70s/it]                                                         {'loss': 0.2802, 'grad_norm': 0.7490633573668417, 'learning_rate': 2.345013477088949e-05, 'epoch': 0.01}
  1%|          | 174/24716 [2:27:02<352:28:13, 51.70s/it]  1%|          | 175/24716 [2:27:52<347:42:30, 51.01s/it]                                                         {'loss': 0.292, 'grad_norm': 1.671449996282634, 'learning_rate': 2.358490566037736e-05, 'epoch': 0.01}
  1%|          | 175/24716 [2:27:52<347:42:30, 51.01s/it]  1%|          | 176/24716 [2:28:55<372:10:09, 54.60s/it]                                                         {'loss': 0.2856, 'grad_norm': 1.7645696267376676, 'learning_rate': 2.371967654986523e-05, 'epoch': 0.01}
  1%|          | 176/24716 [2:28:55<372:10:09, 54.60s/it]  1%|          | 177/24716 [2:29:46<364:22:28, 53.46s/it]                                                         {'loss': 0.3037, 'grad_norm': 1.1996422944191987, 'learning_rate': 2.38544474393531e-05, 'epoch': 0.01}
  1%|          | 177/24716 [2:29:46<364:22:28, 53.46s/it]  1%|          | 178/24716 [2:30:26<338:11:42, 49.62s/it]                                                         {'loss': 0.372, 'grad_norm': 1.4689769456484014, 'learning_rate': 2.3989218328840972e-05, 'epoch': 0.01}
  1%|          | 178/24716 [2:30:26<338:11:42, 49.62s/it]  1%|          | 179/24716 [2:31:25<356:38:03, 52.32s/it]                                                         {'loss': 0.3331, 'grad_norm': 1.03878215768627, 'learning_rate': 2.4123989218328842e-05, 'epoch': 0.01}
  1%|          | 179/24716 [2:31:25<356:38:03, 52.32s/it]  1%|          | 180/24716 [2:32:14<349:22:01, 51.26s/it]                                                         {'loss': 0.2808, 'grad_norm': 1.2108362349173885, 'learning_rate': 2.4258760107816713e-05, 'epoch': 0.01}
  1%|          | 180/24716 [2:32:14<349:22:01, 51.26s/it]  1%|          | 181/24716 [2:33:03<346:03:21, 50.78s/it]                                                         {'loss': 0.3017, 'grad_norm': 0.8924151287446371, 'learning_rate': 2.4393530997304583e-05, 'epoch': 0.01}
  1%|          | 181/24716 [2:33:03<346:03:21, 50.78s/it]  1%|          | 182/24716 [2:34:02<362:57:57, 53.26s/it]                                                         {'loss': 0.2748, 'grad_norm': 0.95876851422061, 'learning_rate': 2.4528301886792453e-05, 'epoch': 0.01}
  1%|          | 182/24716 [2:34:02<362:57:57, 53.26s/it]  1%|          | 183/24716 [2:34:50<350:53:30, 51.49s/it]                                                         {'loss': 0.3281, 'grad_norm': 0.876143277033237, 'learning_rate': 2.4663072776280324e-05, 'epoch': 0.01}
  1%|          | 183/24716 [2:34:50<350:53:30, 51.49s/it]  1%|          | 184/24716 [2:35:47<363:20:27, 53.32s/it]                                                         {'loss': 0.2937, 'grad_norm': 0.9758513101794999, 'learning_rate': 2.4797843665768194e-05, 'epoch': 0.01}
  1%|          | 184/24716 [2:35:47<363:20:27, 53.32s/it]  1%|          | 185/24716 [2:36:41<364:20:46, 53.47s/it]                                                         {'loss': 0.2872, 'grad_norm': 0.9764660351372084, 'learning_rate': 2.4932614555256064e-05, 'epoch': 0.01}
  1%|          | 185/24716 [2:36:41<364:20:46, 53.47s/it]  1%|          | 186/24716 [2:37:22<338:58:46, 49.75s/it]                                                         {'loss': 0.2872, 'grad_norm': 0.8480278324491132, 'learning_rate': 2.5067385444743935e-05, 'epoch': 0.01}
  1%|          | 186/24716 [2:37:22<338:58:46, 49.75s/it]  1%|          | 187/24716 [2:38:15<345:12:43, 50.67s/it]                                                         {'loss': 0.2788, 'grad_norm': 2.493410497173669, 'learning_rate': 2.520215633423181e-05, 'epoch': 0.01}
  1%|          | 187/24716 [2:38:15<345:12:43, 50.67s/it]  1%|          | 188/24716 [2:39:09<352:17:02, 51.71s/it]                                                         {'loss': 0.2887, 'grad_norm': 1.080446357592183, 'learning_rate': 2.5336927223719675e-05, 'epoch': 0.01}
  1%|          | 188/24716 [2:39:09<352:17:02, 51.71s/it]  1%|          | 189/24716 [2:39:49<328:35:38, 48.23s/it]                                                         {'loss': 0.3133, 'grad_norm': 1.3328406673712405, 'learning_rate': 2.547169811320755e-05, 'epoch': 0.01}
  1%|          | 189/24716 [2:39:49<328:35:38, 48.23s/it]  1%|          | 190/24716 [2:40:43<339:53:52, 49.89s/it]                                                         {'loss': 0.2215, 'grad_norm': 0.8313248865737067, 'learning_rate': 2.5606469002695423e-05, 'epoch': 0.01}
  1%|          | 190/24716 [2:40:43<339:53:52, 49.89s/it]  1%|          | 191/24716 [2:41:37<348:27:27, 51.15s/it]                                                         {'loss': 0.2594, 'grad_norm': 1.118312886162645, 'learning_rate': 2.574123989218329e-05, 'epoch': 0.01}
  1%|          | 191/24716 [2:41:37<348:27:27, 51.15s/it]  1%|          | 192/24716 [2:42:26<342:56:11, 50.34s/it]                                                         {'loss': 0.331, 'grad_norm': 2.180432307769288, 'learning_rate': 2.587601078167116e-05, 'epoch': 0.01}
  1%|          | 192/24716 [2:42:26<342:56:11, 50.34s/it]  1%|          | 193/24716 [2:43:22<356:18:53, 52.31s/it]                                                         {'loss': 0.2805, 'grad_norm': 2.3882445745755625, 'learning_rate': 2.601078167115903e-05, 'epoch': 0.01}
  1%|          | 193/24716 [2:43:22<356:18:53, 52.31s/it]  1%|          | 194/24716 [2:44:07<340:39:52, 50.01s/it]                                                         {'loss': 0.2961, 'grad_norm': 0.9175266071950815, 'learning_rate': 2.61455525606469e-05, 'epoch': 0.01}
  1%|          | 194/24716 [2:44:07<340:39:52, 50.01s/it]  1%|          | 195/24716 [2:45:01<349:13:55, 51.27s/it]                                                         {'loss': 0.2558, 'grad_norm': 1.2448999063289117, 'learning_rate': 2.6280323450134768e-05, 'epoch': 0.01}
  1%|          | 195/24716 [2:45:01<349:13:55, 51.27s/it]  1%|          | 196/24716 [2:45:50<344:13:53, 50.54s/it]                                                         {'loss': 0.2503, 'grad_norm': 0.8639171181062401, 'learning_rate': 2.641509433962264e-05, 'epoch': 0.01}
  1%|          | 196/24716 [2:45:50<344:13:53, 50.54s/it]  1%|          | 197/24716 [2:46:50<363:24:55, 53.36s/it]                                                         {'loss': 0.2764, 'grad_norm': 1.4487671852489437, 'learning_rate': 2.6549865229110515e-05, 'epoch': 0.01}
  1%|          | 197/24716 [2:46:50<363:24:55, 53.36s/it]  1%|          | 198/24716 [2:47:34<345:10:25, 50.68s/it]                                                         {'loss': 0.29, 'grad_norm': 0.8762583841963806, 'learning_rate': 2.6684636118598382e-05, 'epoch': 0.01}
  1%|          | 198/24716 [2:47:35<345:10:25, 50.68s/it]  1%|          | 199/24716 [2:48:21<335:46:57, 49.31s/it]                                                         {'loss': 0.2353, 'grad_norm': 0.679983709049691, 'learning_rate': 2.6819407008086256e-05, 'epoch': 0.01}
  1%|          | 199/24716 [2:48:21<335:46:57, 49.31s/it]  1%|          | 200/24716 [2:49:03<321:58:38, 47.28s/it]                                                         {'loss': 0.2386, 'grad_norm': 1.1184240595882544, 'learning_rate': 2.6954177897574123e-05, 'epoch': 0.01}
  1%|          | 200/24716 [2:49:03<321:58:38, 47.28s/it]  1%|          | 201/24716 [2:49:58<337:10:39, 49.51s/it]                                                         {'loss': 0.361, 'grad_norm': 1.0694843139023997, 'learning_rate': 2.7088948787061997e-05, 'epoch': 0.01}
  1%|          | 201/24716 [2:49:58<337:10:39, 49.51s/it]  1%|          | 202/24716 [2:50:47<336:32:07, 49.42s/it]                                                         {'loss': 0.3639, 'grad_norm': 6.752976460839685, 'learning_rate': 2.722371967654987e-05, 'epoch': 0.01}
  1%|          | 202/24716 [2:50:47<336:32:07, 49.42s/it]  1%|          | 203/24716 [2:51:36<335:53:01, 49.33s/it]                                                         {'loss': 0.3218, 'grad_norm': 0.8014305696430722, 'learning_rate': 2.7358490566037738e-05, 'epoch': 0.01}
  1%|          | 203/24716 [2:51:36<335:53:01, 49.33s/it]  1%|          | 204/24716 [2:52:36<358:06:30, 52.59s/it]                                                         {'loss': 0.2391, 'grad_norm': 1.5042060619625595, 'learning_rate': 2.7493261455525608e-05, 'epoch': 0.01}
  1%|          | 204/24716 [2:52:36<358:06:30, 52.59s/it]  1%|          | 205/24716 [2:53:26<352:32:10, 51.78s/it]                                                         {'loss': 0.2832, 'grad_norm': 0.7894769113909578, 'learning_rate': 2.762803234501348e-05, 'epoch': 0.01}
  1%|          | 205/24716 [2:53:26<352:32:10, 51.78s/it]  1%|          | 206/24716 [2:54:15<346:38:07, 50.91s/it]                                                         {'loss': 0.2558, 'grad_norm': 0.9680472827453063, 'learning_rate': 2.776280323450135e-05, 'epoch': 0.01}
  1%|          | 206/24716 [2:54:15<346:38:07, 50.91s/it]  1%|          | 207/24716 [2:55:20<375:56:30, 55.22s/it]                                                         {'loss': 0.2756, 'grad_norm': 0.7653512627732766, 'learning_rate': 2.789757412398922e-05, 'epoch': 0.01}
  1%|          | 207/24716 [2:55:20<375:56:30, 55.22s/it]  1%|          | 208/24716 [2:56:09<361:34:03, 53.11s/it]                                                         {'loss': 0.2874, 'grad_norm': 0.9003147321357282, 'learning_rate': 2.803234501347709e-05, 'epoch': 0.01}
  1%|          | 208/24716 [2:56:09<361:34:03, 53.11s/it]  1%|          | 209/24716 [2:57:07<371:49:01, 54.62s/it]                                                         {'loss': 0.2934, 'grad_norm': 2.1177307081775796, 'learning_rate': 2.8167115902964963e-05, 'epoch': 0.01}
  1%|          | 209/24716 [2:57:07<371:49:01, 54.62s/it]  1%|          | 210/24716 [2:58:01<371:27:57, 54.57s/it]                                                         {'loss': 0.3274, 'grad_norm': 1.6317524820539864, 'learning_rate': 2.830188679245283e-05, 'epoch': 0.01}
  1%|          | 210/24716 [2:58:01<371:27:57, 54.57s/it]  1%|          | 211/24716 [2:59:03<385:21:52, 56.61s/it]                                                         {'loss': 0.2479, 'grad_norm': 0.8667654401921107, 'learning_rate': 2.8436657681940704e-05, 'epoch': 0.01}
  1%|          | 211/24716 [2:59:03<385:21:52, 56.61s/it]  1%|          | 212/24716 [2:59:56<378:50:15, 55.66s/it]                                                         {'loss': 0.2492, 'grad_norm': 0.7568540572176501, 'learning_rate': 2.857142857142857e-05, 'epoch': 0.01}
  1%|          | 212/24716 [2:59:56<378:50:15, 55.66s/it]  1%|          | 213/24716 [3:00:41<357:22:56, 52.51s/it]                                                         {'loss': 0.2779, 'grad_norm': 0.7773451747966964, 'learning_rate': 2.8706199460916445e-05, 'epoch': 0.01}
  1%|          | 213/24716 [3:00:41<357:22:56, 52.51s/it]  1%|          | 214/24716 [3:01:39<367:33:42, 54.00s/it]                                                         {'loss': 0.3172, 'grad_norm': 1.1973063002575848, 'learning_rate': 2.884097035040431e-05, 'epoch': 0.01}
  1%|          | 214/24716 [3:01:39<367:33:42, 54.00s/it]  1%|          | 215/24716 [3:02:23<348:29:20, 51.20s/it]                                                         {'loss': 0.2745, 'grad_norm': 1.9299305275217882, 'learning_rate': 2.8975741239892185e-05, 'epoch': 0.01}
  1%|          | 215/24716 [3:02:23<348:29:20, 51.20s/it]  1%|          | 216/24716 [3:03:13<346:11:37, 50.87s/it]                                                         {'loss': 0.2654, 'grad_norm': 0.9298873542462976, 'learning_rate': 2.911051212938006e-05, 'epoch': 0.01}
  1%|          | 216/24716 [3:03:13<346:11:37, 50.87s/it]  1%|          | 217/24716 [3:04:09<355:03:24, 52.17s/it]                                                         {'loss': 0.2717, 'grad_norm': 0.8773770148265023, 'learning_rate': 2.9245283018867926e-05, 'epoch': 0.01}
  1%|          | 217/24716 [3:04:09<355:03:24, 52.17s/it]  1%|          | 218/24716 [3:05:11<374:59:48, 55.11s/it]                                                         {'loss': 0.2707, 'grad_norm': 0.8589541438070604, 'learning_rate': 2.9380053908355796e-05, 'epoch': 0.01}
  1%|          | 218/24716 [3:05:11<374:59:48, 55.11s/it]  1%|          | 219/24716 [3:06:14<392:41:37, 57.71s/it]                                                         {'loss': 0.2988, 'grad_norm': 1.0311192655831474, 'learning_rate': 2.9514824797843667e-05, 'epoch': 0.01}
  1%|          | 219/24716 [3:06:14<392:41:37, 57.71s/it]  1%|          | 220/24716 [3:07:04<375:10:10, 55.14s/it]                                                         {'loss': 0.2948, 'grad_norm': 0.9699439696498797, 'learning_rate': 2.9649595687331537e-05, 'epoch': 0.01}
  1%|          | 220/24716 [3:07:04<375:10:10, 55.14s/it]  1%|          | 221/24716 [3:08:05<387:54:40, 57.01s/it]                                                         {'loss': 0.2851, 'grad_norm': 1.665283213407015, 'learning_rate': 2.9784366576819404e-05, 'epoch': 0.01}
  1%|          | 221/24716 [3:08:05<387:54:40, 57.01s/it]  1%|          | 222/24716 [3:08:50<364:03:36, 53.51s/it]                                                         {'loss': 0.2596, 'grad_norm': 0.7698282165231457, 'learning_rate': 2.9919137466307278e-05, 'epoch': 0.01}
  1%|          | 222/24716 [3:08:50<364:03:36, 53.51s/it]  1%|          | 223/24716 [3:09:49<374:28:48, 55.04s/it]                                                         {'loss': 0.26, 'grad_norm': 1.3133698032464969, 'learning_rate': 3.005390835579515e-05, 'epoch': 0.01}
  1%|          | 223/24716 [3:09:49<374:28:48, 55.04s/it]  1%|          | 224/24716 [3:10:40<366:58:18, 53.94s/it]                                                         {'loss': 0.267, 'grad_norm': 0.6916056901990829, 'learning_rate': 3.018867924528302e-05, 'epoch': 0.01}
  1%|          | 224/24716 [3:10:40<366:58:18, 53.94s/it]  1%|          | 225/24716 [3:11:30<359:01:03, 52.77s/it]                                                         {'loss': 0.2392, 'grad_norm': 0.6099662748356283, 'learning_rate': 3.0323450134770892e-05, 'epoch': 0.01}
  1%|          | 225/24716 [3:11:30<359:01:03, 52.77s/it]  1%|          | 226/24716 [3:12:13<338:42:47, 49.79s/it]                                                         {'loss': 0.2587, 'grad_norm': 3.261767175374472, 'learning_rate': 3.045822102425876e-05, 'epoch': 0.01}
  1%|          | 226/24716 [3:12:13<338:42:47, 49.79s/it]  1%|          | 227/24716 [3:13:08<348:06:29, 51.17s/it]                                                         {'loss': 0.3489, 'grad_norm': 4.954010655329442, 'learning_rate': 3.059299191374663e-05, 'epoch': 0.01}
  1%|          | 227/24716 [3:13:08<348:06:29, 51.17s/it]  1%|          | 228/24716 [3:14:01<353:12:29, 51.93s/it]                                                         {'loss': 0.2907, 'grad_norm': 1.0169054675651603, 'learning_rate': 3.0727762803234503e-05, 'epoch': 0.01}
  1%|          | 228/24716 [3:14:01<353:12:29, 51.93s/it]  1%|          | 229/24716 [3:14:41<328:17:26, 48.26s/it]                                                         {'loss': 0.2799, 'grad_norm': 1.0650820774532084, 'learning_rate': 3.086253369272237e-05, 'epoch': 0.01}
  1%|          | 229/24716 [3:14:41<328:17:26, 48.26s/it]  1%|          | 230/24716 [3:15:41<352:58:41, 51.90s/it]                                                         {'loss': 0.3305, 'grad_norm': 2.8953466067227915, 'learning_rate': 3.0997304582210244e-05, 'epoch': 0.01}
  1%|          | 230/24716 [3:15:41<352:58:41, 51.90s/it]  1%|          | 231/24716 [3:16:24<333:50:13, 49.08s/it]                                                         {'loss': 0.2648, 'grad_norm': 0.8351890865971187, 'learning_rate': 3.113207547169811e-05, 'epoch': 0.01}
  1%|          | 231/24716 [3:16:24<333:50:13, 49.08s/it]  1%|          | 232/24716 [3:17:13<333:02:38, 48.97s/it]                                                         {'loss': 0.3589, 'grad_norm': 0.7038812116133447, 'learning_rate': 3.1266846361185985e-05, 'epoch': 0.01}
  1%|          | 232/24716 [3:17:13<333:02:38, 48.97s/it]  1%|          | 233/24716 [3:18:06<342:05:49, 50.30s/it]                                                         {'loss': 0.2828, 'grad_norm': 1.9785600372318528, 'learning_rate': 3.140161725067385e-05, 'epoch': 0.01}
  1%|          | 233/24716 [3:18:06<342:05:49, 50.30s/it]  1%|          | 234/24716 [3:19:00<349:44:20, 51.43s/it]                                                         {'loss': 0.2929, 'grad_norm': 1.1599536543592044, 'learning_rate': 3.1536388140161726e-05, 'epoch': 0.01}
  1%|          | 234/24716 [3:19:00<349:44:20, 51.43s/it]  1%|          | 235/24716 [3:20:06<379:03:54, 55.74s/it]                                                         {'loss': 0.4161, 'grad_norm': 1.2575976207852053, 'learning_rate': 3.16711590296496e-05, 'epoch': 0.01}
  1%|          | 235/24716 [3:20:06<379:03:54, 55.74s/it]  1%|          | 236/24716 [3:20:55<365:09:21, 53.70s/it]                                                         {'loss': 0.2929, 'grad_norm': 1.4182087120078684, 'learning_rate': 3.1805929919137466e-05, 'epoch': 0.01}
  1%|          | 236/24716 [3:20:55<365:09:21, 53.70s/it]  1%|          | 237/24716 [3:21:54<375:40:33, 55.25s/it]                                                         {'loss': 0.3568, 'grad_norm': 0.8345226443425833, 'learning_rate': 3.194070080862534e-05, 'epoch': 0.01}
  1%|          | 237/24716 [3:21:54<375:40:33, 55.25s/it]  1%|          | 238/24716 [3:22:47<371:14:43, 54.60s/it]                                                         {'loss': 0.2991, 'grad_norm': 0.5984418802018983, 'learning_rate': 3.207547169811321e-05, 'epoch': 0.01}
  1%|          | 238/24716 [3:22:47<371:14:43, 54.60s/it]  1%|          | 239/24716 [3:23:42<372:00:49, 54.71s/it]                                                         {'loss': 0.2847, 'grad_norm': 1.3120689164631665, 'learning_rate': 3.221024258760108e-05, 'epoch': 0.01}
  1%|          | 239/24716 [3:23:42<372:00:49, 54.71s/it]  1%|          | 240/24716 [3:24:43<384:34:01, 56.56s/it]                                                         {'loss': 0.3366, 'grad_norm': 1.6722010332213169, 'learning_rate': 3.234501347708895e-05, 'epoch': 0.01}
  1%|          | 240/24716 [3:24:43<384:34:01, 56.56s/it]  1%|          | 241/24716 [3:25:32<369:07:03, 54.29s/it]                                                         {'loss': 0.2641, 'grad_norm': 1.1072706431446386, 'learning_rate': 3.247978436657682e-05, 'epoch': 0.01}
  1%|          | 241/24716 [3:25:32<369:07:03, 54.29s/it]  1%|          | 242/24716 [3:26:30<376:38:47, 55.40s/it]                                                         {'loss': 0.2675, 'grad_norm': 0.9125034593527788, 'learning_rate': 3.2614555256064695e-05, 'epoch': 0.01}
  1%|          | 242/24716 [3:26:30<376:38:47, 55.40s/it]  1%|          | 243/24716 [3:27:21<367:45:02, 54.10s/it]                                                         {'loss': 0.2493, 'grad_norm': 0.6453261778141924, 'learning_rate': 3.274932614555256e-05, 'epoch': 0.01}
  1%|          | 243/24716 [3:27:21<367:45:02, 54.10s/it]  1%|          | 244/24716 [3:28:15<369:09:36, 54.31s/it]                                                         {'loss': 0.2661, 'grad_norm': 1.0213448453132066, 'learning_rate': 3.2884097035040436e-05, 'epoch': 0.01}
  1%|          | 244/24716 [3:28:15<369:09:36, 54.31s/it]  1%|          | 245/24716 [3:29:02<354:00:28, 52.08s/it]                                                         {'loss': 0.316, 'grad_norm': 1.257845624395064, 'learning_rate': 3.30188679245283e-05, 'epoch': 0.01}
  1%|          | 245/24716 [3:29:02<354:00:28, 52.08s/it]  1%|          | 246/24716 [3:29:50<346:00:01, 50.90s/it]                                                         {'loss': 0.2699, 'grad_norm': 1.2843455950507556, 'learning_rate': 3.315363881401618e-05, 'epoch': 0.01}
  1%|          | 246/24716 [3:29:50<346:00:01, 50.90s/it]  1%|          | 247/24716 [3:30:43<350:24:46, 51.55s/it]                                                         {'loss': 0.2602, 'grad_norm': 1.2645827179428843, 'learning_rate': 3.3288409703504044e-05, 'epoch': 0.01}
  1%|          | 247/24716 [3:30:43<350:24:46, 51.55s/it]  1%|          | 248/24716 [3:31:27<334:34:51, 49.23s/it]                                                         {'loss': 0.2671, 'grad_norm': 0.8817861264613385, 'learning_rate': 3.342318059299192e-05, 'epoch': 0.01}
  1%|          | 248/24716 [3:31:27<334:34:51, 49.23s/it]  1%|          | 249/24716 [3:32:13<327:10:24, 48.14s/it]                                                         {'loss': 0.331, 'grad_norm': 1.0307114234167265, 'learning_rate': 3.355795148247979e-05, 'epoch': 0.01}
  1%|          | 249/24716 [3:32:13<327:10:24, 48.14s/it]  1%|          | 250/24716 [3:33:04<332:50:41, 48.98s/it]                                                         {'loss': 0.3018, 'grad_norm': 0.9438001605756746, 'learning_rate': 3.369272237196766e-05, 'epoch': 0.01}
  1%|          | 250/24716 [3:33:04<332:50:41, 48.98s/it]  1%|          | 251/24716 [3:33:51<330:13:41, 48.59s/it]                                                         {'loss': 0.2787, 'grad_norm': 1.452663260787468, 'learning_rate': 3.3827493261455525e-05, 'epoch': 0.01}
  1%|          | 251/24716 [3:33:52<330:13:41, 48.59s/it]  1%|          | 252/24716 [3:34:41<331:26:24, 48.77s/it]                                                         {'loss': 0.3722, 'grad_norm': 4.104872737479778, 'learning_rate': 3.39622641509434e-05, 'epoch': 0.01}
  1%|          | 252/24716 [3:34:41<331:26:24, 48.77s/it]  1%|          | 253/24716 [3:35:26<324:14:29, 47.72s/it]                                                         {'loss': 0.2905, 'grad_norm': 1.0025170341192007, 'learning_rate': 3.4097035040431266e-05, 'epoch': 0.01}
  1%|          | 253/24716 [3:35:26<324:14:29, 47.72s/it]  1%|          | 254/24716 [3:36:16<328:26:34, 48.34s/it]                                                         {'loss': 0.3368, 'grad_norm': 2.2209658875948586, 'learning_rate': 3.423180592991914e-05, 'epoch': 0.01}
  1%|          | 254/24716 [3:36:16<328:26:34, 48.34s/it]  1%|          | 255/24716 [3:37:01<322:13:12, 47.42s/it]                                                         {'loss': 0.2227, 'grad_norm': 0.6141518530700006, 'learning_rate': 3.4366576819407007e-05, 'epoch': 0.01}
  1%|          | 255/24716 [3:37:01<322:13:12, 47.42s/it]  1%|          | 256/24716 [3:37:53<331:22:25, 48.77s/it]                                                         {'loss': 0.3052, 'grad_norm': 0.864526962899391, 'learning_rate': 3.450134770889488e-05, 'epoch': 0.01}
  1%|          | 256/24716 [3:37:53<331:22:25, 48.77s/it]  1%|          | 257/24716 [3:38:43<333:03:39, 49.02s/it]                                                         {'loss': 0.2393, 'grad_norm': 0.6621661584763934, 'learning_rate': 3.463611859838275e-05, 'epoch': 0.01}
  1%|          | 257/24716 [3:38:43<333:03:39, 49.02s/it]  1%|          | 258/24716 [3:39:30<329:29:33, 48.50s/it]                                                         {'loss': 0.2778, 'grad_norm': 8.803465028481698, 'learning_rate': 3.477088948787062e-05, 'epoch': 0.01}
  1%|          | 258/24716 [3:39:30<329:29:33, 48.50s/it]  1%|          | 259/24716 [3:40:17<327:18:24, 48.18s/it]                                                         {'loss': 0.2931, 'grad_norm': 0.7368393160606277, 'learning_rate': 3.490566037735849e-05, 'epoch': 0.01}
  1%|          | 259/24716 [3:40:17<327:18:24, 48.18s/it]  1%|          | 260/24716 [3:41:02<319:48:23, 47.08s/it]                                                         {'loss': 0.2715, 'grad_norm': 0.8827842325476472, 'learning_rate': 3.504043126684636e-05, 'epoch': 0.01}
  1%|          | 260/24716 [3:41:02<319:48:23, 47.08s/it]  1%|          | 261/24716 [3:41:57<336:16:52, 49.50s/it]                                                         {'loss': 0.3165, 'grad_norm': 1.1973412882119272, 'learning_rate': 3.5175202156334236e-05, 'epoch': 0.01}
  1%|          | 261/24716 [3:41:57<336:16:52, 49.50s/it]  1%|          | 262/24716 [3:42:45<332:35:51, 48.96s/it]                                                         {'loss': 0.3845, 'grad_norm': 1.27530126864572, 'learning_rate': 3.53099730458221e-05, 'epoch': 0.01}
  1%|          | 262/24716 [3:42:45<332:35:51, 48.96s/it]  1%|          | 263/24716 [3:43:40<345:56:20, 50.93s/it]                                                         {'loss': 0.3179, 'grad_norm': 0.9995573318603105, 'learning_rate': 3.5444743935309976e-05, 'epoch': 0.01}
  1%|          | 263/24716 [3:43:40<345:56:20, 50.93s/it]  1%|          | 264/24716 [3:44:25<332:34:04, 48.96s/it]                                                         {'loss': 0.2733, 'grad_norm': 0.6066712347307646, 'learning_rate': 3.557951482479784e-05, 'epoch': 0.01}
  1%|          | 264/24716 [3:44:25<332:34:04, 48.96s/it]  1%|          | 265/24716 [3:45:06<316:22:24, 46.58s/it]                                                         {'loss': 0.3043, 'grad_norm': 1.7395691958167985, 'learning_rate': 3.571428571428572e-05, 'epoch': 0.01}
  1%|          | 265/24716 [3:45:06<316:22:24, 46.58s/it]  1%|          | 266/24716 [3:46:09<350:10:58, 51.56s/it]                                                         {'loss': 0.2902, 'grad_norm': 1.2581430207800204, 'learning_rate': 3.5849056603773584e-05, 'epoch': 0.01}
  1%|          | 266/24716 [3:46:09<350:10:58, 51.56s/it]  1%|          | 267/24716 [3:47:08<365:22:01, 53.80s/it]                                                         {'loss': 0.2928, 'grad_norm': 1.0564993685937163, 'learning_rate': 3.598382749326146e-05, 'epoch': 0.01}
  1%|          | 267/24716 [3:47:08<365:22:01, 53.80s/it]  1%|          | 268/24716 [3:48:05<371:36:13, 54.72s/it]                                                         {'loss': 0.2572, 'grad_norm': 1.7945083917329814, 'learning_rate': 3.611859838274933e-05, 'epoch': 0.01}
  1%|          | 268/24716 [3:48:05<371:36:13, 54.72s/it]  1%|          | 269/24716 [3:49:04<381:46:10, 56.22s/it]                                                         {'loss': 0.3059, 'grad_norm': 2.440954664705247, 'learning_rate': 3.62533692722372e-05, 'epoch': 0.01}
  1%|          | 269/24716 [3:49:04<381:46:10, 56.22s/it]  1%|          | 270/24716 [3:49:51<361:37:07, 53.25s/it]                                                         {'loss': 0.246, 'grad_norm': 0.6288553592459842, 'learning_rate': 3.638814016172507e-05, 'epoch': 0.01}
  1%|          | 270/24716 [3:49:51<361:37:07, 53.25s/it]  1%|          | 271/24716 [3:50:45<364:17:08, 53.65s/it]                                                         {'loss': 0.2416, 'grad_norm': 0.6128608817941491, 'learning_rate': 3.652291105121294e-05, 'epoch': 0.01}
  1%|          | 271/24716 [3:50:45<364:17:08, 53.65s/it]  1%|          | 272/24716 [3:51:31<348:12:36, 51.28s/it]                                                         {'loss': 0.275, 'grad_norm': 1.0164650280722642, 'learning_rate': 3.665768194070081e-05, 'epoch': 0.01}
  1%|          | 272/24716 [3:51:31<348:12:36, 51.28s/it]  1%|          | 273/24716 [3:52:16<335:16:29, 49.38s/it]                                                         {'loss': 0.3227, 'grad_norm': 2.5978977283822435, 'learning_rate': 3.679245283018868e-05, 'epoch': 0.01}
  1%|          | 273/24716 [3:52:16<335:16:29, 49.38s/it]  1%|          | 274/24716 [3:53:06<336:34:57, 49.57s/it]                                                         {'loss': 0.264, 'grad_norm': 1.0673804005401883, 'learning_rate': 3.6927223719676554e-05, 'epoch': 0.01}
  1%|          | 274/24716 [3:53:06<336:34:57, 49.57s/it]  1%|          | 275/24716 [3:54:00<346:06:47, 50.98s/it]                                                         {'loss': 0.3354, 'grad_norm': 1.560389400765851, 'learning_rate': 3.706199460916443e-05, 'epoch': 0.01}
  1%|          | 275/24716 [3:54:00<346:06:47, 50.98s/it]  1%|          | 276/24716 [3:54:50<342:50:54, 50.50s/it]                                                         {'loss': 0.2966, 'grad_norm': 0.922797738149796, 'learning_rate': 3.7196765498652294e-05, 'epoch': 0.01}
  1%|          | 276/24716 [3:54:50<342:50:54, 50.50s/it]  1%|          | 277/24716 [3:55:30<322:02:48, 47.44s/it]                                                         {'loss': 0.2865, 'grad_norm': 1.3420899343421826, 'learning_rate': 3.733153638814017e-05, 'epoch': 0.01}
  1%|          | 277/24716 [3:55:30<322:02:48, 47.44s/it]  1%|          | 278/24716 [3:56:18<324:13:45, 47.76s/it]                                                         {'loss': 0.2629, 'grad_norm': 1.1484328611550914, 'learning_rate': 3.7466307277628035e-05, 'epoch': 0.01}
  1%|          | 278/24716 [3:56:18<324:13:45, 47.76s/it]  1%|          | 279/24716 [3:57:03<317:52:57, 46.83s/it]                                                         {'loss': 0.3467, 'grad_norm': 1.3310390604944642, 'learning_rate': 3.76010781671159e-05, 'epoch': 0.01}
  1%|          | 279/24716 [3:57:03<317:52:57, 46.83s/it]  1%|          | 280/24716 [3:57:47<312:49:49, 46.09s/it]                                                         {'loss': 0.2992, 'grad_norm': 0.7039882587662544, 'learning_rate': 3.7735849056603776e-05, 'epoch': 0.01}
  1%|          | 280/24716 [3:57:47<312:49:49, 46.09s/it]  1%|          | 281/24716 [3:58:50<345:34:06, 50.91s/it]                                                         {'loss': 0.2661, 'grad_norm': 0.5867918970176734, 'learning_rate': 3.787061994609164e-05, 'epoch': 0.01}
  1%|          | 281/24716 [3:58:50<345:34:06, 50.91s/it]  1%|          | 282/24716 [3:59:45<354:31:02, 52.23s/it]                                                         {'loss': 0.2691, 'grad_norm': 0.711813397993866, 'learning_rate': 3.8005390835579516e-05, 'epoch': 0.01}
  1%|          | 282/24716 [3:59:45<354:31:02, 52.23s/it]  1%|          | 283/24716 [4:00:31<341:47:58, 50.36s/it]                                                         {'loss': 0.2652, 'grad_norm': 1.1349449218899421, 'learning_rate': 3.8140161725067383e-05, 'epoch': 0.01}
  1%|          | 283/24716 [4:00:31<341:47:58, 50.36s/it]  1%|          | 284/24716 [4:01:22<342:38:36, 50.49s/it]                                                         {'loss': 0.2768, 'grad_norm': 0.892258128995932, 'learning_rate': 3.827493261455526e-05, 'epoch': 0.01}
  1%|          | 284/24716 [4:01:22<342:38:36, 50.49s/it]  1%|          | 285/24716 [4:02:23<364:59:03, 53.78s/it]                                                         {'loss': 0.2965, 'grad_norm': 1.3900872069336527, 'learning_rate': 3.8409703504043124e-05, 'epoch': 0.01}
  1%|          | 285/24716 [4:02:23<364:59:03, 53.78s/it]  1%|          | 286/24716 [4:03:08<347:32:51, 51.21s/it]                                                         {'loss': 0.2913, 'grad_norm': 1.5316177398348334, 'learning_rate': 3.8544474393531e-05, 'epoch': 0.01}
  1%|          | 286/24716 [4:03:08<347:32:51, 51.21s/it]  1%|          | 287/24716 [4:03:54<336:22:48, 49.57s/it]                                                         {'loss': 0.2323, 'grad_norm': 0.6873798674729958, 'learning_rate': 3.867924528301887e-05, 'epoch': 0.01}
  1%|          | 287/24716 [4:03:54<336:22:48, 49.57s/it]  1%|          | 288/24716 [4:04:43<334:24:52, 49.28s/it]                                                         {'loss': 0.2545, 'grad_norm': 0.7399934251755576, 'learning_rate': 3.881401617250674e-05, 'epoch': 0.01}
  1%|          | 288/24716 [4:04:43<334:24:52, 49.28s/it]  1%|          | 289/24716 [4:05:30<329:38:04, 48.58s/it]                                                         {'loss': 0.2354, 'grad_norm': 0.9233208360864532, 'learning_rate': 3.894878706199461e-05, 'epoch': 0.01}
  1%|          | 289/24716 [4:05:30<329:38:04, 48.58s/it]  1%|          | 290/24716 [4:06:06<305:27:33, 45.02s/it]                                                         {'loss': 0.3126, 'grad_norm': 2.7819622733320206, 'learning_rate': 3.908355795148248e-05, 'epoch': 0.01}
  1%|          | 290/24716 [4:06:06<305:27:33, 45.02s/it]  1%|          | 291/24716 [4:06:55<313:06:04, 46.15s/it]                                                         {'loss': 0.2682, 'grad_norm': 0.9783585627880118, 'learning_rate': 3.921832884097035e-05, 'epoch': 0.01}
  1%|          | 291/24716 [4:06:55<313:06:04, 46.15s/it]  1%|          | 292/24716 [4:07:42<314:36:27, 46.37s/it]                                                         {'loss': 0.2998, 'grad_norm': 2.0835551361398794, 'learning_rate': 3.935309973045822e-05, 'epoch': 0.01}
  1%|          | 292/24716 [4:07:42<314:36:27, 46.37s/it]  1%|          | 293/24716 [4:08:27<312:08:35, 46.01s/it]                                                         {'loss': 0.3262, 'grad_norm': 1.643400318173549, 'learning_rate': 3.9487870619946094e-05, 'epoch': 0.01}
  1%|          | 293/24716 [4:08:27<312:08:35, 46.01s/it]  1%|          | 294/24716 [4:09:19<323:31:04, 47.69s/it]                                                         {'loss': 0.2689, 'grad_norm': 0.8127449640973277, 'learning_rate': 3.962264150943397e-05, 'epoch': 0.01}
  1%|          | 294/24716 [4:09:19<323:31:04, 47.69s/it]  1%|          | 295/24716 [4:10:04<318:28:00, 46.95s/it]                                                         {'loss': 0.277, 'grad_norm': 0.756240104547101, 'learning_rate': 3.9757412398921835e-05, 'epoch': 0.01}
  1%|          | 295/24716 [4:10:04<318:28:00, 46.95s/it]  1%|          | 296/24716 [4:10:52<320:55:34, 47.31s/it]                                                         {'loss': 0.4219, 'grad_norm': 4.987732209430311, 'learning_rate': 3.989218328840971e-05, 'epoch': 0.01}
  1%|          | 296/24716 [4:10:52<320:55:34, 47.31s/it]  1%|          | 297/24716 [4:11:52<346:18:53, 51.06s/it]                                                         {'loss': 0.2641, 'grad_norm': 0.879772737137807, 'learning_rate': 4.0026954177897575e-05, 'epoch': 0.01}
  1%|          | 297/24716 [4:11:52<346:18:53, 51.06s/it]  1%|          | 298/24716 [4:12:50<359:35:37, 53.02s/it]                                                         {'loss': 0.2675, 'grad_norm': 0.7937174865829733, 'learning_rate': 4.016172506738545e-05, 'epoch': 0.01}
  1%|          | 298/24716 [4:12:50<359:35:37, 53.02s/it]  1%|          | 299/24716 [4:13:44<362:49:00, 53.49s/it]                                                         {'loss': 0.3727, 'grad_norm': 2.28250520916222, 'learning_rate': 4.0296495956873316e-05, 'epoch': 0.01}
  1%|          | 299/24716 [4:13:44<362:49:00, 53.49s/it]  1%|          | 300/24716 [4:14:25<337:17:27, 49.73s/it]                                                         {'loss': 0.2843, 'grad_norm': 1.7101933896051087, 'learning_rate': 4.043126684636119e-05, 'epoch': 0.01}
  1%|          | 300/24716 [4:14:25<337:17:27, 49.73s/it]  1%|          | 301/24716 [4:15:15<338:30:26, 49.91s/it]                                                         {'loss': 0.3035, 'grad_norm': 1.0535896754843865, 'learning_rate': 4.0566037735849064e-05, 'epoch': 0.01}
  1%|          | 301/24716 [4:15:15<338:30:26, 49.91s/it]  1%|          | 302/24716 [4:15:57<320:48:46, 47.31s/it]                                                         {'loss': 0.2636, 'grad_norm': 0.7596466132911576, 'learning_rate': 4.070080862533693e-05, 'epoch': 0.01}
  1%|          | 302/24716 [4:15:57<320:48:46, 47.31s/it]  1%|          | 303/24716 [4:16:43<319:35:36, 47.13s/it]                                                         {'loss': 0.3065, 'grad_norm': 1.1588004042697693, 'learning_rate': 4.0835579514824804e-05, 'epoch': 0.01}
  1%|          | 303/24716 [4:16:43<319:35:36, 47.13s/it]  1%|          | 304/24716 [4:17:33<323:39:12, 47.73s/it]                                                         {'loss': 0.2284, 'grad_norm': 0.5014983881727256, 'learning_rate': 4.097035040431267e-05, 'epoch': 0.01}
  1%|          | 304/24716 [4:17:33<323:39:12, 47.73s/it]  1%|          | 305/24716 [4:18:19<321:14:45, 47.38s/it]                                                         {'loss': 0.3209, 'grad_norm': 1.2958825747374334, 'learning_rate': 4.110512129380054e-05, 'epoch': 0.01}
  1%|          | 305/24716 [4:18:19<321:14:45, 47.38s/it]  1%|          | 306/24716 [4:19:10<328:16:02, 48.41s/it]                                                         {'loss': 0.2813, 'grad_norm': 0.8874503121253106, 'learning_rate': 4.123989218328841e-05, 'epoch': 0.01}
  1%|          | 306/24716 [4:19:10<328:16:02, 48.41s/it]  1%|          | 307/24716 [4:20:04<339:01:26, 50.00s/it]                                                         {'loss': 0.3012, 'grad_norm': 0.8682270455018916, 'learning_rate': 4.137466307277628e-05, 'epoch': 0.01}
  1%|          | 307/24716 [4:20:04<339:01:26, 50.00s/it]  1%|          | 308/24716 [4:21:06<364:28:12, 53.76s/it]                                                         {'loss': 0.5143, 'grad_norm': 1.8751536997409863, 'learning_rate': 4.150943396226415e-05, 'epoch': 0.01}
  1%|          | 308/24716 [4:21:06<364:28:12, 53.76s/it]  1%|▏         | 309/24716 [4:21:56<357:08:58, 52.68s/it]                                                         {'loss': 0.3213, 'grad_norm': 0.8218163253919217, 'learning_rate': 4.164420485175202e-05, 'epoch': 0.01}
  1%|▏         | 309/24716 [4:21:56<357:08:58, 52.68s/it]  1%|▏         | 310/24716 [4:22:46<351:44:22, 51.88s/it]                                                         {'loss': 0.3154, 'grad_norm': 1.1609900141299527, 'learning_rate': 4.1778975741239893e-05, 'epoch': 0.01}
  1%|▏         | 310/24716 [4:22:46<351:44:22, 51.88s/it]  1%|▏         | 311/24716 [4:23:40<355:04:07, 52.38s/it]                                                         {'loss': 0.2525, 'grad_norm': 1.7392876924336385, 'learning_rate': 4.191374663072776e-05, 'epoch': 0.01}
  1%|▏         | 311/24716 [4:23:40<355:04:07, 52.38s/it]  1%|▏         | 312/24716 [4:24:40<371:38:52, 54.82s/it]                                                         {'loss': 0.2967, 'grad_norm': 1.9657445647070961, 'learning_rate': 4.2048517520215634e-05, 'epoch': 0.01}
  1%|▏         | 312/24716 [4:24:40<371:38:52, 54.82s/it]  1%|▏         | 313/24716 [4:25:28<357:39:25, 52.76s/it]                                                         {'loss': 0.3083, 'grad_norm': 0.6958079838062058, 'learning_rate': 4.218328840970351e-05, 'epoch': 0.01}
  1%|▏         | 313/24716 [4:25:28<357:39:25, 52.76s/it]  1%|▏         | 314/24716 [4:26:17<349:54:23, 51.62s/it]                                                         {'loss': 0.2788, 'grad_norm': 0.7998366199745779, 'learning_rate': 4.2318059299191375e-05, 'epoch': 0.01}
  1%|▏         | 314/24716 [4:26:17<349:54:23, 51.62s/it]  1%|▏         | 315/24716 [4:27:15<362:34:41, 53.49s/it]                                                         {'loss': 0.2841, 'grad_norm': 0.7169169959067658, 'learning_rate': 4.245283018867925e-05, 'epoch': 0.01}
  1%|▏         | 315/24716 [4:27:15<362:34:41, 53.49s/it]  1%|▏         | 316/24716 [4:28:02<348:49:16, 51.47s/it]                                                         {'loss': 0.3189, 'grad_norm': 1.1852190368508402, 'learning_rate': 4.2587601078167116e-05, 'epoch': 0.01}
  1%|▏         | 316/24716 [4:28:02<348:49:16, 51.47s/it]  1%|▏         | 317/24716 [4:28:55<351:48:59, 51.91s/it]                                                         {'loss': 0.2452, 'grad_norm': 0.576428396046831, 'learning_rate': 4.272237196765499e-05, 'epoch': 0.01}
  1%|▏         | 317/24716 [4:28:55<351:48:59, 51.91s/it]  1%|▏         | 318/24716 [4:29:43<344:37:11, 50.85s/it]                                                         {'loss': 0.2624, 'grad_norm': 0.6867205550265486, 'learning_rate': 4.2857142857142856e-05, 'epoch': 0.01}
  1%|▏         | 318/24716 [4:29:43<344:37:11, 50.85s/it]  1%|▏         | 319/24716 [4:30:37<351:30:29, 51.87s/it]                                                         {'loss': 0.2412, 'grad_norm': 1.2353520753504497, 'learning_rate': 4.299191374663073e-05, 'epoch': 0.01}
  1%|▏         | 319/24716 [4:30:37<351:30:29, 51.87s/it]  1%|▏         | 320/24716 [4:31:35<363:18:36, 53.61s/it]                                                         {'loss': 0.2486, 'grad_norm': 1.0197277021774935, 'learning_rate': 4.3126684636118604e-05, 'epoch': 0.01}
  1%|▏         | 320/24716 [4:31:35<363:18:36, 53.61s/it]  1%|▏         | 321/24716 [4:32:31<368:02:04, 54.31s/it]                                                         {'loss': 0.2709, 'grad_norm': 0.673035683344273, 'learning_rate': 4.326145552560647e-05, 'epoch': 0.01}
  1%|▏         | 321/24716 [4:32:31<368:02:04, 54.31s/it]  1%|▏         | 322/24716 [4:33:21<359:19:24, 53.03s/it]                                                         {'loss': 0.2871, 'grad_norm': 0.8597027398917618, 'learning_rate': 4.3396226415094345e-05, 'epoch': 0.01}
  1%|▏         | 322/24716 [4:33:21<359:19:24, 53.03s/it]  1%|▏         | 323/24716 [4:34:17<365:11:17, 53.90s/it]                                                         {'loss': 0.3097, 'grad_norm': 1.0862897321503113, 'learning_rate': 4.353099730458221e-05, 'epoch': 0.01}
  1%|▏         | 323/24716 [4:34:17<365:11:17, 53.90s/it]  1%|▏         | 324/24716 [4:35:06<354:38:14, 52.34s/it]                                                         {'loss': 0.2645, 'grad_norm': 0.7527573581756147, 'learning_rate': 4.3665768194070085e-05, 'epoch': 0.01}
  1%|▏         | 324/24716 [4:35:06<354:38:14, 52.34s/it]  1%|▏         | 325/24716 [4:35:51<339:35:03, 50.12s/it]                                                         {'loss': 0.3027, 'grad_norm': 0.6951107529862768, 'learning_rate': 4.380053908355795e-05, 'epoch': 0.01}
  1%|▏         | 325/24716 [4:35:51<339:35:03, 50.12s/it]  1%|▏         | 326/24716 [4:37:00<378:50:15, 55.92s/it]                                                         {'loss': 0.2511, 'grad_norm': 1.3626589548971904, 'learning_rate': 4.3935309973045826e-05, 'epoch': 0.01}
  1%|▏         | 326/24716 [4:37:00<378:50:15, 55.92s/it]  1%|▏         | 327/24716 [4:37:41<347:41:00, 51.32s/it]                                                         {'loss': 0.2545, 'grad_norm': 0.5590611958729502, 'learning_rate': 4.40700808625337e-05, 'epoch': 0.01}
  1%|▏         | 327/24716 [4:37:41<347:41:00, 51.32s/it]  1%|▏         | 328/24716 [4:38:25<333:16:28, 49.20s/it]                                                         {'loss': 0.2726, 'grad_norm': 0.9593604877558732, 'learning_rate': 4.420485175202157e-05, 'epoch': 0.01}
  1%|▏         | 328/24716 [4:38:25<333:16:28, 49.20s/it]  1%|▏         | 329/24716 [4:39:21<346:48:00, 51.19s/it]                                                         {'loss': 0.292, 'grad_norm': 0.8244489633043077, 'learning_rate': 4.433962264150944e-05, 'epoch': 0.01}
  1%|▏         | 329/24716 [4:39:21<346:48:00, 51.19s/it]  1%|▏         | 330/24716 [4:40:02<325:55:37, 48.12s/it]                                                         {'loss': 0.3254, 'grad_norm': 0.7453143269010818, 'learning_rate': 4.447439353099731e-05, 'epoch': 0.01}
  1%|▏         | 330/24716 [4:40:02<325:55:37, 48.12s/it]  1%|▏         | 331/24716 [4:40:55<335:38:07, 49.55s/it]                                                         {'loss': 0.2359, 'grad_norm': 0.9778661827446253, 'learning_rate': 4.4609164420485174e-05, 'epoch': 0.01}
  1%|▏         | 331/24716 [4:40:55<335:38:07, 49.55s/it]  1%|▏         | 332/24716 [4:41:43<332:10:19, 49.04s/it]                                                         {'loss': 0.2649, 'grad_norm': 0.7168440805530825, 'learning_rate': 4.474393530997305e-05, 'epoch': 0.01}
  1%|▏         | 332/24716 [4:41:43<332:10:19, 49.04s/it]  1%|▏         | 333/24716 [4:42:42<352:41:56, 52.07s/it]                                                         {'loss': 0.2672, 'grad_norm': 0.8383100931780693, 'learning_rate': 4.4878706199460915e-05, 'epoch': 0.01}
  1%|▏         | 333/24716 [4:42:42<352:41:56, 52.07s/it]  1%|▏         | 334/24716 [4:43:35<354:33:13, 52.35s/it]                                                         {'loss': 0.231, 'grad_norm': 0.5378052509114845, 'learning_rate': 4.501347708894879e-05, 'epoch': 0.01}
  1%|▏         | 334/24716 [4:43:35<354:33:13, 52.35s/it]  1%|▏         | 335/24716 [4:44:21<342:03:36, 50.51s/it]                                                         {'loss': 0.2271, 'grad_norm': 0.6862992402851519, 'learning_rate': 4.5148247978436656e-05, 'epoch': 0.01}
  1%|▏         | 335/24716 [4:44:21<342:03:36, 50.51s/it]  1%|▏         | 336/24716 [4:45:09<337:54:42, 49.90s/it]                                                         {'loss': 0.2601, 'grad_norm': 0.9658603111829903, 'learning_rate': 4.528301886792453e-05, 'epoch': 0.01}
  1%|▏         | 336/24716 [4:45:09<337:54:42, 49.90s/it]  1%|▏         | 337/24716 [4:45:54<327:54:00, 48.42s/it]                                                         {'loss': 0.2564, 'grad_norm': 0.9884349058050694, 'learning_rate': 4.5417789757412397e-05, 'epoch': 0.01}
  1%|▏         | 337/24716 [4:45:54<327:54:00, 48.42s/it]  1%|▏         | 338/24716 [4:46:54<350:21:30, 51.74s/it]                                                         {'loss': 0.2188, 'grad_norm': 0.7400097371075005, 'learning_rate': 4.555256064690027e-05, 'epoch': 0.01}
  1%|▏         | 338/24716 [4:46:54<350:21:30, 51.74s/it]  1%|▏         | 339/24716 [4:47:51<360:53:46, 53.30s/it]                                                         {'loss': 0.2459, 'grad_norm': 0.6053471510334326, 'learning_rate': 4.5687331536388144e-05, 'epoch': 0.01}
  1%|▏         | 339/24716 [4:47:51<360:53:46, 53.30s/it]  1%|▏         | 340/24716 [4:48:39<351:27:35, 51.91s/it]                                                         {'loss': 0.3094, 'grad_norm': 1.151011184994411, 'learning_rate': 4.582210242587601e-05, 'epoch': 0.01}
  1%|▏         | 340/24716 [4:48:39<351:27:35, 51.91s/it]  1%|▏         | 341/24716 [4:49:42<373:12:41, 55.12s/it]                                                         {'loss': 0.2658, 'grad_norm': 1.4228775418544573, 'learning_rate': 4.5956873315363885e-05, 'epoch': 0.01}
  1%|▏         | 341/24716 [4:49:42<373:12:41, 55.12s/it]  1%|▏         | 342/24716 [4:50:25<348:10:17, 51.42s/it]                                                         {'loss': 0.2271, 'grad_norm': 0.5897516147825983, 'learning_rate': 4.609164420485175e-05, 'epoch': 0.01}
  1%|▏         | 342/24716 [4:50:25<348:10:17, 51.42s/it]  1%|▏         | 343/24716 [4:51:12<340:30:47, 50.30s/it]                                                         {'loss': 0.3326, 'grad_norm': 1.6767037507056763, 'learning_rate': 4.6226415094339625e-05, 'epoch': 0.01}
  1%|▏         | 343/24716 [4:51:12<340:30:47, 50.30s/it]  1%|▏         | 344/24716 [4:52:02<339:25:18, 50.14s/it]                                                         {'loss': 0.2713, 'grad_norm': 1.3929174674296927, 'learning_rate': 4.636118598382749e-05, 'epoch': 0.01}
  1%|▏         | 344/24716 [4:52:02<339:25:18, 50.14s/it]  1%|▏         | 345/24716 [4:52:53<339:42:01, 50.18s/it]                                                         {'loss': 0.2501, 'grad_norm': 0.8270664757794991, 'learning_rate': 4.6495956873315366e-05, 'epoch': 0.01}
  1%|▏         | 345/24716 [4:52:53<339:42:01, 50.18s/it]  1%|▏         | 346/24716 [4:53:48<350:37:44, 51.80s/it]                                                         {'loss': 0.304, 'grad_norm': 1.1035455642791043, 'learning_rate': 4.663072776280324e-05, 'epoch': 0.01}
  1%|▏         | 346/24716 [4:53:48<350:37:44, 51.80s/it]  1%|▏         | 347/24716 [4:54:34<337:45:46, 49.90s/it]                                                         {'loss': 0.3447, 'grad_norm': 0.9946783612329664, 'learning_rate': 4.676549865229111e-05, 'epoch': 0.01}
  1%|▏         | 347/24716 [4:54:34<337:45:46, 49.90s/it]  1%|▏         | 348/24716 [4:55:27<345:33:03, 51.05s/it]                                                         {'loss': 0.3956, 'grad_norm': 2.858053312741948, 'learning_rate': 4.690026954177898e-05, 'epoch': 0.01}
  1%|▏         | 348/24716 [4:55:27<345:33:03, 51.05s/it]  1%|▏         | 349/24716 [4:56:15<338:01:18, 49.94s/it]                                                         {'loss': 0.2804, 'grad_norm': 0.877814642112088, 'learning_rate': 4.703504043126685e-05, 'epoch': 0.01}
  1%|▏         | 349/24716 [4:56:15<338:01:18, 49.94s/it]  1%|▏         | 350/24716 [4:57:04<337:45:53, 49.90s/it]                                                         {'loss': 0.2883, 'grad_norm': 0.7602061475223357, 'learning_rate': 4.716981132075472e-05, 'epoch': 0.01}
  1%|▏         | 350/24716 [4:57:04<337:45:53, 49.90s/it]  1%|▏         | 351/24716 [4:57:49<327:47:21, 48.43s/it]                                                         {'loss': 0.2377, 'grad_norm': 0.721845779208058, 'learning_rate': 4.730458221024259e-05, 'epoch': 0.01}
  1%|▏         | 351/24716 [4:57:49<327:47:21, 48.43s/it]  1%|▏         | 352/24716 [4:58:42<336:04:49, 49.66s/it]                                                         {'loss': 0.2517, 'grad_norm': 0.8010273984162254, 'learning_rate': 4.743935309973046e-05, 'epoch': 0.01}
  1%|▏         | 352/24716 [4:58:42<336:04:49, 49.66s/it]  1%|▏         | 353/24716 [4:59:45<362:32:56, 53.57s/it]                                                         {'loss': 0.2647, 'grad_norm': 1.1231043888372514, 'learning_rate': 4.7574123989218336e-05, 'epoch': 0.01}
  1%|▏         | 353/24716 [4:59:45<362:32:56, 53.57s/it]  1%|▏         | 354/24716 [5:00:45<376:34:06, 55.65s/it]                                                         {'loss': 0.3222, 'grad_norm': 0.6353929131214059, 'learning_rate': 4.77088948787062e-05, 'epoch': 0.01}
  1%|▏         | 354/24716 [5:00:45<376:34:06, 55.65s/it]  1%|▏         | 355/24716 [5:01:38<370:47:42, 54.80s/it]                                                         {'loss': 0.3285, 'grad_norm': 0.9162299494783457, 'learning_rate': 4.7843665768194077e-05, 'epoch': 0.01}
  1%|▏         | 355/24716 [5:01:38<370:47:42, 54.80s/it]  1%|▏         | 356/24716 [5:02:40<385:26:31, 56.96s/it]                                                         {'loss': 0.3262, 'grad_norm': 1.4394083679062855, 'learning_rate': 4.7978436657681944e-05, 'epoch': 0.01}
  1%|▏         | 356/24716 [5:02:40<385:26:31, 56.96s/it]  1%|▏         | 357/24716 [5:03:23<356:26:15, 52.68s/it]                                                         {'loss': 0.2887, 'grad_norm': 0.6547725543736385, 'learning_rate': 4.811320754716982e-05, 'epoch': 0.01}
  1%|▏         | 357/24716 [5:03:23<356:26:15, 52.68s/it]  1%|▏         | 358/24716 [5:04:29<384:45:53, 56.87s/it]                                                         {'loss': 0.3716, 'grad_norm': 0.8983449599050074, 'learning_rate': 4.8247978436657684e-05, 'epoch': 0.01}
  1%|▏         | 358/24716 [5:04:29<384:45:53, 56.87s/it]  1%|▏         | 359/24716 [5:05:12<355:50:49, 52.59s/it]                                                         {'loss': 0.2623, 'grad_norm': 1.7258165610668008, 'learning_rate': 4.838274932614555e-05, 'epoch': 0.01}
  1%|▏         | 359/24716 [5:05:12<355:50:49, 52.59s/it]  1%|▏         | 360/24716 [5:06:07<360:38:57, 53.31s/it]                                                         {'loss': 0.2912, 'grad_norm': 1.8797239695316632, 'learning_rate': 4.8517520215633425e-05, 'epoch': 0.01}
  1%|▏         | 360/24716 [5:06:07<360:38:57, 53.31s/it]  1%|▏         | 361/24716 [5:06:52<344:49:34, 50.97s/it]                                                         {'loss': 0.2708, 'grad_norm': 0.7872499980540799, 'learning_rate': 4.865229110512129e-05, 'epoch': 0.01}
  1%|▏         | 361/24716 [5:06:52<344:49:34, 50.97s/it]  1%|▏         | 362/24716 [5:07:45<347:39:35, 51.39s/it]                                                         {'loss': 0.319, 'grad_norm': 1.1742073141847864, 'learning_rate': 4.8787061994609166e-05, 'epoch': 0.01}
  1%|▏         | 362/24716 [5:07:45<347:39:35, 51.39s/it]  1%|▏         | 363/24716 [5:08:39<352:32:55, 52.12s/it]                                                         {'loss': 0.2479, 'grad_norm': 0.816965441335247, 'learning_rate': 4.892183288409703e-05, 'epoch': 0.01}
  1%|▏         | 363/24716 [5:08:39<352:32:55, 52.12s/it]  1%|▏         | 364/24716 [5:09:41<372:36:29, 55.08s/it]                                                         {'loss': 0.4883, 'grad_norm': 1.8337971640229682, 'learning_rate': 4.9056603773584906e-05, 'epoch': 0.01}
  1%|▏         | 364/24716 [5:09:41<372:36:29, 55.08s/it]  1%|▏         | 365/24716 [5:10:26<353:42:04, 52.29s/it]                                                         {'loss': 0.3071, 'grad_norm': 0.8414021725038282, 'learning_rate': 4.919137466307278e-05, 'epoch': 0.01}
  1%|▏         | 365/24716 [5:10:26<353:42:04, 52.29s/it]  1%|▏         | 366/24716 [5:11:26<367:41:04, 54.36s/it]                                                         {'loss': 0.3127, 'grad_norm': 1.0872855300540136, 'learning_rate': 4.932614555256065e-05, 'epoch': 0.01}
  1%|▏         | 366/24716 [5:11:26<367:41:04, 54.36s/it]  1%|▏         | 367/24716 [5:12:19<365:54:00, 54.10s/it]                                                         {'loss': 0.2767, 'grad_norm': 0.8332103396134898, 'learning_rate': 4.946091644204852e-05, 'epoch': 0.01}
  1%|▏         | 367/24716 [5:12:19<365:54:00, 54.10s/it]  1%|▏         | 368/24716 [5:13:13<365:24:37, 54.03s/it]                                                         {'loss': 0.2351, 'grad_norm': 0.5713383108999539, 'learning_rate': 4.959568733153639e-05, 'epoch': 0.01}
  1%|▏         | 368/24716 [5:13:13<365:24:37, 54.03s/it]  1%|▏         | 369/24716 [5:13:58<346:43:17, 51.27s/it]                                                         {'loss': 0.2783, 'grad_norm': 0.6060981346561306, 'learning_rate': 4.973045822102426e-05, 'epoch': 0.01}
  1%|▏         | 369/24716 [5:13:58<346:43:17, 51.27s/it]  1%|▏         | 370/24716 [5:14:48<344:16:50, 50.91s/it]                                                         {'loss': 0.2913, 'grad_norm': 0.768715857602986, 'learning_rate': 4.986522911051213e-05, 'epoch': 0.01}
  1%|▏         | 370/24716 [5:14:48<344:16:50, 50.91s/it]  2%|▏         | 371/24716 [5:15:47<360:07:26, 53.25s/it]                                                         {'loss': 0.3115, 'grad_norm': 1.0017046859945693, 'learning_rate': 5e-05, 'epoch': 0.02}
  2%|▏         | 371/24716 [5:15:47<360:07:26, 53.25s/it]  2%|▏         | 372/24716 [5:16:39<358:16:30, 52.98s/it]                                                         {'loss': 0.3276, 'grad_norm': 1.3938614129067912, 'learning_rate': 5.013477088948787e-05, 'epoch': 0.02}
  2%|▏         | 372/24716 [5:16:39<358:16:30, 52.98s/it]  2%|▏         | 373/24716 [5:17:38<370:27:34, 54.79s/it]                                                         {'loss': 0.2622, 'grad_norm': 0.7559578206957331, 'learning_rate': 5.026954177897575e-05, 'epoch': 0.02}
  2%|▏         | 373/24716 [5:17:38<370:27:34, 54.79s/it]  2%|▏         | 374/24716 [5:18:29<362:19:10, 53.58s/it]                                                         {'loss': 0.2933, 'grad_norm': 1.3641404433766549, 'learning_rate': 5.040431266846362e-05, 'epoch': 0.02}
  2%|▏         | 374/24716 [5:18:29<362:19:10, 53.58s/it]  2%|▏         | 375/24716 [5:19:35<388:42:24, 57.49s/it]                                                         {'loss': 0.2245, 'grad_norm': 0.7488950369866165, 'learning_rate': 5.0539083557951484e-05, 'epoch': 0.02}
  2%|▏         | 375/24716 [5:19:35<388:42:24, 57.49s/it]  2%|▏         | 376/24716 [5:20:27<377:39:32, 55.86s/it]                                                         {'loss': 0.2311, 'grad_norm': 1.049226225625191, 'learning_rate': 5.067385444743935e-05, 'epoch': 0.02}
  2%|▏         | 376/24716 [5:20:27<377:39:32, 55.86s/it]  2%|▏         | 377/24716 [5:21:25<380:53:06, 56.34s/it]                                                         {'loss': 0.2838, 'grad_norm': 0.7219068387650319, 'learning_rate': 5.080862533692723e-05, 'epoch': 0.02}
  2%|▏         | 377/24716 [5:21:25<380:53:06, 56.34s/it]  2%|▏         | 378/24716 [5:22:07<351:16:44, 51.96s/it]                                                         {'loss': 0.288, 'grad_norm': 0.9204864946578742, 'learning_rate': 5.09433962264151e-05, 'epoch': 0.02}
  2%|▏         | 378/24716 [5:22:07<351:16:44, 51.96s/it]  2%|▏         | 379/24716 [5:23:05<363:34:33, 53.78s/it]                                                         {'loss': 0.33, 'grad_norm': 2.1464396114818234, 'learning_rate': 5.1078167115902965e-05, 'epoch': 0.02}
  2%|▏         | 379/24716 [5:23:05<363:34:33, 53.78s/it]  2%|▏         | 380/24716 [5:23:59<365:06:25, 54.01s/it]                                                         {'loss': 0.314, 'grad_norm': 1.0481707267159674, 'learning_rate': 5.1212938005390846e-05, 'epoch': 0.02}
  2%|▏         | 380/24716 [5:23:59<365:06:25, 54.01s/it]  2%|▏         | 381/24716 [5:24:47<352:38:24, 52.17s/it]                                                         {'loss': 0.3317, 'grad_norm': 1.2268461464365654, 'learning_rate': 5.134770889487871e-05, 'epoch': 0.02}
  2%|▏         | 381/24716 [5:24:47<352:38:24, 52.17s/it]  2%|▏         | 382/24716 [5:25:53<381:30:31, 56.44s/it]                                                         {'loss': 0.2373, 'grad_norm': 0.6857335894489668, 'learning_rate': 5.148247978436658e-05, 'epoch': 0.02}
  2%|▏         | 382/24716 [5:25:53<381:30:31, 56.44s/it]  2%|▏         | 383/24716 [5:26:54<389:46:58, 57.67s/it]                                                         {'loss': 0.2709, 'grad_norm': 0.9761310053122969, 'learning_rate': 5.161725067385445e-05, 'epoch': 0.02}
  2%|▏         | 383/24716 [5:26:54<389:46:58, 57.67s/it]  2%|▏         | 384/24716 [5:27:43<371:54:32, 55.03s/it]                                                         {'loss': 0.2679, 'grad_norm': 1.9108783021536553, 'learning_rate': 5.175202156334232e-05, 'epoch': 0.02}
  2%|▏         | 384/24716 [5:27:43<371:54:32, 55.03s/it]  2%|▏         | 385/24716 [5:28:28<351:07:54, 51.95s/it]                                                         {'loss': 0.2347, 'grad_norm': 0.5316935725645509, 'learning_rate': 5.188679245283019e-05, 'epoch': 0.02}
  2%|▏         | 385/24716 [5:28:28<351:07:54, 51.95s/it]  2%|▏         | 386/24716 [5:29:11<334:24:22, 49.48s/it]                                                         {'loss': 0.2773, 'grad_norm': 0.9734562682302248, 'learning_rate': 5.202156334231806e-05, 'epoch': 0.02}
  2%|▏         | 386/24716 [5:29:11<334:24:22, 49.48s/it]  2%|▏         | 387/24716 [5:29:59<331:39:08, 49.08s/it]                                                         {'loss': 0.2615, 'grad_norm': 0.5795927318853888, 'learning_rate': 5.2156334231805935e-05, 'epoch': 0.02}
  2%|▏         | 387/24716 [5:29:59<331:39:08, 49.08s/it]  2%|▏         | 388/24716 [5:30:56<347:31:50, 51.43s/it]                                                         {'loss': 0.4133, 'grad_norm': 1.285791388499471, 'learning_rate': 5.22911051212938e-05, 'epoch': 0.02}
  2%|▏         | 388/24716 [5:30:56<347:31:50, 51.43s/it]  2%|▏         | 389/24716 [5:31:55<362:08:29, 53.59s/it]                                                         {'loss': 0.2476, 'grad_norm': 0.7344528174458146, 'learning_rate': 5.242587601078167e-05, 'epoch': 0.02}
  2%|▏         | 389/24716 [5:31:55<362:08:29, 53.59s/it]  2%|▏         | 390/24716 [5:32:51<367:43:07, 54.42s/it]                                                         {'loss': 0.2677, 'grad_norm': 0.7548729373794919, 'learning_rate': 5.2560646900269536e-05, 'epoch': 0.02}
  2%|▏         | 390/24716 [5:32:51<367:43:07, 54.42s/it]  2%|▏         | 391/24716 [5:33:36<348:24:26, 51.56s/it]                                                         {'loss': 0.235, 'grad_norm': 2.0853240061352785, 'learning_rate': 5.2695417789757416e-05, 'epoch': 0.02}
  2%|▏         | 391/24716 [5:33:36<348:24:26, 51.56s/it]  2%|▏         | 392/24716 [5:34:28<349:06:48, 51.67s/it]                                                         {'loss': 0.2711, 'grad_norm': 1.0860433991270981, 'learning_rate': 5.283018867924528e-05, 'epoch': 0.02}
  2%|▏         | 392/24716 [5:34:28<349:06:48, 51.67s/it]  2%|▏         | 393/24716 [5:35:17<344:03:25, 50.92s/it]                                                         {'loss': 0.3022, 'grad_norm': 2.54170222780921, 'learning_rate': 5.296495956873315e-05, 'epoch': 0.02}
  2%|▏         | 393/24716 [5:35:17<344:03:25, 50.92s/it]  2%|▏         | 394/24716 [5:35:57<321:55:32, 47.65s/it]                                                         {'loss': 0.2396, 'grad_norm': 1.008538767373729, 'learning_rate': 5.309973045822103e-05, 'epoch': 0.02}
  2%|▏         | 394/24716 [5:35:57<321:55:32, 47.65s/it]  2%|▏         | 395/24716 [5:36:39<309:46:46, 45.85s/it]                                                         {'loss': 0.3241, 'grad_norm': 1.3812081939084324, 'learning_rate': 5.32345013477089e-05, 'epoch': 0.02}
  2%|▏         | 395/24716 [5:36:39<309:46:46, 45.85s/it]  2%|▏         | 396/24716 [5:37:33<326:06:09, 48.27s/it]                                                         {'loss': 0.3497, 'grad_norm': 2.19530647781957, 'learning_rate': 5.3369272237196765e-05, 'epoch': 0.02}
  2%|▏         | 396/24716 [5:37:33<326:06:09, 48.27s/it]  2%|▏         | 397/24716 [5:38:26<336:21:01, 49.79s/it]                                                         {'loss': 0.3035, 'grad_norm': 2.4242447074989135, 'learning_rate': 5.350404312668463e-05, 'epoch': 0.02}
  2%|▏         | 397/24716 [5:38:26<336:21:01, 49.79s/it]  2%|▏         | 398/24716 [5:39:20<344:39:52, 51.02s/it]                                                         {'loss': 0.2297, 'grad_norm': 0.7132413197741377, 'learning_rate': 5.363881401617251e-05, 'epoch': 0.02}
  2%|▏         | 398/24716 [5:39:20<344:39:52, 51.02s/it]  2%|▏         | 399/24716 [5:40:02<325:55:29, 48.25s/it]                                                         {'loss': 0.2989, 'grad_norm': 0.7452401208812179, 'learning_rate': 5.377358490566038e-05, 'epoch': 0.02}
  2%|▏         | 399/24716 [5:40:02<325:55:29, 48.25s/it]  2%|▏         | 400/24716 [5:40:41<307:53:40, 45.58s/it]                                                         {'loss': 0.3784, 'grad_norm': 1.6961089195771875, 'learning_rate': 5.3908355795148246e-05, 'epoch': 0.02}
  2%|▏         | 400/24716 [5:40:41<307:53:40, 45.58s/it]  2%|▏         | 401/24716 [5:41:30<313:44:35, 46.45s/it]                                                         {'loss': 0.2012, 'grad_norm': 0.9493424259140841, 'learning_rate': 5.404312668463613e-05, 'epoch': 0.02}
  2%|▏         | 401/24716 [5:41:30<313:44:35, 46.45s/it]  2%|▏         | 402/24716 [5:42:16<312:34:58, 46.28s/it]                                                         {'loss': 0.2685, 'grad_norm': 0.5876205522350076, 'learning_rate': 5.4177897574123994e-05, 'epoch': 0.02}
  2%|▏         | 402/24716 [5:42:16<312:34:58, 46.28s/it]  2%|▏         | 403/24716 [5:43:08<324:50:17, 48.10s/it]                                                         {'loss': 0.3364, 'grad_norm': 0.8498657924553235, 'learning_rate': 5.431266846361186e-05, 'epoch': 0.02}
  2%|▏         | 403/24716 [5:43:08<324:50:17, 48.10s/it]  2%|▏         | 404/24716 [5:44:06<344:37:04, 51.03s/it]                                                         {'loss': 0.3722, 'grad_norm': 1.7024579263063446, 'learning_rate': 5.444743935309974e-05, 'epoch': 0.02}
  2%|▏         | 404/24716 [5:44:06<344:37:04, 51.03s/it]  2%|▏         | 405/24716 [5:45:00<350:33:14, 51.91s/it]                                                         {'loss': 0.2707, 'grad_norm': 1.0963706928352426, 'learning_rate': 5.458221024258761e-05, 'epoch': 0.02}
  2%|▏         | 405/24716 [5:45:00<350:33:14, 51.91s/it]  2%|▏         | 406/24716 [5:45:49<344:39:25, 51.04s/it]                                                         {'loss': 0.244, 'grad_norm': 1.080309816904517, 'learning_rate': 5.4716981132075475e-05, 'epoch': 0.02}
  2%|▏         | 406/24716 [5:45:49<344:39:25, 51.04s/it]  2%|▏         | 407/24716 [5:46:51<367:26:27, 54.42s/it]                                                         {'loss': 0.3006, 'grad_norm': 1.0009038857093433, 'learning_rate': 5.485175202156334e-05, 'epoch': 0.02}
  2%|▏         | 407/24716 [5:46:51<367:26:27, 54.42s/it]  2%|▏         | 408/24716 [5:47:43<361:24:28, 53.52s/it]                                                         {'loss': 0.2497, 'grad_norm': 1.3489926974496635, 'learning_rate': 5.4986522911051216e-05, 'epoch': 0.02}
  2%|▏         | 408/24716 [5:47:43<361:24:28, 53.52s/it]  2%|▏         | 409/24716 [5:48:44<377:05:14, 55.85s/it]                                                         {'loss': 0.2458, 'grad_norm': 0.8049399412217372, 'learning_rate': 5.512129380053909e-05, 'epoch': 0.02}
  2%|▏         | 409/24716 [5:48:44<377:05:14, 55.85s/it]  2%|▏         | 410/24716 [5:49:42<382:17:46, 56.62s/it]                                                         {'loss': 0.2377, 'grad_norm': 0.6282140703671855, 'learning_rate': 5.525606469002696e-05, 'epoch': 0.02}
  2%|▏         | 410/24716 [5:49:42<382:17:46, 56.62s/it]  2%|▏         | 411/24716 [5:50:44<391:46:04, 58.03s/it]                                                         {'loss': 0.2876, 'grad_norm': 1.0480071015244303, 'learning_rate': 5.539083557951483e-05, 'epoch': 0.02}
  2%|▏         | 411/24716 [5:50:44<391:46:04, 58.03s/it]  2%|▏         | 412/24716 [5:51:30<368:23:08, 54.57s/it]                                                         {'loss': 0.2475, 'grad_norm': 1.7490757041665996, 'learning_rate': 5.55256064690027e-05, 'epoch': 0.02}
  2%|▏         | 412/24716 [5:51:30<368:23:08, 54.57s/it]  2%|▏         | 413/24716 [5:52:28<374:35:54, 55.49s/it]                                                         {'loss': 0.3337, 'grad_norm': 1.477071333881195, 'learning_rate': 5.5660377358490564e-05, 'epoch': 0.02}
  2%|▏         | 413/24716 [5:52:28<374:35:54, 55.49s/it]  2%|▏         | 414/24716 [5:53:26<379:38:47, 56.24s/it]                                                         {'loss': 0.3008, 'grad_norm': 2.346322308472811, 'learning_rate': 5.579514824797844e-05, 'epoch': 0.02}
  2%|▏         | 414/24716 [5:53:26<379:38:47, 56.24s/it]  2%|▏         | 415/24716 [5:54:11<357:30:04, 52.96s/it]                                                         {'loss': 0.3133, 'grad_norm': 1.0502114639748257, 'learning_rate': 5.592991913746631e-05, 'epoch': 0.02}
  2%|▏         | 415/24716 [5:54:11<357:30:04, 52.96s/it]  2%|▏         | 416/24716 [5:55:03<355:32:24, 52.67s/it]                                                         {'loss': 0.2706, 'grad_norm': 0.8963384581615559, 'learning_rate': 5.606469002695418e-05, 'epoch': 0.02}
  2%|▏         | 416/24716 [5:55:03<355:32:24, 52.67s/it]  2%|▏         | 417/24716 [5:56:02<367:28:37, 54.44s/it]                                                         {'loss': 0.3204, 'grad_norm': 2.108168034395772, 'learning_rate': 5.6199460916442046e-05, 'epoch': 0.02}
  2%|▏         | 417/24716 [5:56:02<367:28:37, 54.44s/it]  2%|▏         | 418/24716 [5:56:56<367:45:16, 54.49s/it]                                                         {'loss': 0.2947, 'grad_norm': 1.1311094422568344, 'learning_rate': 5.6334231805929926e-05, 'epoch': 0.02}
  2%|▏         | 418/24716 [5:56:56<367:45:16, 54.49s/it]  2%|▏         | 419/24716 [5:57:47<360:17:59, 53.38s/it]                                                         {'loss': 0.267, 'grad_norm': 1.295555813978901, 'learning_rate': 5.646900269541779e-05, 'epoch': 0.02}
  2%|▏         | 419/24716 [5:57:47<360:17:59, 53.38s/it]  2%|▏         | 420/24716 [5:58:52<383:45:15, 56.86s/it]                                                         {'loss': 0.291, 'grad_norm': 0.7948566154108266, 'learning_rate': 5.660377358490566e-05, 'epoch': 0.02}
  2%|▏         | 420/24716 [5:58:52<383:45:15, 56.86s/it]  2%|▏         | 421/24716 [5:59:33<352:40:58, 52.26s/it]                                                         {'loss': 0.256, 'grad_norm': 0.89712488060825, 'learning_rate': 5.673854447439353e-05, 'epoch': 0.02}
  2%|▏         | 421/24716 [5:59:33<352:40:58, 52.26s/it]  2%|▏         | 422/24716 [6:00:29<359:43:06, 53.30s/it]                                                         {'loss': 0.2557, 'grad_norm': 1.2762570369203428, 'learning_rate': 5.687331536388141e-05, 'epoch': 0.02}
  2%|▏         | 422/24716 [6:00:29<359:43:06, 53.30s/it]  2%|▏         | 423/24716 [6:01:19<352:44:12, 52.27s/it]                                                         {'loss': 0.2567, 'grad_norm': 0.6127326121371445, 'learning_rate': 5.7008086253369275e-05, 'epoch': 0.02}
  2%|▏         | 423/24716 [6:01:19<352:44:12, 52.27s/it]  2%|▏         | 424/24716 [6:02:00<329:45:09, 48.87s/it]                                                         {'loss': 0.3076, 'grad_norm': 0.8465832556710073, 'learning_rate': 5.714285714285714e-05, 'epoch': 0.02}
  2%|▏         | 424/24716 [6:02:00<329:45:09, 48.87s/it]  2%|▏         | 425/24716 [6:02:49<329:10:04, 48.78s/it]                                                         {'loss': 0.2455, 'grad_norm': 0.9319508021270828, 'learning_rate': 5.727762803234502e-05, 'epoch': 0.02}
  2%|▏         | 425/24716 [6:02:49<329:10:04, 48.78s/it]  2%|▏         | 426/24716 [6:03:32<318:41:00, 47.23s/it]                                                         {'loss': 0.2982, 'grad_norm': 0.8686620424157392, 'learning_rate': 5.741239892183289e-05, 'epoch': 0.02}
  2%|▏         | 426/24716 [6:03:32<318:41:00, 47.23s/it]  2%|▏         | 427/24716 [6:04:21<322:27:42, 47.79s/it]                                                         {'loss': 0.2234, 'grad_norm': 0.5542318269496271, 'learning_rate': 5.7547169811320756e-05, 'epoch': 0.02}
  2%|▏         | 427/24716 [6:04:21<322:27:42, 47.79s/it]  2%|▏         | 428/24716 [6:05:13<330:11:04, 48.94s/it]                                                         {'loss': 0.2094, 'grad_norm': 1.9716452196870873, 'learning_rate': 5.768194070080862e-05, 'epoch': 0.02}
  2%|▏         | 428/24716 [6:05:13<330:11:04, 48.94s/it]  2%|▏         | 429/24716 [6:06:04<334:26:26, 49.57s/it]                                                         {'loss': 0.2374, 'grad_norm': 0.6365122330931513, 'learning_rate': 5.7816711590296504e-05, 'epoch': 0.02}
  2%|▏         | 429/24716 [6:06:04<334:26:26, 49.57s/it]  2%|▏         | 430/24716 [6:06:51<329:49:03, 48.89s/it]                                                         {'loss': 0.2671, 'grad_norm': 1.3399058909816202, 'learning_rate': 5.795148247978437e-05, 'epoch': 0.02}
  2%|▏         | 430/24716 [6:06:51<329:49:03, 48.89s/it]  2%|▏         | 431/24716 [6:07:42<333:57:49, 49.51s/it]                                                         {'loss': 0.3195, 'grad_norm': 1.9794443814601679, 'learning_rate': 5.808625336927224e-05, 'epoch': 0.02}
  2%|▏         | 431/24716 [6:07:42<333:57:49, 49.51s/it]  2%|▏         | 432/24716 [6:08:36<343:17:17, 50.89s/it]                                                         {'loss': 0.3508, 'grad_norm': 1.6074346935421189, 'learning_rate': 5.822102425876012e-05, 'epoch': 0.02}
  2%|▏         | 432/24716 [6:08:36<343:17:17, 50.89s/it]  2%|▏         | 433/24716 [6:09:26<340:40:10, 50.50s/it]                                                         {'loss': 0.2837, 'grad_norm': 1.3958762967403662, 'learning_rate': 5.8355795148247985e-05, 'epoch': 0.02}
  2%|▏         | 433/24716 [6:09:26<340:40:10, 50.50s/it]  2%|▏         | 434/24716 [6:10:19<345:32:57, 51.23s/it]                                                         {'loss': 0.3816, 'grad_norm': 1.8885941849327497, 'learning_rate': 5.849056603773585e-05, 'epoch': 0.02}
  2%|▏         | 434/24716 [6:10:19<345:32:57, 51.23s/it]  2%|▏         | 435/24716 [6:11:17<359:07:27, 53.25s/it]                                                         {'loss': 0.3475, 'grad_norm': 1.54433307654429, 'learning_rate': 5.862533692722372e-05, 'epoch': 0.02}
  2%|▏         | 435/24716 [6:11:17<359:07:27, 53.25s/it]  2%|▏         | 436/24716 [6:12:03<344:27:14, 51.07s/it]                                                         {'loss': 0.2845, 'grad_norm': 0.913873712927597, 'learning_rate': 5.876010781671159e-05, 'epoch': 0.02}
  2%|▏         | 436/24716 [6:12:03<344:27:14, 51.07s/it]  2%|▏         | 437/24716 [6:12:47<330:19:32, 48.98s/it]                                                         {'loss': 0.2985, 'grad_norm': 0.863603343347342, 'learning_rate': 5.8894878706199467e-05, 'epoch': 0.02}
  2%|▏         | 437/24716 [6:12:47<330:19:32, 48.98s/it]  2%|▏         | 438/24716 [6:13:49<356:32:28, 52.87s/it]                                                         {'loss': 0.2933, 'grad_norm': 0.8558108192778525, 'learning_rate': 5.9029649595687334e-05, 'epoch': 0.02}
  2%|▏         | 438/24716 [6:13:49<356:32:28, 52.87s/it]  2%|▏         | 439/24716 [6:14:29<331:16:14, 49.12s/it]                                                         {'loss': 0.3868, 'grad_norm': 4.868320754257168, 'learning_rate': 5.916442048517521e-05, 'epoch': 0.02}
  2%|▏         | 439/24716 [6:14:29<331:16:14, 49.12s/it]  2%|▏         | 440/24716 [6:15:24<342:06:32, 50.73s/it]                                                         {'loss': 0.2777, 'grad_norm': 0.867160239623214, 'learning_rate': 5.9299191374663074e-05, 'epoch': 0.02}
  2%|▏         | 440/24716 [6:15:24<342:06:32, 50.73s/it]  2%|▏         | 441/24716 [6:16:21<355:38:14, 52.74s/it]                                                         {'loss': 0.3278, 'grad_norm': 0.7432617327732951, 'learning_rate': 5.943396226415094e-05, 'epoch': 0.02}
  2%|▏         | 441/24716 [6:16:21<355:38:14, 52.74s/it]  2%|▏         | 442/24716 [6:17:14<356:36:42, 52.89s/it]                                                         {'loss': 0.2747, 'grad_norm': 0.6301778191065017, 'learning_rate': 5.956873315363881e-05, 'epoch': 0.02}
  2%|▏         | 442/24716 [6:17:14<356:36:42, 52.89s/it]  2%|▏         | 443/24716 [6:18:07<356:26:23, 52.86s/it]                                                         {'loss': 0.2874, 'grad_norm': 0.7062814231143071, 'learning_rate': 5.970350404312669e-05, 'epoch': 0.02}
  2%|▏         | 443/24716 [6:18:07<356:26:23, 52.86s/it]  2%|▏         | 444/24716 [6:18:57<349:14:04, 51.80s/it]                                                         {'loss': 0.294, 'grad_norm': 1.5454267147669483, 'learning_rate': 5.9838274932614556e-05, 'epoch': 0.02}
  2%|▏         | 444/24716 [6:18:57<349:14:04, 51.80s/it]  2%|▏         | 445/24716 [6:19:40<331:59:08, 49.24s/it]                                                         {'loss': 0.2951, 'grad_norm': 0.9443193276931242, 'learning_rate': 5.997304582210242e-05, 'epoch': 0.02}
  2%|▏         | 445/24716 [6:19:40<331:59:08, 49.24s/it]  2%|▏         | 446/24716 [6:20:43<359:40:41, 53.35s/it]                                                         {'loss': 0.2896, 'grad_norm': 0.7633727809838629, 'learning_rate': 6.01078167115903e-05, 'epoch': 0.02}
  2%|▏         | 446/24716 [6:20:43<359:40:41, 53.35s/it]  2%|▏         | 447/24716 [6:21:37<360:53:42, 53.53s/it]                                                         {'loss': 0.2628, 'grad_norm': 0.9146605132983974, 'learning_rate': 6.024258760107817e-05, 'epoch': 0.02}
  2%|▏         | 447/24716 [6:21:37<360:53:42, 53.53s/it]  2%|▏         | 448/24716 [6:22:27<354:10:06, 52.54s/it]                                                         {'loss': 0.316, 'grad_norm': 2.960344848009101, 'learning_rate': 6.037735849056604e-05, 'epoch': 0.02}
  2%|▏         | 448/24716 [6:22:27<354:10:06, 52.54s/it]  2%|▏         | 449/24716 [6:23:15<344:52:53, 51.16s/it]                                                         {'loss': 0.3518, 'grad_norm': 0.739387763722495, 'learning_rate': 6.0512129380053904e-05, 'epoch': 0.02}
  2%|▏         | 449/24716 [6:23:15<344:52:53, 51.16s/it]  2%|▏         | 450/24716 [6:24:20<373:06:39, 55.35s/it]                                                         {'loss': 0.2888, 'grad_norm': 1.2843266446394257, 'learning_rate': 6.0646900269541785e-05, 'epoch': 0.02}
  2%|▏         | 450/24716 [6:24:20<373:06:39, 55.35s/it]  2%|▏         | 451/24716 [6:25:03<347:33:36, 51.56s/it]                                                         {'loss': 0.2807, 'grad_norm': 0.7604040474192346, 'learning_rate': 6.078167115902965e-05, 'epoch': 0.02}
  2%|▏         | 451/24716 [6:25:03<347:33:36, 51.56s/it]  2%|▏         | 452/24716 [6:25:58<355:49:17, 52.79s/it]                                                         {'loss': 0.2399, 'grad_norm': 0.7960365810831947, 'learning_rate': 6.091644204851752e-05, 'epoch': 0.02}
  2%|▏         | 452/24716 [6:25:58<355:49:17, 52.79s/it]  2%|▏         | 453/24716 [6:26:43<339:51:45, 50.43s/it]                                                         {'loss': 0.2535, 'grad_norm': 0.7768161346262438, 'learning_rate': 6.10512129380054e-05, 'epoch': 0.02}
  2%|▏         | 453/24716 [6:26:43<339:51:45, 50.43s/it]  2%|▏         | 454/24716 [6:27:36<345:02:34, 51.20s/it]                                                         {'loss': 0.2639, 'grad_norm': 0.6827360134437979, 'learning_rate': 6.118598382749326e-05, 'epoch': 0.02}
  2%|▏         | 454/24716 [6:27:36<345:02:34, 51.20s/it]  2%|▏         | 455/24716 [6:28:18<326:13:03, 48.41s/it]                                                         {'loss': 0.2687, 'grad_norm': 0.5342965432386912, 'learning_rate': 6.132075471698113e-05, 'epoch': 0.02}
  2%|▏         | 455/24716 [6:28:18<326:13:03, 48.41s/it]  2%|▏         | 456/24716 [6:29:15<343:18:13, 50.94s/it]                                                         {'loss': 0.3296, 'grad_norm': 1.5852820778824706, 'learning_rate': 6.145552560646901e-05, 'epoch': 0.02}
  2%|▏         | 456/24716 [6:29:15<343:18:13, 50.94s/it]  2%|▏         | 457/24716 [6:29:56<323:36:51, 48.02s/it]                                                         {'loss': 0.302, 'grad_norm': 1.3650917057285228, 'learning_rate': 6.159029649595688e-05, 'epoch': 0.02}
  2%|▏         | 457/24716 [6:29:56<323:36:51, 48.02s/it]  2%|▏         | 458/24716 [6:30:48<331:16:23, 49.16s/it]                                                         {'loss': 0.2994, 'grad_norm': 0.9544085297360543, 'learning_rate': 6.172506738544474e-05, 'epoch': 0.02}
  2%|▏         | 458/24716 [6:30:48<331:16:23, 49.16s/it]  2%|▏         | 459/24716 [6:31:36<328:18:02, 48.72s/it]                                                         {'loss': 0.3331, 'grad_norm': 0.762996455643, 'learning_rate': 6.185983827493261e-05, 'epoch': 0.02}
  2%|▏         | 459/24716 [6:31:36<328:18:02, 48.72s/it]  2%|▏         | 460/24716 [6:32:25<328:49:58, 48.80s/it]                                                         {'loss': 0.2635, 'grad_norm': 0.845151968499285, 'learning_rate': 6.199460916442049e-05, 'epoch': 0.02}
  2%|▏         | 460/24716 [6:32:25<328:49:58, 48.80s/it]  2%|▏         | 461/24716 [6:33:19<340:46:32, 50.58s/it]                                                         {'loss': 0.3427, 'grad_norm': 1.2605068276590652, 'learning_rate': 6.212938005390836e-05, 'epoch': 0.02}
  2%|▏         | 461/24716 [6:33:19<340:46:32, 50.58s/it]  2%|▏         | 462/24716 [6:34:19<358:48:38, 53.26s/it]                                                         {'loss': 0.2762, 'grad_norm': 0.6521233352898611, 'learning_rate': 6.226415094339622e-05, 'epoch': 0.02}
  2%|▏         | 462/24716 [6:34:19<358:48:38, 53.26s/it]  2%|▏         | 463/24716 [6:35:13<360:16:28, 53.48s/it]                                                         {'loss': 0.2736, 'grad_norm': 0.7895881038471815, 'learning_rate': 6.239892183288411e-05, 'epoch': 0.02}
  2%|▏         | 463/24716 [6:35:13<360:16:28, 53.48s/it]  2%|▏         | 464/24716 [6:36:12<371:33:01, 55.15s/it]                                                         {'loss': 0.2593, 'grad_norm': 1.0097468034766701, 'learning_rate': 6.253369272237197e-05, 'epoch': 0.02}
  2%|▏         | 464/24716 [6:36:12<371:33:01, 55.15s/it]  2%|▏         | 465/24716 [6:37:07<371:13:03, 55.11s/it]                                                         {'loss': 0.2307, 'grad_norm': 1.9988496526138155, 'learning_rate': 6.266846361185984e-05, 'epoch': 0.02}
  2%|▏         | 465/24716 [6:37:07<371:13:03, 55.11s/it]  2%|▏         | 466/24716 [6:38:00<366:37:11, 54.43s/it]                                                         {'loss': 0.2988, 'grad_norm': 1.0867449777773375, 'learning_rate': 6.28032345013477e-05, 'epoch': 0.02}
  2%|▏         | 466/24716 [6:38:00<366:37:11, 54.43s/it]  2%|▏         | 467/24716 [6:38:57<371:45:49, 55.19s/it]                                                         {'loss': 0.2433, 'grad_norm': 0.5594536292358512, 'learning_rate': 6.293800539083559e-05, 'epoch': 0.02}
  2%|▏         | 467/24716 [6:38:57<371:45:49, 55.19s/it]  2%|▏         | 468/24716 [6:39:59<385:56:02, 57.30s/it]                                                         {'loss': 0.2593, 'grad_norm': 0.8984687205369083, 'learning_rate': 6.307277628032345e-05, 'epoch': 0.02}
  2%|▏         | 468/24716 [6:39:59<385:56:02, 57.30s/it]  2%|▏         | 469/24716 [6:40:45<363:51:31, 54.02s/it]                                                         {'loss': 0.2851, 'grad_norm': 0.6314151607244203, 'learning_rate': 6.320754716981132e-05, 'epoch': 0.02}
  2%|▏         | 469/24716 [6:40:45<363:51:31, 54.02s/it]  2%|▏         | 470/24716 [6:41:35<355:13:22, 52.74s/it]                                                         {'loss': 0.296, 'grad_norm': 0.9138880066476508, 'learning_rate': 6.33423180592992e-05, 'epoch': 0.02}
  2%|▏         | 470/24716 [6:41:35<355:13:22, 52.74s/it]  2%|▏         | 471/24716 [6:42:32<362:27:23, 53.82s/it]                                                         {'loss': 0.2819, 'grad_norm': 0.7491148145943646, 'learning_rate': 6.347708894878707e-05, 'epoch': 0.02}
  2%|▏         | 471/24716 [6:42:32<362:27:23, 53.82s/it]  2%|▏         | 472/24716 [6:43:21<354:32:52, 52.65s/it]                                                         {'loss': 0.2318, 'grad_norm': 0.5141047885150066, 'learning_rate': 6.361185983827493e-05, 'epoch': 0.02}
  2%|▏         | 472/24716 [6:43:21<354:32:52, 52.65s/it]  2%|▏         | 473/24716 [6:44:14<354:54:05, 52.70s/it]                                                         {'loss': 0.2284, 'grad_norm': 1.1643371369075919, 'learning_rate': 6.37466307277628e-05, 'epoch': 0.02}
  2%|▏         | 473/24716 [6:44:14<354:54:05, 52.70s/it]  2%|▏         | 474/24716 [6:45:02<345:29:23, 51.31s/it]                                                         {'loss': 0.3169, 'grad_norm': 0.932334156342701, 'learning_rate': 6.388140161725068e-05, 'epoch': 0.02}
  2%|▏         | 474/24716 [6:45:02<345:29:23, 51.31s/it]  2%|▏         | 475/24716 [6:45:55<347:18:58, 51.58s/it]                                                         {'loss': 0.3312, 'grad_norm': 0.8838027352367038, 'learning_rate': 6.401617250673855e-05, 'epoch': 0.02}
  2%|▏         | 475/24716 [6:45:55<347:18:58, 51.58s/it]  2%|▏         | 476/24716 [6:46:52<358:30:29, 53.24s/it]                                                         {'loss': 0.3051, 'grad_norm': 1.5681641699064637, 'learning_rate': 6.415094339622641e-05, 'epoch': 0.02}
  2%|▏         | 476/24716 [6:46:52<358:30:29, 53.24s/it]  2%|▏         | 477/24716 [6:47:45<358:40:07, 53.27s/it]                                                         {'loss': 0.2889, 'grad_norm': 2.051513507450734, 'learning_rate': 6.428571428571429e-05, 'epoch': 0.02}
  2%|▏         | 477/24716 [6:47:45<358:40:07, 53.27s/it]  2%|▏         | 478/24716 [6:48:39<359:55:59, 53.46s/it]                                                         {'loss': 0.2369, 'grad_norm': 0.8187455795429862, 'learning_rate': 6.442048517520216e-05, 'epoch': 0.02}
  2%|▏         | 478/24716 [6:48:39<359:55:59, 53.46s/it]  2%|▏         | 479/24716 [6:49:33<362:10:15, 53.79s/it]                                                         {'loss': 0.3077, 'grad_norm': 1.8580176743832344, 'learning_rate': 6.455525606469002e-05, 'epoch': 0.02}
  2%|▏         | 479/24716 [6:49:33<362:10:15, 53.79s/it]  2%|▏         | 480/24716 [6:50:23<352:49:49, 52.41s/it]                                                         {'loss': 0.3344, 'grad_norm': 0.8495838438446783, 'learning_rate': 6.46900269541779e-05, 'epoch': 0.02}
  2%|▏         | 480/24716 [6:50:23<352:49:49, 52.41s/it]  2%|▏         | 481/24716 [6:51:19<361:45:36, 53.74s/it]                                                         {'loss': 0.2935, 'grad_norm': 0.7926683178318316, 'learning_rate': 6.482479784366577e-05, 'epoch': 0.02}
  2%|▏         | 481/24716 [6:51:19<361:45:36, 53.74s/it]  2%|▏         | 482/24716 [6:52:05<344:15:45, 51.14s/it]                                                         {'loss': 0.2837, 'grad_norm': 1.3762072271341377, 'learning_rate': 6.495956873315364e-05, 'epoch': 0.02}
  2%|▏         | 482/24716 [6:52:05<344:15:45, 51.14s/it]  2%|▏         | 483/24716 [6:53:00<352:05:19, 52.31s/it]                                                         {'loss': 0.2737, 'grad_norm': 0.7943900446130896, 'learning_rate': 6.50943396226415e-05, 'epoch': 0.02}
  2%|▏         | 483/24716 [6:53:00<352:05:19, 52.31s/it]  2%|▏         | 484/24716 [6:53:59<367:14:57, 54.56s/it]                                                         {'loss': 0.2749, 'grad_norm': 4.085986413512756, 'learning_rate': 6.522911051212939e-05, 'epoch': 0.02}
  2%|▏         | 484/24716 [6:53:59<367:14:57, 54.56s/it]  2%|▏         | 485/24716 [6:54:41<341:16:23, 50.70s/it]                                                         {'loss': 0.2564, 'grad_norm': 0.9646275717843893, 'learning_rate': 6.536388140161725e-05, 'epoch': 0.02}
  2%|▏         | 485/24716 [6:54:41<341:16:23, 50.70s/it]  2%|▏         | 486/24716 [6:55:36<349:12:12, 51.88s/it]                                                         {'loss': 0.2462, 'grad_norm': 1.2357454524088591, 'learning_rate': 6.549865229110512e-05, 'epoch': 0.02}
  2%|▏         | 486/24716 [6:55:36<349:12:12, 51.88s/it]  2%|▏         | 487/24716 [6:56:37<368:43:43, 54.79s/it]                                                         {'loss': 0.2883, 'grad_norm': 0.6311352494534833, 'learning_rate': 6.563342318059298e-05, 'epoch': 0.02}
  2%|▏         | 487/24716 [6:56:37<368:43:43, 54.79s/it]  2%|▏         | 488/24716 [6:57:17<338:35:44, 50.31s/it]                                                         {'loss': 0.2533, 'grad_norm': 0.6489727244042108, 'learning_rate': 6.576819407008087e-05, 'epoch': 0.02}
  2%|▏         | 488/24716 [6:57:17<338:35:44, 50.31s/it]  2%|▏         | 489/24716 [6:58:02<327:14:09, 48.63s/it]                                                         {'loss': 0.308, 'grad_norm': 0.778931501497209, 'learning_rate': 6.590296495956873e-05, 'epoch': 0.02}
  2%|▏         | 489/24716 [6:58:02<327:14:09, 48.63s/it]  2%|▏         | 490/24716 [6:58:51<328:34:38, 48.83s/it]                                                         {'loss': 0.2238, 'grad_norm': 0.9433805033570615, 'learning_rate': 6.60377358490566e-05, 'epoch': 0.02}
  2%|▏         | 490/24716 [6:58:51<328:34:38, 48.83s/it]  2%|▏         | 491/24716 [6:59:43<333:38:28, 49.58s/it]                                                         {'loss': 0.2684, 'grad_norm': 0.667472569413627, 'learning_rate': 6.617250673854448e-05, 'epoch': 0.02}
  2%|▏         | 491/24716 [6:59:43<333:38:28, 49.58s/it]  2%|▏         | 492/24716 [7:00:31<331:31:31, 49.27s/it]                                                         {'loss': 0.2893, 'grad_norm': 0.9331167006334949, 'learning_rate': 6.630727762803235e-05, 'epoch': 0.02}
  2%|▏         | 492/24716 [7:00:31<331:31:31, 49.27s/it]  2%|▏         | 493/24716 [7:01:23<337:09:02, 50.11s/it]                                                         {'loss': 0.2712, 'grad_norm': 0.5923214693158809, 'learning_rate': 6.644204851752021e-05, 'epoch': 0.02}
  2%|▏         | 493/24716 [7:01:23<337:09:02, 50.11s/it]  2%|▏         | 494/24716 [7:02:17<344:15:19, 51.17s/it]                                                         {'loss': 0.2618, 'grad_norm': 0.672612227315269, 'learning_rate': 6.657681940700809e-05, 'epoch': 0.02}
  2%|▏         | 494/24716 [7:02:17<344:15:19, 51.17s/it]  2%|▏         | 495/24716 [7:03:20<369:13:49, 54.88s/it]                                                         {'loss': 0.2889, 'grad_norm': 0.8636882953341595, 'learning_rate': 6.671159029649596e-05, 'epoch': 0.02}
  2%|▏         | 495/24716 [7:03:20<369:13:49, 54.88s/it]  2%|▏         | 496/24716 [7:04:12<361:51:23, 53.79s/it]                                                         {'loss': 0.3338, 'grad_norm': 0.9792563221346511, 'learning_rate': 6.684636118598383e-05, 'epoch': 0.02}
  2%|▏         | 496/24716 [7:04:12<361:51:23, 53.79s/it]  2%|▏         | 497/24716 [7:05:06<363:40:00, 54.06s/it]                                                         {'loss': 0.257, 'grad_norm': 1.3715267003501093, 'learning_rate': 6.69811320754717e-05, 'epoch': 0.02}
  2%|▏         | 497/24716 [7:05:06<363:40:00, 54.06s/it]  2%|▏         | 498/24716 [7:06:01<364:47:35, 54.23s/it]                                                         {'loss': 0.257, 'grad_norm': 0.9382666456897149, 'learning_rate': 6.711590296495958e-05, 'epoch': 0.02}
  2%|▏         | 498/24716 [7:06:01<364:47:35, 54.23s/it]  2%|▏         | 499/24716 [7:06:51<355:48:57, 52.89s/it]                                                         {'loss': 0.3304, 'grad_norm': 0.6818302451339672, 'learning_rate': 6.725067385444744e-05, 'epoch': 0.02}
  2%|▏         | 499/24716 [7:06:51<355:48:57, 52.89s/it]  2%|▏         | 500/24716 [7:07:39<347:00:40, 51.59s/it]                                                         {'loss': 0.3375, 'grad_norm': 0.7537361042194017, 'learning_rate': 6.738544474393532e-05, 'epoch': 0.02}
  2%|▏         | 500/24716 [7:07:39<347:00:40, 51.59s/it]  2%|▏         | 501/24716 [7:08:28<341:31:35, 50.77s/it]                                                         {'loss': 0.2884, 'grad_norm': 0.7892124126910307, 'learning_rate': 6.752021563342318e-05, 'epoch': 0.02}
  2%|▏         | 501/24716 [7:08:28<341:31:35, 50.77s/it]  2%|▏         | 502/24716 [7:09:20<343:40:50, 51.10s/it]                                                         {'loss': 0.3281, 'grad_norm': 0.7219802702616533, 'learning_rate': 6.765498652291105e-05, 'epoch': 0.02}
  2%|▏         | 502/24716 [7:09:20<343:40:50, 51.10s/it]  2%|▏         | 503/24716 [7:10:21<363:46:20, 54.09s/it]                                                         {'loss': 0.2985, 'grad_norm': 0.7612729866589044, 'learning_rate': 6.778975741239892e-05, 'epoch': 0.02}
  2%|▏         | 503/24716 [7:10:21<363:46:20, 54.09s/it]  2%|▏         | 504/24716 [7:11:04<341:16:46, 50.74s/it]                                                         {'loss': 0.3182, 'grad_norm': 0.8033037061076456, 'learning_rate': 6.79245283018868e-05, 'epoch': 0.02}
  2%|▏         | 504/24716 [7:11:04<341:16:46, 50.74s/it]  2%|▏         | 505/24716 [7:12:06<363:23:23, 54.03s/it]                                                         {'loss': 0.2673, 'grad_norm': 0.6873935003389973, 'learning_rate': 6.805929919137467e-05, 'epoch': 0.02}
  2%|▏         | 505/24716 [7:12:06<363:23:23, 54.03s/it]  2%|▏         | 506/24716 [7:12:56<355:53:15, 52.92s/it]                                                         {'loss': 0.2885, 'grad_norm': 0.7112263360024951, 'learning_rate': 6.819407008086253e-05, 'epoch': 0.02}
  2%|▏         | 506/24716 [7:12:56<355:53:15, 52.92s/it]  2%|▏         | 507/24716 [7:13:54<365:47:36, 54.40s/it]                                                         {'loss': 0.3141, 'grad_norm': 0.5800282932144233, 'learning_rate': 6.83288409703504e-05, 'epoch': 0.02}
  2%|▏         | 507/24716 [7:13:54<365:47:36, 54.40s/it]  2%|▏         | 508/24716 [7:14:52<373:02:01, 55.47s/it]                                                         {'loss': 0.2762, 'grad_norm': 0.9338200782327604, 'learning_rate': 6.846361185983828e-05, 'epoch': 0.02}
  2%|▏         | 508/24716 [7:14:52<373:02:01, 55.47s/it]  2%|▏         | 509/24716 [7:15:40<357:41:49, 53.20s/it]                                                         {'loss': 0.298, 'grad_norm': 0.7486505329262817, 'learning_rate': 6.859838274932615e-05, 'epoch': 0.02}
  2%|▏         | 509/24716 [7:15:40<357:41:49, 53.20s/it]  2%|▏         | 510/24716 [7:16:43<377:58:04, 56.21s/it]                                                         {'loss': 0.3109, 'grad_norm': 0.7332505066262273, 'learning_rate': 6.873315363881401e-05, 'epoch': 0.02}
  2%|▏         | 510/24716 [7:16:43<377:58:04, 56.21s/it]  2%|▏         | 511/24716 [7:17:29<357:55:38, 53.23s/it]                                                         {'loss': 0.3075, 'grad_norm': 0.7489630841756116, 'learning_rate': 6.886792452830189e-05, 'epoch': 0.02}
  2%|▏         | 511/24716 [7:17:29<357:55:38, 53.23s/it]  2%|▏         | 512/24716 [7:18:24<361:32:17, 53.77s/it]                                                         {'loss': 0.3441, 'grad_norm': 0.8159505969265114, 'learning_rate': 6.900269541778976e-05, 'epoch': 0.02}
  2%|▏         | 512/24716 [7:18:24<361:32:17, 53.77s/it]  2%|▏         | 513/24716 [7:19:22<368:45:02, 54.85s/it]                                                         {'loss': 0.2888, 'grad_norm': 0.8700995686664603, 'learning_rate': 6.913746630727763e-05, 'epoch': 0.02}
  2%|▏         | 513/24716 [7:19:22<368:45:02, 54.85s/it]  2%|▏         | 514/24716 [7:20:22<380:33:46, 56.61s/it]                                                         {'loss': 0.2728, 'grad_norm': 0.8003505331313044, 'learning_rate': 6.92722371967655e-05, 'epoch': 0.02}
  2%|▏         | 514/24716 [7:20:22<380:33:46, 56.61s/it]  2%|▏         | 515/24716 [7:21:04<351:16:08, 52.25s/it]                                                         {'loss': 0.2781, 'grad_norm': 1.0524470837437063, 'learning_rate': 6.940700808625338e-05, 'epoch': 0.02}
  2%|▏         | 515/24716 [7:21:04<351:16:08, 52.25s/it]  2%|▏         | 516/24716 [7:21:51<338:58:30, 50.43s/it]                                                         {'loss': 0.272, 'grad_norm': 0.6191227843491643, 'learning_rate': 6.954177897574124e-05, 'epoch': 0.02}
  2%|▏         | 516/24716 [7:21:51<338:58:30, 50.43s/it]  2%|▏         | 517/24716 [7:22:49<354:40:39, 52.76s/it]                                                         {'loss': 0.2985, 'grad_norm': 0.5907547633259752, 'learning_rate': 6.967654986522912e-05, 'epoch': 0.02}
  2%|▏         | 517/24716 [7:22:49<354:40:39, 52.76s/it]  2%|▏         | 518/24716 [7:23:33<337:34:17, 50.22s/it]                                                         {'loss': 0.2082, 'grad_norm': 0.4785618547116373, 'learning_rate': 6.981132075471698e-05, 'epoch': 0.02}
  2%|▏         | 518/24716 [7:23:33<337:34:17, 50.22s/it]  2%|▏         | 519/24716 [7:24:18<327:57:18, 48.79s/it]                                                         {'loss': 0.2622, 'grad_norm': 0.6810642492119183, 'learning_rate': 6.994609164420486e-05, 'epoch': 0.02}
  2%|▏         | 519/24716 [7:24:19<327:57:18, 48.79s/it]  2%|▏         | 520/24716 [7:25:04<322:07:46, 47.93s/it]                                                         {'loss': 0.1803, 'grad_norm': 0.6449150385281225, 'learning_rate': 7.008086253369272e-05, 'epoch': 0.02}
  2%|▏         | 520/24716 [7:25:04<322:07:46, 47.93s/it]  2%|▏         | 521/24716 [7:25:53<323:06:29, 48.08s/it]                                                         {'loss': 0.2654, 'grad_norm': 0.9085051117802772, 'learning_rate': 7.02156334231806e-05, 'epoch': 0.02}
  2%|▏         | 521/24716 [7:25:53<323:06:29, 48.08s/it]  2%|▏         | 522/24716 [7:26:42<324:54:28, 48.35s/it]                                                         {'loss': 0.1965, 'grad_norm': 0.48790897465723276, 'learning_rate': 7.035040431266847e-05, 'epoch': 0.02}
  2%|▏         | 522/24716 [7:26:42<324:54:28, 48.35s/it]  2%|▏         | 523/24716 [7:27:28<321:12:30, 47.80s/it]                                                         {'loss': 0.2489, 'grad_norm': 2.4430122872830466, 'learning_rate': 7.048517520215634e-05, 'epoch': 0.02}
  2%|▏         | 523/24716 [7:27:28<321:12:30, 47.80s/it]  2%|▏         | 524/24716 [7:28:26<340:52:17, 50.72s/it]                                                         {'loss': 0.2799, 'grad_norm': 0.8126705590820107, 'learning_rate': 7.06199460916442e-05, 'epoch': 0.02}
  2%|▏         | 524/24716 [7:28:26<340:52:17, 50.72s/it]  2%|▏         | 525/24716 [7:29:29<364:55:08, 54.31s/it]                                                         {'loss': 0.274, 'grad_norm': 0.8257895042088566, 'learning_rate': 7.075471698113208e-05, 'epoch': 0.02}
  2%|▏         | 525/24716 [7:29:29<364:55:08, 54.31s/it]  2%|▏         | 526/24716 [7:30:21<361:36:05, 53.81s/it]                                                         {'loss': 0.2684, 'grad_norm': 2.5283643371035835, 'learning_rate': 7.088948787061995e-05, 'epoch': 0.02}
  2%|▏         | 526/24716 [7:30:21<361:36:05, 53.81s/it]  2%|▏         | 527/24716 [7:31:14<358:35:13, 53.37s/it]                                                         {'loss': 0.2349, 'grad_norm': 0.43522104189995786, 'learning_rate': 7.102425876010783e-05, 'epoch': 0.02}
  2%|▏         | 527/24716 [7:31:14<358:35:13, 53.37s/it]  2%|▏         | 528/24716 [7:32:06<356:19:42, 53.03s/it]                                                         {'loss': 0.2474, 'grad_norm': 0.647625287080145, 'learning_rate': 7.115902964959569e-05, 'epoch': 0.02}
  2%|▏         | 528/24716 [7:32:06<356:19:42, 53.03s/it]  2%|▏         | 529/24716 [7:32:50<339:24:16, 50.52s/it]                                                         {'loss': 0.2861, 'grad_norm': 1.5906288433566333, 'learning_rate': 7.129380053908356e-05, 'epoch': 0.02}
  2%|▏         | 529/24716 [7:32:50<339:24:16, 50.52s/it]  2%|▏         | 530/24716 [7:33:39<336:26:29, 50.08s/it]                                                         {'loss': 0.2424, 'grad_norm': 1.0284597754225924, 'learning_rate': 7.142857142857143e-05, 'epoch': 0.02}
  2%|▏         | 530/24716 [7:33:39<336:26:29, 50.08s/it]  2%|▏         | 531/24716 [7:34:36<349:37:35, 52.04s/it]                                                         {'loss': 0.2296, 'grad_norm': 2.053529206784906, 'learning_rate': 7.156334231805931e-05, 'epoch': 0.02}
  2%|▏         | 531/24716 [7:34:36<349:37:35, 52.04s/it]  2%|▏         | 532/24716 [7:35:39<370:33:53, 55.16s/it]                                                         {'loss': 0.2883, 'grad_norm': 0.7437117103095209, 'learning_rate': 7.169811320754717e-05, 'epoch': 0.02}
  2%|▏         | 532/24716 [7:35:39<370:33:53, 55.16s/it]  2%|▏         | 533/24716 [7:36:15<332:59:55, 49.57s/it]                                                         {'loss': 0.2635, 'grad_norm': 0.8116415774234222, 'learning_rate': 7.183288409703504e-05, 'epoch': 0.02}
  2%|▏         | 533/24716 [7:36:15<332:59:55, 49.57s/it]  2%|▏         | 534/24716 [7:37:08<340:04:55, 50.63s/it]                                                         {'loss': 0.2684, 'grad_norm': 0.6570887227009827, 'learning_rate': 7.196765498652292e-05, 'epoch': 0.02}
  2%|▏         | 534/24716 [7:37:08<340:04:55, 50.63s/it]  2%|▏         | 535/24716 [7:38:05<353:03:39, 52.56s/it]                                                         {'loss': 0.8751, 'grad_norm': 6.632053103832002, 'learning_rate': 7.210242587601078e-05, 'epoch': 0.02}
  2%|▏         | 535/24716 [7:38:05<353:03:39, 52.56s/it]  2%|▏         | 536/24716 [7:38:51<339:40:53, 50.57s/it]                                                         {'loss': 0.2998, 'grad_norm': 0.6377028622980917, 'learning_rate': 7.223719676549866e-05, 'epoch': 0.02}
  2%|▏         | 536/24716 [7:38:51<339:40:53, 50.57s/it]  2%|▏         | 537/24716 [7:39:57<370:50:53, 55.22s/it]                                                         {'loss': 0.3066, 'grad_norm': 0.796692704777415, 'learning_rate': 7.237196765498652e-05, 'epoch': 0.02}
  2%|▏         | 537/24716 [7:39:57<370:50:53, 55.22s/it]  2%|▏         | 538/24716 [7:40:49<363:31:03, 54.13s/it]                                                         {'loss': 0.2959, 'grad_norm': 0.5668824700445183, 'learning_rate': 7.25067385444744e-05, 'epoch': 0.02}
  2%|▏         | 538/24716 [7:40:49<363:31:03, 54.13s/it]  2%|▏         | 539/24716 [7:41:37<351:49:39, 52.39s/it]                                                         {'loss': 0.2644, 'grad_norm': 0.5438175314758017, 'learning_rate': 7.264150943396226e-05, 'epoch': 0.02}
  2%|▏         | 539/24716 [7:41:37<351:49:39, 52.39s/it]  2%|▏         | 540/24716 [7:42:31<354:54:51, 52.85s/it]                                                         {'loss': 0.3505, 'grad_norm': 3.482715917801436, 'learning_rate': 7.277628032345014e-05, 'epoch': 0.02}
  2%|▏         | 540/24716 [7:42:31<354:54:51, 52.85s/it]  2%|▏         | 541/24716 [7:43:21<349:13:02, 52.00s/it]                                                         {'loss': 0.2529, 'grad_norm': 0.6049319548592796, 'learning_rate': 7.2911051212938e-05, 'epoch': 0.02}
  2%|▏         | 541/24716 [7:43:21<349:13:02, 52.00s/it]  2%|▏         | 542/24716 [7:44:19<360:42:58, 53.72s/it]                                                         {'loss': 0.266, 'grad_norm': 1.1519692103300878, 'learning_rate': 7.304582210242588e-05, 'epoch': 0.02}
  2%|▏         | 542/24716 [7:44:19<360:42:58, 53.72s/it]  2%|▏         | 543/24716 [7:45:15<364:40:00, 54.31s/it]                                                         {'loss': 0.2247, 'grad_norm': 0.441586851441672, 'learning_rate': 7.318059299191375e-05, 'epoch': 0.02}
  2%|▏         | 543/24716 [7:45:15<364:40:00, 54.31s/it]  2%|▏         | 544/24716 [7:45:51<329:04:03, 49.01s/it]                                                         {'loss': 0.2652, 'grad_norm': 0.5292931639088665, 'learning_rate': 7.331536388140163e-05, 'epoch': 0.02}
  2%|▏         | 544/24716 [7:45:51<329:04:03, 49.01s/it]  2%|▏         | 545/24716 [7:46:41<330:02:37, 49.16s/it]                                                         {'loss': 0.2538, 'grad_norm': 0.6962436760240062, 'learning_rate': 7.345013477088949e-05, 'epoch': 0.02}
  2%|▏         | 545/24716 [7:46:41<330:02:37, 49.16s/it]  2%|▏         | 546/24716 [7:47:30<330:29:12, 49.22s/it]                                                         {'loss': 0.2394, 'grad_norm': 1.0818236808203303, 'learning_rate': 7.358490566037736e-05, 'epoch': 0.02}
  2%|▏         | 546/24716 [7:47:30<330:29:12, 49.22s/it]  2%|▏         | 547/24716 [7:48:21<333:16:10, 49.64s/it]                                                         {'loss': 0.2797, 'grad_norm': 0.5982861954083274, 'learning_rate': 7.371967654986523e-05, 'epoch': 0.02}
  2%|▏         | 547/24716 [7:48:21<333:16:10, 49.64s/it]  2%|▏         | 548/24716 [7:49:22<356:39:59, 53.13s/it]                                                         {'loss': 0.2702, 'grad_norm': 0.7459310697405857, 'learning_rate': 7.385444743935311e-05, 'epoch': 0.02}
  2%|▏         | 548/24716 [7:49:22<356:39:59, 53.13s/it]  2%|▏         | 549/24716 [7:50:09<343:56:33, 51.23s/it]                                                         {'loss': 0.2915, 'grad_norm': 0.9508432579900048, 'learning_rate': 7.398921832884097e-05, 'epoch': 0.02}
  2%|▏         | 549/24716 [7:50:09<343:56:33, 51.23s/it]  2%|▏         | 550/24716 [7:51:11<365:11:44, 54.40s/it]                                                         {'loss': 0.3231, 'grad_norm': 1.02034783058718, 'learning_rate': 7.412398921832885e-05, 'epoch': 0.02}
  2%|▏         | 550/24716 [7:51:11<365:11:44, 54.40s/it]  2%|▏         | 551/24716 [7:52:03<362:14:22, 53.96s/it]                                                         {'loss': 0.2495, 'grad_norm': 0.7267508408306712, 'learning_rate': 7.425876010781671e-05, 'epoch': 0.02}
  2%|▏         | 551/24716 [7:52:03<362:14:22, 53.96s/it]  2%|▏         | 552/24716 [7:52:57<361:25:02, 53.84s/it]                                                         {'loss': 0.2556, 'grad_norm': 0.5678443935325446, 'learning_rate': 7.439353099730459e-05, 'epoch': 0.02}
  2%|▏         | 552/24716 [7:52:57<361:25:02, 53.84s/it]  2%|▏         | 553/24716 [7:53:48<356:10:41, 53.07s/it]                                                         {'loss': 0.3159, 'grad_norm': 1.2439352946794813, 'learning_rate': 7.452830188679245e-05, 'epoch': 0.02}
  2%|▏         | 553/24716 [7:53:48<356:10:41, 53.07s/it]  2%|▏         | 554/24716 [7:54:36<345:15:57, 51.44s/it]                                                         {'loss': 0.2344, 'grad_norm': 0.5956279801894749, 'learning_rate': 7.466307277628034e-05, 'epoch': 0.02}
  2%|▏         | 554/24716 [7:54:36<345:15:57, 51.44s/it]  2%|▏         | 555/24716 [7:55:25<340:32:11, 50.74s/it]                                                         {'loss': 0.2552, 'grad_norm': 1.0121963822387225, 'learning_rate': 7.47978436657682e-05, 'epoch': 0.02}
  2%|▏         | 555/24716 [7:55:25<340:32:11, 50.74s/it]  2%|▏         | 556/24716 [7:56:06<321:11:30, 47.86s/it]                                                         {'loss': 0.2386, 'grad_norm': 0.6412872883295215, 'learning_rate': 7.493261455525607e-05, 'epoch': 0.02}
  2%|▏         | 556/24716 [7:56:06<321:11:30, 47.86s/it]  2%|▏         | 557/24716 [7:56:51<314:23:33, 46.85s/it]                                                         {'loss': 0.3315, 'grad_norm': 1.4364440031032053, 'learning_rate': 7.506738544474394e-05, 'epoch': 0.02}
  2%|▏         | 557/24716 [7:56:51<314:23:33, 46.85s/it]  2%|▏         | 558/24716 [7:57:31<301:53:10, 44.99s/it]                                                         {'loss': 0.2722, 'grad_norm': 1.0925496205658307, 'learning_rate': 7.52021563342318e-05, 'epoch': 0.02}
  2%|▏         | 558/24716 [7:57:31<301:53:10, 44.99s/it]  2%|▏         | 559/24716 [7:58:27<322:43:30, 48.09s/it]                                                         {'loss': 0.2416, 'grad_norm': 0.5193482286528904, 'learning_rate': 7.533692722371968e-05, 'epoch': 0.02}
  2%|▏         | 559/24716 [7:58:27<322:43:30, 48.09s/it]  2%|▏         | 560/24716 [7:59:13<318:46:48, 47.51s/it]                                                         {'loss': 0.2921, 'grad_norm': 0.7924771893390582, 'learning_rate': 7.547169811320755e-05, 'epoch': 0.02}
  2%|▏         | 560/24716 [7:59:13<318:46:48, 47.51s/it]  2%|▏         | 561/24716 [8:00:12<342:15:38, 51.01s/it]                                                         {'loss': 0.2334, 'grad_norm': 0.6277466279116575, 'learning_rate': 7.560646900269543e-05, 'epoch': 0.02}
  2%|▏         | 561/24716 [8:00:12<342:15:38, 51.01s/it]  2%|▏         | 562/24716 [8:00:48<312:58:52, 46.65s/it]                                                         {'loss': 0.1797, 'grad_norm': 1.6850356764934906, 'learning_rate': 7.574123989218329e-05, 'epoch': 0.02}
  2%|▏         | 562/24716 [8:00:48<312:58:52, 46.65s/it]  2%|▏         | 563/24716 [8:01:49<341:11:17, 50.85s/it]                                                         {'loss': 0.2862, 'grad_norm': 0.8117665115934292, 'learning_rate': 7.587601078167116e-05, 'epoch': 0.02}
  2%|▏         | 563/24716 [8:01:49<341:11:17, 50.85s/it]  2%|▏         | 564/24716 [8:02:40<340:39:27, 50.78s/it]                                                         {'loss': 0.2535, 'grad_norm': 0.5366415624202747, 'learning_rate': 7.601078167115903e-05, 'epoch': 0.02}
  2%|▏         | 564/24716 [8:02:40<340:39:27, 50.78s/it]  2%|▏         | 565/24716 [8:03:16<311:39:49, 46.46s/it]                                                         {'loss': 0.2771, 'grad_norm': 0.9917066240881304, 'learning_rate': 7.61455525606469e-05, 'epoch': 0.02}
  2%|▏         | 565/24716 [8:03:16<311:39:49, 46.46s/it]  2%|▏         | 566/24716 [8:04:12<330:17:09, 49.24s/it]                                                         {'loss': 0.3181, 'grad_norm': 1.1139879678423354, 'learning_rate': 7.628032345013477e-05, 'epoch': 0.02}
  2%|▏         | 566/24716 [8:04:12<330:17:09, 49.24s/it]  2%|▏         | 567/24716 [8:04:48<303:56:43, 45.31s/it]                                                         {'loss': 0.2145, 'grad_norm': 0.5366870802899508, 'learning_rate': 7.641509433962265e-05, 'epoch': 0.02}
  2%|▏         | 567/24716 [8:04:48<303:56:43, 45.31s/it]  2%|▏         | 568/24716 [8:05:30<297:29:39, 44.35s/it]                                                         {'loss': 0.2629, 'grad_norm': 0.5601236983858626, 'learning_rate': 7.654986522911051e-05, 'epoch': 0.02}
  2%|▏         | 568/24716 [8:05:30<297:29:39, 44.35s/it]  2%|▏         | 569/24716 [8:06:11<289:47:05, 43.20s/it]                                                         {'loss': 0.268, 'grad_norm': 1.2519264932006235, 'learning_rate': 7.668463611859839e-05, 'epoch': 0.02}
  2%|▏         | 569/24716 [8:06:11<289:47:05, 43.20s/it]  2%|▏         | 570/24716 [8:07:07<316:04:27, 47.12s/it]                                                         {'loss': 0.2809, 'grad_norm': 0.5428097921522925, 'learning_rate': 7.681940700808625e-05, 'epoch': 0.02}
  2%|▏         | 570/24716 [8:07:07<316:04:27, 47.12s/it]  2%|▏         | 571/24716 [8:07:57<321:15:30, 47.90s/it]                                                         {'loss': 0.2735, 'grad_norm': 2.024276274110971, 'learning_rate': 7.695417789757414e-05, 'epoch': 0.02}
  2%|▏         | 571/24716 [8:07:57<321:15:30, 47.90s/it]  2%|▏         | 572/24716 [8:08:47<326:48:30, 48.73s/it]                                                         {'loss': 0.2344, 'grad_norm': 0.4941434689730373, 'learning_rate': 7.7088948787062e-05, 'epoch': 0.02}
  2%|▏         | 572/24716 [8:08:47<326:48:30, 48.73s/it]  2%|▏         | 573/24716 [8:09:45<344:56:22, 51.43s/it]                                                         {'loss': 0.2288, 'grad_norm': 0.5463509395912547, 'learning_rate': 7.722371967654987e-05, 'epoch': 0.02}
  2%|▏         | 573/24716 [8:09:45<344:56:22, 51.43s/it]  2%|▏         | 574/24716 [8:10:37<346:44:36, 51.71s/it]                                                         {'loss': 0.2945, 'grad_norm': 0.6775807298732986, 'learning_rate': 7.735849056603774e-05, 'epoch': 0.02}
  2%|▏         | 574/24716 [8:10:37<346:44:36, 51.71s/it]  2%|▏         | 575/24716 [8:11:29<347:37:27, 51.84s/it]                                                         {'loss': 0.3282, 'grad_norm': 0.685647047313233, 'learning_rate': 7.749326145552562e-05, 'epoch': 0.02}
  2%|▏         | 575/24716 [8:11:29<347:37:27, 51.84s/it]  2%|▏         | 576/24716 [8:12:29<363:02:19, 54.14s/it]                                                         {'loss': 0.2583, 'grad_norm': 0.7789885847728661, 'learning_rate': 7.762803234501348e-05, 'epoch': 0.02}
  2%|▏         | 576/24716 [8:12:29<363:02:19, 54.14s/it]  2%|▏         | 577/24716 [8:13:23<362:12:32, 54.02s/it]                                                         {'loss': 0.2835, 'grad_norm': 1.9036498569956868, 'learning_rate': 7.776280323450135e-05, 'epoch': 0.02}
  2%|▏         | 577/24716 [8:13:23<362:12:32, 54.02s/it]  2%|▏         | 578/24716 [8:14:16<360:32:38, 53.77s/it]                                                         {'loss': 0.307, 'grad_norm': 1.6199985270091568, 'learning_rate': 7.789757412398922e-05, 'epoch': 0.02}
  2%|▏         | 578/24716 [8:14:16<360:32:38, 53.77s/it]  2%|▏         | 579/24716 [8:15:02<345:18:39, 51.50s/it]                                                         {'loss': 0.2316, 'grad_norm': 0.5841124599985753, 'learning_rate': 7.80323450134771e-05, 'epoch': 0.02}
  2%|▏         | 579/24716 [8:15:02<345:18:39, 51.50s/it]  2%|▏         | 580/24716 [8:15:53<343:23:13, 51.22s/it]                                                         {'loss': 0.2619, 'grad_norm': 1.093586771421683, 'learning_rate': 7.816711590296496e-05, 'epoch': 0.02}
  2%|▏         | 580/24716 [8:15:53<343:23:13, 51.22s/it]  2%|▏         | 581/24716 [8:16:49<354:17:07, 52.85s/it]                                                         {'loss': 0.2908, 'grad_norm': 0.6791197949226346, 'learning_rate': 7.830188679245283e-05, 'epoch': 0.02}
  2%|▏         | 581/24716 [8:16:49<354:17:07, 52.85s/it]  2%|▏         | 582/24716 [8:17:35<339:50:56, 50.69s/it]                                                         {'loss': 0.2794, 'grad_norm': 1.409544918823538, 'learning_rate': 7.84366576819407e-05, 'epoch': 0.02}
  2%|▏         | 582/24716 [8:17:35<339:50:56, 50.69s/it]  2%|▏         | 583/24716 [8:18:22<331:38:39, 49.47s/it]                                                         {'loss': 0.2891, 'grad_norm': 1.4600358545414929, 'learning_rate': 7.857142857142858e-05, 'epoch': 0.02}
  2%|▏         | 583/24716 [8:18:22<331:38:39, 49.47s/it]  2%|▏         | 584/24716 [8:19:19<347:38:23, 51.86s/it]                                                         {'loss': 0.2646, 'grad_norm': 0.6508472393814283, 'learning_rate': 7.870619946091644e-05, 'epoch': 0.02}
  2%|▏         | 584/24716 [8:19:19<347:38:23, 51.86s/it]  2%|▏         | 585/24716 [8:20:13<352:43:44, 52.62s/it]                                                         {'loss': 0.3279, 'grad_norm': 1.2893761306479674, 'learning_rate': 7.884097035040431e-05, 'epoch': 0.02}
  2%|▏         | 585/24716 [8:20:13<352:43:44, 52.62s/it]  2%|▏         | 586/24716 [8:21:00<339:45:47, 50.69s/it]                                                         {'loss': 0.2893, 'grad_norm': 1.0266130582580466, 'learning_rate': 7.897574123989219e-05, 'epoch': 0.02}
  2%|▏         | 586/24716 [8:21:00<339:45:47, 50.69s/it]  2%|▏         | 587/24716 [8:21:48<335:39:12, 50.08s/it]                                                         {'loss': 0.2894, 'grad_norm': 4.320721501848945, 'learning_rate': 7.911051212938005e-05, 'epoch': 0.02}
  2%|▏         | 587/24716 [8:21:48<335:39:12, 50.08s/it]  2%|▏         | 588/24716 [8:22:42<343:30:12, 51.25s/it]                                                         {'loss': 0.2903, 'grad_norm': 1.1990770401599882, 'learning_rate': 7.924528301886794e-05, 'epoch': 0.02}
  2%|▏         | 588/24716 [8:22:42<343:30:12, 51.25s/it]  2%|▏         | 589/24716 [8:23:33<343:17:58, 51.22s/it]                                                         {'loss': 0.2429, 'grad_norm': 0.595061246305224, 'learning_rate': 7.93800539083558e-05, 'epoch': 0.02}
  2%|▏         | 589/24716 [8:23:33<343:17:58, 51.22s/it]  2%|▏         | 590/24716 [8:24:31<356:21:42, 53.18s/it]                                                         {'loss': 0.2868, 'grad_norm': 1.3345917365660191, 'learning_rate': 7.951482479784367e-05, 'epoch': 0.02}
  2%|▏         | 590/24716 [8:24:31<356:21:42, 53.18s/it]  2%|▏         | 591/24716 [8:25:29<366:29:18, 54.69s/it]                                                         {'loss': 0.4488, 'grad_norm': 4.93376652954266, 'learning_rate': 7.964959568733153e-05, 'epoch': 0.02}
  2%|▏         | 591/24716 [8:25:29<366:29:18, 54.69s/it]  2%|▏         | 592/24716 [8:26:30<379:22:47, 56.61s/it]                                                         {'loss': 0.3249, 'grad_norm': 0.9877073690100263, 'learning_rate': 7.978436657681942e-05, 'epoch': 0.02}
  2%|▏         | 592/24716 [8:26:30<379:22:47, 56.61s/it]  2%|▏         | 593/24716 [8:27:22<368:53:43, 55.05s/it]                                                         {'loss': 0.3387, 'grad_norm': 1.4361446688812853, 'learning_rate': 7.991913746630728e-05, 'epoch': 0.02}
  2%|▏         | 593/24716 [8:27:22<368:53:43, 55.05s/it]  2%|▏         | 594/24716 [8:28:10<355:49:47, 53.10s/it]                                                         {'loss': 0.2377, 'grad_norm': 1.7404313428905507, 'learning_rate': 8.005390835579515e-05, 'epoch': 0.02}
  2%|▏         | 594/24716 [8:28:10<355:49:47, 53.10s/it]  2%|▏         | 595/24716 [8:28:51<331:21:10, 49.45s/it]                                                         {'loss': 0.2412, 'grad_norm': 0.7930312763261819, 'learning_rate': 8.018867924528302e-05, 'epoch': 0.02}
  2%|▏         | 595/24716 [8:28:51<331:21:10, 49.45s/it]  2%|▏         | 596/24716 [8:29:38<325:25:20, 48.57s/it]                                                         {'loss': 0.2643, 'grad_norm': 0.652873730944111, 'learning_rate': 8.03234501347709e-05, 'epoch': 0.02}
  2%|▏         | 596/24716 [8:29:38<325:25:20, 48.57s/it]  2%|▏         | 597/24716 [8:30:34<340:05:58, 50.76s/it]                                                         {'loss': 0.2739, 'grad_norm': 0.7832741782448531, 'learning_rate': 8.045822102425876e-05, 'epoch': 0.02}
  2%|▏         | 597/24716 [8:30:34<340:05:58, 50.76s/it]  2%|▏         | 598/24716 [8:31:18<325:57:44, 48.66s/it]                                                         {'loss': 0.3434, 'grad_norm': 1.1544034293408272, 'learning_rate': 8.059299191374663e-05, 'epoch': 0.02}
  2%|▏         | 598/24716 [8:31:18<325:57:44, 48.66s/it]  2%|▏         | 599/24716 [8:32:15<344:00:13, 51.35s/it]                                                         {'loss': 0.33, 'grad_norm': 0.6565359852234316, 'learning_rate': 8.07277628032345e-05, 'epoch': 0.02}
  2%|▏         | 599/24716 [8:32:15<344:00:13, 51.35s/it]  2%|▏         | 600/24716 [8:33:04<339:14:55, 50.64s/it]                                                         {'loss': 0.2248, 'grad_norm': 0.5043375436842071, 'learning_rate': 8.086253369272238e-05, 'epoch': 0.02}
  2%|▏         | 600/24716 [8:33:04<339:14:55, 50.64s/it]  2%|▏         | 601/24716 [8:33:46<322:07:51, 48.09s/it]                                                         {'loss': 0.2705, 'grad_norm': 1.823109071154856, 'learning_rate': 8.099730458221024e-05, 'epoch': 0.02}
  2%|▏         | 601/24716 [8:33:46<322:07:51, 48.09s/it]  2%|▏         | 602/24716 [8:34:44<340:46:14, 50.87s/it]                                                         {'loss': 0.279, 'grad_norm': 1.409128705160452, 'learning_rate': 8.113207547169813e-05, 'epoch': 0.02}
  2%|▏         | 602/24716 [8:34:44<340:46:14, 50.87s/it]  2%|▏         | 603/24716 [8:35:26<323:54:18, 48.36s/it]                                                         {'loss': 0.3411, 'grad_norm': 1.0786842564742904, 'learning_rate': 8.126684636118599e-05, 'epoch': 0.02}
  2%|▏         | 603/24716 [8:35:26<323:54:18, 48.36s/it]  2%|▏         | 604/24716 [8:36:08<311:26:31, 46.50s/it]                                                         {'loss': 0.3041, 'grad_norm': 1.2325159040254225, 'learning_rate': 8.140161725067386e-05, 'epoch': 0.02}
  2%|▏         | 604/24716 [8:36:08<311:26:31, 46.50s/it]  2%|▏         | 605/24716 [8:37:04<329:45:36, 49.24s/it]                                                         {'loss': 0.2693, 'grad_norm': 0.6221428453453415, 'learning_rate': 8.153638814016172e-05, 'epoch': 0.02}
  2%|▏         | 605/24716 [8:37:04<329:45:36, 49.24s/it]  2%|▏         | 606/24716 [8:37:48<318:41:31, 47.59s/it]                                                         {'loss': 0.2887, 'grad_norm': 0.6854745133417082, 'learning_rate': 8.167115902964961e-05, 'epoch': 0.02}
  2%|▏         | 606/24716 [8:37:48<318:41:31, 47.59s/it]  2%|▏         | 607/24716 [8:38:54<357:15:41, 53.35s/it]                                                         {'loss': 0.3269, 'grad_norm': 1.1083053466947224, 'learning_rate': 8.180592991913747e-05, 'epoch': 0.02}
  2%|▏         | 607/24716 [8:38:54<357:15:41, 53.35s/it]  2%|▏         | 608/24716 [8:39:49<360:15:20, 53.80s/it]                                                         {'loss': 0.2597, 'grad_norm': 0.6554686065699324, 'learning_rate': 8.194070080862534e-05, 'epoch': 0.02}
  2%|▏         | 608/24716 [8:39:49<360:15:20, 53.80s/it]  2%|▏         | 609/24716 [8:40:46<366:20:49, 54.71s/it]                                                         {'loss': 0.2736, 'grad_norm': 1.5219945365946534, 'learning_rate': 8.207547169811322e-05, 'epoch': 0.02}
  2%|▏         | 609/24716 [8:40:46<366:20:49, 54.71s/it]  2%|▏         | 610/24716 [8:41:35<354:41:01, 52.97s/it]                                                         {'loss': 0.2796, 'grad_norm': 0.7823779750462071, 'learning_rate': 8.221024258760108e-05, 'epoch': 0.02}
  2%|▏         | 610/24716 [8:41:35<354:41:01, 52.97s/it]  2%|▏         | 611/24716 [8:42:30<359:36:39, 53.71s/it]                                                         {'loss': 0.354, 'grad_norm': 0.8930234324844465, 'learning_rate': 8.234501347708895e-05, 'epoch': 0.02}
  2%|▏         | 611/24716 [8:42:30<359:36:39, 53.71s/it]  2%|▏         | 612/24716 [8:43:19<349:34:05, 52.21s/it]                                                         {'loss': 0.2727, 'grad_norm': 1.5002550646113006, 'learning_rate': 8.247978436657682e-05, 'epoch': 0.02}
  2%|▏         | 612/24716 [8:43:19<349:34:05, 52.21s/it]  2%|▏         | 613/24716 [8:43:59<325:29:31, 48.62s/it]                                                         {'loss': 0.2971, 'grad_norm': 0.7304167782348818, 'learning_rate': 8.26145552560647e-05, 'epoch': 0.02}
  2%|▏         | 613/24716 [8:43:59<325:29:31, 48.62s/it]  2%|▏         | 614/24716 [8:45:01<351:14:40, 52.46s/it]                                                         {'loss': 0.2859, 'grad_norm': 0.6713905996379994, 'learning_rate': 8.274932614555256e-05, 'epoch': 0.02}
  2%|▏         | 614/24716 [8:45:01<351:14:40, 52.46s/it]  2%|▏         | 615/24716 [8:46:03<369:51:20, 55.25s/it]                                                         {'loss': 0.2398, 'grad_norm': 0.618551186877278, 'learning_rate': 8.288409703504043e-05, 'epoch': 0.02}
  2%|▏         | 615/24716 [8:46:03<369:51:20, 55.25s/it]  2%|▏         | 616/24716 [8:47:01<375:36:11, 56.11s/it]                                                         {'loss': 0.3046, 'grad_norm': 0.8883150565695559, 'learning_rate': 8.30188679245283e-05, 'epoch': 0.02}
  2%|▏         | 616/24716 [8:47:01<375:36:11, 56.11s/it]  2%|▏         | 617/24716 [8:47:43<348:48:55, 52.11s/it]                                                         {'loss': 0.2665, 'grad_norm': 0.5689230491320949, 'learning_rate': 8.315363881401618e-05, 'epoch': 0.02}
  2%|▏         | 617/24716 [8:47:43<348:48:55, 52.11s/it]  3%|▎         | 618/24716 [8:48:28<332:49:14, 49.72s/it]                                                         {'loss': 0.3339, 'grad_norm': 0.7988665424802411, 'learning_rate': 8.328840970350404e-05, 'epoch': 0.03}
  3%|▎         | 618/24716 [8:48:28<332:49:14, 49.72s/it]  3%|▎         | 619/24716 [8:49:19<336:17:53, 50.24s/it]                                                         {'loss': 0.3233, 'grad_norm': 0.7797624122998794, 'learning_rate': 8.342318059299193e-05, 'epoch': 0.03}
  3%|▎         | 619/24716 [8:49:19<336:17:53, 50.24s/it]  3%|▎         | 620/24716 [8:50:08<333:58:29, 49.90s/it]                                                         {'loss': 0.3288, 'grad_norm': 2.29654522772402, 'learning_rate': 8.355795148247979e-05, 'epoch': 0.03}
  3%|▎         | 620/24716 [8:50:08<333:58:29, 49.90s/it]  3%|▎         | 621/24716 [8:51:08<354:23:58, 52.95s/it]                                                         {'loss': 0.3011, 'grad_norm': 0.7488521249193408, 'learning_rate': 8.369272237196766e-05, 'epoch': 0.03}
  3%|▎         | 621/24716 [8:51:08<354:23:58, 52.95s/it]  3%|▎         | 622/24716 [8:52:12<375:15:31, 56.07s/it]                                                         {'loss': 0.3096, 'grad_norm': 1.852397775341779, 'learning_rate': 8.382749326145552e-05, 'epoch': 0.03}
  3%|▎         | 622/24716 [8:52:12<375:15:31, 56.07s/it]  3%|▎         | 623/24716 [8:52:59<357:30:07, 53.42s/it]                                                         {'loss': 0.2965, 'grad_norm': 0.9644096974245885, 'learning_rate': 8.396226415094341e-05, 'epoch': 0.03}
  3%|▎         | 623/24716 [8:52:59<357:30:07, 53.42s/it]  3%|▎         | 624/24716 [8:53:52<356:09:06, 53.22s/it]                                                         {'loss': 0.2512, 'grad_norm': 1.5565103075727829, 'learning_rate': 8.409703504043127e-05, 'epoch': 0.03}
  3%|▎         | 624/24716 [8:53:52<356:09:06, 53.22s/it]  3%|▎         | 625/24716 [8:54:37<339:44:27, 50.77s/it]                                                         {'loss': 0.2586, 'grad_norm': 0.5636698132938749, 'learning_rate': 8.423180592991914e-05, 'epoch': 0.03}
  3%|▎         | 625/24716 [8:54:37<339:44:27, 50.77s/it]  3%|▎         | 626/24716 [8:55:23<331:49:19, 49.59s/it]                                                         {'loss': 0.2346, 'grad_norm': 0.5198731548731084, 'learning_rate': 8.436657681940702e-05, 'epoch': 0.03}
  3%|▎         | 626/24716 [8:55:23<331:49:19, 49.59s/it]  3%|▎         | 627/24716 [8:56:15<336:38:36, 50.31s/it]                                                         {'loss': 0.2607, 'grad_norm': 0.7657020739065169, 'learning_rate': 8.450134770889489e-05, 'epoch': 0.03}
  3%|▎         | 627/24716 [8:56:15<336:38:36, 50.31s/it]  3%|▎         | 628/24716 [8:57:15<354:18:33, 52.95s/it]                                                         {'loss': 0.3188, 'grad_norm': 1.2671217354101498, 'learning_rate': 8.463611859838275e-05, 'epoch': 0.03}
  3%|▎         | 628/24716 [8:57:15<354:18:33, 52.95s/it]  3%|▎         | 629/24716 [8:58:11<360:56:57, 53.95s/it]                                                         {'loss': 0.2865, 'grad_norm': 0.7267993802262, 'learning_rate': 8.477088948787062e-05, 'epoch': 0.03}
  3%|▎         | 629/24716 [8:58:11<360:56:57, 53.95s/it]  3%|▎         | 630/24716 [8:59:09<369:00:34, 55.15s/it]                                                         {'loss': 0.2821, 'grad_norm': 0.79485777057715, 'learning_rate': 8.49056603773585e-05, 'epoch': 0.03}
  3%|▎         | 630/24716 [8:59:09<369:00:34, 55.15s/it]  3%|▎         | 631/24716 [8:59:52<344:58:54, 51.56s/it]                                                         {'loss': 0.2867, 'grad_norm': 0.7739648931190275, 'learning_rate': 8.504043126684637e-05, 'epoch': 0.03}
  3%|▎         | 631/24716 [8:59:52<344:58:54, 51.56s/it]  3%|▎         | 632/24716 [9:00:41<340:34:42, 50.91s/it]                                                         {'loss': 0.272, 'grad_norm': 8.170686248806454, 'learning_rate': 8.517520215633423e-05, 'epoch': 0.03}
  3%|▎         | 632/24716 [9:00:41<340:34:42, 50.91s/it]  3%|▎         | 633/24716 [9:01:34<344:20:16, 51.47s/it]                                                         {'loss': 0.2601, 'grad_norm': 0.4847545806696143, 'learning_rate': 8.53099730458221e-05, 'epoch': 0.03}
  3%|▎         | 633/24716 [9:01:34<344:20:16, 51.47s/it]  3%|▎         | 634/24716 [9:02:23<339:01:04, 50.68s/it]                                                         {'loss': 0.2412, 'grad_norm': 0.5856234623889313, 'learning_rate': 8.544474393530998e-05, 'epoch': 0.03}
  3%|▎         | 634/24716 [9:02:23<339:01:04, 50.68s/it]  3%|▎         | 635/24716 [9:03:30<370:59:15, 55.46s/it]                                                         {'loss': 0.2726, 'grad_norm': 0.8742157739602102, 'learning_rate': 8.557951482479785e-05, 'epoch': 0.03}
  3%|▎         | 635/24716 [9:03:30<370:59:15, 55.46s/it]  3%|▎         | 636/24716 [9:04:21<361:54:35, 54.11s/it]                                                         {'loss': 0.2532, 'grad_norm': 0.5438579990833474, 'learning_rate': 8.571428571428571e-05, 'epoch': 0.03}
  3%|▎         | 636/24716 [9:04:21<361:54:35, 54.11s/it]  3%|▎         | 637/24716 [9:05:14<359:52:25, 53.80s/it]                                                         {'loss': 0.2398, 'grad_norm': 0.8370858748424848, 'learning_rate': 8.584905660377359e-05, 'epoch': 0.03}
  3%|▎         | 637/24716 [9:05:14<359:52:25, 53.80s/it]  3%|▎         | 638/24716 [9:06:04<353:17:30, 52.82s/it]                                                         {'loss': 0.302, 'grad_norm': 0.5344026493820658, 'learning_rate': 8.598382749326146e-05, 'epoch': 0.03}
  3%|▎         | 638/24716 [9:06:04<353:17:30, 52.82s/it]  3%|▎         | 639/24716 [9:06:58<354:33:32, 53.01s/it]                                                         {'loss': 0.2832, 'grad_norm': 1.685786217569267, 'learning_rate': 8.611859838274932e-05, 'epoch': 0.03}
  3%|▎         | 639/24716 [9:06:58<354:33:32, 53.01s/it]  3%|▎         | 640/24716 [9:07:48<348:15:00, 52.07s/it]                                                         {'loss': 0.2832, 'grad_norm': 1.259914803735018, 'learning_rate': 8.625336927223721e-05, 'epoch': 0.03}
  3%|▎         | 640/24716 [9:07:48<348:15:00, 52.07s/it]  3%|▎         | 641/24716 [9:08:44<357:44:00, 53.49s/it]                                                         {'loss': 0.3029, 'grad_norm': 0.5879067563838344, 'learning_rate': 8.638814016172507e-05, 'epoch': 0.03}
  3%|▎         | 641/24716 [9:08:44<357:44:00, 53.49s/it]  3%|▎         | 642/24716 [9:09:35<351:11:13, 52.52s/it]                                                         {'loss': 0.2657, 'grad_norm': 1.0243058956935764, 'learning_rate': 8.652291105121294e-05, 'epoch': 0.03}
  3%|▎         | 642/24716 [9:09:35<351:11:13, 52.52s/it]  3%|▎         | 643/24716 [9:10:30<356:35:28, 53.33s/it]                                                         {'loss': 0.2847, 'grad_norm': 0.5852351472639823, 'learning_rate': 8.66576819407008e-05, 'epoch': 0.03}
  3%|▎         | 643/24716 [9:10:30<356:35:28, 53.33s/it]  3%|▎         | 644/24716 [9:11:32<373:26:39, 55.85s/it]                                                         {'loss': 0.2262, 'grad_norm': 0.8847710601627742, 'learning_rate': 8.679245283018869e-05, 'epoch': 0.03}
  3%|▎         | 644/24716 [9:11:32<373:26:39, 55.85s/it]  3%|▎         | 645/24716 [9:12:19<356:45:39, 53.36s/it]                                                         {'loss': 0.3205, 'grad_norm': 1.1334274933838238, 'learning_rate': 8.692722371967655e-05, 'epoch': 0.03}
  3%|▎         | 645/24716 [9:12:19<356:45:39, 53.36s/it]  3%|▎         | 646/24716 [9:13:00<332:03:36, 49.66s/it]                                                         {'loss': 0.2787, 'grad_norm': 0.7807117101861507, 'learning_rate': 8.706199460916442e-05, 'epoch': 0.03}
  3%|▎         | 646/24716 [9:13:00<332:03:36, 49.66s/it]  3%|▎         | 647/24716 [9:13:48<328:32:09, 49.14s/it]                                                         {'loss': 0.256, 'grad_norm': 1.0927641847621783, 'learning_rate': 8.71967654986523e-05, 'epoch': 0.03}
  3%|▎         | 647/24716 [9:13:48<328:32:09, 49.14s/it]  3%|▎         | 648/24716 [9:14:46<346:22:05, 51.81s/it]                                                         {'loss': 0.2564, 'grad_norm': 0.6676426469379338, 'learning_rate': 8.733153638814017e-05, 'epoch': 0.03}
  3%|▎         | 648/24716 [9:14:46<346:22:05, 51.81s/it]  3%|▎         | 649/24716 [9:15:18<306:30:36, 45.85s/it]                                                         {'loss': 0.3604, 'grad_norm': 1.6281376784169845, 'learning_rate': 8.746630727762803e-05, 'epoch': 0.03}
  3%|▎         | 649/24716 [9:15:18<306:30:36, 45.85s/it]  3%|▎         | 650/24716 [9:16:10<318:04:57, 47.58s/it]                                                         {'loss': 0.287, 'grad_norm': 2.0429218884572125, 'learning_rate': 8.76010781671159e-05, 'epoch': 0.03}
  3%|▎         | 650/24716 [9:16:10<318:04:57, 47.58s/it]  3%|▎         | 651/24716 [9:17:08<339:51:12, 50.84s/it]                                                         {'loss': 0.3117, 'grad_norm': 0.9323327251491735, 'learning_rate': 8.773584905660378e-05, 'epoch': 0.03}
  3%|▎         | 651/24716 [9:17:08<339:51:12, 50.84s/it]  3%|▎         | 652/24716 [9:17:50<321:51:49, 48.15s/it]                                                         {'loss': 0.2435, 'grad_norm': 0.6044571912230614, 'learning_rate': 8.787061994609165e-05, 'epoch': 0.03}
  3%|▎         | 652/24716 [9:17:50<321:51:49, 48.15s/it]  3%|▎         | 653/24716 [9:18:42<328:43:28, 49.18s/it]                                                         {'loss': 0.3845, 'grad_norm': 1.6804536246037722, 'learning_rate': 8.800539083557951e-05, 'epoch': 0.03}
  3%|▎         | 653/24716 [9:18:42<328:43:28, 49.18s/it]  3%|▎         | 654/24716 [9:19:26<319:29:47, 47.80s/it]                                                         {'loss': 0.2557, 'grad_norm': 0.6590299480660403, 'learning_rate': 8.81401617250674e-05, 'epoch': 0.03}
  3%|▎         | 654/24716 [9:19:26<319:29:47, 47.80s/it]  3%|▎         | 655/24716 [9:20:18<327:28:12, 49.00s/it]                                                         {'loss': 0.2238, 'grad_norm': 0.642333053768689, 'learning_rate': 8.827493261455526e-05, 'epoch': 0.03}
  3%|▎         | 655/24716 [9:20:18<327:28:12, 49.00s/it]  3%|▎         | 656/24716 [9:21:12<338:19:16, 50.62s/it]                                                         {'loss': 0.2916, 'grad_norm': 0.8997864514950246, 'learning_rate': 8.840970350404313e-05, 'epoch': 0.03}
  3%|▎         | 656/24716 [9:21:12<338:19:16, 50.62s/it]  3%|▎         | 657/24716 [9:22:05<342:38:09, 51.27s/it]                                                         {'loss': 0.2602, 'grad_norm': 0.6187019459423977, 'learning_rate': 8.8544474393531e-05, 'epoch': 0.03}
  3%|▎         | 657/24716 [9:22:05<342:38:09, 51.27s/it]  3%|▎         | 658/24716 [9:23:04<357:37:51, 53.52s/it]                                                         {'loss': 0.2436, 'grad_norm': 1.2742209820184924, 'learning_rate': 8.867924528301888e-05, 'epoch': 0.03}
  3%|▎         | 658/24716 [9:23:04<357:37:51, 53.52s/it]  3%|▎         | 659/24716 [9:23:52<347:00:57, 51.93s/it]                                                         {'loss': 0.238, 'grad_norm': 0.5311636997660133, 'learning_rate': 8.881401617250674e-05, 'epoch': 0.03}
  3%|▎         | 659/24716 [9:23:52<347:00:57, 51.93s/it]  3%|▎         | 660/24716 [9:24:45<349:29:30, 52.30s/it]                                                         {'loss': 0.2829, 'grad_norm': 0.7023036316366068, 'learning_rate': 8.894878706199461e-05, 'epoch': 0.03}
  3%|▎         | 660/24716 [9:24:45<349:29:30, 52.30s/it]  3%|▎         | 661/24716 [9:25:28<330:33:52, 49.47s/it]                                                         {'loss': 0.29, 'grad_norm': 0.6582060276309976, 'learning_rate': 8.908355795148249e-05, 'epoch': 0.03}
  3%|▎         | 661/24716 [9:25:28<330:33:52, 49.47s/it]  3%|▎         | 662/24716 [9:26:03<300:35:13, 44.99s/it]                                                         {'loss': 0.2519, 'grad_norm': 0.5769076585851689, 'learning_rate': 8.921832884097035e-05, 'epoch': 0.03}
  3%|▎         | 662/24716 [9:26:03<300:35:13, 44.99s/it]  3%|▎         | 663/24716 [9:26:36<276:21:20, 41.36s/it]                                                         {'loss': 0.1931, 'grad_norm': 0.4262664881972096, 'learning_rate': 8.935309973045822e-05, 'epoch': 0.03}
  3%|▎         | 663/24716 [9:26:36<276:21:20, 41.36s/it]  3%|▎         | 664/24716 [9:27:12<265:31:45, 39.74s/it]                                                         {'loss': 0.2799, 'grad_norm': 0.7048444238780126, 'learning_rate': 8.94878706199461e-05, 'epoch': 0.03}
  3%|▎         | 664/24716 [9:27:12<265:31:45, 39.74s/it]  3%|▎         | 665/24716 [9:27:44<250:36:56, 37.51s/it]                                                         {'loss': 0.3973, 'grad_norm': 0.7091321996300947, 'learning_rate': 8.962264150943397e-05, 'epoch': 0.03}
  3%|▎         | 665/24716 [9:27:44<250:36:56, 37.51s/it]  3%|▎         | 666/24716 [9:28:21<249:23:31, 37.33s/it]                                                         {'loss': 0.2614, 'grad_norm': 0.4963071944423893, 'learning_rate': 8.975741239892183e-05, 'epoch': 0.03}
  3%|▎         | 666/24716 [9:28:21<249:23:31, 37.33s/it]  3%|▎         | 667/24716 [9:28:55<243:28:00, 36.45s/it]                                                         {'loss': 0.2837, 'grad_norm': 0.9044184975184157, 'learning_rate': 8.98921832884097e-05, 'epoch': 0.03}
  3%|▎         | 667/24716 [9:28:55<243:28:00, 36.45s/it]  3%|▎         | 668/24716 [9:29:27<233:25:05, 34.94s/it]                                                         {'loss': 0.234, 'grad_norm': 0.6365858362215153, 'learning_rate': 9.002695417789758e-05, 'epoch': 0.03}
  3%|▎         | 668/24716 [9:29:27<233:25:05, 34.94s/it]  3%|▎         | 669/24716 [9:30:04<239:03:25, 35.79s/it]                                                         {'loss': 0.2259, 'grad_norm': 0.7218668212870638, 'learning_rate': 9.016172506738545e-05, 'epoch': 0.03}
  3%|▎         | 669/24716 [9:30:04<239:03:25, 35.79s/it]  3%|▎         | 670/24716 [9:30:40<239:38:41, 35.88s/it]                                                         {'loss': 0.3202, 'grad_norm': 1.1305674894935358, 'learning_rate': 9.029649595687331e-05, 'epoch': 0.03}
  3%|▎         | 670/24716 [9:30:40<239:38:41, 35.88s/it]  3%|▎         | 671/24716 [9:31:13<233:42:13, 34.99s/it]                                                         {'loss': 0.3782, 'grad_norm': 1.498523819464474, 'learning_rate': 9.04312668463612e-05, 'epoch': 0.03}
  3%|▎         | 671/24716 [9:31:13<233:42:13, 34.99s/it]  3%|▎         | 672/24716 [9:31:44<224:54:23, 33.67s/it]                                                         {'loss': 0.3203, 'grad_norm': 0.535633711251748, 'learning_rate': 9.056603773584906e-05, 'epoch': 0.03}
  3%|▎         | 672/24716 [9:31:44<224:54:23, 33.67s/it]  3%|▎         | 673/24716 [9:32:20<229:48:22, 34.41s/it]                                                         {'loss': 0.2804, 'grad_norm': 1.217804100118869, 'learning_rate': 9.070080862533693e-05, 'epoch': 0.03}
  3%|▎         | 673/24716 [9:32:20<229:48:22, 34.41s/it]  3%|▎         | 674/24716 [9:32:55<230:21:53, 34.49s/it]                                                         {'loss': 0.3046, 'grad_norm': 0.5967474020097061, 'learning_rate': 9.083557951482479e-05, 'epoch': 0.03}
  3%|▎         | 674/24716 [9:32:55<230:21:53, 34.49s/it]  3%|▎         | 675/24716 [9:33:27<226:08:09, 33.86s/it]                                                         {'loss': 0.3438, 'grad_norm': 1.7575518074314889, 'learning_rate': 9.097035040431268e-05, 'epoch': 0.03}
  3%|▎         | 675/24716 [9:33:27<226:08:09, 33.86s/it]  3%|▎         | 676/24716 [9:33:59<223:00:49, 33.40s/it]                                                         {'loss': 0.2808, 'grad_norm': 0.8687720251176865, 'learning_rate': 9.110512129380054e-05, 'epoch': 0.03}
  3%|▎         | 676/24716 [9:34:00<223:00:49, 33.40s/it]  3%|▎         | 677/24716 [9:34:29<216:01:22, 32.35s/it]                                                         {'loss': 0.3559, 'grad_norm': 1.223750434990713, 'learning_rate': 9.123989218328841e-05, 'epoch': 0.03}
  3%|▎         | 677/24716 [9:34:29<216:01:22, 32.35s/it]  3%|▎         | 678/24716 [9:35:04<219:40:59, 32.90s/it]                                                         {'loss': 0.2678, 'grad_norm': 0.5627941343845138, 'learning_rate': 9.137466307277629e-05, 'epoch': 0.03}
  3%|▎         | 678/24716 [9:35:04<219:40:59, 32.90s/it]  3%|▎         | 679/24716 [9:35:37<219:54:51, 32.94s/it]                                                         {'loss': 0.2811, 'grad_norm': 0.5890526492838827, 'learning_rate': 9.150943396226416e-05, 'epoch': 0.03}
  3%|▎         | 679/24716 [9:35:37<219:54:51, 32.94s/it]  3%|▎         | 680/24716 [9:36:08<217:33:05, 32.58s/it]                                                         {'loss': 0.2551, 'grad_norm': 0.38662658139275896, 'learning_rate': 9.164420485175202e-05, 'epoch': 0.03}
  3%|▎         | 680/24716 [9:36:08<217:33:05, 32.58s/it]  3%|▎         | 681/24716 [9:36:42<220:30:35, 33.03s/it]                                                         {'loss': 0.2655, 'grad_norm': 0.4413242100936264, 'learning_rate': 9.17789757412399e-05, 'epoch': 0.03}
  3%|▎         | 681/24716 [9:36:42<220:30:35, 33.03s/it]  3%|▎         | 682/24716 [9:37:18<225:34:19, 33.79s/it]                                                         {'loss': 0.2764, 'grad_norm': 0.6582188850593405, 'learning_rate': 9.191374663072777e-05, 'epoch': 0.03}
  3%|▎         | 682/24716 [9:37:18<225:34:19, 33.79s/it]  3%|▎         | 683/24716 [9:37:49<220:34:39, 33.04s/it]                                                         {'loss': 0.2902, 'grad_norm': 0.6532522455654907, 'learning_rate': 9.204851752021564e-05, 'epoch': 0.03}
  3%|▎         | 683/24716 [9:37:49<220:34:39, 33.04s/it]  3%|▎         | 684/24716 [9:38:22<220:42:51, 33.06s/it]                                                         {'loss': 0.255, 'grad_norm': 1.5132097203381492, 'learning_rate': 9.21832884097035e-05, 'epoch': 0.03}
  3%|▎         | 684/24716 [9:38:22<220:42:51, 33.06s/it]  3%|▎         | 685/24716 [9:38:52<213:45:37, 32.02s/it]                                                         {'loss': 0.2451, 'grad_norm': 0.4757595152436534, 'learning_rate': 9.231805929919138e-05, 'epoch': 0.03}
  3%|▎         | 685/24716 [9:38:52<213:45:37, 32.02s/it]  3%|▎         | 686/24716 [9:39:28<221:51:23, 33.24s/it]                                                         {'loss': 0.2586, 'grad_norm': 0.6173298200187809, 'learning_rate': 9.245283018867925e-05, 'epoch': 0.03}
  3%|▎         | 686/24716 [9:39:28<221:51:23, 33.24s/it]  3%|▎         | 687/24716 [9:40:05<228:51:23, 34.29s/it]                                                         {'loss': 0.2852, 'grad_norm': 0.5305663175426258, 'learning_rate': 9.258760107816712e-05, 'epoch': 0.03}
  3%|▎         | 687/24716 [9:40:05<228:51:23, 34.29s/it]  3%|▎         | 688/24716 [9:40:39<229:39:20, 34.41s/it]                                                         {'loss': 0.3051, 'grad_norm': 0.5178201795093994, 'learning_rate': 9.272237196765498e-05, 'epoch': 0.03}
  3%|▎         | 688/24716 [9:40:39<229:39:20, 34.41s/it]  3%|▎         | 689/24716 [9:41:16<233:17:03, 34.95s/it]                                                         {'loss': 0.2933, 'grad_norm': 0.6566333426185539, 'learning_rate': 9.285714285714286e-05, 'epoch': 0.03}
  3%|▎         | 689/24716 [9:41:16<233:17:03, 34.95s/it]  3%|▎         | 690/24716 [9:41:50<232:30:25, 34.84s/it]                                                         {'loss': 0.2507, 'grad_norm': 0.671919378359206, 'learning_rate': 9.299191374663073e-05, 'epoch': 0.03}
  3%|▎         | 690/24716 [9:41:50<232:30:25, 34.84s/it]  3%|▎         | 691/24716 [9:42:25<231:38:41, 34.71s/it]                                                         {'loss': 0.2875, 'grad_norm': 0.8018122640983115, 'learning_rate': 9.31266846361186e-05, 'epoch': 0.03}
  3%|▎         | 691/24716 [9:42:25<231:38:41, 34.71s/it]  3%|▎         | 692/24716 [9:42:58<229:36:06, 34.41s/it]                                                         {'loss': 0.2986, 'grad_norm': 0.5268198190862713, 'learning_rate': 9.326145552560648e-05, 'epoch': 0.03}
  3%|▎         | 692/24716 [9:42:58<229:36:06, 34.41s/it]  3%|▎         | 693/24716 [9:43:30<224:59:02, 33.72s/it]                                                         {'loss': 0.3015, 'grad_norm': 0.9600577567086743, 'learning_rate': 9.339622641509434e-05, 'epoch': 0.03}
  3%|▎         | 693/24716 [9:43:30<224:59:02, 33.72s/it]  3%|▎         | 694/24716 [9:44:09<234:33:12, 35.15s/it]                                                         {'loss': 0.2579, 'grad_norm': 2.3819946583047473, 'learning_rate': 9.353099730458221e-05, 'epoch': 0.03}
  3%|▎         | 694/24716 [9:44:09<234:33:12, 35.15s/it]  3%|▎         | 695/24716 [9:44:44<234:14:41, 35.11s/it]                                                         {'loss': 0.2647, 'grad_norm': 0.590893625314222, 'learning_rate': 9.366576819407007e-05, 'epoch': 0.03}
  3%|▎         | 695/24716 [9:44:44<234:14:41, 35.11s/it]  3%|▎         | 696/24716 [9:45:22<240:59:07, 36.12s/it]                                                         {'loss': 0.2456, 'grad_norm': 0.611417539818065, 'learning_rate': 9.380053908355796e-05, 'epoch': 0.03}
  3%|▎         | 696/24716 [9:45:23<240:59:07, 36.12s/it]  3%|▎         | 697/24716 [9:45:59<241:07:58, 36.14s/it]                                                         {'loss': 0.3112, 'grad_norm': 1.3966365205539397, 'learning_rate': 9.393530997304582e-05, 'epoch': 0.03}
  3%|▎         | 697/24716 [9:45:59<241:07:58, 36.14s/it]  3%|▎         | 698/24716 [9:46:32<234:39:29, 35.17s/it]                                                         {'loss': 0.3088, 'grad_norm': 0.6844465615596583, 'learning_rate': 9.40700808625337e-05, 'epoch': 0.03}
  3%|▎         | 698/24716 [9:46:32<234:39:29, 35.17s/it]  3%|▎         | 699/24716 [9:47:06<232:28:34, 34.85s/it]                                                         {'loss': 0.2597, 'grad_norm': 0.7517038042680658, 'learning_rate': 9.420485175202157e-05, 'epoch': 0.03}
  3%|▎         | 699/24716 [9:47:06<232:28:34, 34.85s/it]  3%|▎         | 700/24716 [9:47:37<225:35:11, 33.82s/it]                                                         {'loss': 0.265, 'grad_norm': 0.630827464164525, 'learning_rate': 9.433962264150944e-05, 'epoch': 0.03}
  3%|▎         | 700/24716 [9:47:37<225:35:11, 33.82s/it]  3%|▎         | 701/24716 [9:48:09<222:31:51, 33.36s/it]                                                         {'loss': 0.2606, 'grad_norm': 0.6303212432150723, 'learning_rate': 9.44743935309973e-05, 'epoch': 0.03}
  3%|▎         | 701/24716 [9:48:09<222:31:51, 33.36s/it]  3%|▎         | 702/24716 [9:48:46<228:48:21, 34.30s/it]                                                         {'loss': 0.3106, 'grad_norm': 0.5374693674843574, 'learning_rate': 9.460916442048518e-05, 'epoch': 0.03}
  3%|▎         | 702/24716 [9:48:46<228:48:21, 34.30s/it]  3%|▎         | 703/24716 [9:49:19<225:37:47, 33.83s/it]                                                         {'loss': 0.3068, 'grad_norm': 0.64124585409118, 'learning_rate': 9.474393530997305e-05, 'epoch': 0.03}
  3%|▎         | 703/24716 [9:49:19<225:37:47, 33.83s/it]  3%|▎         | 704/24716 [9:49:54<228:08:33, 34.20s/it]                                                         {'loss': 0.2515, 'grad_norm': 0.7172033095736096, 'learning_rate': 9.487870619946092e-05, 'epoch': 0.03}
  3%|▎         | 704/24716 [9:49:54<228:08:33, 34.20s/it]  3%|▎         | 705/24716 [9:50:31<234:42:58, 35.19s/it]                                                         {'loss': 0.2645, 'grad_norm': 1.4254860200077972, 'learning_rate': 9.501347708894878e-05, 'epoch': 0.03}
  3%|▎         | 705/24716 [9:50:31<234:42:58, 35.19s/it]  3%|▎         | 706/24716 [9:51:06<233:10:42, 34.96s/it]                                                         {'loss': 0.2346, 'grad_norm': 0.5760912758262431, 'learning_rate': 9.514824797843667e-05, 'epoch': 0.03}
  3%|▎         | 706/24716 [9:51:06<233:10:42, 34.96s/it]  3%|▎         | 707/24716 [9:51:38<227:26:02, 34.10s/it]                                                         {'loss': 0.2991, 'grad_norm': 0.7635678605047317, 'learning_rate': 9.528301886792453e-05, 'epoch': 0.03}
  3%|▎         | 707/24716 [9:51:38<227:26:02, 34.10s/it]  3%|▎         | 708/24716 [9:52:12<228:00:19, 34.19s/it]                                                         {'loss': 0.2884, 'grad_norm': 0.4917743479793275, 'learning_rate': 9.54177897574124e-05, 'epoch': 0.03}
  3%|▎         | 708/24716 [9:52:12<228:00:19, 34.19s/it]  3%|▎         | 709/24716 [9:52:48<232:32:05, 34.87s/it]                                                         {'loss': 0.2875, 'grad_norm': 1.4166538169172769, 'learning_rate': 9.555256064690027e-05, 'epoch': 0.03}
  3%|▎         | 709/24716 [9:52:49<232:32:05, 34.87s/it]  3%|▎         | 710/24716 [9:53:21<226:48:31, 34.01s/it]                                                         {'loss': 0.2334, 'grad_norm': 0.44862547849161366, 'learning_rate': 9.568733153638815e-05, 'epoch': 0.03}
  3%|▎         | 710/24716 [9:53:21<226:48:31, 34.01s/it]  3%|▎         | 711/24716 [9:53:55<227:33:58, 34.13s/it]                                                         {'loss': 0.2408, 'grad_norm': 0.7855438282268451, 'learning_rate': 9.582210242587601e-05, 'epoch': 0.03}
  3%|▎         | 711/24716 [9:53:55<227:33:58, 34.13s/it]  3%|▎         | 712/24716 [9:54:31<231:41:17, 34.75s/it]                                                         {'loss': 0.3098, 'grad_norm': 0.6878947072300384, 'learning_rate': 9.595687331536389e-05, 'epoch': 0.03}
  3%|▎         | 712/24716 [9:54:31<231:41:17, 34.75s/it]  3%|▎         | 713/24716 [9:55:02<224:51:23, 33.72s/it]                                                         {'loss': 0.2618, 'grad_norm': 0.4102336699376489, 'learning_rate': 9.609164420485176e-05, 'epoch': 0.03}
  3%|▎         | 713/24716 [9:55:02<224:51:23, 33.72s/it]  3%|▎         | 714/24716 [9:55:38<227:45:30, 34.16s/it]                                                         {'loss': 0.318, 'grad_norm': 0.5683698251311635, 'learning_rate': 9.622641509433963e-05, 'epoch': 0.03}
  3%|▎         | 714/24716 [9:55:38<227:45:30, 34.16s/it]  3%|▎         | 715/24716 [9:56:13<230:48:58, 34.62s/it]                                                         {'loss': 0.2749, 'grad_norm': 0.6409776731476614, 'learning_rate': 9.63611859838275e-05, 'epoch': 0.03}
  3%|▎         | 715/24716 [9:56:13<230:48:58, 34.62s/it]  3%|▎         | 716/24716 [9:56:47<228:20:55, 34.25s/it]                                                         {'loss': 0.2352, 'grad_norm': 0.4227756488103125, 'learning_rate': 9.649595687331537e-05, 'epoch': 0.03}
  3%|▎         | 716/24716 [9:56:47<228:20:55, 34.25s/it]  3%|▎         | 717/24716 [9:57:21<229:01:43, 34.36s/it]                                                         {'loss': 0.248, 'grad_norm': 1.166674816242822, 'learning_rate': 9.663072776280324e-05, 'epoch': 0.03}
  3%|▎         | 717/24716 [9:57:21<229:01:43, 34.36s/it]  3%|▎         | 718/24716 [9:57:53<223:12:40, 33.48s/it]                                                         {'loss': 0.2606, 'grad_norm': 0.4944221855763919, 'learning_rate': 9.67654986522911e-05, 'epoch': 0.03}
  3%|▎         | 718/24716 [9:57:53<223:12:40, 33.48s/it]  3%|▎         | 719/24716 [9:58:24<218:10:04, 32.73s/it]                                                         {'loss': 0.2677, 'grad_norm': 0.6594155309979419, 'learning_rate': 9.690026954177898e-05, 'epoch': 0.03}
  3%|▎         | 719/24716 [9:58:24<218:10:04, 32.73s/it]  3%|▎         | 720/24716 [9:58:54<212:46:24, 31.92s/it]                                                         {'loss': 0.267, 'grad_norm': 0.49096381900686764, 'learning_rate': 9.703504043126685e-05, 'epoch': 0.03}
  3%|▎         | 720/24716 [9:58:54<212:46:24, 31.92s/it]  3%|▎         | 721/24716 [9:59:23<207:14:26, 31.09s/it]                                                         {'loss': 0.3497, 'grad_norm': 0.6737645916913197, 'learning_rate': 9.716981132075472e-05, 'epoch': 0.03}
  3%|▎         | 721/24716 [9:59:23<207:14:26, 31.09s/it]  3%|▎         | 722/24716 [9:59:54<208:06:00, 31.22s/it]                                                         {'loss': 0.289, 'grad_norm': 0.5708676297911842, 'learning_rate': 9.730458221024258e-05, 'epoch': 0.03}
  3%|▎         | 722/24716 [9:59:54<208:06:00, 31.22s/it]  3%|▎         | 723/24716 [10:00:29<215:26:33, 32.33s/it]                                                          {'loss': 0.3044, 'grad_norm': 1.710524130044805, 'learning_rate': 9.743935309973047e-05, 'epoch': 0.03}
  3%|▎         | 723/24716 [10:00:29<215:26:33, 32.33s/it]  3%|▎         | 724/24716 [10:01:01<214:31:55, 32.19s/it]                                                          {'loss': 0.2987, 'grad_norm': 0.841172234467542, 'learning_rate': 9.757412398921833e-05, 'epoch': 0.03}
  3%|▎         | 724/24716 [10:01:01<214:31:55, 32.19s/it]  3%|▎         | 725/24716 [10:01:32<210:48:13, 31.63s/it]                                                          {'loss': 0.3157, 'grad_norm': 0.728771743647735, 'learning_rate': 9.77088948787062e-05, 'epoch': 0.03}
  3%|▎         | 725/24716 [10:01:32<210:48:13, 31.63s/it]  3%|▎         | 726/24716 [10:02:07<217:52:07, 32.69s/it]                                                          {'loss': 0.2353, 'grad_norm': 0.4443744285293266, 'learning_rate': 9.784366576819407e-05, 'epoch': 0.03}
  3%|▎         | 726/24716 [10:02:07<217:52:07, 32.69s/it]  3%|▎         | 727/24716 [10:02:38<215:30:41, 32.34s/it]                                                          {'loss': 0.2263, 'grad_norm': 0.42684714830257803, 'learning_rate': 9.797843665768195e-05, 'epoch': 0.03}
  3%|▎         | 727/24716 [10:02:38<215:30:41, 32.34s/it]  3%|▎         | 728/24716 [10:03:10<214:02:13, 32.12s/it]                                                          {'loss': 0.2618, 'grad_norm': 0.36420120090716696, 'learning_rate': 9.811320754716981e-05, 'epoch': 0.03}
  3%|▎         | 728/24716 [10:03:10<214:02:13, 32.12s/it]  3%|▎         | 729/24716 [10:03:42<213:57:51, 32.11s/it]                                                          {'loss': 0.2722, 'grad_norm': 0.3964310150584462, 'learning_rate': 9.824797843665769e-05, 'epoch': 0.03}
  3%|▎         | 729/24716 [10:03:42<213:57:51, 32.11s/it]  3%|▎         | 730/24716 [10:04:16<217:21:36, 32.62s/it]                                                          {'loss': 0.3012, 'grad_norm': 1.0555330334622413, 'learning_rate': 9.838274932614556e-05, 'epoch': 0.03}
  3%|▎         | 730/24716 [10:04:16<217:21:36, 32.62s/it]  3%|▎         | 731/24716 [10:04:49<218:17:28, 32.76s/it]                                                          {'loss': 0.2166, 'grad_norm': 0.37279857904129254, 'learning_rate': 9.851752021563343e-05, 'epoch': 0.03}
  3%|▎         | 731/24716 [10:04:49<218:17:28, 32.76s/it]  3%|▎         | 732/24716 [10:05:21<216:33:32, 32.51s/it]                                                          {'loss': 0.2807, 'grad_norm': 0.5847422404637257, 'learning_rate': 9.86522911051213e-05, 'epoch': 0.03}
  3%|▎         | 732/24716 [10:05:21<216:33:32, 32.51s/it]  3%|▎         | 733/24716 [10:05:53<215:07:54, 32.29s/it]                                                          {'loss': 0.2476, 'grad_norm': 0.6165944964124488, 'learning_rate': 9.878706199460917e-05, 'epoch': 0.03}
  3%|▎         | 733/24716 [10:05:53<215:07:54, 32.29s/it]  3%|▎         | 734/24716 [10:06:24<213:45:49, 32.09s/it]                                                          {'loss': 0.2659, 'grad_norm': 0.6260792895532745, 'learning_rate': 9.892183288409704e-05, 'epoch': 0.03}
  3%|▎         | 734/24716 [10:06:24<213:45:49, 32.09s/it]  3%|▎         | 735/24716 [10:06:54<208:19:44, 31.27s/it]                                                          {'loss': 0.3049, 'grad_norm': 0.6329966639340471, 'learning_rate': 9.905660377358492e-05, 'epoch': 0.03}
  3%|▎         | 735/24716 [10:06:54<208:19:44, 31.27s/it]  3%|▎         | 736/24716 [10:07:21<201:00:17, 30.18s/it]                                                          {'loss': 0.2876, 'grad_norm': 0.6870169412841394, 'learning_rate': 9.919137466307278e-05, 'epoch': 0.03}
  3%|▎         | 736/24716 [10:07:21<201:00:17, 30.18s/it]  3%|▎         | 737/24716 [10:07:51<200:37:56, 30.12s/it]                                                          {'loss': 0.3776, 'grad_norm': 0.6973480266134163, 'learning_rate': 9.932614555256066e-05, 'epoch': 0.03}
  3%|▎         | 737/24716 [10:07:51<200:37:56, 30.12s/it]  3%|▎         | 738/24716 [10:08:25<208:46:29, 31.34s/it]                                                          {'loss': 0.2478, 'grad_norm': 0.5155943231568317, 'learning_rate': 9.946091644204852e-05, 'epoch': 0.03}
  3%|▎         | 738/24716 [10:08:25<208:46:29, 31.34s/it]  3%|▎         | 739/24716 [10:09:02<218:26:38, 32.80s/it]                                                          {'loss': 0.2731, 'grad_norm': 0.4847188372919232, 'learning_rate': 9.95956873315364e-05, 'epoch': 0.03}
  3%|▎         | 739/24716 [10:09:02<218:26:38, 32.80s/it]  3%|▎         | 740/24716 [10:09:34<218:41:23, 32.84s/it]                                                          {'loss': 0.2881, 'grad_norm': 0.6264464651206691, 'learning_rate': 9.973045822102426e-05, 'epoch': 0.03}
  3%|▎         | 740/24716 [10:09:34<218:41:23, 32.84s/it]  3%|▎         | 741/24716 [10:10:11<225:10:44, 33.81s/it]                                                          {'loss': 0.3158, 'grad_norm': 1.0666464492482808, 'learning_rate': 9.986522911051213e-05, 'epoch': 0.03}
  3%|▎         | 741/24716 [10:10:11<225:10:44, 33.81s/it]  3%|▎         | 742/24716 [10:10:42<220:43:45, 33.15s/it]                                                          {'loss': 0.2591, 'grad_norm': 0.3808831069598605, 'learning_rate': 0.0001, 'epoch': 0.03}
  3%|▎         | 742/24716 [10:10:42<220:43:45, 33.15s/it]  3%|▎         | 743/24716 [10:11:14<218:03:12, 32.74s/it]                                                          {'loss': 0.2555, 'grad_norm': 0.6773361710023715, 'learning_rate': 9.999999957070212e-05, 'epoch': 0.03}
  3%|▎         | 743/24716 [10:11:14<218:03:12, 32.74s/it]  3%|▎         | 744/24716 [10:11:46<217:10:43, 32.61s/it]                                                          {'loss': 0.2736, 'grad_norm': 0.6349960653129165, 'learning_rate': 9.999999828280846e-05, 'epoch': 0.03}
  3%|▎         | 744/24716 [10:11:46<217:10:43, 32.61s/it]  3%|▎         | 745/24716 [10:12:18<216:06:07, 32.45s/it]                                                          {'loss': 0.2917, 'grad_norm': 0.7067248524034468, 'learning_rate': 9.999999613631906e-05, 'epoch': 0.03}
  3%|▎         | 745/24716 [10:12:18<216:06:07, 32.45s/it]  3%|▎         | 746/24716 [10:12:53<220:19:24, 33.09s/it]                                                          {'loss': 0.3124, 'grad_norm': 1.1383842516509453, 'learning_rate': 9.999999313123395e-05, 'epoch': 0.03}
  3%|▎         | 746/24716 [10:12:53<220:19:24, 33.09s/it]  3%|▎         | 747/24716 [10:13:23<214:22:51, 32.20s/it]                                                          {'loss': 0.4025, 'grad_norm': 1.4637734184865336, 'learning_rate': 9.999998926755319e-05, 'epoch': 0.03}
  3%|▎         | 747/24716 [10:13:23<214:22:51, 32.20s/it]  3%|▎         | 748/24716 [10:13:56<216:20:02, 32.49s/it]                                                          {'loss': 0.2842, 'grad_norm': 1.2406176954874255, 'learning_rate': 9.999998454527682e-05, 'epoch': 0.03}
  3%|▎         | 748/24716 [10:13:56<216:20:02, 32.49s/it]  3%|▎         | 749/24716 [10:14:26<210:10:46, 31.57s/it]                                                          {'loss': 0.2659, 'grad_norm': 0.5354469820893216, 'learning_rate': 9.999997896440496e-05, 'epoch': 0.03}
  3%|▎         | 749/24716 [10:14:26<210:10:46, 31.57s/it]  3%|▎         | 750/24716 [10:14:58<211:12:59, 31.73s/it]                                                          {'loss': 0.2613, 'grad_norm': 0.5070518762802219, 'learning_rate': 9.999997252493769e-05, 'epoch': 0.03}
  3%|▎         | 750/24716 [10:14:58<211:12:59, 31.73s/it]  3%|▎         | 751/24716 [10:15:29<209:32:26, 31.48s/it]                                                          {'loss': 0.3079, 'grad_norm': 0.7314368405076686, 'learning_rate': 9.999996522687509e-05, 'epoch': 0.03}
  3%|▎         | 751/24716 [10:15:29<209:32:26, 31.48s/it]  3%|▎         | 752/24716 [10:15:59<207:34:24, 31.18s/it]                                                          {'loss': 0.2728, 'grad_norm': 1.2271346602489115, 'learning_rate': 9.999995707021734e-05, 'epoch': 0.03}
  3%|▎         | 752/24716 [10:15:59<207:34:24, 31.18s/it]  3%|▎         | 753/24716 [10:16:31<208:15:09, 31.29s/it]                                                          {'loss': 0.3068, 'grad_norm': 0.8491190885893498, 'learning_rate': 9.999994805496453e-05, 'epoch': 0.03}
  3%|▎         | 753/24716 [10:16:31<208:15:09, 31.29s/it]  3%|▎         | 754/24716 [10:17:03<210:53:54, 31.68s/it]                                                          {'loss': 0.2925, 'grad_norm': 1.9269246409530159, 'learning_rate': 9.999993818111685e-05, 'epoch': 0.03}
  3%|▎         | 754/24716 [10:17:03<210:53:54, 31.68s/it]  3%|▎         | 755/24716 [10:17:33<206:42:23, 31.06s/it]                                                          {'loss': 0.2819, 'grad_norm': 0.9329969080040883, 'learning_rate': 9.999992744867446e-05, 'epoch': 0.03}
  3%|▎         | 755/24716 [10:17:33<206:42:23, 31.06s/it]  3%|▎         | 756/24716 [10:18:02<203:08:56, 30.52s/it]                                                          {'loss': 0.2235, 'grad_norm': 0.6216429544652567, 'learning_rate': 9.999991585763752e-05, 'epoch': 0.03}
  3%|▎         | 756/24716 [10:18:02<203:08:56, 30.52s/it]  3%|▎         | 757/24716 [10:18:33<204:22:56, 30.71s/it]                                                          {'loss': 0.2593, 'grad_norm': 7.869806705357935, 'learning_rate': 9.999990340800627e-05, 'epoch': 0.03}
  3%|▎         | 757/24716 [10:18:33<204:22:56, 30.71s/it]  3%|▎         | 758/24716 [10:19:07<211:17:00, 31.75s/it]                                                          {'loss': 0.2728, 'grad_norm': 1.3138352144245689, 'learning_rate': 9.999989009978088e-05, 'epoch': 0.03}
  3%|▎         | 758/24716 [10:19:07<211:17:00, 31.75s/it]  3%|▎         | 759/24716 [10:19:37<206:46:18, 31.07s/it]                                                          {'loss': 0.2818, 'grad_norm': 2.7694117620170395, 'learning_rate': 9.999987593296162e-05, 'epoch': 0.03}
  3%|▎         | 759/24716 [10:19:37<206:46:18, 31.07s/it]  3%|▎         | 760/24716 [10:20:12<214:46:08, 32.27s/it]                                                          {'loss': 0.2851, 'grad_norm': 0.64601335011432, 'learning_rate': 9.999986090754873e-05, 'epoch': 0.03}
  3%|▎         | 760/24716 [10:20:12<214:46:08, 32.27s/it]  3%|▎         | 761/24716 [10:20:46<218:29:20, 32.83s/it]                                                          {'loss': 0.3432, 'grad_norm': 0.7206995951140174, 'learning_rate': 9.999984502354242e-05, 'epoch': 0.03}
  3%|▎         | 761/24716 [10:20:46<218:29:20, 32.83s/it]  3%|▎         | 762/24716 [10:21:21<221:46:18, 33.33s/it]                                                          {'loss': 0.2493, 'grad_norm': 0.4751588996937551, 'learning_rate': 9.999982828094304e-05, 'epoch': 0.03}
  3%|▎         | 762/24716 [10:21:21<221:46:18, 33.33s/it]  3%|▎         | 763/24716 [10:21:54<222:08:08, 33.39s/it]                                                          {'loss': 0.306, 'grad_norm': 1.0869707058495761, 'learning_rate': 9.999981067975079e-05, 'epoch': 0.03}
  3%|▎         | 763/24716 [10:21:54<222:08:08, 33.39s/it]  3%|▎         | 764/24716 [10:22:26<219:29:24, 32.99s/it]                                                          {'loss': 0.2366, 'grad_norm': 0.6748853538768687, 'learning_rate': 9.999979221996604e-05, 'epoch': 0.03}
  3%|▎         | 764/24716 [10:22:26<219:29:24, 32.99s/it]  3%|▎         | 765/24716 [10:23:00<221:07:50, 33.24s/it]                                                          {'loss': 0.2719, 'grad_norm': 0.37878293275651986, 'learning_rate': 9.999977290158907e-05, 'epoch': 0.03}
  3%|▎         | 765/24716 [10:23:00<221:07:50, 33.24s/it]  3%|▎         | 766/24716 [10:23:34<221:50:48, 33.35s/it]                                                          {'loss': 0.2858, 'grad_norm': 1.1105002128763581, 'learning_rate': 9.999975272462023e-05, 'epoch': 0.03}
  3%|▎         | 766/24716 [10:23:34<221:50:48, 33.35s/it]  3%|▎         | 767/24716 [10:24:08<223:16:45, 33.56s/it]                                                          {'loss': 0.3281, 'grad_norm': 0.5542693060225683, 'learning_rate': 9.999973168905988e-05, 'epoch': 0.03}
  3%|▎         | 767/24716 [10:24:08<223:16:45, 33.56s/it]  3%|▎         | 768/24716 [10:24:36<213:23:39, 32.08s/it]                                                          {'loss': 0.3183, 'grad_norm': 0.7421445171604221, 'learning_rate': 9.999970979490833e-05, 'epoch': 0.03}
  3%|▎         | 768/24716 [10:24:36<213:23:39, 32.08s/it]  3%|▎         | 769/24716 [10:25:10<216:19:17, 32.52s/it]                                                          {'loss': 0.2697, 'grad_norm': 1.347061886941557, 'learning_rate': 9.9999687042166e-05, 'epoch': 0.03}
  3%|▎         | 769/24716 [10:25:10<216:19:17, 32.52s/it]  3%|▎         | 770/24716 [10:25:45<222:10:48, 33.40s/it]                                                          {'loss': 0.2389, 'grad_norm': 0.3251180451545907, 'learning_rate': 9.999966343083326e-05, 'epoch': 0.03}
  3%|▎         | 770/24716 [10:25:45<222:10:48, 33.40s/it]  3%|▎         | 771/24716 [10:26:19<222:58:20, 33.52s/it]                                                          {'loss': 0.2592, 'grad_norm': 1.0802327194912307, 'learning_rate': 9.999963896091055e-05, 'epoch': 0.03}
  3%|▎         | 771/24716 [10:26:19<222:58:20, 33.52s/it]  3%|▎         | 772/24716 [10:26:50<217:20:41, 32.68s/it]                                                          {'loss': 0.2551, 'grad_norm': 0.5460820587546239, 'learning_rate': 9.999961363239825e-05, 'epoch': 0.03}
  3%|▎         | 772/24716 [10:26:50<217:20:41, 32.68s/it]  3%|▎         | 773/24716 [10:27:24<220:58:27, 33.23s/it]                                                          {'loss': 0.2436, 'grad_norm': 1.0778340603118155, 'learning_rate': 9.999958744529681e-05, 'epoch': 0.03}
  3%|▎         | 773/24716 [10:27:24<220:58:27, 33.23s/it]  3%|▎         | 774/24716 [10:27:54<213:18:34, 32.07s/it]                                                          {'loss': 0.3179, 'grad_norm': 0.5108844747338287, 'learning_rate': 9.999956039960667e-05, 'epoch': 0.03}
  3%|▎         | 774/24716 [10:27:54<213:18:34, 32.07s/it]  3%|▎         | 775/24716 [10:28:28<216:45:15, 32.59s/it]                                                          {'loss': 0.2589, 'grad_norm': 0.5454180156269354, 'learning_rate': 9.999953249532832e-05, 'epoch': 0.03}
  3%|▎         | 775/24716 [10:28:28<216:45:15, 32.59s/it]  3%|▎         | 776/24716 [10:29:00<215:33:53, 32.42s/it]                                                          {'loss': 0.3212, 'grad_norm': 1.294968198272652, 'learning_rate': 9.999950373246221e-05, 'epoch': 0.03}
  3%|▎         | 776/24716 [10:29:00<215:33:53, 32.42s/it]  3%|▎         | 777/24716 [10:29:31<213:10:11, 32.06s/it]                                                          {'loss': 0.3416, 'grad_norm': 2.3266457731654833, 'learning_rate': 9.999947411100886e-05, 'epoch': 0.03}
  3%|▎         | 777/24716 [10:29:31<213:10:11, 32.06s/it]  3%|▎         | 778/24716 [10:30:01<208:51:53, 31.41s/it]                                                          {'loss': 0.2267, 'grad_norm': 1.149061282808798, 'learning_rate': 9.999944363096876e-05, 'epoch': 0.03}
  3%|▎         | 778/24716 [10:30:01<208:51:53, 31.41s/it]  3%|▎         | 779/24716 [10:30:36<216:11:25, 32.51s/it]                                                          {'loss': 0.26, 'grad_norm': 2.8501522750293717, 'learning_rate': 9.999941229234244e-05, 'epoch': 0.03}
  3%|▎         | 779/24716 [10:30:36<216:11:25, 32.51s/it]  3%|▎         | 780/24716 [10:31:08<216:05:00, 32.50s/it]                                                          {'loss': 0.3024, 'grad_norm': 0.7283325391041459, 'learning_rate': 9.999938009513044e-05, 'epoch': 0.03}
  3%|▎         | 780/24716 [10:31:08<216:05:00, 32.50s/it]  3%|▎         | 781/24716 [10:31:44<221:55:18, 33.38s/it]                                                          {'loss': 0.2971, 'grad_norm': 0.4169320700483299, 'learning_rate': 9.99993470393333e-05, 'epoch': 0.03}
  3%|▎         | 781/24716 [10:31:44<221:55:18, 33.38s/it]  3%|▎         | 782/24716 [10:32:16<220:44:35, 33.20s/it]                                                          {'loss': 0.3209, 'grad_norm': 0.5805966268102654, 'learning_rate': 9.999931312495159e-05, 'epoch': 0.03}
  3%|▎         | 782/24716 [10:32:16<220:44:35, 33.20s/it]  3%|▎         | 783/24716 [10:32:51<223:43:03, 33.65s/it]                                                          {'loss': 0.3008, 'grad_norm': 0.8490003661702321, 'learning_rate': 9.999927835198591e-05, 'epoch': 0.03}
  3%|▎         | 783/24716 [10:32:51<223:43:03, 33.65s/it]  3%|▎         | 784/24716 [10:33:21<216:26:58, 32.56s/it]                                                          {'loss': 0.2874, 'grad_norm': 0.677627027511202, 'learning_rate': 9.999924272043686e-05, 'epoch': 0.03}
  3%|▎         | 784/24716 [10:33:21<216:26:58, 32.56s/it]  3%|▎         | 785/24716 [10:33:50<208:21:09, 31.34s/it]                                                          {'loss': 0.3054, 'grad_norm': 0.4181075920041294, 'learning_rate': 9.999920623030503e-05, 'epoch': 0.03}
  3%|▎         | 785/24716 [10:33:50<208:21:09, 31.34s/it]  3%|▎         | 786/24716 [10:34:20<207:15:00, 31.18s/it]                                                          {'loss': 0.2182, 'grad_norm': 0.44248574812666625, 'learning_rate': 9.999916888159105e-05, 'epoch': 0.03}
  3%|▎         | 786/24716 [10:34:20<207:15:00, 31.18s/it]  3%|▎         | 787/24716 [10:34:57<217:37:02, 32.74s/it]                                                          {'loss': 0.2978, 'grad_norm': 0.5209564785286361, 'learning_rate': 9.999913067429556e-05, 'epoch': 0.03}
  3%|▎         | 787/24716 [10:34:57<217:37:02, 32.74s/it]  3%|▎         | 788/24716 [10:35:27<212:45:12, 32.01s/it]                                                          {'loss': 0.3269, 'grad_norm': 0.7586739170280448, 'learning_rate': 9.999909160841923e-05, 'epoch': 0.03}
  3%|▎         | 788/24716 [10:35:27<212:45:12, 32.01s/it]  3%|▎         | 789/24716 [10:35:59<211:33:48, 31.83s/it]                                                          {'loss': 0.2446, 'grad_norm': 2.3492317896308594, 'learning_rate': 9.999905168396274e-05, 'epoch': 0.03}
  3%|▎         | 789/24716 [10:35:59<211:33:48, 31.83s/it]  3%|▎         | 790/24716 [10:36:31<212:17:31, 31.94s/it]                                                          {'loss': 0.2751, 'grad_norm': 0.6718211007687515, 'learning_rate': 9.999901090092674e-05, 'epoch': 0.03}
  3%|▎         | 790/24716 [10:36:31<212:17:31, 31.94s/it]  3%|▎         | 791/24716 [10:37:04<213:58:38, 32.20s/it]                                                          {'loss': 0.3879, 'grad_norm': 0.7472666950857882, 'learning_rate': 9.999896925931194e-05, 'epoch': 0.03}
  3%|▎         | 791/24716 [10:37:04<213:58:38, 32.20s/it]  3%|▎         | 792/24716 [10:37:32<206:36:11, 31.09s/it]                                                          {'loss': 0.2538, 'grad_norm': 0.5282795159329665, 'learning_rate': 9.999892675911909e-05, 'epoch': 0.03}
  3%|▎         | 792/24716 [10:37:32<206:36:11, 31.09s/it]  3%|▎         | 793/24716 [10:38:04<207:59:55, 31.30s/it]                                                          {'loss': 0.3873, 'grad_norm': 0.7744398278746688, 'learning_rate': 9.999888340034889e-05, 'epoch': 0.03}
  3%|▎         | 793/24716 [10:38:04<207:59:55, 31.30s/it]  3%|▎         | 794/24716 [10:38:34<205:00:29, 30.85s/it]                                                          {'loss': 0.3183, 'grad_norm': 0.7713710539597386, 'learning_rate': 9.999883918300207e-05, 'epoch': 0.03}
  3%|▎         | 794/24716 [10:38:34<205:00:29, 30.85s/it]  3%|▎         | 795/24716 [10:39:10<215:51:19, 32.49s/it]                                                          {'loss': 0.2757, 'grad_norm': 0.45611053122765155, 'learning_rate': 9.999879410707942e-05, 'epoch': 0.03}
  3%|▎         | 795/24716 [10:39:10<215:51:19, 32.49s/it]  3%|▎         | 796/24716 [10:39:44<219:52:31, 33.09s/it]                                                          {'loss': 0.2593, 'grad_norm': 0.47747953496874984, 'learning_rate': 9.99987481725817e-05, 'epoch': 0.03}
  3%|▎         | 796/24716 [10:39:44<219:52:31, 33.09s/it]  3%|▎         | 797/24716 [10:40:15<214:05:33, 32.22s/it]                                                          {'loss': 0.2325, 'grad_norm': 0.6896902084023817, 'learning_rate': 9.99987013795097e-05, 'epoch': 0.03}
  3%|▎         | 797/24716 [10:40:15<214:05:33, 32.22s/it]  3%|▎         | 798/24716 [10:40:40<199:52:58, 30.09s/it]                                                          {'loss': 0.3323, 'grad_norm': 0.7038815400937773, 'learning_rate': 9.999865372786423e-05, 'epoch': 0.03}
  3%|▎         | 798/24716 [10:40:40<199:52:58, 30.09s/it]  3%|▎         | 799/24716 [10:41:12<204:28:59, 30.78s/it]                                                          {'loss': 0.2476, 'grad_norm': 0.4359250701058416, 'learning_rate': 9.999860521764611e-05, 'epoch': 0.03}
  3%|▎         | 799/24716 [10:41:12<204:28:59, 30.78s/it]  3%|▎         | 800/24716 [10:41:48<214:40:18, 32.31s/it]                                                          {'loss': 0.2896, 'grad_norm': 0.44703290252563027, 'learning_rate': 9.999855584885616e-05, 'epoch': 0.03}
  3%|▎         | 800/24716 [10:41:48<214:40:18, 32.31s/it]  3%|▎         | 801/24716 [10:42:19<211:40:01, 31.86s/it]                                                          {'loss': 0.2391, 'grad_norm': 0.3595419146711368, 'learning_rate': 9.999850562149523e-05, 'epoch': 0.03}
  3%|▎         | 801/24716 [10:42:19<211:40:01, 31.86s/it]  3%|▎         | 802/24716 [10:42:53<215:54:32, 32.50s/it]                                                          {'loss': 0.4047, 'grad_norm': 1.6760157389364385, 'learning_rate': 9.999845453556419e-05, 'epoch': 0.03}
  3%|▎         | 802/24716 [10:42:53<215:54:32, 32.50s/it]  3%|▎         | 803/24716 [10:43:28<221:29:58, 33.35s/it]                                                          {'loss': 0.2823, 'grad_norm': 0.5738413116681378, 'learning_rate': 9.999840259106391e-05, 'epoch': 0.03}
  3%|▎         | 803/24716 [10:43:28<221:29:58, 33.35s/it]  3%|▎         | 804/24716 [10:43:58<215:02:34, 32.38s/it]                                                          {'loss': 0.2949, 'grad_norm': 0.6647986747983468, 'learning_rate': 9.99983497879953e-05, 'epoch': 0.03}
  3%|▎         | 804/24716 [10:43:58<215:02:34, 32.38s/it]  3%|▎         | 805/24716 [10:44:32<217:25:48, 32.74s/it]                                                          {'loss': 0.3198, 'grad_norm': 1.1747090556360027, 'learning_rate': 9.999829612635922e-05, 'epoch': 0.03}
  3%|▎         | 805/24716 [10:44:32<217:25:48, 32.74s/it]  3%|▎         | 806/24716 [10:45:06<219:57:50, 33.12s/it]                                                          {'loss': 0.2806, 'grad_norm': 0.9363337538397494, 'learning_rate': 9.999824160615664e-05, 'epoch': 0.03}
  3%|▎         | 806/24716 [10:45:06<219:57:50, 33.12s/it]  3%|▎         | 807/24716 [10:45:40<222:55:57, 33.57s/it]                                                          {'loss': 0.2973, 'grad_norm': 0.4810818104479378, 'learning_rate': 9.99981862273885e-05, 'epoch': 0.03}
  3%|▎         | 807/24716 [10:45:40<222:55:57, 33.57s/it]  3%|▎         | 808/24716 [10:46:12<219:43:59, 33.09s/it]                                                          {'loss': 0.2369, 'grad_norm': 0.3555784642363441, 'learning_rate': 9.999812999005571e-05, 'epoch': 0.03}
  3%|▎         | 808/24716 [10:46:12<219:43:59, 33.09s/it]  3%|▎         | 809/24716 [10:46:43<214:23:52, 32.28s/it]                                                          {'loss': 0.2463, 'grad_norm': 0.3553354002986472, 'learning_rate': 9.999807289415926e-05, 'epoch': 0.03}
  3%|▎         | 809/24716 [10:46:43<214:23:52, 32.28s/it]  3%|▎         | 810/24716 [10:47:17<218:36:47, 32.92s/it]                                                          {'loss': 0.2479, 'grad_norm': 0.4150352959153051, 'learning_rate': 9.999801493970013e-05, 'epoch': 0.03}
  3%|▎         | 810/24716 [10:47:17<218:36:47, 32.92s/it]  3%|▎         | 811/24716 [10:47:50<218:55:00, 32.97s/it]                                                          {'loss': 0.289, 'grad_norm': 1.5346090966604944, 'learning_rate': 9.99979561266793e-05, 'epoch': 0.03}
  3%|▎         | 811/24716 [10:47:50<218:55:00, 32.97s/it]  3%|▎         | 812/24716 [10:48:19<210:02:46, 31.63s/it]                                                          {'loss': 0.2648, 'grad_norm': 0.4663505360058269, 'learning_rate': 9.99978964550978e-05, 'epoch': 0.03}
  3%|▎         | 812/24716 [10:48:19<210:02:46, 31.63s/it]  3%|▎         | 813/24716 [10:48:53<214:58:44, 32.38s/it]                                                          {'loss': 0.2512, 'grad_norm': 0.49290345008061814, 'learning_rate': 9.999783592495665e-05, 'epoch': 0.03}
  3%|▎         | 813/24716 [10:48:53<214:58:44, 32.38s/it]  3%|▎         | 814/24716 [10:49:23<209:23:35, 31.54s/it]                                                          {'loss': 0.2656, 'grad_norm': 0.7393791118651224, 'learning_rate': 9.999777453625689e-05, 'epoch': 0.03}
  3%|▎         | 814/24716 [10:49:23<209:23:35, 31.54s/it]  3%|▎         | 815/24716 [10:49:55<210:30:43, 31.71s/it]                                                          {'loss': 0.2439, 'grad_norm': 0.5236972490319491, 'learning_rate': 9.999771228899956e-05, 'epoch': 0.03}
  3%|▎         | 815/24716 [10:49:55<210:30:43, 31.71s/it]  3%|▎         | 816/24716 [10:50:30<217:41:40, 32.79s/it]                                                          {'loss': 0.2759, 'grad_norm': 0.8841956673999262, 'learning_rate': 9.999764918318575e-05, 'epoch': 0.03}
  3%|▎         | 816/24716 [10:50:30<217:41:40, 32.79s/it]  3%|▎         | 817/24716 [10:51:05<222:39:25, 33.54s/it]                                                          {'loss': 0.3082, 'grad_norm': 0.7112694191619234, 'learning_rate': 9.999758521881652e-05, 'epoch': 0.03}
  3%|▎         | 817/24716 [10:51:05<222:39:25, 33.54s/it]  3%|▎         | 818/24716 [10:51:41<227:07:47, 34.21s/it]                                                          {'loss': 0.265, 'grad_norm': 0.6811191478858456, 'learning_rate': 9.999752039589299e-05, 'epoch': 0.03}
  3%|▎         | 818/24716 [10:51:41<227:07:47, 34.21s/it]  3%|▎         | 819/24716 [10:52:12<221:30:59, 33.37s/it]                                                          {'loss': 0.2592, 'grad_norm': 0.8946329703959223, 'learning_rate': 9.999745471441627e-05, 'epoch': 0.03}
  3%|▎         | 819/24716 [10:52:13<221:30:59, 33.37s/it]  3%|▎         | 820/24716 [10:52:43<215:11:54, 32.42s/it]                                                          {'loss': 0.2427, 'grad_norm': 2.515365843970483, 'learning_rate': 9.999738817438746e-05, 'epoch': 0.03}
  3%|▎         | 820/24716 [10:52:43<215:11:54, 32.42s/it]  3%|▎         | 821/24716 [10:53:13<211:49:20, 31.91s/it]                                                          {'loss': 0.2498, 'grad_norm': 0.6420563526742683, 'learning_rate': 9.999732077580774e-05, 'epoch': 0.03}
  3%|▎         | 821/24716 [10:53:13<211:49:20, 31.91s/it]  3%|▎         | 822/24716 [10:53:45<211:49:53, 31.92s/it]                                                          {'loss': 0.2969, 'grad_norm': 1.4874661656926131, 'learning_rate': 9.999725251867826e-05, 'epoch': 0.03}
  3%|▎         | 822/24716 [10:53:45<211:49:53, 31.92s/it]  3%|▎         | 823/24716 [10:54:45<267:04:19, 40.24s/it]                                                          {'loss': 0.2393, 'grad_norm': 1.0310259133028217, 'learning_rate': 9.999718340300017e-05, 'epoch': 0.03}
  3%|▎         | 823/24716 [10:54:45<267:04:19, 40.24s/it]  3%|▎         | 824/24716 [10:55:42<301:25:31, 45.42s/it]                                                          {'loss': 0.2872, 'grad_norm': 0.7488876040932393, 'learning_rate': 9.999711342877469e-05, 'epoch': 0.03}
  3%|▎         | 824/24716 [10:55:42<301:25:31, 45.42s/it]  3%|▎         | 825/24716 [10:56:23<291:05:27, 43.86s/it]                                                          {'loss': 0.2921, 'grad_norm': 0.5431343717888002, 'learning_rate': 9.999704259600299e-05, 'epoch': 0.03}
  3%|▎         | 825/24716 [10:56:23<291:05:27, 43.86s/it]  3%|▎         | 826/24716 [10:57:19<316:16:46, 47.66s/it]                                                          {'loss': 0.2361, 'grad_norm': 1.1922136639923318, 'learning_rate': 9.999697090468629e-05, 'epoch': 0.03}
  3%|▎         | 826/24716 [10:57:19<316:16:46, 47.66s/it]  3%|▎         | 827/24716 [10:58:09<320:29:11, 48.30s/it]                                                          {'loss': 0.2361, 'grad_norm': 1.0236815541436044, 'learning_rate': 9.999689835482584e-05, 'epoch': 0.03}
  3%|▎         | 827/24716 [10:58:09<320:29:11, 48.30s/it]  3%|▎         | 828/24716 [10:59:05<335:11:29, 50.51s/it]                                                          {'loss': 0.2908, 'grad_norm': 1.6810193667013367, 'learning_rate': 9.999682494642288e-05, 'epoch': 0.03}
  3%|▎         | 828/24716 [10:59:05<335:11:29, 50.51s/it]  3%|▎         | 829/24716 [10:59:50<325:02:03, 48.99s/it]                                                          {'loss': 0.2717, 'grad_norm': 1.7961901252949197, 'learning_rate': 9.999675067947867e-05, 'epoch': 0.03}
  3%|▎         | 829/24716 [10:59:50<325:02:03, 48.99s/it]  3%|▎         | 830/24716 [11:00:32<310:13:08, 46.75s/it]                                                          {'loss': 0.3255, 'grad_norm': 0.7621020778540704, 'learning_rate': 9.999667555399447e-05, 'epoch': 0.03}
  3%|▎         | 830/24716 [11:00:32<310:13:08, 46.75s/it]  3%|▎         | 831/24716 [11:01:30<333:48:07, 50.31s/it]                                                          {'loss': 0.2975, 'grad_norm': 1.3473037198525817, 'learning_rate': 9.999659956997159e-05, 'epoch': 0.03}
  3%|▎         | 831/24716 [11:01:30<333:48:07, 50.31s/it]  3%|▎         | 832/24716 [11:02:33<358:00:44, 53.96s/it]                                                          {'loss': 0.2654, 'grad_norm': 0.4351128196254896, 'learning_rate': 9.99965227274113e-05, 'epoch': 0.03}
  3%|▎         | 832/24716 [11:02:33<358:00:44, 53.96s/it]  3%|▎         | 833/24716 [11:03:27<358:53:31, 54.10s/it]                                                          {'loss': 0.2717, 'grad_norm': 0.7389591788620241, 'learning_rate': 9.999644502631499e-05, 'epoch': 0.03}
  3%|▎         | 833/24716 [11:03:27<358:53:31, 54.10s/it]  3%|▎         | 834/24716 [11:04:08<331:33:46, 49.98s/it]                                                          {'loss': 0.2975, 'grad_norm': 1.576703685552188, 'learning_rate': 9.999636646668393e-05, 'epoch': 0.03}
  3%|▎         | 834/24716 [11:04:08<331:33:46, 49.98s/it]  3%|▎         | 835/24716 [11:04:56<327:55:17, 49.43s/it]                                                          {'loss': 0.2285, 'grad_norm': 0.6070018024277481, 'learning_rate': 9.999628704851948e-05, 'epoch': 0.03}
  3%|▎         | 835/24716 [11:04:56<327:55:17, 49.43s/it]  3%|▎         | 836/24716 [11:05:39<316:31:40, 47.72s/it]                                                          {'loss': 0.2303, 'grad_norm': 0.6612203759764961, 'learning_rate': 9.999620677182303e-05, 'epoch': 0.03}
  3%|▎         | 836/24716 [11:05:39<316:31:40, 47.72s/it]  3%|▎         | 837/24716 [11:06:33<328:44:42, 49.56s/it]                                                          {'loss': 0.3104, 'grad_norm': 0.5880126642478708, 'learning_rate': 9.999612563659594e-05, 'epoch': 0.03}
  3%|▎         | 837/24716 [11:06:33<328:44:42, 49.56s/it]  3%|▎         | 838/24716 [11:07:28<338:09:01, 50.98s/it]                                                          {'loss': 0.3307, 'grad_norm': 0.6498662035759682, 'learning_rate': 9.99960436428396e-05, 'epoch': 0.03}
  3%|▎         | 838/24716 [11:07:28<338:09:01, 50.98s/it]  3%|▎         | 839/24716 [11:08:07<314:22:17, 47.40s/it]                                                          {'loss': 0.2625, 'grad_norm': 3.1521226954662724, 'learning_rate': 9.999596079055543e-05, 'epoch': 0.03}
  3%|▎         | 839/24716 [11:08:07<314:22:17, 47.40s/it]  3%|▎         | 840/24716 [11:08:55<315:38:57, 47.59s/it]                                                          {'loss': 0.2401, 'grad_norm': 0.6278902421791411, 'learning_rate': 9.999587707974483e-05, 'epoch': 0.03}
  3%|▎         | 840/24716 [11:08:55<315:38:57, 47.59s/it]  3%|▎         | 841/24716 [11:09:43<316:36:59, 47.74s/it]                                                          {'loss': 0.2934, 'grad_norm': 1.7775775726012144, 'learning_rate': 9.999579251040927e-05, 'epoch': 0.03}
  3%|▎         | 841/24716 [11:09:43<316:36:59, 47.74s/it]  3%|▎         | 842/24716 [11:10:42<339:21:44, 51.17s/it]                                                          {'loss': 0.2826, 'grad_norm': 0.9495979909406945, 'learning_rate': 9.999570708255017e-05, 'epoch': 0.03}
  3%|▎         | 842/24716 [11:10:42<339:21:44, 51.17s/it]  3%|▎         | 843/24716 [11:11:32<336:17:11, 50.71s/it]                                                          {'loss': 0.3263, 'grad_norm': 0.5192698536019852, 'learning_rate': 9.999562079616902e-05, 'epoch': 0.03}
  3%|▎         | 843/24716 [11:11:32<336:17:11, 50.71s/it]  3%|▎         | 844/24716 [11:12:29<350:24:00, 52.84s/it]                                                          {'loss': 0.2541, 'grad_norm': 2.3954370511187566, 'learning_rate': 9.999553365126731e-05, 'epoch': 0.03}
  3%|▎         | 844/24716 [11:12:29<350:24:00, 52.84s/it]  3%|▎         | 845/24716 [11:13:19<344:43:13, 51.99s/it]                                                          {'loss': 0.2941, 'grad_norm': 1.0564069929125244, 'learning_rate': 9.999544564784649e-05, 'epoch': 0.03}
  3%|▎         | 845/24716 [11:13:19<344:43:13, 51.99s/it]  3%|▎         | 846/24716 [11:14:09<339:34:38, 51.21s/it]                                                          {'loss': 0.2804, 'grad_norm': 0.7160096178899628, 'learning_rate': 9.999535678590812e-05, 'epoch': 0.03}
  3%|▎         | 846/24716 [11:14:09<339:34:38, 51.21s/it]  3%|▎         | 847/24716 [11:15:00<338:52:30, 51.11s/it]                                                          {'loss': 0.2803, 'grad_norm': 1.1181483472144238, 'learning_rate': 9.99952670654537e-05, 'epoch': 0.03}
  3%|▎         | 847/24716 [11:15:00<338:52:30, 51.11s/it]  3%|▎         | 848/24716 [11:15:48<333:40:55, 50.33s/it]                                                          {'loss': 0.2572, 'grad_norm': 0.6226635806894127, 'learning_rate': 9.999517648648479e-05, 'epoch': 0.03}
  3%|▎         | 848/24716 [11:15:48<333:40:55, 50.33s/it]  3%|▎         | 849/24716 [11:16:39<335:41:02, 50.63s/it]                                                          {'loss': 0.2496, 'grad_norm': 1.174070036890237, 'learning_rate': 9.999508504900292e-05, 'epoch': 0.03}
  3%|▎         | 849/24716 [11:16:39<335:41:02, 50.63s/it]  3%|▎         | 850/24716 [11:17:34<342:38:59, 51.69s/it]                                                          {'loss': 0.2707, 'grad_norm': 0.5676622985669082, 'learning_rate': 9.999499275300969e-05, 'epoch': 0.03}
  3%|▎         | 850/24716 [11:17:34<342:38:59, 51.69s/it]  3%|▎         | 851/24716 [11:18:35<362:40:59, 54.71s/it]                                                          {'loss': 0.257, 'grad_norm': 0.8061238303095775, 'learning_rate': 9.999489959850665e-05, 'epoch': 0.03}
  3%|▎         | 851/24716 [11:18:35<362:40:59, 54.71s/it]  3%|▎         | 852/24716 [11:19:24<350:31:57, 52.88s/it]                                                          {'loss': 0.3352, 'grad_norm': 1.1489051655256715, 'learning_rate': 9.999480558549544e-05, 'epoch': 0.03}
  3%|▎         | 852/24716 [11:19:24<350:31:57, 52.88s/it]  3%|▎         | 853/24716 [11:20:15<346:46:56, 52.32s/it]                                                          {'loss': 0.2911, 'grad_norm': 0.7775070719555456, 'learning_rate': 9.999471071397764e-05, 'epoch': 0.03}
  3%|▎         | 853/24716 [11:20:15<346:46:56, 52.32s/it]  3%|▎         | 854/24716 [11:21:06<343:39:03, 51.85s/it]                                                          {'loss': 0.2305, 'grad_norm': 0.6909462915094159, 'learning_rate': 9.999461498395489e-05, 'epoch': 0.03}
  3%|▎         | 854/24716 [11:21:06<343:39:03, 51.85s/it]  3%|▎         | 855/24716 [11:21:49<327:25:54, 49.40s/it]                                                          {'loss': 0.31, 'grad_norm': 0.8563913987400982, 'learning_rate': 9.999451839542884e-05, 'epoch': 0.03}
  3%|▎         | 855/24716 [11:21:49<327:25:54, 49.40s/it]  3%|▎         | 856/24716 [11:22:29<307:39:43, 46.42s/it]                                                          [E ProcessGroupNCCL.cpp:475] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=1855118, OpType=_ALLGATHER_BASE, NumelIn=5728128, NumelOut=17184384, Timeout(ms)=1800000) ran for 1800884 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:475] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=1855118, OpType=_ALLGATHER_BASE, NumelIn=5728128, NumelOut=17184384, Timeout(ms)=1800000) ran for 1800404 milliseconds before timing out.
{'loss': 0.2434, 'grad_norm': 0.9167801791329362, 'learning_rate': 9.999442094840114e-05, 'epoch': 0.03}
  3%|▎         | 856/24716 [14:50:48<307:39:43, 46.42s/it][E ProcessGroupNCCL.cpp:489] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:495] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:489] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:495] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:916] [Rank 1] NCCL watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=1855118, OpType=_ALLGATHER_BASE, NumelIn=5728128, NumelOut=17184384, Timeout(ms)=1800000) ran for 1800884 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:916] [Rank 2] NCCL watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=1855118, OpType=_ALLGATHER_BASE, NumelIn=5728128, NumelOut=17184384, Timeout(ms)=1800000) ran for 1800404 milliseconds before timing out.
[2025-08-29 11:00:17,313] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 1384243 closing signal SIGTERM
[2025-08-29 11:00:17,980] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -6) local_rank: 1 (pid: 1384244) of binary: /hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/bin/python
Traceback (most recent call last):
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.2', 'console_scripts', 'torchrun')())
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
========================================================
llava/train/train_mem.py FAILED
--------------------------------------------------------
Failures:
[1]:
  time      : 2025-08-29_11:00:17
  host      : 956aa2bad2ae
  rank      : 2 (local_rank: 2)
  exitcode  : -6 (pid: 1384245)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 1384245
--------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-08-29_11:00:17
  host      : 956aa2bad2ae
  rank      : 1 (local_rank: 1)
  exitcode  : -6 (pid: 1384244)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 1384244
========================================================
