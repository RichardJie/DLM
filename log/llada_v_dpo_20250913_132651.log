[2025-09-13 13:26:54,519] torch.distributed.run: [WARNING] 
[2025-09-13 13:26:54,519] torch.distributed.run: [WARNING] *****************************************
[2025-09-13 13:26:54,519] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2025-09-13 13:26:54,519] torch.distributed.run: [WARNING] *****************************************
[2025-09-13 13:26:56,800] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-09-13 13:26:56,803] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-09-13 13:26:56,811] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Please install pyav to use video processing functions.
Please install pyav to use video processing functions.
Please install pyav to use video processing functions.
OpenCLIP not installed
OpenCLIP not installed
OpenCLIP not installed
/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-09-13 13:27:01,072] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-09-13 13:27:01,072] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-09-13 13:27:01,072] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-09-13 13:27:01,103] [INFO] [comm.py:637:init_distributed] cdb=None
You are using a model of type llada to instantiate a model of type llava_llada. This is not supported for all configurations of models and can yield errors.
You are using a model of type llada to instantiate a model of type llava_llada. This is not supported for all configurations of models and can yield errors.
You are using a model of type llada to instantiate a model of type llava_llada. This is not supported for all configurations of models and can yield errors.
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:01<00:09,  1.90s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:01<00:09,  1.89s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:01<00:09,  1.94s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:04<00:08,  2.12s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:04<00:08,  2.12s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:04<00:08,  2.16s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:06<00:06,  2.20s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:06<00:06,  2.16s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:06<00:06,  2.19s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:08<00:04,  2.19s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:08<00:04,  2.23s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:08<00:04,  2.20s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:10<00:02,  2.18s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:10<00:02,  2.21s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:10<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:12<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:12<00:00,  2.05s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:12<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:12<00:00,  2.08s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:12<00:00,  1.99s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:12<00:00,  2.08s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Rank 0:  Loaded PEFT adapter from /hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/exp/llada_v_finetune (trainable).
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Rank 0:  Prompt version: llava_llada
Rank 0:  Loading vision tower: /hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/models/siglip2-so400m-patch14-384
Rank 0:  Total parameters: ~8518.72 MB)
Rank 0:  Trainable parameters: ~105.39 MB)
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Rank 0:  Loading vision tower: /hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/models/siglip2-so400m-patch14-384
/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/trl/trainer/dpo_trainer.py:239: UserWarning: `max_prompt_length` is not set in the DPOTrainer's init it will default to `128` by default, but you should do it yourself in the future.
  warnings.warn(
Rank 0:  Loading /hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/dataset/coco2017/llava_multi/coco_val2017_DPO_pairs_small_focus.jsonl
Rank 0:  Loaded 18059 samples from /hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/dataset/coco2017/llava_multi/coco_val2017_DPO_pairs_small_focus.jsonl
Rank 0:  Formatting inputs...Skip in lazy mode
/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/trl/trainer/dpo_trainer.py:239: UserWarning: `max_prompt_length` is not set in the DPOTrainer's init it will default to `128` by default, but you should do it yourself in the future.
  warnings.warn(
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2025-09-13 13:30:22,013] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.2, git-hash=unknown, git-branch=unknown
/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/trl/trainer/dpo_trainer.py:239: UserWarning: `max_prompt_length` is not set in the DPOTrainer's init it will default to `128` by default, but you should do it yourself in the future.
  warnings.warn(
[2025-09-13 13:30:37,278] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/utils/cpp_extension.py:28: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import packaging  # type: ignore[attr-defined]
/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/utils/cpp_extension.py:28: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import packaging  # type: ignore[attr-defined]
/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/utils/cpp_extension.py:28: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import packaging  # type: ignore[attr-defined]
Using /hpc2hdd/home/yuxuanzhao/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Using /hpc2hdd/home/yuxuanzhao/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Using /hpc2hdd/home/yuxuanzhao/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /hpc2hdd/home/yuxuanzhao/.cache/torch_extensions/py39_cu121/fused_adam/build.ninja...
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/3] /hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/cuda_12_1/bin/nvcc  -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/ops/csrc/includes -I/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/ops/csrc/adam -isystem /hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/include -isystem /hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/include/TH -isystem /hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/include/THC -isystem /hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/cuda_12_1/include -isystem /hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -lineinfo --use_fast_math -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_80,code=compute_80 -DBF16_AVAILABLE -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -std=c++17 -c /hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/ops/csrc/adam/multi_tensor_adam.cu -o multi_tensor_adam.cuda.o 
[2/3] c++ -MMD -MF fused_adam_frontend.o.d -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/ops/csrc/includes -I/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/ops/csrc/adam -isystem /hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/include -isystem /hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/include/TH -isystem /hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/include/THC -isystem /hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/cuda_12_1/include -isystem /hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DBF16_AVAILABLE -c /hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/ops/csrc/adam/fused_adam_frontend.cpp -o fused_adam_frontend.o 
[3/3] c++ fused_adam_frontend.o multi_tensor_adam.cuda.o -shared -L/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/cuda_12_1/lib64 -lcudart -o fused_adam.so
Loading extension module fused_adam...
Time to load fused_adam op: 29.268951654434204 seconds
/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400412039/work/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = get_accelerator().IntTensor([0])
[2025-09-13 13:31:07,906] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer
[2025-09-13 13:31:07,906] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
Loading extension module fused_adam...
Time to load fused_adam op: 29.24596381187439 seconds
/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400412039/work/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = get_accelerator().IntTensor([0])
Loading extension module fused_adam...
Time to load fused_adam op: 28.947245597839355 seconds
/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400412039/work/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = get_accelerator().IntTensor([0])
[2025-09-13 13:31:07,988] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[2025-09-13 13:31:07,988] [INFO] [logging.py:96:log_dist] [Rank 0] Creating BF16 optimizer
[2025-09-13 13:31:08,126] [INFO] [utils.py:802:see_memory_usage] begin bf16_optimizer
[2025-09-13 13:31:08,127] [INFO] [utils.py:803:see_memory_usage] MA 16.72 GB         Max_MA 16.72 GB         CA 16.93 GB         Max_CA 17 GB 
[2025-09-13 13:31:08,127] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 150.84 GB, percent = 15.0%
[2025-09-13 13:31:08,250] [INFO] [utils.py:802:see_memory_usage] before initializing group 0
[2025-09-13 13:31:08,251] [INFO] [utils.py:803:see_memory_usage] MA 16.72 GB         Max_MA 16.72 GB         CA 16.93 GB         Max_CA 17 GB 
[2025-09-13 13:31:08,251] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 150.84 GB, percent = 15.0%
Traceback (most recent call last):
  File "/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/llava/train/train_dpo.py", line 1902, in <module>
    train()
  File "/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/llava/train/train_dpo.py", line 1861, in train
    trainer = LLaVADPOTrainer(
  File "/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/trl/trainer/dpo_trainer.py", line 339, in __init__
Traceback (most recent call last):
    self.ref_model = self._prepare_deepspeed(self.ref_model)
  File "/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/trl/trainer/dpo_trainer.py", line 366, in _prepare_deepspeed
  File "/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/llava/train/train_dpo.py", line 1902, in <module>
    model, *_ = deepspeed.initialize(model=model, config=config_kwargs)
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/__init__.py", line 171, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 304, in __init__
    train()
  File "/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/llava/train/train_dpo.py", line 1861, in train
Traceback (most recent call last):
  File "/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/llava/train/train_dpo.py", line 1902, in <module>
    trainer = LLaVADPOTrainer(
  File "/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/trl/trainer/dpo_trainer.py", line 339, in __init__
    self.ref_model = self._prepare_deepspeed(self.ref_model)
  File "/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/trl/trainer/dpo_trainer.py", line 366, in _prepare_deepspeed
    model, *_ = deepspeed.initialize(model=model, config=config_kwargs)
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/__init__.py", line 171, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 304, in __init__
    train()
  File "/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/llava/train/train_dpo.py", line 1861, in train
    trainer = LLaVADPOTrainer(
  File "/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/trl/trainer/dpo_trainer.py", line 339, in __init__
    self.ref_model = self._prepare_deepspeed(self.ref_model)
  File "/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/trl/trainer/dpo_trainer.py", line 366, in _prepare_deepspeed
    model, *_ = deepspeed.initialize(model=model, config=config_kwargs)
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/__init__.py", line 171, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 304, in __init__
    self._configure_optimizer(optimizer, model_parameters)
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1230, in _configure_optimizer
    self._configure_optimizer(optimizer, model_parameters)    
self._configure_optimizer(optimizer, model_parameters)
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1230, in _configure_optimizer
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1230, in _configure_optimizer
    self.optimizer = self._configure_bf16_optimizer(basic_optimizer)
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1435, in _configure_bf16_optimizer
    optimizer = BF16_Optimizer(optimizer,
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/runtime/bf16_optimizer.py", line 82, in __init__
    self._setup_for_real_optimizer()
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/runtime/bf16_optimizer.py", line 101, in _setup_for_real_optimizer
    self._flatten_dense_tensors_aligned(self.bf16_groups[i],
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/runtime/bf16_optimizer.py", line 231, in _flatten_dense_tensors_aligned
    return self.flatten(align_dense_tensors(tensor_list, alignment))
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/_utils.py", line 498, in _flatten_dense_tensors
        self.optimizer = self._configure_bf16_optimizer(basic_optimizer)self.optimizer = self._configure_bf16_optimizer(basic_optimizer)

  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1435, in _configure_bf16_optimizer
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1435, in _configure_bf16_optimizer
    return torch._C._nn.flatten_dense_tensors(tensors)
RuntimeError: torch.cat(): expected a non-empty list of Tensors
    optimizer = BF16_Optimizer(optimizer,
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/runtime/bf16_optimizer.py", line 82, in __init__
    optimizer = BF16_Optimizer(optimizer,
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/runtime/bf16_optimizer.py", line 82, in __init__
    self._setup_for_real_optimizer()
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/runtime/bf16_optimizer.py", line 101, in _setup_for_real_optimizer
    self._setup_for_real_optimizer()
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/runtime/bf16_optimizer.py", line 101, in _setup_for_real_optimizer
    self._flatten_dense_tensors_aligned(self.bf16_groups[i],
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/runtime/bf16_optimizer.py", line 231, in _flatten_dense_tensors_aligned
    self._flatten_dense_tensors_aligned(self.bf16_groups[i],
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/deepspeed/runtime/bf16_optimizer.py", line 231, in _flatten_dense_tensors_aligned
    return self.flatten(align_dense_tensors(tensor_list, alignment))
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/_utils.py", line 498, in _flatten_dense_tensors
    return self.flatten(align_dense_tensors(tensor_list, alignment))
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/_utils.py", line 498, in _flatten_dense_tensors
    return torch._C._nn.flatten_dense_tensors(tensors)
RuntimeError: torch.cat(): expected a non-empty list of Tensors
    return torch._C._nn.flatten_dense_tensors(tensors)
RuntimeError: torch.cat(): expected a non-empty list of Tensors
[2025-09-13 13:31:14,783] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 965736) of binary: /hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/bin/python
Traceback (most recent call last):
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.2', 'console_scripts', 'torchrun')())
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
llava/train/train_dpo.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-09-13_13:31:14
  host      : d5fd97d7a706
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 965740)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2025-09-13_13:31:14
  host      : d5fd97d7a706
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 965750)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-09-13_13:31:14
  host      : d5fd97d7a706
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 965736)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
