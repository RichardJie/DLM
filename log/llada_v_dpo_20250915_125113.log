[2025-09-15 12:51:15,321] torch.distributed.run: [WARNING] 
[2025-09-15 12:51:15,321] torch.distributed.run: [WARNING] *****************************************
[2025-09-15 12:51:15,321] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2025-09-15 12:51:15,321] torch.distributed.run: [WARNING] *****************************************
[2025-09-15 12:51:18,063] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-09-15 12:51:18,064] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-09-15 12:51:18,064] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Please install pyav to use video processing functions.
Please install pyav to use video processing functions.
Please install pyav to use video processing functions.
OpenCLIP not installedOpenCLIP not installed

OpenCLIP not installed
/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2025-09-15 12:51:41,885] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-09-15 12:51:41,885] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-09-15 12:51:41,889] [INFO] [comm.py:637:init_distributed] cdb=None
You are using a model of type llada to instantiate a model of type llava_llada. This is not supported for all configurations of models and can yield errors.
[2025-09-15 12:51:42,056] [INFO] [comm.py:637:init_distributed] cdb=None
You are using a model of type llada to instantiate a model of type llava_llada. This is not supported for all configurations of models and can yield errors.
You are using a model of type llada to instantiate a model of type llava_llada. This is not supported for all configurations of models and can yield errors.
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:03,  1.30it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:01<00:07,  1.51s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:03,  1.36it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:03<00:07,  1.82s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:06,  1.53s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:05,  1.49s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:05<00:05,  1.83s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:05<00:05,  2.00s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:04<00:05,  1.79s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:08<00:04,  2.17s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:07<00:04,  2.04s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:07<00:04,  2.07s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:10<00:02,  2.09s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:09<00:02,  2.03s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:09<00:02,  2.04s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:09<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:09<00:00,  1.62s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:10<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:10<00:00,  1.74s/it]
Traceback (most recent call last):
  File "/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/llava/train/train_dpo.py", line 1902, in <module>
Traceback (most recent call last):
  File "/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/llava/train/train_dpo.py", line 1902, in <module>
    train()
  File "/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/llava/train/train_dpo.py", line 1602, in train
    model, ref_model = get_model(model_args, training_args, bnb_model_from_pretrained_args)
  File "/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/llava/train/train_dpo.py", line 1349, in get_model
    train()
  File "/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/llava/train/train_dpo.py", line 1602, in train
    model = policy_cls.from_pretrained(
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3677, in from_pretrained
    model, ref_model = get_model(model_args, training_args, bnb_model_from_pretrained_args)
  File "/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/llava/train/train_dpo.py", line 1349, in get_model
    model = policy_cls.from_pretrained(
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3677, in from_pretrained
    ) = cls._load_pretrained_model(    
) = cls._load_pretrained_model(  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/transformers/modeling_utils.py", line 4155, in _load_pretrained_model

  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/transformers/modeling_utils.py", line 4155, in _load_pretrained_model
    raise RuntimeError(f"Error(s) in loading state_dict for {model.__class__.__name__}:\n\t{error_msg}")
RuntimeError: Error(s) in loading state_dict for LlavaLLaDAModelLM:
	size mismatch for model.embed_tokens.weight: copying a param with shape torch.Size([126349, 4096]) from checkpoint, the shape in current model is torch.Size([126464, 4096]).
	size mismatch for model.layers.0.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.0.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.0.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.1.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.1.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.1.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.2.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.2.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.2.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.3.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.3.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.3.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.4.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.4.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.4.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.5.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.5.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.5.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.6.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.6.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.6.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.7.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.7.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.7.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.8.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.8.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.8.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.9.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.9.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.9.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.10.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.10.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.10.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.11.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.11.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.11.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.12.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.12.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.12.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.13.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.13.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.13.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.14.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.14.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.14.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.15.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.15.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.15.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.16.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.16.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.16.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.17.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.17.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.17.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.18.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.18.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.18.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.19.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.19.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.19.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.20.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.20.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.20.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.21.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.21.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.21.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.22.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.22.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.22.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.23.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.23.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.23.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.24.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.24.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.24.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.25.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.25.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.25.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.26.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.26.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.26.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.27.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.27.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.27.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.28.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.28.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.28.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.29.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.29.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.29.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.30.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.30.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.30.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.31.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.31.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.31.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for lm_head.weight: copying a param with shape torch.Size([126349, 4096]) from checkpoint, the shape in current model is torch.Size([126464, 4096]).
	You may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.
    raise RuntimeError(f"Error(s) in loading state_dict for {model.__class__.__name__}:\n\t{error_msg}")
RuntimeError: Error(s) in loading state_dict for LlavaLLaDAModelLM:
	size mismatch for model.embed_tokens.weight: copying a param with shape torch.Size([126349, 4096]) from checkpoint, the shape in current model is torch.Size([126464, 4096]).
	size mismatch for model.layers.0.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.0.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.0.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.1.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.1.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.1.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.2.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.2.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.2.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.3.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.3.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.3.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.4.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.4.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.4.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.5.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.5.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.5.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.6.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.6.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.6.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.7.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.7.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.7.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.8.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.8.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.8.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.9.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.9.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.9.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.10.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.10.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.10.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.11.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.11.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.11.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.12.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.12.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.12.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.13.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.13.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.13.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.14.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.14.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.14.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.15.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.15.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.15.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.16.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.16.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.16.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.17.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.17.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.17.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.18.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.18.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.18.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.19.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.19.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.19.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.20.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.20.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.20.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.21.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.21.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.21.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.22.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.22.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.22.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.23.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.23.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.23.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.24.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.24.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.24.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.25.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.25.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.25.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.26.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.26.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.26.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.27.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.27.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.27.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.28.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.28.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.28.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.29.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.29.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.29.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.30.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.30.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.30.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.31.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.31.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.31.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for lm_head.weight: copying a param with shape torch.Size([126349, 4096]) from checkpoint, the shape in current model is torch.Size([126464, 4096]).
	You may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.
Loading checkpoint shards: 100%|██████████| 6/6 [00:09<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:09<00:00,  1.61s/it]
Traceback (most recent call last):
  File "/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/llava/train/train_dpo.py", line 1902, in <module>
    train()
  File "/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/llava/train/train_dpo.py", line 1602, in train
    model, ref_model = get_model(model_args, training_args, bnb_model_from_pretrained_args)
  File "/hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/train/llava/train/train_dpo.py", line 1349, in get_model
    model = policy_cls.from_pretrained(
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3677, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/transformers/modeling_utils.py", line 4155, in _load_pretrained_model
    raise RuntimeError(f"Error(s) in loading state_dict for {model.__class__.__name__}:\n\t{error_msg}")
RuntimeError: Error(s) in loading state_dict for LlavaLLaDAModelLM:
	size mismatch for model.embed_tokens.weight: copying a param with shape torch.Size([126349, 4096]) from checkpoint, the shape in current model is torch.Size([126464, 4096]).
	size mismatch for model.layers.0.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.0.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.0.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.1.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.1.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.1.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.2.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.2.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.2.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.3.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.3.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.3.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.4.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.4.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.4.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.5.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.5.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.5.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.6.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.6.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.6.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.7.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.7.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.7.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.8.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.8.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.8.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.9.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.9.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.9.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.10.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.10.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.10.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.11.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.11.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.11.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.12.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.12.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.12.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.13.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.13.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.13.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.14.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.14.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.14.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.15.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.15.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.15.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.16.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.16.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.16.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.17.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.17.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.17.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.18.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.18.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.18.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.19.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.19.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.19.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.20.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.20.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.20.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.21.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.21.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.21.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.22.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.22.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.22.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.23.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.23.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.23.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.24.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.24.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.24.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.25.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.25.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.25.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.26.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.26.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.26.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.27.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.27.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.27.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.28.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.28.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.28.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.29.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.29.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.29.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.30.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.30.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.30.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for model.layers.31.mlp.gate_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.31.mlp.up_proj.weight: copying a param with shape torch.Size([12288, 4096]) from checkpoint, the shape in current model is torch.Size([11008, 4096]).
	size mismatch for model.layers.31.mlp.down_proj.weight: copying a param with shape torch.Size([4096, 12288]) from checkpoint, the shape in current model is torch.Size([4096, 11008]).
	size mismatch for lm_head.weight: copying a param with shape torch.Size([126349, 4096]) from checkpoint, the shape in current model is torch.Size([126464, 4096]).
	You may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.
[2025-09-15 12:55:40,614] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 3949209) of binary: /hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/bin/python
Traceback (most recent call last):
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.2', 'console_scripts', 'torchrun')())
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
llava/train/train_dpo.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-09-15_12:55:40
  host      : d5fd97d7a706
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 3949210)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2025-09-15_12:55:40
  host      : d5fd97d7a706
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 3949211)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-09-15_12:55:40
  host      : d5fd97d7a706
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3949209)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
