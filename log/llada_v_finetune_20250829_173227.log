WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2025-08-29 17:33:37,123] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-29 17:33:37,124] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-29 17:33:37,125] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Please install pyav to use video processing functions.
Please install pyav to use video processing functions.Please install pyav to use video processing functions.

/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
OpenCLIP not installed
OpenCLIP not installed
OpenCLIP not installed
[2025-08-29 17:33:59,175] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-08-29 17:33:59,181] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-08-29 17:33:59,182] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-08-29 17:33:59,188] [INFO] [comm.py:637:init_distributed] cdb=None
You are using a model of type llava_llada to instantiate a model of type llada. This is not supported for all configurations of models and can yield errors.
Rank 0:  Overwriting config with {'use_pos_skipping': False, 'pos_skipping_range': 4096, 'mm_spatial_pool_mode': 'bilinear'}
You are using a model of type llava_llada to instantiate a model of type llada. This is not supported for all configurations of models and can yield errors.
You are using a model of type llava_llada to instantiate a model of type llada. This is not supported for all configurations of models and can yield errors.
Rank 0:  Loading vision tower: google/siglip2-so400m-patch14-384
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:04<00:22,  4.54s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:04<00:23,  4.65s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:04<00:24,  4.87s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:08<00:17,  4.33s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:08<00:17,  4.29s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:08<00:16,  4.24s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:13<00:13,  4.38s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:13<00:13,  4.34s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:13<00:13,  4.38s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:17<00:08,  4.28s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:17<00:08,  4.21s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:17<00:08,  4.33s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:21<00:04,  4.17s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:21<00:04,  4.12s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:21<00:04,  4.19s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:23<00:00,  3.59s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:23<00:00,  3.95s/it]
Rank 0:  Adding LoRA adapters...
Loading checkpoint shards: 100%|██████████| 6/6 [00:23<00:00,  3.55s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:23<00:00,  3.92s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:23<00:00,  3.62s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:23<00:00,  3.99s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Rank 0:  Prompt version: llava_llada
Rank 0:  google/siglip2-so400m-patch14-384 is already loaded, `load_model` called again, skipping.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Rank 0:  Total parameters: ~8523.53 MB)
Rank 0:  Trainable parameters: ~105.39 MB)
Rank 0:  Loading data using traditional JSON format
Rank 0:  Loading /hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/dataset/coco2017/llava_multi/coco_val2017_grouped_by_category.json
Rank 0:  Loaded 4952 samples from /hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/dataset/coco2017/llava_multi/coco_val2017_grouped_by_category.json
Rank 0:  Loaded 4952 samples from /hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/dataset/coco2017/llava_multi/coco_val2017_grouped_by_category.json
Rank 0:  Formatting inputs...Skip in lazy mode
Rank 0:  Setting NCCL timeout to INF to avoid running errors.
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
