[2025-08-25 20:56:26,919] torch.distributed.run: [WARNING] 
[2025-08-25 20:56:26,919] torch.distributed.run: [WARNING] *****************************************
[2025-08-25 20:56:26,919] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2025-08-25 20:56:26,919] torch.distributed.run: [WARNING] *****************************************
[2025-08-25 20:56:32,270] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-25 20:56:32,270] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-25 20:56:32,270] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Please install pyav to use video processing functions.
Please install pyav to use video processing functions.
Please install pyav to use video processing functions.
/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
OpenCLIP not installed
OpenCLIP not installed
OpenCLIP not installed
[2025-08-25 20:56:40,264] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-08-25 20:56:40,265] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-08-25 20:56:40,265] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-08-25 20:56:40,266] [INFO] [comm.py:637:init_distributed] cdb=None
You are using a model of type llava_llada to instantiate a model of type llada. This is not supported for all configurations of models and can yield errors.
Rank 0:  Overwriting config with {'use_pos_skipping': False, 'pos_skipping_range': 4096, 'mm_spatial_pool_mode': 'bilinear'}
You are using a model of type llava_llada to instantiate a model of type llada. This is not supported for all configurations of models and can yield errors.
You are using a model of type llava_llada to instantiate a model of type llada. This is not supported for all configurations of models and can yield errors.
Rank 0:  Loading vision tower: google/siglip2-so400m-patch14-384
[2025-08-25 20:56:49,140] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 1035, num_elems = 16.48B
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  5.67it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  5.46it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00,  5.46it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:02,  1.85it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:02<00:02,  1.02it/s]Loading checkpoint shards:  50%|█████     | 3/6 [00:02<00:03,  1.08s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:03<00:18,  3.61s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:06<00:04,  2.09s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:06<00:04,  2.14s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:07<00:14,  3.73s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:10<00:02,  2.73s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:10<00:02,  2.70s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:11<00:11,  3.71s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:14<00:07,  3.69s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:18<00:03,  3.61s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:20<00:00,  5.39s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:20<00:00,  3.45s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:20<00:00,  5.41s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:20<00:00,  3.45s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:21<00:00,  3.57s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:21<00:00,  3.62s/it]
Rank 0:  Adding LoRA adapters...
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Rank 0:  Prompt version: llava_llada
Rank 0:  google/siglip2-so400m-patch14-384 is already loaded, `load_model` called again, skipping.
Rank 0:  Total parameters: ~8523.53 MB)
Rank 0:  Trainable parameters: ~105.39 MB)
Rank 0:  Loading data using traditional JSON format
Rank 0:  Loading /hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/dataset/textvqa_bbox_coords_384/textvqa_bbox_coords_llava_384.json
Rank 0:  Loaded 4370 samples from /hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/dataset/textvqa_bbox_coords_384/textvqa_bbox_coords_llava_384.json
Rank 0:  Loaded 4370 samples from /hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/dataset/textvqa_bbox_coords_384/textvqa_bbox_coords_llava_384.json
Rank 0:  Formatting inputs...Skip in lazy mode
Rank 0:  Setting NCCL timeout to INF to avoid running errors.
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Parameter Offload: Total persistent parameters: 6414240 in 487 params
  0%|          | 0/910 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable To disable this warning, you can either:
TOKENIZERS_PARALLELISM	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable =(true | false)
TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  0%|          | 1/910 [00:41<10:23:09, 41.13s/it]                                                  {'loss': 2.0981, 'grad_norm': 3.7069980079121785, 'learning_rate': 3.5714285714285714e-06, 'epoch': 0.01}
  0%|          | 1/910 [00:41<10:23:09, 41.13s/it]  0%|          | 2/910 [01:07<8:12:17, 32.53s/it]                                                  {'loss': 1.9326, 'grad_norm': 7.061068883500159, 'learning_rate': 7.142857142857143e-06, 'epoch': 0.02}
  0%|          | 2/910 [01:07<8:12:17, 32.53s/it]  0%|          | 3/910 [01:33<7:28:33, 29.67s/it]                                                 {'loss': 1.4901, 'grad_norm': 3.1487874808144807, 'learning_rate': 1.0714285714285714e-05, 'epoch': 0.03}
  0%|          | 3/910 [01:33<7:28:33, 29.67s/it][2025-08-25 21:00:45,525] [WARNING] [stage3.py:1949:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  0%|          | 4/910 [02:00<7:10:56, 28.54s/it]                                                 {'loss': 1.6555, 'grad_norm': 4.2696942729946405, 'learning_rate': 1.4285714285714285e-05, 'epoch': 0.04}
  0%|          | 4/910 [02:00<7:10:56, 28.54s/it]  1%|          | 5/910 [02:27<7:00:13, 27.86s/it]                                                 {'loss': 1.312, 'grad_norm': 2.8333888727556924, 'learning_rate': 1.785714285714286e-05, 'epoch': 0.05}
  1%|          | 5/910 [02:27<7:00:13, 27.86s/it]  1%|          | 6/910 [02:53<6:51:47, 27.33s/it]                                                 {'loss': 2.1302, 'grad_norm': 3.79220356288828, 'learning_rate': 2.1428571428571428e-05, 'epoch': 0.07}
  1%|          | 6/910 [02:53<6:51:47, 27.33s/it]  1%|          | 7/910 [03:20<6:47:14, 27.06s/it]                                                 {'loss': 1.5928, 'grad_norm': 3.0178601613298057, 'learning_rate': 2.5e-05, 'epoch': 0.08}
  1%|          | 7/910 [03:20<6:47:14, 27.06s/it]  1%|          | 8/910 [03:46<6:45:36, 26.98s/it]                                                 {'loss': 1.4772, 'grad_norm': 2.1690671487179785, 'learning_rate': 2.857142857142857e-05, 'epoch': 0.09}
  1%|          | 8/910 [03:46<6:45:36, 26.98s/it]  1%|          | 9/910 [04:13<6:42:55, 26.83s/it]                                                 {'loss': 1.7585, 'grad_norm': 4.302975048819333, 'learning_rate': 3.2142857142857144e-05, 'epoch': 0.1}
  1%|          | 9/910 [04:13<6:42:55, 26.83s/it]  1%|          | 10/910 [04:40<6:41:20, 26.76s/it]                                                  {'loss': 1.548, 'grad_norm': 2.5395060308789623, 'learning_rate': 3.571428571428572e-05, 'epoch': 0.11}
  1%|          | 10/910 [04:40<6:41:20, 26.76s/it]  1%|          | 11/910 [05:06<6:41:12, 26.78s/it]                                                  {'loss': 1.6677, 'grad_norm': 5.104098008884049, 'learning_rate': 3.928571428571429e-05, 'epoch': 0.12}
  1%|          | 11/910 [05:06<6:41:12, 26.78s/it]  1%|▏         | 12/910 [05:33<6:40:04, 26.73s/it]                                                  {'loss': 1.2757, 'grad_norm': 1.9870415646723578, 'learning_rate': 4.2857142857142856e-05, 'epoch': 0.13}
  1%|▏         | 12/910 [05:33<6:40:04, 26.73s/it]  1%|▏         | 13/910 [05:59<6:38:01, 26.62s/it]                                                  {'loss': 1.4316, 'grad_norm': 7.718831433109125, 'learning_rate': 4.642857142857143e-05, 'epoch': 0.14}
  1%|▏         | 13/910 [05:59<6:38:01, 26.62s/it]  2%|▏         | 14/910 [06:25<6:35:01, 26.45s/it]                                                  {'loss': 1.5111, 'grad_norm': 6.108292628966308, 'learning_rate': 5e-05, 'epoch': 0.15}
  2%|▏         | 14/910 [06:25<6:35:01, 26.45s/it]  2%|▏         | 15/910 [06:52<6:33:02, 26.35s/it]                                                  {'loss': 0.9643, 'grad_norm': 2.528243935928665, 'learning_rate': 5.3571428571428575e-05, 'epoch': 0.16}
  2%|▏         | 15/910 [06:52<6:33:02, 26.35s/it]  2%|▏         | 16/910 [07:18<6:30:59, 26.24s/it]                                                  {'loss': 0.9109, 'grad_norm': 2.110373596665984, 'learning_rate': 5.714285714285714e-05, 'epoch': 0.18}
  2%|▏         | 16/910 [07:18<6:30:59, 26.24s/it]  2%|▏         | 17/910 [07:44<6:30:10, 26.22s/it]                                                  {'loss': 0.81, 'grad_norm': 2.565998355083442, 'learning_rate': 6.0714285714285715e-05, 'epoch': 0.19}
  2%|▏         | 17/910 [07:44<6:30:10, 26.22s/it]  2%|▏         | 18/910 [08:10<6:29:18, 26.19s/it]                                                  {'loss': 0.8019, 'grad_norm': 1.3860138024369097, 'learning_rate': 6.428571428571429e-05, 'epoch': 0.2}
  2%|▏         | 18/910 [08:10<6:29:18, 26.19s/it]  2%|▏         | 19/910 [08:36<6:28:44, 26.18s/it]                                                  {'loss': 0.6181, 'grad_norm': 0.981133936249957, 'learning_rate': 6.785714285714286e-05, 'epoch': 0.21}
  2%|▏         | 19/910 [08:36<6:28:44, 26.18s/it]  2%|▏         | 20/910 [09:02<6:28:48, 26.21s/it]                                                  {'loss': 0.5516, 'grad_norm': 0.7575797604337158, 'learning_rate': 7.142857142857143e-05, 'epoch': 0.22}
  2%|▏         | 20/910 [09:02<6:28:48, 26.21s/it]  2%|▏         | 21/910 [09:29<6:30:34, 26.36s/it]                                                  {'loss': 0.526, 'grad_norm': 1.607881902289661, 'learning_rate': 7.500000000000001e-05, 'epoch': 0.23}
  2%|▏         | 21/910 [09:29<6:30:34, 26.36s/it]  2%|▏         | 22/910 [09:55<6:30:31, 26.39s/it]                                                  {'loss': 0.6243, 'grad_norm': 1.3921431453973663, 'learning_rate': 7.857142857142858e-05, 'epoch': 0.24}
  2%|▏         | 22/910 [09:55<6:30:31, 26.39s/it]  3%|▎         | 23/910 [10:22<6:30:27, 26.41s/it]                                                  {'loss': 0.5619, 'grad_norm': 2.1131623379123994, 'learning_rate': 8.214285714285714e-05, 'epoch': 0.25}
  3%|▎         | 23/910 [10:22<6:30:27, 26.41s/it]  3%|▎         | 24/910 [10:49<6:30:47, 26.46s/it]                                                  {'loss': 0.4976, 'grad_norm': 1.978501290929062, 'learning_rate': 8.571428571428571e-05, 'epoch': 0.26}
  3%|▎         | 24/910 [10:49<6:30:47, 26.46s/it]  3%|▎         | 25/910 [11:15<6:31:56, 26.57s/it]                                                  {'loss': 0.5414, 'grad_norm': 1.159930542261743, 'learning_rate': 8.92857142857143e-05, 'epoch': 0.27}
  3%|▎         | 25/910 [11:15<6:31:56, 26.57s/it]  3%|▎         | 26/910 [11:42<6:32:26, 26.64s/it]                                                  {'loss': 0.3786, 'grad_norm': 0.5607551280246815, 'learning_rate': 9.285714285714286e-05, 'epoch': 0.29}
  3%|▎         | 26/910 [11:42<6:32:26, 26.64s/it]  3%|▎         | 27/910 [12:08<6:29:44, 26.48s/it]                                                  {'loss': 0.5373, 'grad_norm': 1.0440282084372325, 'learning_rate': 9.642857142857143e-05, 'epoch': 0.3}
  3%|▎         | 27/910 [12:08<6:29:44, 26.48s/it]  3%|▎         | 28/910 [12:34<6:27:33, 26.36s/it]                                                  {'loss': 0.3568, 'grad_norm': 0.7532106134352602, 'learning_rate': 0.0001, 'epoch': 0.31}
  3%|▎         | 28/910 [12:34<6:27:33, 26.36s/it]  3%|▎         | 29/910 [13:01<6:26:37, 26.33s/it]                                                  {'loss': 0.4955, 'grad_norm': 0.7776941615095134, 'learning_rate': 9.999968282268041e-05, 'epoch': 0.32}
  3%|▎         | 29/910 [13:01<6:26:37, 26.33s/it]  3%|▎         | 30/910 [13:27<6:25:20, 26.27s/it]                                                  {'loss': 0.4357, 'grad_norm': 0.5805000975267451, 'learning_rate': 9.999873129474573e-05, 'epoch': 0.33}
  3%|▎         | 30/910 [13:27<6:25:20, 26.27s/it]  3%|▎         | 31/910 [13:53<6:24:46, 26.26s/it]                                                  {'loss': 0.529, 'grad_norm': 0.8637092321375243, 'learning_rate': 9.999714542826806e-05, 'epoch': 0.34}
  3%|▎         | 31/910 [13:53<6:24:46, 26.26s/it]  4%|▎         | 32/910 [14:19<6:24:07, 26.25s/it]                                                  {'loss': 0.5, 'grad_norm': 3.201639378822231, 'learning_rate': 9.999492524336743e-05, 'epoch': 0.35}
  4%|▎         | 32/910 [14:19<6:24:07, 26.25s/it]  4%|▎         | 33/910 [14:46<6:25:33, 26.38s/it]                                                  {'loss': 0.5026, 'grad_norm': 0.556922025361748, 'learning_rate': 9.999207076821155e-05, 'epoch': 0.36}
  4%|▎         | 33/910 [14:46<6:25:33, 26.38s/it]  4%|▎         | 34/910 [15:12<6:25:21, 26.39s/it]                                                  {'loss': 0.5034, 'grad_norm': 2.385038709853012, 'learning_rate': 9.99885820390154e-05, 'epoch': 0.37}
  4%|▎         | 34/910 [15:12<6:25:21, 26.39s/it]  4%|▍         | 35/910 [15:39<6:25:50, 26.46s/it]                                                  {'loss': 0.5427, 'grad_norm': 1.2053684441319514, 'learning_rate': 9.998445910004082e-05, 'epoch': 0.38}
  4%|▍         | 35/910 [15:39<6:25:50, 26.46s/it]  4%|▍         | 36/910 [16:05<6:25:28, 26.46s/it]                                                  {'loss': 0.4524, 'grad_norm': 1.2324774093542687, 'learning_rate': 9.99797020035959e-05, 'epoch': 0.4}
  4%|▍         | 36/910 [16:05<6:25:28, 26.46s/it]  4%|▍         | 37/910 [16:32<6:26:35, 26.57s/it]                                                  {'loss': 0.4917, 'grad_norm': 1.0773867614519326, 'learning_rate': 9.99743108100344e-05, 'epoch': 0.41}
  4%|▍         | 37/910 [16:32<6:26:35, 26.57s/it]  4%|▍         | 38/910 [16:59<6:25:55, 26.55s/it]                                                  {'loss': 0.3726, 'grad_norm': 1.7664291442406885, 'learning_rate': 9.996828558775486e-05, 'epoch': 0.42}
  4%|▍         | 38/910 [16:59<6:25:55, 26.55s/it]  4%|▍         | 39/910 [17:26<6:28:28, 26.76s/it]                                                  {'loss': 0.4695, 'grad_norm': 1.0825471575362418, 'learning_rate': 9.996162641319984e-05, 'epoch': 0.43}
  4%|▍         | 39/910 [17:26<6:28:28, 26.76s/it]  4%|▍         | 40/910 [17:52<6:24:07, 26.49s/it]                                                  {'loss': 0.4889, 'grad_norm': 1.182239307062636, 'learning_rate': 9.995433337085491e-05, 'epoch': 0.44}
  4%|▍         | 40/910 [17:52<6:24:07, 26.49s/it]  5%|▍         | 41/910 [18:18<6:21:31, 26.34s/it]                                                  {'loss': 0.4475, 'grad_norm': 0.7116663566617146, 'learning_rate': 9.994640655324758e-05, 'epoch': 0.45}
  5%|▍         | 41/910 [18:18<6:21:31, 26.34s/it]  5%|▍         | 42/910 [18:44<6:20:06, 26.27s/it]                                                  {'loss': 0.4023, 'grad_norm': 0.6689221099289305, 'learning_rate': 9.993784606094612e-05, 'epoch': 0.46}
  5%|▍         | 42/910 [18:44<6:20:06, 26.27s/it]  5%|▍         | 43/910 [19:11<6:21:13, 26.38s/it]                                                  {'loss': 0.4702, 'grad_norm': 1.4490332493658167, 'learning_rate': 9.992865200255829e-05, 'epoch': 0.47}
  5%|▍         | 43/910 [19:11<6:21:13, 26.38s/it]  5%|▍         | 44/910 [19:37<6:20:16, 26.35s/it]                                                  {'loss': 0.3718, 'grad_norm': 1.460454827252274, 'learning_rate': 9.991882449472995e-05, 'epoch': 0.48}
  5%|▍         | 44/910 [19:37<6:20:16, 26.35s/it]  5%|▍         | 45/910 [20:03<6:19:07, 26.30s/it]                                                  {'loss': 0.4299, 'grad_norm': 1.246126977102789, 'learning_rate': 9.99083636621436e-05, 'epoch': 0.49}
  5%|▍         | 45/910 [20:03<6:19:07, 26.30s/it]  5%|▌         | 46/910 [20:29<6:18:42, 26.30s/it]                                                  {'loss': 0.4723, 'grad_norm': 0.5983107507848088, 'learning_rate': 9.989726963751682e-05, 'epoch': 0.51}
  5%|▌         | 46/910 [20:29<6:18:42, 26.30s/it]  5%|▌         | 47/910 [20:56<6:18:32, 26.32s/it]                                                  {'loss': 0.3896, 'grad_norm': 0.7930285224855929, 'learning_rate': 9.988554256160052e-05, 'epoch': 0.52}
  5%|▌         | 47/910 [20:56<6:18:32, 26.32s/it][2025-08-25 21:20:08,228] [WARNING] [stage3.py:1949:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  5%|▌         | 48/910 [21:23<6:22:07, 26.60s/it]                                                  {'loss': 0.5176, 'grad_norm': 0.9423264690097357, 'learning_rate': 9.987318258317717e-05, 'epoch': 0.53}
  5%|▌         | 48/910 [21:23<6:22:07, 26.60s/it]  5%|▌         | 49/910 [21:49<6:21:19, 26.57s/it]                                                  {'loss': 0.4001, 'grad_norm': 0.6021819200428618, 'learning_rate': 9.986018985905901e-05, 'epoch': 0.54}
  5%|▌         | 49/910 [21:49<6:21:19, 26.57s/it]  5%|▌         | 50/910 [22:16<6:20:54, 26.58s/it]                                                  {'loss': 0.5713, 'grad_norm': 2.6552821748289896, 'learning_rate': 9.984656455408591e-05, 'epoch': 0.55}
  5%|▌         | 50/910 [22:16<6:20:54, 26.58s/it]  6%|▌         | 51/910 [22:43<6:22:22, 26.71s/it]                                                  {'loss': 0.422, 'grad_norm': 0.5808478274227049, 'learning_rate': 9.983230684112338e-05, 'epoch': 0.56}
  6%|▌         | 51/910 [22:43<6:22:22, 26.71s/it]  6%|▌         | 52/910 [23:10<6:21:21, 26.67s/it]                                                  {'loss': 0.4689, 'grad_norm': 0.7973089643654856, 'learning_rate': 9.981741690106034e-05, 'epoch': 0.57}
  6%|▌         | 52/910 [23:10<6:21:21, 26.67s/it]  6%|▌         | 53/910 [23:36<6:19:59, 26.60s/it]                                                  {'loss': 0.4391, 'grad_norm': 2.330825377019308, 'learning_rate': 9.980189492280687e-05, 'epoch': 0.58}
  6%|▌         | 53/910 [23:36<6:19:59, 26.60s/it]  6%|▌         | 54/910 [24:03<6:19:56, 26.63s/it]                                                  {'loss': 0.4822, 'grad_norm': 0.5183816802312181, 'learning_rate': 9.978574110329173e-05, 'epoch': 0.59}
  6%|▌         | 54/910 [24:03<6:19:56, 26.63s/it]  6%|▌         | 55/910 [24:29<6:17:13, 26.47s/it]                                                  {'loss': 0.4129, 'grad_norm': 0.7938814879859006, 'learning_rate': 9.976895564745991e-05, 'epoch': 0.6}
  6%|▌         | 55/910 [24:29<6:17:13, 26.47s/it]  6%|▌         | 56/910 [24:55<6:16:06, 26.42s/it]                                                  {'loss': 0.3787, 'grad_norm': 0.548494143467596, 'learning_rate': 9.975153876827008e-05, 'epoch': 0.62}
  6%|▌         | 56/910 [24:55<6:16:06, 26.42s/it]  6%|▋         | 57/910 [25:22<6:16:58, 26.52s/it]                                                  {'loss': 0.3886, 'grad_norm': 0.6264380586760293, 'learning_rate': 9.973349068669177e-05, 'epoch': 0.63}
  6%|▋         | 57/910 [25:22<6:16:58, 26.52s/it]  6%|▋         | 58/910 [25:48<6:15:03, 26.41s/it]                                                  {'loss': 0.5376, 'grad_norm': 2.269642534904999, 'learning_rate': 9.971481163170268e-05, 'epoch': 0.64}
  6%|▋         | 58/910 [25:48<6:15:03, 26.41s/it]  6%|▋         | 59/910 [26:14<6:13:32, 26.34s/it]                                                  {'loss': 0.4767, 'grad_norm': 1.415305825456465, 'learning_rate': 9.969550184028572e-05, 'epoch': 0.65}
  6%|▋         | 59/910 [26:14<6:13:32, 26.34s/it]  7%|▋         | 60/910 [26:41<6:12:56, 26.33s/it]                                                  {'loss': 0.4155, 'grad_norm': 0.4563883254385516, 'learning_rate': 9.9675561557426e-05, 'epoch': 0.66}
  7%|▋         | 60/910 [26:41<6:12:56, 26.33s/it]  7%|▋         | 61/910 [27:07<6:14:36, 26.47s/it]                                                  {'loss': 0.47, 'grad_norm': 0.5476826966955903, 'learning_rate': 9.965499103610774e-05, 'epoch': 0.67}
  7%|▋         | 61/910 [27:07<6:14:36, 26.47s/it]  7%|▋         | 62/910 [27:34<6:14:37, 26.51s/it]                                                  {'loss': 0.4533, 'grad_norm': 1.0604616110490244, 'learning_rate': 9.963379053731103e-05, 'epoch': 0.68}
  7%|▋         | 62/910 [27:34<6:14:37, 26.51s/it]  7%|▋         | 63/910 [28:01<6:14:41, 26.54s/it]                                                  {'loss': 0.5902, 'grad_norm': 1.513894920701123, 'learning_rate': 9.961196033000861e-05, 'epoch': 0.69}
  7%|▋         | 63/910 [28:01<6:14:41, 26.54s/it]  7%|▋         | 64/910 [28:28<6:16:31, 26.70s/it]                                                  {'loss': 0.4429, 'grad_norm': 0.8115283196016334, 'learning_rate': 9.95895006911623e-05, 'epoch': 0.7}
  7%|▋         | 64/910 [28:28<6:16:31, 26.70s/it]  7%|▋         | 65/910 [28:54<6:15:15, 26.65s/it]                                                  {'loss': 0.4459, 'grad_norm': 0.6665531489572606, 'learning_rate': 9.956641190571967e-05, 'epoch': 0.71}
  7%|▋         | 65/910 [28:54<6:15:15, 26.65s/it]  7%|▋         | 66/910 [29:21<6:15:14, 26.68s/it]                                                  {'loss': 0.3967, 'grad_norm': 0.5168190508230603, 'learning_rate': 9.954269426661024e-05, 'epoch': 0.73}
  7%|▋         | 66/910 [29:21<6:15:14, 26.68s/it]  7%|▋         | 67/910 [29:47<6:11:43, 26.46s/it]                                                  {'loss': 0.347, 'grad_norm': 0.4067687670681054, 'learning_rate': 9.951834807474191e-05, 'epoch': 0.74}
  7%|▋         | 67/910 [29:47<6:11:43, 26.46s/it]  7%|▋         | 68/910 [30:13<6:09:52, 26.36s/it]                                                  {'loss': 0.4242, 'grad_norm': 0.6766637680761701, 'learning_rate': 9.949337363899709e-05, 'epoch': 0.75}
  7%|▋         | 68/910 [30:13<6:09:52, 26.36s/it]  8%|▊         | 69/910 [30:39<6:08:27, 26.29s/it]                                                  {'loss': 0.5531, 'grad_norm': 1.3670200716609604, 'learning_rate': 9.946777127622874e-05, 'epoch': 0.76}
  8%|▊         | 69/910 [30:39<6:08:27, 26.29s/it]  8%|▊         | 70/910 [31:06<6:09:28, 26.39s/it]                                                  {'loss': 0.4057, 'grad_norm': 0.6634826368749513, 'learning_rate': 9.944154131125642e-05, 'epoch': 0.77}
  8%|▊         | 70/910 [31:06<6:09:28, 26.39s/it]  8%|▊         | 71/910 [31:32<6:08:03, 26.32s/it]                                                  {'loss': 0.433, 'grad_norm': 0.8436015642762051, 'learning_rate': 9.941468407686217e-05, 'epoch': 0.78}
  8%|▊         | 71/910 [31:32<6:08:03, 26.32s/it]  8%|▊         | 72/910 [31:58<6:06:52, 26.27s/it]                                                  {'loss': 0.5338, 'grad_norm': 0.6488531776017501, 'learning_rate': 9.938719991378614e-05, 'epoch': 0.79}
  8%|▊         | 72/910 [31:58<6:06:52, 26.27s/it]  8%|▊         | 73/910 [32:24<6:05:52, 26.23s/it]                                                  {'loss': 0.4084, 'grad_norm': 0.5133831675677257, 'learning_rate': 9.935908917072252e-05, 'epoch': 0.8}
  8%|▊         | 73/910 [32:24<6:05:52, 26.23s/it]  8%|▊         | 74/910 [32:51<6:06:44, 26.32s/it]                                                  {'loss': 0.3978, 'grad_norm': 0.3830433791501872, 'learning_rate': 9.933035220431488e-05, 'epoch': 0.81}
  8%|▊         | 74/910 [32:51<6:06:44, 26.32s/it]  8%|▊         | 75/910 [33:17<6:07:25, 26.40s/it]                                                  {'loss': 0.3397, 'grad_norm': 0.9816344578854516, 'learning_rate': 9.930098937915178e-05, 'epoch': 0.82}
  8%|▊         | 75/910 [33:17<6:07:25, 26.40s/it]  8%|▊         | 76/910 [33:44<6:06:50, 26.39s/it]                                                  {'loss': 0.4337, 'grad_norm': 1.0748241803102163, 'learning_rate': 9.927100106776212e-05, 'epoch': 0.84}
  8%|▊         | 76/910 [33:44<6:06:50, 26.39s/it]  8%|▊         | 77/910 [34:10<6:07:40, 26.48s/it]                                                  {'loss': 0.4701, 'grad_norm': 0.9346547234226361, 'learning_rate': 9.924038765061042e-05, 'epoch': 0.85}
  8%|▊         | 77/910 [34:10<6:07:40, 26.48s/it]  9%|▊         | 78/910 [34:37<6:08:16, 26.56s/it]                                                  {'loss': 0.4397, 'grad_norm': 0.6011508137420458, 'learning_rate': 9.920914951609188e-05, 'epoch': 0.86}
  9%|▊         | 78/910 [34:37<6:08:16, 26.56s/it]  9%|▊         | 79/910 [35:04<6:09:07, 26.65s/it]                                                  {'loss': 0.443, 'grad_norm': 1.5897267951218346, 'learning_rate': 9.917728706052764e-05, 'epoch': 0.87}
  9%|▊         | 79/910 [35:04<6:09:07, 26.65s/it]  9%|▉         | 80/910 [35:30<6:06:24, 26.49s/it]                                                  {'loss': 0.5085, 'grad_norm': 0.4286573381376047, 'learning_rate': 9.914480068815964e-05, 'epoch': 0.88}
  9%|▉         | 80/910 [35:30<6:06:24, 26.49s/it]  9%|▉         | 81/910 [35:56<6:04:04, 26.35s/it]                                                  {'loss': 0.4288, 'grad_norm': 1.0676444021441232, 'learning_rate': 9.911169081114549e-05, 'epoch': 0.89}
  9%|▉         | 81/910 [35:56<6:04:04, 26.35s/it]  9%|▉         | 82/910 [36:22<6:01:50, 26.22s/it]                                                  {'loss': 0.4411, 'grad_norm': 1.3497539276910149, 'learning_rate': 9.907795784955327e-05, 'epoch': 0.9}
  9%|▉         | 82/910 [36:22<6:01:50, 26.22s/it]  9%|▉         | 83/910 [36:48<6:01:19, 26.21s/it]                                                  {'loss': 0.4797, 'grad_norm': 0.7966365717097526, 'learning_rate': 9.904360223135621e-05, 'epoch': 0.91}
  9%|▉         | 83/910 [36:48<6:01:19, 26.21s/it]  9%|▉         | 84/910 [37:14<6:00:22, 26.18s/it]                                                  {'loss': 0.4851, 'grad_norm': 2.4837314659766077, 'learning_rate': 9.900862439242719e-05, 'epoch': 0.92}
  9%|▉         | 84/910 [37:14<6:00:22, 26.18s/it]  9%|▉         | 85/910 [37:41<6:00:02, 26.19s/it]                                                  {'loss': 0.4428, 'grad_norm': 1.0514988848787346, 'learning_rate': 9.897302477653334e-05, 'epoch': 0.93}
  9%|▉         | 85/910 [37:41<6:00:02, 26.19s/it]  9%|▉         | 86/910 [38:07<6:00:29, 26.25s/it]                                                  {'loss': 0.4779, 'grad_norm': 1.1739914758156076, 'learning_rate': 9.893680383533026e-05, 'epoch': 0.95}
  9%|▉         | 86/910 [38:07<6:00:29, 26.25s/it] 10%|▉         | 87/910 [38:33<6:00:50, 26.31s/it]                                                  {'loss': 0.4289, 'grad_norm': 1.3923407627830524, 'learning_rate': 9.889996202835641e-05, 'epoch': 0.96}
 10%|▉         | 87/910 [38:33<6:00:50, 26.31s/it] 10%|▉         | 88/910 [39:00<6:01:24, 26.38s/it]                                                  {'loss': 0.4148, 'grad_norm': 1.1420685328429623, 'learning_rate': 9.88624998230272e-05, 'epoch': 0.97}
 10%|▉         | 88/910 [39:00<6:01:24, 26.38s/it] 10%|▉         | 89/910 [39:26<6:01:39, 26.43s/it]                                                  {'loss': 0.3955, 'grad_norm': 0.5732205595067099, 'learning_rate': 9.882441769462912e-05, 'epoch': 0.98}
 10%|▉         | 89/910 [39:26<6:01:39, 26.43s/it] 10%|▉         | 90/910 [39:53<6:02:46, 26.54s/it]                                                  {'loss': 0.4965, 'grad_norm': 1.6876657132128476, 'learning_rate': 9.878571612631364e-05, 'epoch': 0.99}
 10%|▉         | 90/910 [39:53<6:02:46, 26.54s/it] 10%|█         | 91/910 [40:21<6:07:37, 26.93s/it]                                                  {'loss': 0.4605, 'grad_norm': 1.014228623725615, 'learning_rate': 9.874639560909117e-05, 'epoch': 1.0}
 10%|█         | 91/910 [40:21<6:07:37, 26.93s/it] 10%|█         | 92/910 [41:06<7:22:35, 32.46s/it]                                                  {'loss': 0.4243, 'grad_norm': 0.9754125801247148, 'learning_rate': 9.870645664182478e-05, 'epoch': 1.01}
 10%|█         | 92/910 [41:06<7:22:35, 32.46s/it] 10%|█         | 93/910 [41:33<6:56:11, 30.56s/it]                                                  {'loss': 0.4151, 'grad_norm': 0.603282288397187, 'learning_rate': 9.86658997312238e-05, 'epoch': 1.02}
 10%|█         | 93/910 [41:33<6:56:11, 30.56s/it] 10%|█         | 94/910 [41:59<6:37:33, 29.23s/it]                                                  {'loss': 0.4027, 'grad_norm': 0.8986885026976525, 'learning_rate': 9.862472539183756e-05, 'epoch': 1.03}
 10%|█         | 94/910 [41:59<6:37:33, 29.23s/it] 10%|█         | 95/910 [42:25<6:23:17, 28.22s/it]                                                  {'loss': 0.4503, 'grad_norm': 0.813422495974989, 'learning_rate': 9.858293414604871e-05, 'epoch': 1.04}
 10%|█         | 95/910 [42:25<6:23:17, 28.22s/it] 11%|█         | 96/910 [42:51<6:14:28, 27.60s/it]                                                  {'loss': 0.4179, 'grad_norm': 0.7358992145948146, 'learning_rate': 9.854052652406666e-05, 'epoch': 1.05}
 11%|█         | 96/910 [42:51<6:14:28, 27.60s/it] 11%|█         | 97/910 [43:17<6:08:21, 27.19s/it]                                                  {'loss': 0.4408, 'grad_norm': 0.6385000774134417, 'learning_rate': 9.849750306392084e-05, 'epoch': 1.07}
 11%|█         | 97/910 [43:17<6:08:21, 27.19s/it] 11%|█         | 98/910 [43:43<6:04:06, 26.90s/it]                                                  {'loss': 0.4258, 'grad_norm': 0.8016579207534852, 'learning_rate': 9.84538643114539e-05, 'epoch': 1.08}
 11%|█         | 98/910 [43:43<6:04:06, 26.90s/it] 11%|█         | 99/910 [44:10<6:01:37, 26.75s/it]                                                  {'loss': 0.3892, 'grad_norm': 0.6066110394100631, 'learning_rate': 9.840961082031472e-05, 'epoch': 1.09}
 11%|█         | 99/910 [44:10<6:01:37, 26.75s/it] 11%|█         | 100/910 [44:37<6:02:03, 26.82s/it]                                                   {'loss': 0.4381, 'grad_norm': 2.9871587133106337, 'learning_rate': 9.836474315195147e-05, 'epoch': 1.1}
 11%|█         | 100/910 [44:37<6:02:03, 26.82s/it] 11%|█         | 101/910 [45:03<6:00:24, 26.73s/it]                                                   {'loss': 0.3803, 'grad_norm': 0.5277690772892453, 'learning_rate': 9.83192618756044e-05, 'epoch': 1.11}
 11%|█         | 101/910 [45:03<6:00:24, 26.73s/it] 11%|█         | 102/910 [45:30<5:59:19, 26.68s/it]                                                   {'loss': 0.427, 'grad_norm': 0.9394807463634324, 'learning_rate': 9.827316756829871e-05, 'epoch': 1.12}
 11%|█         | 102/910 [45:30<5:59:19, 26.68s/it] 11%|█▏        | 103/910 [45:57<6:00:00, 26.77s/it]                                                   {'loss': 0.4118, 'grad_norm': 0.5211376118413955, 'learning_rate': 9.822646081483713e-05, 'epoch': 1.13}
 11%|█▏        | 103/910 [45:57<6:00:00, 26.77s/it] 11%|█▏        | 104/910 [46:23<5:59:35, 26.77s/it]                                                   {'loss': 0.4496, 'grad_norm': 1.893108062764749, 'learning_rate': 9.817914220779258e-05, 'epoch': 1.14}
 11%|█▏        | 104/910 [46:23<5:59:35, 26.77s/it] 12%|█▏        | 105/910 [46:50<5:58:52, 26.75s/it]                                                   {'loss': 0.393, 'grad_norm': 0.8021887430334926, 'learning_rate': 9.81312123475006e-05, 'epoch': 1.15}
 12%|█▏        | 105/910 [46:50<5:58:52, 26.75s/it] 12%|█▏        | 106/910 [47:17<5:57:33, 26.68s/it]                                                   {'loss': 0.4239, 'grad_norm': 0.9384736478950046, 'learning_rate': 9.808267184205183e-05, 'epoch': 1.16}
 12%|█▏        | 106/910 [47:17<5:57:33, 26.68s/it] 12%|█▏        | 107/910 [47:43<5:54:46, 26.51s/it]                                                   {'loss': 0.4381, 'grad_norm': 8.712248591550052, 'learning_rate': 9.80335213072841e-05, 'epoch': 1.18}
 12%|█▏        | 107/910 [47:43<5:54:46, 26.51s/it] 12%|█▏        | 108/910 [48:09<5:52:38, 26.38s/it]                                                   {'loss': 0.438, 'grad_norm': 0.7580859604709275, 'learning_rate': 9.798376136677486e-05, 'epoch': 1.19}
 12%|█▏        | 108/910 [48:09<5:52:38, 26.38s/it] 12%|█▏        | 109/910 [48:35<5:51:39, 26.34s/it]                                                   {'loss': 0.492, 'grad_norm': 1.2109525819083515, 'learning_rate': 9.793339265183303e-05, 'epoch': 1.2}
 12%|█▏        | 109/910 [48:35<5:51:39, 26.34s/it] 12%|█▏        | 110/910 [49:01<5:50:25, 26.28s/it]                                                   {'loss': 0.4306, 'grad_norm': 0.7477804991006558, 'learning_rate': 9.788241580149123e-05, 'epoch': 1.21}
 12%|█▏        | 110/910 [49:01<5:50:25, 26.28s/it] 12%|█▏        | 111/910 [49:28<5:52:13, 26.45s/it]                                                   {'loss': 0.3695, 'grad_norm': 0.872529340472989, 'learning_rate': 9.783083146249748e-05, 'epoch': 1.22}
 12%|█▏        | 111/910 [49:28<5:52:13, 26.45s/it] 12%|█▏        | 112/910 [49:54<5:51:31, 26.43s/it]                                                   {'loss': 0.4698, 'grad_norm': 1.2046346357232196, 'learning_rate': 9.777864028930705e-05, 'epoch': 1.23}
 12%|█▏        | 112/910 [49:54<5:51:31, 26.43s/it] 12%|█▏        | 113/910 [50:21<5:51:39, 26.47s/it]                                                   {'loss': 0.4304, 'grad_norm': 0.892555042512581, 'learning_rate': 9.772584294407419e-05, 'epoch': 1.24}
 12%|█▏        | 113/910 [50:21<5:51:39, 26.47s/it] 13%|█▎        | 114/910 [50:48<5:52:09, 26.55s/it]                                                   {'loss': 0.5015, 'grad_norm': 1.817959535149381, 'learning_rate': 9.767244009664376e-05, 'epoch': 1.25}
 13%|█▎        | 114/910 [50:48<5:52:09, 26.55s/it] 13%|█▎        | 115/910 [51:14<5:52:02, 26.57s/it]                                                   {'loss': 0.4175, 'grad_norm': 0.6344587605554193, 'learning_rate': 9.761843242454261e-05, 'epoch': 1.26}
 13%|█▎        | 115/910 [51:14<5:52:02, 26.57s/it] 13%|█▎        | 116/910 [51:41<5:51:35, 26.57s/it]                                                   {'loss': 0.4391, 'grad_norm': 0.8612184953554795, 'learning_rate': 9.75638206129711e-05, 'epoch': 1.27}
 13%|█▎        | 116/910 [51:41<5:51:35, 26.57s/it] 13%|█▎        | 117/910 [52:07<5:50:53, 26.55s/it]                                                   {'loss': 0.4033, 'grad_norm': 1.897967436725783, 'learning_rate': 9.750860535479433e-05, 'epoch': 1.29}
 13%|█▎        | 117/910 [52:07<5:50:53, 26.55s/it] 13%|█▎        | 118/910 [52:34<5:51:41, 26.64s/it]                                                   {'loss': 0.436, 'grad_norm': 0.7709555638975548, 'learning_rate': 9.745278735053343e-05, 'epoch': 1.3}
 13%|█▎        | 118/910 [52:34<5:51:41, 26.64s/it] 13%|█▎        | 119/910 [53:01<5:51:12, 26.64s/it]                                                   {'loss': 0.3956, 'grad_norm': 0.6983340864829619, 'learning_rate': 9.73963673083566e-05, 'epoch': 1.31}
 13%|█▎        | 119/910 [53:01<5:51:12, 26.64s/it] 13%|█▎        | 120/910 [53:27<5:48:47, 26.49s/it]                                                   {'loss': 0.3909, 'grad_norm': 0.6080726994614203, 'learning_rate': 9.733934594407011e-05, 'epoch': 1.32}
 13%|█▎        | 120/910 [53:27<5:48:47, 26.49s/it] 13%|█▎        | 121/910 [53:53<5:46:05, 26.32s/it]                                                   {'loss': 0.4232, 'grad_norm': 0.7595013667424144, 'learning_rate': 9.728172398110934e-05, 'epoch': 1.33}
 13%|█▎        | 121/910 [53:53<5:46:05, 26.32s/it] 13%|█▎        | 122/910 [54:19<5:44:58, 26.27s/it]                                                   {'loss': 0.436, 'grad_norm': 0.7651671296063884, 'learning_rate': 9.722350215052946e-05, 'epoch': 1.34}
 13%|█▎        | 122/910 [54:19<5:44:58, 26.27s/it] 14%|█▎        | 123/910 [54:45<5:44:30, 26.26s/it]                                                   {'loss': 0.3338, 'grad_norm': 0.5723399360967644, 'learning_rate': 9.716468119099625e-05, 'epoch': 1.35}
 14%|█▎        | 123/910 [54:45<5:44:30, 26.26s/it] 14%|█▎        | 124/910 [55:12<5:45:10, 26.35s/it]                                                   {'loss': 0.3628, 'grad_norm': 0.42579790535561546, 'learning_rate': 9.710526184877667e-05, 'epoch': 1.36}
 14%|█▎        | 124/910 [55:12<5:45:10, 26.35s/it] 14%|█▎        | 125/910 [55:38<5:44:44, 26.35s/it]                                                   {'loss': 0.3425, 'grad_norm': 0.7680185314349222, 'learning_rate': 9.704524487772944e-05, 'epoch': 1.37}
 14%|█▎        | 125/910 [55:38<5:44:44, 26.35s/it] 14%|█▍        | 126/910 [56:05<5:44:39, 26.38s/it]                                                   {'loss': 0.4173, 'grad_norm': 1.0303339197344894, 'learning_rate': 9.698463103929542e-05, 'epoch': 1.38}
 14%|█▍        | 126/910 [56:05<5:44:39, 26.38s/it] 14%|█▍        | 127/910 [56:31<5:44:44, 26.42s/it]                                                   {'loss': 0.4241, 'grad_norm': 0.5591813293404404, 'learning_rate': 9.692342110248802e-05, 'epoch': 1.4}
 14%|█▍        | 127/910 [56:31<5:44:44, 26.42s/it] 14%|█▍        | 128/910 [56:58<5:46:45, 26.61s/it]                                                   {'loss': 0.449, 'grad_norm': 0.889133248366415, 'learning_rate': 9.68616158438834e-05, 'epoch': 1.41}
 14%|█▍        | 128/910 [56:58<5:46:45, 26.61s/it] 14%|█▍        | 129/910 [57:25<5:46:13, 26.60s/it]                                                   {'loss': 0.4565, 'grad_norm': 0.8473560455496981, 'learning_rate': 9.679921604761057e-05, 'epoch': 1.42}
 14%|█▍        | 129/910 [57:25<5:46:13, 26.60s/it] 14%|█▍        | 130/910 [57:51<5:45:53, 26.61s/it]                                                   {'loss': 0.4512, 'grad_norm': 0.7331526214322988, 'learning_rate': 9.673622250534156e-05, 'epoch': 1.43}
 14%|█▍        | 130/910 [57:51<5:45:53, 26.61s/it] 14%|█▍        | 131/910 [58:18<5:46:08, 26.66s/it]                                                   {'loss': 0.4303, 'grad_norm': 1.4560408110474625, 'learning_rate': 9.667263601628128e-05, 'epoch': 1.44}
 14%|█▍        | 131/910 [58:18<5:46:08, 26.66s/it] 15%|█▍        | 132/910 [58:44<5:43:05, 26.46s/it]                                                   {'loss': 0.4847, 'grad_norm': 0.5592472841345167, 'learning_rate': 9.660845738715743e-05, 'epoch': 1.45}
 15%|█▍        | 132/910 [58:44<5:43:05, 26.46s/it] 15%|█▍        | 133/910 [59:10<5:41:02, 26.34s/it]                                                   {'loss': 0.4877, 'grad_norm': 1.214964555998301, 'learning_rate': 9.654368743221022e-05, 'epoch': 1.46}
 15%|█▍        | 133/910 [59:10<5:41:02, 26.34s/it] 15%|█▍        | 134/910 [59:37<5:40:30, 26.33s/it]                                                   {'loss': 0.3936, 'grad_norm': 0.7873436243267643, 'learning_rate': 9.647832697318207e-05, 'epoch': 1.47}
 15%|█▍        | 134/910 [59:37<5:40:30, 26.33s/it] 15%|█▍        | 135/910 [1:00:03<5:41:07, 26.41s/it]                                                     {'loss': 0.4621, 'grad_norm': 2.0809458905410767, 'learning_rate': 9.641237683930722e-05, 'epoch': 1.48}
 15%|█▍        | 135/910 [1:00:03<5:41:07, 26.41s/it] 15%|█▍        | 136/910 [1:00:29<5:40:06, 26.36s/it]                                                     {'loss': 0.3975, 'grad_norm': 0.5907527131287212, 'learning_rate': 9.63458378673011e-05, 'epoch': 1.49}
 15%|█▍        | 136/910 [1:00:29<5:40:06, 26.36s/it] 15%|█▌        | 137/910 [1:00:56<5:39:13, 26.33s/it]                                                     {'loss': 0.4848, 'grad_norm': 0.7458511477742624, 'learning_rate': 9.627871090134983e-05, 'epoch': 1.51}
 15%|█▌        | 137/910 [1:00:56<5:39:13, 26.33s/it] 15%|█▌        | 138/910 [1:01:22<5:39:15, 26.37s/it]                                                     {'loss': 0.3994, 'grad_norm': 0.7537336673318972, 'learning_rate': 9.621099679309947e-05, 'epoch': 1.52}
 15%|█▌        | 138/910 [1:01:22<5:39:15, 26.37s/it] 15%|█▌        | 139/910 [1:01:49<5:38:58, 26.38s/it]                                                     {'loss': 0.4385, 'grad_norm': 0.5208176792788496, 'learning_rate': 9.614269640164519e-05, 'epoch': 1.53}
 15%|█▌        | 139/910 [1:01:49<5:38:58, 26.38s/it] 15%|█▌        | 140/910 [1:02:15<5:39:08, 26.43s/it]                                                     {'loss': 0.4434, 'grad_norm': 0.7550222391220086, 'learning_rate': 9.607381059352038e-05, 'epoch': 1.54}
 15%|█▌        | 140/910 [1:02:15<5:39:08, 26.43s/it] 15%|█▌        | 141/910 [1:02:42<5:39:01, 26.45s/it]                                                     {'loss': 0.4656, 'grad_norm': 1.3632133822678532, 'learning_rate': 9.60043402426857e-05, 'epoch': 1.55}
 15%|█▌        | 141/910 [1:02:42<5:39:01, 26.45s/it] 16%|█▌        | 142/910 [1:03:08<5:39:22, 26.51s/it]                                                     {'loss': 0.3702, 'grad_norm': 0.6234928297110585, 'learning_rate': 9.593428623051792e-05, 'epoch': 1.56}
 16%|█▌        | 142/910 [1:03:08<5:39:22, 26.51s/it] 16%|█▌        | 143/910 [1:03:35<5:40:05, 26.60s/it]                                                     {'loss': 0.3397, 'grad_norm': 0.46456797758153157, 'learning_rate': 9.58636494457988e-05, 'epoch': 1.57}
 16%|█▌        | 143/910 [1:03:35<5:40:05, 26.60s/it] 16%|█▌        | 144/910 [1:04:02<5:39:12, 26.57s/it]                                                     {'loss': 0.4454, 'grad_norm': 0.6905383332912024, 'learning_rate': 9.579243078470379e-05, 'epoch': 1.58}
 16%|█▌        | 144/910 [1:04:02<5:39:12, 26.57s/it] 16%|█▌        | 145/910 [1:04:28<5:39:03, 26.59s/it]                                                     {'loss': 0.3429, 'grad_norm': 0.6862523761046261, 'learning_rate': 9.572063115079063e-05, 'epoch': 1.59}
 16%|█▌        | 145/910 [1:04:28<5:39:03, 26.59s/it] 16%|█▌        | 146/910 [1:04:54<5:36:53, 26.46s/it]                                                     {'loss': 0.4252, 'grad_norm': 0.8502991608276793, 'learning_rate': 9.564825145498795e-05, 'epoch': 1.6}
 16%|█▌        | 146/910 [1:04:54<5:36:53, 26.46s/it] 16%|█▌        | 147/910 [1:05:20<5:34:51, 26.33s/it]                                                     {'loss': 0.4553, 'grad_norm': 0.7503892853713757, 'learning_rate': 9.557529261558367e-05, 'epoch': 1.62}
 16%|█▌        | 147/910 [1:05:20<5:34:51, 26.33s/it] 16%|█▋        | 148/910 [1:05:47<5:33:44, 26.28s/it]                                                     {'loss': 0.4238, 'grad_norm': 0.7435900416182365, 'learning_rate': 9.550175555821333e-05, 'epoch': 1.63}
 16%|█▋        | 148/910 [1:05:47<5:33:44, 26.28s/it] 16%|█▋        | 149/910 [1:06:13<5:32:17, 26.20s/it]                                                     {'loss': 0.4518, 'grad_norm': 0.7573135441123581, 'learning_rate': 9.542764121584844e-05, 'epoch': 1.64}
 16%|█▋        | 149/910 [1:06:13<5:32:17, 26.20s/it] 16%|█▋        | 150/910 [1:06:39<5:32:30, 26.25s/it]                                                     {'loss': 0.3885, 'grad_norm': 0.8913858327073823, 'learning_rate': 9.53529505287845e-05, 'epoch': 1.65}
 16%|█▋        | 150/910 [1:06:39<5:32:30, 26.25s/it] 17%|█▋        | 151/910 [1:07:05<5:31:29, 26.20s/it]                                                     {'loss': 0.461, 'grad_norm': 0.7681791400214372, 'learning_rate': 9.527768444462922e-05, 'epoch': 1.66}
 17%|█▋        | 151/910 [1:07:05<5:31:29, 26.20s/it] 17%|█▋        | 152/910 [1:07:31<5:31:22, 26.23s/it]                                                     {'loss': 0.3996, 'grad_norm': 0.6141632769995298, 'learning_rate': 9.520184391829036e-05, 'epoch': 1.67}
 17%|█▋        | 152/910 [1:07:31<5:31:22, 26.23s/it] 17%|█▋        | 153/910 [1:07:58<5:31:40, 26.29s/it]                                                     {'loss': 0.4538, 'grad_norm': 0.6458185295145658, 'learning_rate': 9.512542991196376e-05, 'epoch': 1.68}
 17%|█▋        | 153/910 [1:07:58<5:31:40, 26.29s/it] 17%|█▋        | 154/910 [1:08:24<5:32:45, 26.41s/it]                                                     {'loss': 0.3154, 'grad_norm': 0.5539878197428628, 'learning_rate': 9.504844339512095e-05, 'epoch': 1.69}
 17%|█▋        | 154/910 [1:08:24<5:32:45, 26.41s/it] 17%|█▋        | 155/910 [1:08:51<5:34:02, 26.55s/it]                                                     {'loss': 0.4082, 'grad_norm': 0.8004575608310934, 'learning_rate': 9.497088534449708e-05, 'epoch': 1.7}
 17%|█▋        | 155/910 [1:08:51<5:34:02, 26.55s/it] 17%|█▋        | 156/910 [1:09:18<5:34:08, 26.59s/it]                                                     {'loss': 0.4582, 'grad_norm': 0.553611427124583, 'learning_rate': 9.489275674407826e-05, 'epoch': 1.71}
 17%|█▋        | 156/910 [1:09:18<5:34:08, 26.59s/it] 17%|█▋        | 157/910 [1:09:45<5:34:02, 26.62s/it]                                                     {'loss': 0.4326, 'grad_norm': 0.9670474155586127, 'learning_rate': 9.481405858508934e-05, 'epoch': 1.73}
 17%|█▋        | 157/910 [1:09:45<5:34:02, 26.62s/it] 17%|█▋        | 158/910 [1:10:12<5:34:21, 26.68s/it]                                                     {'loss': 0.4534, 'grad_norm': 0.7490465760432242, 'learning_rate': 9.473479186598116e-05, 'epoch': 1.74}
 17%|█▋        | 158/910 [1:10:12<5:34:21, 26.68s/it] 17%|█▋        | 159/910 [1:10:38<5:31:23, 26.48s/it]                                                     {'loss': 0.4262, 'grad_norm': 1.299914686587069, 'learning_rate': 9.465495759241792e-05, 'epoch': 1.75}
 17%|█▋        | 159/910 [1:10:38<5:31:23, 26.48s/it] 18%|█▊        | 160/910 [1:11:04<5:29:39, 26.37s/it]                                                     {'loss': 0.3831, 'grad_norm': 0.7489981599151587, 'learning_rate': 9.457455677726448e-05, 'epoch': 1.76}
 18%|█▊        | 160/910 [1:11:04<5:29:39, 26.37s/it] 18%|█▊        | 161/910 [1:11:30<5:29:12, 26.37s/it]                                                     {'loss': 0.4044, 'grad_norm': 0.922447191599856, 'learning_rate': 9.449359044057345e-05, 'epoch': 1.77}
 18%|█▊        | 161/910 [1:11:30<5:29:12, 26.37s/it] 18%|█▊        | 162/910 [1:11:56<5:28:15, 26.33s/it]                                                     {'loss': 0.4527, 'grad_norm': 0.7613275485747399, 'learning_rate': 9.44120596095722e-05, 'epoch': 1.78}
 18%|█▊        | 162/910 [1:11:56<5:28:15, 26.33s/it] 18%|█▊        | 163/910 [1:12:23<5:27:36, 26.31s/it]                                                     {'loss': 0.3845, 'grad_norm': 0.5608431779253035, 'learning_rate': 9.432996531865002e-05, 'epoch': 1.79}
 18%|█▊        | 163/910 [1:12:23<5:27:36, 26.31s/it] 18%|█▊        | 164/910 [1:12:49<5:27:57, 26.38s/it]                                                     {'loss': 0.4385, 'grad_norm': 0.6642764831728808, 'learning_rate': 9.424730860934472e-05, 'epoch': 1.8}
 18%|█▊        | 164/910 [1:12:49<5:27:57, 26.38s/it] 18%|█▊        | 165/910 [1:13:15<5:27:41, 26.39s/it]                                                     {'loss': 0.4832, 'grad_norm': 1.4747280815008785, 'learning_rate': 9.416409053032972e-05, 'epoch': 1.81}
 18%|█▊        | 165/910 [1:13:15<5:27:41, 26.39s/it] 18%|█▊        | 166/910 [1:13:42<5:28:03, 26.46s/it]                                                     {'loss': 0.4767, 'grad_norm': 0.678922374368249, 'learning_rate': 9.408031213740045e-05, 'epoch': 1.82}
 18%|█▊        | 166/910 [1:13:42<5:28:03, 26.46s/it] 18%|█▊        | 167/910 [1:14:09<5:28:38, 26.54s/it]                                                     {'loss': 0.6189, 'grad_norm': 3.8892430458625142, 'learning_rate': 9.39959744934612e-05, 'epoch': 1.84}
 18%|█▊        | 167/910 [1:14:09<5:28:38, 26.54s/it] 18%|█▊        | 168/910 [1:14:35<5:28:21, 26.55s/it]                                                     {'loss': 0.4352, 'grad_norm': 0.5766037578978769, 'learning_rate': 9.391107866851143e-05, 'epoch': 1.85}
 18%|█▊        | 168/910 [1:14:35<5:28:21, 26.55s/it] 19%|█▊        | 169/910 [1:15:02<5:28:47, 26.62s/it]                                                     {'loss': 0.4495, 'grad_norm': 0.6237818401572182, 'learning_rate': 9.382562573963238e-05, 'epoch': 1.86}
 19%|█▊        | 169/910 [1:15:02<5:28:47, 26.62s/it] 19%|█▊        | 170/910 [1:15:29<5:29:28, 26.71s/it]                                                     {'loss': 0.47, 'grad_norm': 0.8206666346708982, 'learning_rate': 9.373961679097331e-05, 'epoch': 1.87}
 19%|█▊        | 170/910 [1:15:29<5:29:28, 26.71s/it] 19%|█▉        | 171/910 [1:15:56<5:30:17, 26.82s/it]                                                     {'loss': 0.4244, 'grad_norm': 1.1792111405384582, 'learning_rate': 9.365305291373769e-05, 'epoch': 1.88}
 19%|█▉        | 171/910 [1:15:56<5:30:17, 26.82s/it] 19%|█▉        | 172/910 [1:16:22<5:27:03, 26.59s/it]                                                     {'loss': 0.4624, 'grad_norm': 1.0881318779315052, 'learning_rate': 9.356593520616948e-05, 'epoch': 1.89}
 19%|█▉        | 172/910 [1:16:22<5:27:03, 26.59s/it] 19%|█▉        | 173/910 [1:16:48<5:24:32, 26.42s/it]                                                     {'loss': 0.4283, 'grad_norm': 0.7613432395882503, 'learning_rate': 9.347826477353911e-05, 'epoch': 1.9}
 19%|█▉        | 173/910 [1:16:48<5:24:32, 26.42s/it] 19%|█▉        | 174/910 [1:17:14<5:23:16, 26.35s/it]                                                     {'loss': 0.4078, 'grad_norm': 1.1308677745414366, 'learning_rate': 9.33900427281295e-05, 'epoch': 1.91}
 19%|█▉        | 174/910 [1:17:14<5:23:16, 26.35s/it] 19%|█▉        | 175/910 [1:17:40<5:21:34, 26.25s/it]                                                     {'loss': 0.4369, 'grad_norm': 0.8980242001302332, 'learning_rate': 9.330127018922194e-05, 'epoch': 1.92}
 19%|█▉        | 175/910 [1:17:40<5:21:34, 26.25s/it] 19%|█▉        | 176/910 [1:18:07<5:22:13, 26.34s/it]                                                     {'loss': 0.4472, 'grad_norm': 0.6358268956741852, 'learning_rate': 9.321194828308185e-05, 'epoch': 1.93}
 19%|█▉        | 176/910 [1:18:07<5:22:13, 26.34s/it] 19%|█▉        | 177/910 [1:18:33<5:21:21, 26.30s/it]                                                     {'loss': 0.442, 'grad_norm': 0.5386234076718148, 'learning_rate': 9.312207814294454e-05, 'epoch': 1.95}
 19%|█▉        | 177/910 [1:18:33<5:21:21, 26.30s/it] 20%|█▉        | 178/910 [1:18:59<5:20:22, 26.26s/it]                                                     {'loss': 0.3953, 'grad_norm': 0.6067146370491053, 'learning_rate': 9.303166090900082e-05, 'epoch': 1.96}
 20%|█▉        | 178/910 [1:18:59<5:20:22, 26.26s/it] 20%|█▉        | 179/910 [1:19:26<5:20:11, 26.28s/it]                                                     {'loss': 0.488, 'grad_norm': 0.7663858599385855, 'learning_rate': 9.294069772838253e-05, 'epoch': 1.97}
 20%|█▉        | 179/910 [1:19:26<5:20:11, 26.28s/it] 20%|█▉        | 180/910 [1:19:52<5:21:03, 26.39s/it]                                                     {'loss': 0.3728, 'grad_norm': 0.4105951527023665, 'learning_rate': 9.284918975514797e-05, 'epoch': 1.98}
 20%|█▉        | 180/910 [1:19:52<5:21:03, 26.39s/it] 20%|█▉        | 181/910 [1:20:19<5:20:57, 26.42s/it]                                                     {'loss': 0.4903, 'grad_norm': 1.0519216143223054, 'learning_rate': 9.275713815026731e-05, 'epoch': 1.99}
 20%|█▉        | 181/910 [1:20:19<5:20:57, 26.42s/it] 20%|██        | 182/910 [1:20:48<5:29:04, 27.12s/it]                                                     {'loss': 0.4394, 'grad_norm': 0.6833872552121123, 'learning_rate': 9.266454408160779e-05, 'epoch': 2.0}
 20%|██        | 182/910 [1:20:48<5:29:04, 27.12s/it] 20%|██        | 183/910 [1:21:33<6:36:23, 32.72s/it]                                                     {'loss': 0.3774, 'grad_norm': 1.1629893800632354, 'learning_rate': 9.257140872391895e-05, 'epoch': 2.01}
 20%|██        | 183/910 [1:21:33<6:36:23, 32.72s/it] 20%|██        | 184/910 [1:22:00<6:12:10, 30.76s/it]                                                     {'loss': 0.407, 'grad_norm': 0.7108600342272132, 'learning_rate': 9.24777332588177e-05, 'epoch': 2.02}
 20%|██        | 184/910 [1:22:00<6:12:10, 30.76s/it] 20%|██        | 185/910 [1:22:26<5:54:28, 29.34s/it]                                                     {'loss': 0.4054, 'grad_norm': 0.5581436399990375, 'learning_rate': 9.238351887477337e-05, 'epoch': 2.03}
 20%|██        | 185/910 [1:22:26<5:54:28, 29.34s/it] 20%|██        | 186/910 [1:22:52<5:42:19, 28.37s/it]                                                     {'loss': 0.3443, 'grad_norm': 0.6764902916005693, 'learning_rate': 9.22887667670926e-05, 'epoch': 2.04}
 20%|██        | 186/910 [1:22:52<5:42:19, 28.37s/it] 21%|██        | 187/910 [1:23:18<5:34:07, 27.73s/it]                                                     {'loss': 0.4662, 'grad_norm': 0.7256609875507481, 'learning_rate': 9.219347813790416e-05, 'epoch': 2.05}
 21%|██        | 187/910 [1:23:18<5:34:07, 27.73s/it] 21%|██        | 188/910 [1:23:45<5:29:48, 27.41s/it]                                                     {'loss': 0.4351, 'grad_norm': 0.8666432730758555, 'learning_rate': 9.209765419614375e-05, 'epoch': 2.07}
 21%|██        | 188/910 [1:23:45<5:29:48, 27.41s/it] 21%|██        | 189/910 [1:24:11<5:25:16, 27.07s/it]                                                     {'loss': 0.423, 'grad_norm': 0.641184614653009, 'learning_rate': 9.200129615753859e-05, 'epoch': 2.08}
 21%|██        | 189/910 [1:24:11<5:25:16, 27.07s/it] 21%|██        | 190/910 [1:24:37<5:22:34, 26.88s/it]                                                     {'loss': 0.3595, 'grad_norm': 0.5096156825951003, 'learning_rate': 9.190440524459203e-05, 'epoch': 2.09}
 21%|██        | 190/910 [1:24:37<5:22:34, 26.88s/it] 21%|██        | 191/910 [1:25:04<5:21:52, 26.86s/it]                                                     {'loss': 0.3645, 'grad_norm': 0.38214715681020656, 'learning_rate': 9.180698268656813e-05, 'epoch': 2.1}
 21%|██        | 191/910 [1:25:04<5:21:52, 26.86s/it] 21%|██        | 192/910 [1:25:31<5:20:37, 26.79s/it]                                                     {'loss': 0.4523, 'grad_norm': 0.9107927779448884, 'learning_rate': 9.170902971947589e-05, 'epoch': 2.11}
 21%|██        | 192/910 [1:25:31<5:20:37, 26.79s/it] 21%|██        | 193/910 [1:25:57<5:19:45, 26.76s/it]                                                     {'loss': 0.407, 'grad_norm': 0.5739514134841448, 'learning_rate': 9.16105475860537e-05, 'epoch': 2.12}
 21%|██        | 193/910 [1:25:57<5:19:45, 26.76s/it] 21%|██▏       | 194/910 [1:26:25<5:20:24, 26.85s/it]                                                     {'loss': 0.4197, 'grad_norm': 0.8524932346426664, 'learning_rate': 9.151153753575351e-05, 'epoch': 2.13}
 21%|██▏       | 194/910 [1:26:25<5:20:24, 26.85s/it] 21%|██▏       | 195/910 [1:26:51<5:19:14, 26.79s/it]                                                     {'loss': 0.4012, 'grad_norm': 0.579025477426054, 'learning_rate': 9.141200082472503e-05, 'epoch': 2.14}
 21%|██▏       | 195/910 [1:26:51<5:19:14, 26.79s/it] 22%|██▏       | 196/910 [1:27:18<5:19:01, 26.81s/it]                                                     {'loss': 0.4364, 'grad_norm': 0.8932131324847454, 'learning_rate': 9.131193871579975e-05, 'epoch': 2.15}
 22%|██▏       | 196/910 [1:27:18<5:19:01, 26.81s/it] 22%|██▏       | 197/910 [1:27:45<5:18:32, 26.81s/it]                                                     {'loss': 0.3836, 'grad_norm': 0.6527004434394771, 'learning_rate': 9.121135247847492e-05, 'epoch': 2.16}
 22%|██▏       | 197/910 [1:27:45<5:18:32, 26.81s/it] 22%|██▏       | 198/910 [1:28:11<5:16:07, 26.64s/it]                                                     {'loss': 0.4878, 'grad_norm': 0.5997981900108469, 'learning_rate': 9.111024338889747e-05, 'epoch': 2.18}
 22%|██▏       | 198/910 [1:28:11<5:16:07, 26.64s/it] 22%|██▏       | 199/910 [1:28:37<5:13:45, 26.48s/it]                                                     {'loss': 0.4346, 'grad_norm': 6.02864475004653, 'learning_rate': 9.10086127298478e-05, 'epoch': 2.19}
 22%|██▏       | 199/910 [1:28:37<5:13:45, 26.48s/it] 22%|██▏       | 200/910 [1:29:04<5:13:15, 26.47s/it]                                                     {'loss': 0.4601, 'grad_norm': 0.9448202765682586, 'learning_rate': 9.090646179072351e-05, 'epoch': 2.2}
 22%|██▏       | 200/910 [1:29:04<5:13:15, 26.47s/it] 22%|██▏       | 201/910 [1:29:30<5:12:42, 26.46s/it]                                                     {'loss': 0.4365, 'grad_norm': 0.495655859615767, 'learning_rate': 9.080379186752304e-05, 'epoch': 2.21}
 22%|██▏       | 201/910 [1:29:30<5:12:42, 26.46s/it] 22%|██▏       | 202/910 [1:29:56<5:11:51, 26.43s/it]                                                     {'loss': 0.4282, 'grad_norm': 1.436573183566315, 'learning_rate': 9.070060426282925e-05, 'epoch': 2.22}
 22%|██▏       | 202/910 [1:29:56<5:11:51, 26.43s/it] 22%|██▏       | 203/910 [1:30:23<5:10:45, 26.37s/it]                                                     {'loss': 0.4822, 'grad_norm': 13.716606973829588, 'learning_rate': 9.059690028579284e-05, 'epoch': 2.23}
 22%|██▏       | 203/910 [1:30:23<5:10:45, 26.37s/it] 22%|██▏       | 204/910 [1:30:49<5:10:41, 26.40s/it]                                                     {'loss': 0.4984, 'grad_norm': 1.0391462513699508, 'learning_rate': 9.049268125211577e-05, 'epoch': 2.24}
 22%|██▏       | 204/910 [1:30:49<5:10:41, 26.40s/it] 23%|██▎       | 205/910 [1:31:16<5:10:48, 26.45s/it]                                                     {'loss': 0.3795, 'grad_norm': 1.045609234910916, 'learning_rate': 9.038794848403463e-05, 'epoch': 2.25}
 23%|██▎       | 205/910 [1:31:16<5:10:48, 26.45s/it] 23%|██▎       | 206/910 [1:31:42<5:11:29, 26.55s/it]                                                     {'loss': 0.4199, 'grad_norm': 0.7766808673967106, 'learning_rate': 9.028270331030373e-05, 'epoch': 2.26}
 23%|██▎       | 206/910 [1:31:42<5:11:29, 26.55s/it] 23%|██▎       | 207/910 [1:32:09<5:11:07, 26.55s/it]                                                     {'loss': 0.4231, 'grad_norm': 0.5209387992900227, 'learning_rate': 9.017694706617837e-05, 'epoch': 2.27}
 23%|██▎       | 207/910 [1:32:09<5:11:07, 26.55s/it] 23%|██▎       | 208/910 [1:32:36<5:11:18, 26.61s/it]                                                     {'loss': 0.404, 'grad_norm': 3.0699049125235844, 'learning_rate': 9.007068109339784e-05, 'epoch': 2.29}
 23%|██▎       | 208/910 [1:32:36<5:11:18, 26.61s/it] 23%|██▎       | 209/910 [1:33:03<5:12:00, 26.71s/it]                                                     {'loss': 0.378, 'grad_norm': 2.50219046691353, 'learning_rate': 8.996390674016837e-05, 'epoch': 2.3}
 23%|██▎       | 209/910 [1:33:03<5:12:00, 26.71s/it] 23%|██▎       | 210/910 [1:33:30<5:11:54, 26.74s/it]                                                     {'loss': 0.5151, 'grad_norm': 1.259945152685697, 'learning_rate': 8.985662536114613e-05, 'epoch': 2.31}
 23%|██▎       | 210/910 [1:33:30<5:11:54, 26.74s/it] 23%|██▎       | 211/910 [1:33:56<5:10:05, 26.62s/it]                                                     {'loss': 0.384, 'grad_norm': 0.7063908557480864, 'learning_rate': 8.974883831741989e-05, 'epoch': 2.32}
 23%|██▎       | 211/910 [1:33:56<5:10:05, 26.62s/it] 23%|██▎       | 212/910 [1:34:22<5:08:02, 26.48s/it]                                                     {'loss': 0.4217, 'grad_norm': 0.7187439727764605, 'learning_rate': 8.964054697649389e-05, 'epoch': 2.33}
 23%|██▎       | 212/910 [1:34:22<5:08:02, 26.48s/it] 23%|██▎       | 213/910 [1:34:48<5:06:33, 26.39s/it]                                                     {'loss': 0.3991, 'grad_norm': 0.531513410682583, 'learning_rate': 8.953175271227041e-05, 'epoch': 2.34}
 23%|██▎       | 213/910 [1:34:48<5:06:33, 26.39s/it] 24%|██▎       | 214/910 [1:35:15<5:06:32, 26.43s/it]                                                     {'loss': 0.461, 'grad_norm': 1.1473321035786805, 'learning_rate': 8.942245690503239e-05, 'epoch': 2.35}
 24%|██▎       | 214/910 [1:35:15<5:06:32, 26.43s/it] 24%|██▎       | 215/910 [1:35:41<5:04:50, 26.32s/it]                                                     {'loss': 0.39, 'grad_norm': 1.8266820595330633, 'learning_rate': 8.931266094142587e-05, 'epoch': 2.36}
 24%|██▎       | 215/910 [1:35:41<5:04:50, 26.32s/it] 24%|██▎       | 216/910 [1:36:07<5:03:47, 26.26s/it]                                                     {'loss': 0.4972, 'grad_norm': 1.1607695520134356, 'learning_rate': 8.920236621444243e-05, 'epoch': 2.37}
 24%|██▎       | 216/910 [1:36:07<5:03:47, 26.26s/it] 24%|██▍       | 217/910 [1:36:33<5:03:51, 26.31s/it]                                                     {'loss': 0.3731, 'grad_norm': 0.894352550105626, 'learning_rate': 8.90915741234015e-05, 'epoch': 2.38}
 24%|██▍       | 217/910 [1:36:33<5:03:51, 26.31s/it] 24%|██▍       | 218/910 [1:37:00<5:04:46, 26.43s/it]                                                     {'loss': 0.4614, 'grad_norm': 1.2193351465149709, 'learning_rate': 8.89802860739326e-05, 'epoch': 2.4}
 24%|██▍       | 218/910 [1:37:00<5:04:46, 26.43s/it] 24%|██▍       | 219/910 [1:37:27<5:04:54, 26.47s/it]                                                     {'loss': 0.4784, 'grad_norm': 0.9214923646521113, 'learning_rate': 8.886850347795758e-05, 'epoch': 2.41}
 24%|██▍       | 219/910 [1:37:27<5:04:54, 26.47s/it] 24%|██▍       | 220/910 [1:37:53<5:04:52, 26.51s/it]                                                     {'loss': 0.4703, 'grad_norm': 0.7246210881058472, 'learning_rate': 8.87562277536726e-05, 'epoch': 2.42}
 24%|██▍       | 220/910 [1:37:53<5:04:52, 26.51s/it] 24%|██▍       | 221/910 [1:38:20<5:05:31, 26.61s/it]                                                     {'loss': 0.4137, 'grad_norm': 0.5902940474773759, 'learning_rate': 8.864346032553016e-05, 'epoch': 2.43}
 24%|██▍       | 221/910 [1:38:20<5:05:31, 26.61s/it] 24%|██▍       | 222/910 [1:38:47<5:05:47, 26.67s/it]                                                     {'loss': 0.4866, 'grad_norm': 0.7806060338863089, 'learning_rate': 8.853020262422111e-05, 'epoch': 2.44}
 24%|██▍       | 222/910 [1:38:47<5:05:47, 26.67s/it] 25%|██▍       | 223/910 [1:39:14<5:06:57, 26.81s/it]                                                     {'loss': 0.4135, 'grad_norm': 0.6375521243666546, 'learning_rate': 8.84164560866564e-05, 'epoch': 2.45}
 25%|██▍       | 223/910 [1:39:14<5:06:57, 26.81s/it] 25%|██▍       | 224/910 [1:39:40<5:03:50, 26.57s/it]                                                     {'loss': 0.4244, 'grad_norm': 0.780772103818126, 'learning_rate': 8.83022221559489e-05, 'epoch': 2.46}
 25%|██▍       | 224/910 [1:39:40<5:03:50, 26.57s/it] 25%|██▍       | 225/910 [1:40:06<5:02:23, 26.49s/it]                                                     {'loss': 0.4151, 'grad_norm': 0.6679931071423573, 'learning_rate': 8.818750228139512e-05, 'epoch': 2.47}
 25%|██▍       | 225/910 [1:40:06<5:02:23, 26.49s/it] 25%|██▍       | 226/910 [1:40:33<5:02:37, 26.55s/it]                                                     {'loss': 0.4006, 'grad_norm': 0.5396479698794454, 'learning_rate': 8.807229791845673e-05, 'epoch': 2.48}
 25%|██▍       | 226/910 [1:40:33<5:02:37, 26.55s/it] 25%|██▍       | 227/910 [1:40:59<5:01:24, 26.48s/it]                                                     {'loss': 0.4438, 'grad_norm': 1.1796001269518201, 'learning_rate': 8.795661052874217e-05, 'epoch': 2.49}
 25%|██▍       | 227/910 [1:40:59<5:01:24, 26.48s/it] 25%|██▌       | 228/910 [1:41:26<5:01:20, 26.51s/it]                                                     {'loss': 0.401, 'grad_norm': 0.6033743593770454, 'learning_rate': 8.78404415799881e-05, 'epoch': 2.51}
 25%|██▌       | 228/910 [1:41:26<5:01:20, 26.51s/it] 25%|██▌       | 229/910 [1:41:52<5:00:12, 26.45s/it]                                                     {'loss': 0.4226, 'grad_norm': 1.2718726825108393, 'learning_rate': 8.772379254604073e-05, 'epoch': 2.52}
 25%|██▌       | 229/910 [1:41:52<5:00:12, 26.45s/it] 25%|██▌       | 230/910 [1:42:19<5:01:07, 26.57s/it]                                                     {'loss': 0.3946, 'grad_norm': 1.086192124172692, 'learning_rate': 8.76066649068372e-05, 'epoch': 2.53}
 25%|██▌       | 230/910 [1:42:19<5:01:07, 26.57s/it] 25%|██▌       | 231/910 [1:42:46<5:00:42, 26.57s/it]                                                     {'loss': 0.4549, 'grad_norm': 1.3337813405933834, 'learning_rate': 8.748906014838672e-05, 'epoch': 2.54}
 25%|██▌       | 231/910 [1:42:46<5:00:42, 26.57s/it] 25%|██▌       | 232/910 [1:43:12<5:00:38, 26.61s/it]                                                     {'loss': 0.4237, 'grad_norm': 0.5650214435997397, 'learning_rate': 8.737097976275178e-05, 'epoch': 2.55}
 25%|██▌       | 232/910 [1:43:12<5:00:38, 26.61s/it] 26%|██▌       | 233/910 [1:43:39<5:00:33, 26.64s/it]                                                     {'loss': 0.4344, 'grad_norm': 0.4646914537045171, 'learning_rate': 8.725242524802918e-05, 'epoch': 2.56}
 26%|██▌       | 233/910 [1:43:39<5:00:33, 26.64s/it] 26%|██▌       | 234/910 [1:44:06<5:00:33, 26.68s/it]                                                     {'loss': 0.4668, 'grad_norm': 2.526660742257538, 'learning_rate': 8.713339810833106e-05, 'epoch': 2.57}
 26%|██▌       | 234/910 [1:44:06<5:00:33, 26.68s/it] 26%|██▌       | 235/910 [1:44:33<5:00:39, 26.72s/it]                                                     {'loss': 0.3668, 'grad_norm': 0.7363747171491528, 'learning_rate': 8.701389985376578e-05, 'epoch': 2.58}
 26%|██▌       | 235/910 [1:44:33<5:00:39, 26.72s/it] 26%|██▌       | 236/910 [1:45:00<5:00:47, 26.78s/it]                                                     {'loss': 0.4588, 'grad_norm': 0.8771600716479262, 'learning_rate': 8.689393200041879e-05, 'epoch': 2.59}
 26%|██▌       | 236/910 [1:45:00<5:00:47, 26.78s/it] 26%|██▌       | 237/910 [1:45:26<5:00:09, 26.76s/it]                                                     {'loss': 0.4789, 'grad_norm': 0.728642862511416, 'learning_rate': 8.677349607033336e-05, 'epoch': 2.6}
 26%|██▌       | 237/910 [1:45:26<5:00:09, 26.76s/it] 26%|██▌       | 238/910 [1:45:52<4:57:43, 26.58s/it]                                                     {'loss': 0.3782, 'grad_norm': 1.3080475941510186, 'learning_rate': 8.665259359149132e-05, 'epoch': 2.62}
 26%|██▌       | 238/910 [1:45:52<4:57:43, 26.58s/it] 26%|██▋       | 239/910 [1:46:19<4:56:09, 26.48s/it]                                                     {'loss': 0.4185, 'grad_norm': 0.583644153611002, 'learning_rate': 8.653122609779363e-05, 'epoch': 2.63}
 26%|██▋       | 239/910 [1:46:19<4:56:09, 26.48s/it] 26%|██▋       | 240/910 [1:46:45<4:53:45, 26.31s/it]                                                     {'loss': 0.4674, 'grad_norm': 0.3876955809850764, 'learning_rate': 8.640939512904096e-05, 'epoch': 2.64}
 26%|██▋       | 240/910 [1:46:45<4:53:45, 26.31s/it] 26%|██▋       | 241/910 [1:47:11<4:53:52, 26.36s/it]                                                     {'loss': 0.3785, 'grad_norm': 0.6448614290825431, 'learning_rate': 8.62871022309141e-05, 'epoch': 2.65}
 26%|██▋       | 241/910 [1:47:11<4:53:52, 26.36s/it] 27%|██▋       | 242/910 [1:47:37<4:52:39, 26.29s/it]                                                     {'loss': 0.4063, 'grad_norm': 0.7880115960058813, 'learning_rate': 8.616434895495439e-05, 'epoch': 2.66}
 27%|██▋       | 242/910 [1:47:37<4:52:39, 26.29s/it] 27%|██▋       | 243/910 [1:48:03<4:52:03, 26.27s/it]                                                     {'loss': 0.4382, 'grad_norm': 1.3177316571969697, 'learning_rate': 8.604113685854407e-05, 'epoch': 2.67}
 27%|██▋       | 243/910 [1:48:03<4:52:03, 26.27s/it] 27%|██▋       | 244/910 [1:48:30<4:52:14, 26.33s/it]                                                     {'loss': 0.4211, 'grad_norm': 0.6252973211215636, 'learning_rate': 8.591746750488639e-05, 'epoch': 2.68}
 27%|██▋       | 244/910 [1:48:30<4:52:14, 26.33s/it] 27%|██▋       | 245/910 [1:48:57<4:53:14, 26.46s/it]                                                     {'loss': 0.4485, 'grad_norm': 0.49054351627997833, 'learning_rate': 8.579334246298593e-05, 'epoch': 2.69}
 27%|██▋       | 245/910 [1:48:57<4:53:14, 26.46s/it] 27%|██▋       | 246/910 [1:49:23<4:53:20, 26.51s/it]                                                     {'loss': 0.4605, 'grad_norm': 0.6665163088890121, 'learning_rate': 8.56687633076286e-05, 'epoch': 2.7}
 27%|██▋       | 246/910 [1:49:23<4:53:20, 26.51s/it] 27%|██▋       | 247/910 [1:49:50<4:53:33, 26.57s/it]                                                     {'loss': 0.4193, 'grad_norm': 0.5046927943472745, 'learning_rate': 8.554373161936175e-05, 'epoch': 2.71}
 27%|██▋       | 247/910 [1:49:50<4:53:33, 26.57s/it] 27%|██▋       | 248/910 [1:50:17<4:53:37, 26.61s/it]                                                     {'loss': 0.4183, 'grad_norm': 0.7306421228428833, 'learning_rate': 8.541824898447398e-05, 'epoch': 2.73}
 27%|██▋       | 248/910 [1:50:17<4:53:37, 26.61s/it] 27%|██▋       | 249/910 [1:50:43<4:53:43, 26.66s/it]                                                     {'loss': 0.4453, 'grad_norm': 0.6199245581554967, 'learning_rate': 8.52923169949751e-05, 'epoch': 2.74}
 27%|██▋       | 249/910 [1:50:43<4:53:43, 26.66s/it] 27%|██▋       | 250/910 [1:51:10<4:52:47, 26.62s/it]                                                     {'loss': 0.3765, 'grad_norm': 0.41867405949776443, 'learning_rate': 8.516593724857598e-05, 'epoch': 2.75}
 27%|██▋       | 250/910 [1:51:10<4:52:47, 26.62s/it] 28%|██▊       | 251/910 [1:51:36<4:50:33, 26.45s/it]                                                     {'loss': 0.426, 'grad_norm': 0.7433278505911538, 'learning_rate': 8.503911134866817e-05, 'epoch': 2.76}
 28%|██▊       | 251/910 [1:51:36<4:50:33, 26.45s/it] 28%|██▊       | 252/910 [1:52:03<4:50:28, 26.49s/it]                                                     {'loss': 0.4363, 'grad_norm': 0.9176112938995288, 'learning_rate': 8.491184090430364e-05, 'epoch': 2.77}
 28%|██▊       | 252/910 [1:52:03<4:50:28, 26.49s/it] 28%|██▊       | 253/910 [1:52:29<4:49:03, 26.40s/it]                                                     {'loss': 0.3801, 'grad_norm': 0.8290921592058664, 'learning_rate': 8.478412753017433e-05, 'epoch': 2.78}
 28%|██▊       | 253/910 [1:52:29<4:49:03, 26.40s/it] 28%|██▊       | 254/910 [1:52:55<4:47:54, 26.33s/it]                                                     {'loss': 0.4143, 'grad_norm': 1.1501125421098342, 'learning_rate': 8.465597284659164e-05, 'epoch': 2.79}
 28%|██▊       | 254/910 [1:52:55<4:47:54, 26.33s/it] 28%|██▊       | 255/910 [1:53:21<4:47:23, 26.33s/it]                                                     {'loss': 0.4552, 'grad_norm': 0.6442012591630427, 'learning_rate': 8.452737847946596e-05, 'epoch': 2.8}
 28%|██▊       | 255/910 [1:53:21<4:47:23, 26.33s/it] 28%|██▊       | 256/910 [1:53:48<4:46:40, 26.30s/it]                                                     {'loss': 0.4345, 'grad_norm': 0.7078633995369762, 'learning_rate': 8.439834606028594e-05, 'epoch': 2.81}
 28%|██▊       | 256/910 [1:53:48<4:46:40, 26.30s/it] 28%|██▊       | 257/910 [1:54:14<4:47:50, 26.45s/it]                                                     {'loss': 0.4939, 'grad_norm': 0.6084683400857904, 'learning_rate': 8.426887722609786e-05, 'epoch': 2.82}
 28%|██▊       | 257/910 [1:54:14<4:47:50, 26.45s/it] 28%|██▊       | 258/910 [1:54:41<4:47:45, 26.48s/it]                                                     {'loss': 0.4032, 'grad_norm': 0.7059175709304496, 'learning_rate': 8.413897361948484e-05, 'epoch': 2.84}
 28%|██▊       | 258/910 [1:54:41<4:47:45, 26.48s/it] 28%|██▊       | 259/910 [1:55:08<4:48:19, 26.57s/it]                                                     {'loss': 0.4562, 'grad_norm': 0.716510001403829, 'learning_rate': 8.400863688854597e-05, 'epoch': 2.85}
 28%|██▊       | 259/910 [1:55:08<4:48:19, 26.57s/it] 29%|██▊       | 260/910 [1:55:34<4:47:51, 26.57s/it]                                                     {'loss': 0.379, 'grad_norm': 0.7126441663448618, 'learning_rate': 8.387786868687548e-05, 'epoch': 2.86}
 29%|██▊       | 260/910 [1:55:34<4:47:51, 26.57s/it] 29%|██▊       | 261/910 [1:56:01<4:47:35, 26.59s/it]                                                     {'loss': 0.4048, 'grad_norm': 0.9363327622758302, 'learning_rate': 8.374667067354164e-05, 'epoch': 2.87}
 29%|██▊       | 261/910 [1:56:01<4:47:35, 26.59s/it] 29%|██▉       | 262/910 [1:56:28<4:47:27, 26.62s/it]                                                     {'loss': 0.416, 'grad_norm': 0.6097268267086565, 'learning_rate': 8.361504451306585e-05, 'epoch': 2.88}
 29%|██▉       | 262/910 [1:56:28<4:47:27, 26.62s/it] 29%|██▉       | 263/910 [1:56:54<4:47:38, 26.68s/it]                                                     {'loss': 0.4736, 'grad_norm': 1.8288567270460034, 'learning_rate': 8.34829918754014e-05, 'epoch': 2.89}
 29%|██▉       | 263/910 [1:56:54<4:47:38, 26.68s/it] 29%|██▉       | 264/910 [1:57:20<4:45:16, 26.50s/it]                                                     {'loss': 0.3767, 'grad_norm': 1.1373749854711936, 'learning_rate': 8.335051443591235e-05, 'epoch': 2.9}
 29%|██▉       | 264/910 [1:57:20<4:45:16, 26.50s/it] 29%|██▉       | 265/910 [1:57:46<4:42:35, 26.29s/it]                                                     {'loss': 0.4503, 'grad_norm': 0.8719142546912515, 'learning_rate': 8.321761387535231e-05, 'epoch': 2.91}
 29%|██▉       | 265/910 [1:57:46<4:42:35, 26.29s/it] 29%|██▉       | 266/910 [1:58:12<4:41:31, 26.23s/it]                                                     {'loss': 0.3916, 'grad_norm': 0.7517951102818768, 'learning_rate': 8.308429187984297e-05, 'epoch': 2.92}
 29%|██▉       | 266/910 [1:58:12<4:41:31, 26.23s/it] 29%|██▉       | 267/910 [1:58:38<4:40:39, 26.19s/it]                                                     {'loss': 0.5009, 'grad_norm': 2.989009348319746, 'learning_rate': 8.295055014085289e-05, 'epoch': 2.93}
 29%|██▉       | 267/910 [1:58:38<4:40:39, 26.19s/it] 29%|██▉       | 268/910 [1:59:05<4:40:09, 26.18s/it]                                                     {'loss': 0.3887, 'grad_norm': 0.9733051945909056, 'learning_rate': 8.28163903551759e-05, 'epoch': 2.95}
 29%|██▉       | 268/910 [1:59:05<4:40:09, 26.18s/it] 30%|██▉       | 269/910 [1:59:31<4:39:28, 26.16s/it]                                                     {'loss': 0.4425, 'grad_norm': 1.771435843853214, 'learning_rate': 8.268181422490968e-05, 'epoch': 2.96}
 30%|██▉       | 269/910 [1:59:31<4:39:28, 26.16s/it] 30%|██▉       | 270/910 [1:59:57<4:40:19, 26.28s/it]                                                     {'loss': 0.4273, 'grad_norm': 0.9639784134752393, 'learning_rate': 8.254682345743405e-05, 'epoch': 2.97}
 30%|██▉       | 270/910 [1:59:57<4:40:19, 26.28s/it] 30%|██▉       | 271/910 [2:00:24<4:40:30, 26.34s/it]                                                     {'loss': 0.4541, 'grad_norm': 0.4909571456273723, 'learning_rate': 8.241141976538943e-05, 'epoch': 2.98}
 30%|██▉       | 271/910 [2:00:24<4:40:30, 26.34s/it] 30%|██▉       | 272/910 [2:00:50<4:40:44, 26.40s/it]                                                     {'loss': 0.4563, 'grad_norm': 1.0328470661425189, 'learning_rate': 8.2275604866655e-05, 'epoch': 2.99}
 30%|██▉       | 272/910 [2:00:50<4:40:44, 26.40s/it] 30%|███       | 273/910 [2:01:18<4:44:48, 26.83s/it]                                                     {'loss': 0.434, 'grad_norm': 0.994061348175307, 'learning_rate': 8.213938048432697e-05, 'epoch': 3.0}
 30%|███       | 273/910 [2:01:18<4:44:48, 26.83s/it] 30%|███       | 274/910 [2:02:04<5:45:50, 32.63s/it]                                                     {'loss': 0.4515, 'grad_norm': 1.333730047316796, 'learning_rate': 8.200274834669675e-05, 'epoch': 3.01}
 30%|███       | 274/910 [2:02:04<5:45:50, 32.63s/it] 30%|███       | 275/910 [2:02:31<5:27:07, 30.91s/it]                                                     {'loss': 0.3978, 'grad_norm': 0.766576597429344, 'learning_rate': 8.186571018722893e-05, 'epoch': 3.02}
 30%|███       | 275/910 [2:02:31<5:27:07, 30.91s/it] 30%|███       | 276/910 [2:02:57<5:12:02, 29.53s/it]                                                     {'loss': 0.3755, 'grad_norm': 0.6150104897566491, 'learning_rate': 8.172826774453936e-05, 'epoch': 3.03}
 30%|███       | 276/910 [2:02:57<5:12:02, 29.53s/it] 30%|███       | 277/910 [2:03:24<5:01:07, 28.54s/it]                                                     {'loss': 0.4088, 'grad_norm': 0.4990253962874048, 'learning_rate': 8.159042276237308e-05, 'epoch': 3.04}
 30%|███       | 277/910 [2:03:24<5:01:07, 28.54s/it] 31%|███       | 278/910 [2:03:50<4:53:16, 27.84s/it]                                                     {'loss': 0.4005, 'grad_norm': 0.4306982364772944, 'learning_rate': 8.145217698958212e-05, 'epoch': 3.05}
 31%|███       | 278/910 [2:03:50<4:53:16, 27.84s/it] 31%|███       | 279/910 [2:04:16<4:47:41, 27.36s/it]                                                     {'loss': 0.4563, 'grad_norm': 0.7808815519610481, 'learning_rate': 8.131353218010346e-05, 'epoch': 3.07}
 31%|███       | 279/910 [2:04:16<4:47:41, 27.36s/it] 31%|███       | 280/910 [2:04:42<4:42:53, 26.94s/it]                                                     {'loss': 0.4829, 'grad_norm': 1.7306009918079373, 'learning_rate': 8.117449009293668e-05, 'epoch': 3.08}
 31%|███       | 280/910 [2:04:42<4:42:53, 26.94s/it] 31%|███       | 281/910 [2:05:08<4:40:02, 26.71s/it]                                                     {'loss': 0.3954, 'grad_norm': 0.5413765394470053, 'learning_rate': 8.10350524921216e-05, 'epoch': 3.09}
 31%|███       | 281/910 [2:05:08<4:40:02, 26.71s/it] 31%|███       | 282/910 [2:05:34<4:38:02, 26.56s/it]                                                     {'loss': 0.3596, 'grad_norm': 0.5352133839950726, 'learning_rate': 8.089522114671603e-05, 'epoch': 3.1}
 31%|███       | 282/910 [2:05:35<4:38:02, 26.56s/it] 31%|███       | 283/910 [2:06:01<4:37:00, 26.51s/it]                                                     {'loss': 0.3929, 'grad_norm': 0.5400208748934624, 'learning_rate': 8.07549978307732e-05, 'epoch': 3.11}
 31%|███       | 283/910 [2:06:01<4:37:00, 26.51s/it] 31%|███       | 284/910 [2:06:27<4:36:34, 26.51s/it]                                                     {'loss': 0.4707, 'grad_norm': 0.9529152205746816, 'learning_rate': 8.061438432331934e-05, 'epoch': 3.12}
 31%|███       | 284/910 [2:06:27<4:36:34, 26.51s/it] 31%|███▏      | 285/910 [2:06:54<4:35:49, 26.48s/it]                                                     {'loss': 0.4085, 'grad_norm': 0.4692834539202439, 'learning_rate': 8.047338240833106e-05, 'epoch': 3.13}
 31%|███▏      | 285/910 [2:06:54<4:35:49, 26.48s/it] 31%|███▏      | 286/910 [2:07:21<4:36:29, 26.59s/it]                                                     {'loss': 0.427, 'grad_norm': 1.1172064332685097, 'learning_rate': 8.033199387471277e-05, 'epoch': 3.14}
 31%|███▏      | 286/910 [2:07:21<4:36:29, 26.59s/it] 32%|███▏      | 287/910 [2:07:47<4:35:55, 26.57s/it]                                                     {'loss': 0.3802, 'grad_norm': 0.8199644913790056, 'learning_rate': 8.019022051627388e-05, 'epoch': 3.15}
 32%|███▏      | 287/910 [2:07:47<4:35:55, 26.57s/it] 32%|███▏      | 288/910 [2:08:14<4:35:59, 26.62s/it]                                                     {'loss': 0.41, 'grad_norm': 0.7954338287269, 'learning_rate': 8.004806413170613e-05, 'epoch': 3.16}
 32%|███▏      | 288/910 [2:08:14<4:35:59, 26.62s/it] 32%|███▏      | 289/910 [2:08:41<4:36:47, 26.74s/it]                                                     {'loss': 0.3957, 'grad_norm': 0.4439913904566669, 'learning_rate': 7.990552652456081e-05, 'epoch': 3.18}
 32%|███▏      | 289/910 [2:08:41<4:36:47, 26.74s/it] 32%|███▏      | 290/910 [2:09:07<4:34:12, 26.54s/it]                                                     {'loss': 0.3786, 'grad_norm': 0.7377140787403582, 'learning_rate': 7.976260950322572e-05, 'epoch': 3.19}
 32%|███▏      | 290/910 [2:09:07<4:34:12, 26.54s/it] 32%|███▏      | 291/910 [2:09:33<4:32:20, 26.40s/it]                                                     {'loss': 0.3832, 'grad_norm': 0.6065976180604454, 'learning_rate': 7.96193148809024e-05, 'epoch': 3.2}
 32%|███▏      | 291/910 [2:09:33<4:32:20, 26.40s/it] 32%|███▏      | 292/910 [2:09:59<4:31:24, 26.35s/it]                                                     {'loss': 0.3557, 'grad_norm': 0.8972196395292696, 'learning_rate': 7.9475644475583e-05, 'epoch': 3.21}
 32%|███▏      | 292/910 [2:09:59<4:31:24, 26.35s/it] 32%|███▏      | 293/910 [2:10:26<4:30:37, 26.32s/it]                                                     {'loss': 0.3899, 'grad_norm': 0.8455931471275615, 'learning_rate': 7.933160011002728e-05, 'epoch': 3.22}
 32%|███▏      | 293/910 [2:10:26<4:30:37, 26.32s/it] 32%|███▏      | 294/910 [2:10:52<4:29:20, 26.24s/it]                                                     {'loss': 0.4279, 'grad_norm': 1.1616492386767963, 'learning_rate': 7.91871836117395e-05, 'epoch': 3.23}
 32%|███▏      | 294/910 [2:10:52<4:29:20, 26.24s/it] 32%|███▏      | 295/910 [2:11:18<4:28:54, 26.23s/it]                                                     {'loss': 0.388, 'grad_norm': 0.6017936280944064, 'learning_rate': 7.904239681294514e-05, 'epoch': 3.24}
 32%|███▏      | 295/910 [2:11:18<4:28:54, 26.23s/it] 33%|███▎      | 296/910 [2:11:44<4:29:39, 26.35s/it]                                                     {'loss': 0.3393, 'grad_norm': 0.7005154514959087, 'learning_rate': 7.889724155056777e-05, 'epoch': 3.25}
 33%|███▎      | 296/910 [2:11:44<4:29:39, 26.35s/it] 33%|███▎      | 297/910 [2:12:11<4:31:04, 26.53s/it]                                                     {'loss': 0.4439, 'grad_norm': 0.6484966619430622, 'learning_rate': 7.875171966620568e-05, 'epoch': 3.26}
 33%|███▎      | 297/910 [2:12:11<4:31:04, 26.53s/it] 33%|███▎      | 298/910 [2:12:38<4:30:20, 26.50s/it]                                                     {'loss': 0.4658, 'grad_norm': 0.8535367071108168, 'learning_rate': 7.860583300610849e-05, 'epoch': 3.27}
 33%|███▎      | 298/910 [2:12:38<4:30:20, 26.50s/it] 33%|███▎      | 299/910 [2:13:05<4:30:59, 26.61s/it]                                                     {'loss': 0.4022, 'grad_norm': 0.800694888365215, 'learning_rate': 7.84595834211538e-05, 'epoch': 3.29}
 33%|███▎      | 299/910 [2:13:05<4:30:59, 26.61s/it] 33%|███▎      | 300/910 [2:13:31<4:29:53, 26.55s/it]                                                     {'loss': 0.4026, 'grad_norm': 0.46226245108262776, 'learning_rate': 7.83129727668237e-05, 'epoch': 3.3}
 33%|███▎      | 300/910 [2:13:31<4:29:53, 26.55s/it] 33%|███▎      | 301/910 [2:13:58<4:29:43, 26.57s/it]                                                     {'loss': 0.3904, 'grad_norm': 0.5913121581481086, 'learning_rate': 7.81660029031811e-05, 'epoch': 3.31}
 33%|███▎      | 301/910 [2:13:58<4:29:43, 26.57s/it] 33%|███▎      | 302/910 [2:14:24<4:29:49, 26.63s/it]                                                     {'loss': 0.4186, 'grad_norm': 0.5362885623056717, 'learning_rate': 7.801867569484636e-05, 'epoch': 3.32}
 33%|███▎      | 302/910 [2:14:24<4:29:49, 26.63s/it] 33%|███▎      | 303/910 [2:14:51<4:28:02, 26.50s/it]                                                     {'loss': 0.3477, 'grad_norm': 0.7872163379946381, 'learning_rate': 7.78709930109734e-05, 'epoch': 3.33}
 33%|███▎      | 303/910 [2:14:51<4:28:02, 26.50s/it] 33%|███▎      | 304/910 [2:15:17<4:27:26, 26.48s/it]                                                     {'loss': 0.4003, 'grad_norm': 2.132553839007453, 'learning_rate': 7.772295672522615e-05, 'epoch': 3.34}
 33%|███▎      | 304/910 [2:15:17<4:27:26, 26.48s/it] 34%|███▎      | 305/910 [2:15:43<4:25:55, 26.37s/it]                                                     {'loss': 0.4876, 'grad_norm': 0.8088984049265326, 'learning_rate': 7.75745687157547e-05, 'epoch': 3.35}
 34%|███▎      | 305/910 [2:15:43<4:25:55, 26.37s/it] 34%|███▎      | 306/910 [2:16:09<4:25:04, 26.33s/it]                                                     {'loss': 0.605, 'grad_norm': 1.0123397047240783, 'learning_rate': 7.74258308651715e-05, 'epoch': 3.36}
 34%|███▎      | 306/910 [2:16:09<4:25:04, 26.33s/it] 34%|███▎      | 307/910 [2:16:36<4:24:10, 26.29s/it]                                                     {'loss': 0.4003, 'grad_norm': 0.6431535537178232, 'learning_rate': 7.727674506052743e-05, 'epoch': 3.37}
 34%|███▎      | 307/910 [2:16:36<4:24:10, 26.29s/it] 34%|███▍      | 308/910 [2:17:02<4:23:35, 26.27s/it]                                                     {'loss': 0.4311, 'grad_norm': 1.0209708192853217, 'learning_rate': 7.712731319328798e-05, 'epoch': 3.38}
 34%|███▍      | 308/910 [2:17:02<4:23:35, 26.27s/it] 34%|███▍      | 309/910 [2:17:28<4:23:46, 26.33s/it]                                                     {'loss': 0.4583, 'grad_norm': 0.8046345952724381, 'learning_rate': 7.697753715930906e-05, 'epoch': 3.4}
 34%|███▍      | 309/910 [2:17:28<4:23:46, 26.33s/it] 34%|███▍      | 310/910 [2:17:55<4:24:11, 26.42s/it]                                                     {'loss': 0.4166, 'grad_norm': 1.074832935345281, 'learning_rate': 7.682741885881315e-05, 'epoch': 3.41}
 34%|███▍      | 310/910 [2:17:55<4:24:11, 26.42s/it] 34%|███▍      | 311/910 [2:18:21<4:23:53, 26.43s/it]                                                     {'loss': 0.4381, 'grad_norm': 3.82972603862167, 'learning_rate': 7.667696019636503e-05, 'epoch': 3.42}
 34%|███▍      | 311/910 [2:18:21<4:23:53, 26.43s/it] 34%|███▍      | 312/910 [2:18:48<4:24:43, 26.56s/it]                                                     {'loss': 0.4184, 'grad_norm': 0.6291032417896597, 'learning_rate': 7.652616308084774e-05, 'epoch': 3.43}
 34%|███▍      | 312/910 [2:18:48<4:24:43, 26.56s/it] 34%|███▍      | 313/910 [2:19:15<4:24:28, 26.58s/it]                                                     {'loss': 0.3655, 'grad_norm': 0.5628475734971828, 'learning_rate': 7.637502942543824e-05, 'epoch': 3.44}
 34%|███▍      | 313/910 [2:19:15<4:24:28, 26.58s/it] 35%|███▍      | 314/910 [2:19:42<4:24:10, 26.59s/it]                                                     {'loss': 0.3701, 'grad_norm': 0.5054970516130644, 'learning_rate': 7.622356114758328e-05, 'epoch': 3.45}
 35%|███▍      | 314/910 [2:19:42<4:24:10, 26.59s/it] 35%|███▍      | 315/910 [2:20:08<4:24:38, 26.69s/it]                                                     {'loss': 0.4295, 'grad_norm': 0.7300835822773261, 'learning_rate': 7.60717601689749e-05, 'epoch': 3.46}
 35%|███▍      | 315/910 [2:20:08<4:24:38, 26.69s/it] 35%|███▍      | 316/910 [2:20:35<4:22:35, 26.52s/it]                                                     {'loss': 0.4045, 'grad_norm': 1.453445925509742, 'learning_rate': 7.591962841552627e-05, 'epoch': 3.47}
 35%|███▍      | 316/910 [2:20:35<4:22:35, 26.52s/it] 35%|███▍      | 317/910 [2:21:01<4:21:07, 26.42s/it]                                                     {'loss': 0.3992, 'grad_norm': 0.6576894094186523, 'learning_rate': 7.576716781734698e-05, 'epoch': 3.48}
 35%|███▍      | 317/910 [2:21:01<4:21:07, 26.42s/it] 35%|███▍      | 318/910 [2:21:27<4:19:30, 26.30s/it]                                                     {'loss': 0.4039, 'grad_norm': 0.537662336391533, 'learning_rate': 7.561438030871885e-05, 'epoch': 3.49}
 35%|███▍      | 318/910 [2:21:27<4:19:30, 26.30s/it] 35%|███▌      | 319/910 [2:21:53<4:18:57, 26.29s/it]                                                     {'loss': 0.5205, 'grad_norm': 0.6090408004512285, 'learning_rate': 7.546126782807116e-05, 'epoch': 3.51}
 35%|███▌      | 319/910 [2:21:53<4:18:57, 26.29s/it] 35%|███▌      | 320/910 [2:22:19<4:18:17, 26.27s/it]                                                     {'loss': 0.3798, 'grad_norm': 0.6684457434043736, 'learning_rate': 7.530783231795615e-05, 'epoch': 3.52}
 35%|███▌      | 320/910 [2:22:19<4:18:17, 26.27s/it] 35%|███▌      | 321/910 [2:22:46<4:18:24, 26.32s/it]                                                     {'loss': 0.3531, 'grad_norm': 0.6671569019654934, 'learning_rate': 7.515407572502437e-05, 'epoch': 3.53}
 35%|███▌      | 321/910 [2:22:46<4:18:24, 26.32s/it] 35%|███▌      | 322/910 [2:23:12<4:17:48, 26.31s/it]                                                     {'loss': 0.5399, 'grad_norm': 0.6694960326270931, 'learning_rate': 7.500000000000001e-05, 'epoch': 3.54}
 35%|███▌      | 322/910 [2:23:12<4:17:48, 26.31s/it] 35%|███▌      | 323/910 [2:23:38<4:17:37, 26.33s/it]                                                     {'loss': 0.3857, 'grad_norm': 0.643225865249895, 'learning_rate': 7.484560709765605e-05, 'epoch': 3.55}
 35%|███▌      | 323/910 [2:23:38<4:17:37, 26.33s/it] 36%|███▌      | 324/910 [2:24:05<4:18:05, 26.43s/it]                                                     {'loss': 0.3729, 'grad_norm': 0.40667643225057165, 'learning_rate': 7.469089897678958e-05, 'epoch': 3.56}
 36%|███▌      | 324/910 [2:24:05<4:18:05, 26.43s/it] 36%|███▌      | 325/910 [2:24:32<4:18:15, 26.49s/it]                                                     {'loss': 0.4353, 'grad_norm': 0.5274652859573452, 'learning_rate': 7.45358776001969e-05, 'epoch': 3.57}
 36%|███▌      | 325/910 [2:24:32<4:18:15, 26.49s/it] 36%|███▌      | 326/910 [2:24:58<4:18:28, 26.56s/it]                                                     {'loss': 0.4214, 'grad_norm': 0.5108788528809755, 'learning_rate': 7.438054493464858e-05, 'epoch': 3.58}
 36%|███▌      | 326/910 [2:24:58<4:18:28, 26.56s/it] 36%|███▌      | 327/910 [2:25:25<4:18:14, 26.58s/it]                                                     {'loss': 0.3903, 'grad_norm': 0.41896634188110393, 'learning_rate': 7.422490295086458e-05, 'epoch': 3.59}
 36%|███▌      | 327/910 [2:25:25<4:18:14, 26.58s/it] 36%|███▌      | 328/910 [2:25:52<4:18:16, 26.63s/it]                                                     {'loss': 0.4083, 'grad_norm': 0.5521382514879364, 'learning_rate': 7.406895362348916e-05, 'epoch': 3.6}
 36%|███▌      | 328/910 [2:25:52<4:18:16, 26.63s/it] 36%|███▌      | 329/910 [2:26:18<4:17:27, 26.59s/it]                                                     {'loss': 0.3461, 'grad_norm': 0.6501653368444931, 'learning_rate': 7.391269893106592e-05, 'epoch': 3.62}
 36%|███▌      | 329/910 [2:26:18<4:17:27, 26.59s/it] 36%|███▋      | 330/910 [2:26:44<4:15:33, 26.44s/it]                                                     {'loss': 0.4239, 'grad_norm': 1.1358298272847231, 'learning_rate': 7.375614085601265e-05, 'epoch': 3.63}
 36%|███▋      | 330/910 [2:26:44<4:15:33, 26.44s/it] 36%|███▋      | 331/910 [2:27:10<4:13:56, 26.32s/it]                                                     {'loss': 0.3998, 'grad_norm': 0.7046390407365791, 'learning_rate': 7.359928138459615e-05, 'epoch': 3.64}
 36%|███▋      | 331/910 [2:27:10<4:13:56, 26.32s/it] 36%|███▋      | 332/910 [2:27:37<4:14:11, 26.39s/it]                                                     {'loss': 0.4394, 'grad_norm': 0.6062532512603034, 'learning_rate': 7.344212250690712e-05, 'epoch': 3.65}
 36%|███▋      | 332/910 [2:27:37<4:14:11, 26.39s/it] 37%|███▋      | 333/910 [2:28:03<4:13:07, 26.32s/it]                                                     {'loss': 0.4181, 'grad_norm': 0.4403398481664859, 'learning_rate': 7.32846662168348e-05, 'epoch': 3.66}
 37%|███▋      | 333/910 [2:28:03<4:13:07, 26.32s/it] 37%|███▋      | 334/910 [2:28:29<4:12:33, 26.31s/it]                                                     {'loss': 0.4471, 'grad_norm': 0.545826086978889, 'learning_rate': 7.312691451204178e-05, 'epoch': 3.67}
 37%|███▋      | 334/910 [2:28:29<4:12:33, 26.31s/it] 37%|███▋      | 335/910 [2:28:56<4:11:49, 26.28s/it]                                                     {'loss': 0.386, 'grad_norm': 0.434366964237066, 'learning_rate': 7.296886939393852e-05, 'epoch': 3.68}
 37%|███▋      | 335/910 [2:28:56<4:11:49, 26.28s/it] 37%|███▋      | 336/910 [2:29:22<4:12:01, 26.34s/it]                                                     {'loss': 0.3644, 'grad_norm': 0.714687064305501, 'learning_rate': 7.281053286765815e-05, 'epoch': 3.69}
 37%|███▋      | 336/910 [2:29:22<4:12:01, 26.34s/it] 37%|███▋      | 337/910 [2:29:49<4:12:19, 26.42s/it]                                                     {'loss': 0.4808, 'grad_norm': 0.7239807931788659, 'learning_rate': 7.265190694203085e-05, 'epoch': 3.7}
 37%|███▋      | 337/910 [2:29:49<4:12:19, 26.42s/it] 37%|███▋      | 338/910 [2:30:15<4:12:54, 26.53s/it]                                                     {'loss': 0.5369, 'grad_norm': 3.422637227243269, 'learning_rate': 7.249299362955846e-05, 'epoch': 3.71}
 37%|███▋      | 338/910 [2:30:15<4:12:54, 26.53s/it] 37%|███▋      | 339/910 [2:30:42<4:12:44, 26.56s/it]                                                     {'loss': 0.4124, 'grad_norm': 0.5722647496593123, 'learning_rate': 7.233379494638891e-05, 'epoch': 3.73}
 37%|███▋      | 339/910 [2:30:42<4:12:44, 26.56s/it] 37%|███▋      | 340/910 [2:31:09<4:12:17, 26.56s/it]                                                     {'loss': 0.3225, 'grad_norm': 0.6974164185199478, 'learning_rate': 7.217431291229067e-05, 'epoch': 3.74}
 37%|███▋      | 340/910 [2:31:09<4:12:17, 26.56s/it] 37%|███▋      | 341/910 [2:31:35<4:12:13, 26.60s/it]                                                     {'loss': 0.3878, 'grad_norm': 0.9161425418492437, 'learning_rate': 7.201454955062712e-05, 'epoch': 3.75}
 37%|███▋      | 341/910 [2:31:35<4:12:13, 26.60s/it] 38%|███▊      | 342/910 [2:32:02<4:13:05, 26.74s/it]                                                     {'loss': 0.339, 'grad_norm': 0.5201997246652259, 'learning_rate': 7.185450688833084e-05, 'epoch': 3.76}
 38%|███▊      | 342/910 [2:32:02<4:13:05, 26.74s/it] 38%|███▊      | 343/910 [2:32:28<4:10:29, 26.51s/it]                                                     {'loss': 0.3913, 'grad_norm': 0.9247373388583698, 'learning_rate': 7.169418695587791e-05, 'epoch': 3.77}
 38%|███▊      | 343/910 [2:32:28<4:10:29, 26.51s/it] 38%|███▊      | 344/910 [2:32:54<4:08:43, 26.37s/it]                                                     {'loss': 0.3702, 'grad_norm': 0.5103402211557581, 'learning_rate': 7.153359178726223e-05, 'epoch': 3.78}
 38%|███▊      | 344/910 [2:32:54<4:08:43, 26.37s/it] 38%|███▊      | 345/910 [2:33:21<4:07:44, 26.31s/it]                                                     {'loss': 0.4264, 'grad_norm': 0.5747102963884065, 'learning_rate': 7.137272341996958e-05, 'epoch': 3.79}
 38%|███▊      | 345/910 [2:33:21<4:07:44, 26.31s/it] 38%|███▊      | 346/910 [2:33:47<4:06:54, 26.27s/it]                                                     {'loss': 0.43, 'grad_norm': 0.5785009245193902, 'learning_rate': 7.121158389495186e-05, 'epoch': 3.8}
 38%|███▊      | 346/910 [2:33:47<4:06:54, 26.27s/it] 38%|███▊      | 347/910 [2:34:13<4:05:41, 26.18s/it]                                                     {'loss': 0.3993, 'grad_norm': 0.4662367091637851, 'learning_rate': 7.10501752566012e-05, 'epoch': 3.81}
 38%|███▊      | 347/910 [2:34:13<4:05:41, 26.18s/it] 38%|███▊      | 348/910 [2:34:39<4:04:39, 26.12s/it]                                                     {'loss': 0.4135, 'grad_norm': 0.6562533470508346, 'learning_rate': 7.088849955272396e-05, 'epoch': 3.82}
 38%|███▊      | 348/910 [2:34:39<4:04:39, 26.12s/it] 38%|███▊      | 349/910 [2:35:05<4:05:00, 26.20s/it]                                                     {'loss': 0.4339, 'grad_norm': 1.0710449114996718, 'learning_rate': 7.072655883451478e-05, 'epoch': 3.84}
 38%|███▊      | 349/910 [2:35:05<4:05:00, 26.20s/it] 38%|███▊      | 350/910 [2:35:32<4:05:54, 26.35s/it]                                                     {'loss': 0.3784, 'grad_norm': 0.6151685346209387, 'learning_rate': 7.056435515653059e-05, 'epoch': 3.85}
 38%|███▊      | 350/910 [2:35:32<4:05:54, 26.35s/it] 39%|███▊      | 351/910 [2:35:58<4:06:15, 26.43s/it]                                                     {'loss': 0.404, 'grad_norm': 0.727359132962766, 'learning_rate': 7.040189057666449e-05, 'epoch': 3.86}
 39%|███▊      | 351/910 [2:35:58<4:06:15, 26.43s/it] 39%|███▊      | 352/910 [2:36:25<4:05:59, 26.45s/it]                                                     {'loss': 0.4107, 'grad_norm': 0.8311243880300704, 'learning_rate': 7.023916715611969e-05, 'epoch': 3.87}
 39%|███▊      | 352/910 [2:36:25<4:05:59, 26.45s/it] 39%|███▉      | 353/910 [2:36:51<4:05:38, 26.46s/it]                                                     {'loss': 0.4042, 'grad_norm': 1.723971280578327, 'learning_rate': 7.007618695938334e-05, 'epoch': 3.88}
 39%|███▉      | 353/910 [2:36:51<4:05:38, 26.46s/it] 39%|███▉      | 354/910 [2:37:18<4:05:42, 26.52s/it]                                                     {'loss': 0.3872, 'grad_norm': 3.081284197975694, 'learning_rate': 6.991295205420028e-05, 'epoch': 3.89}
 39%|███▉      | 354/910 [2:37:18<4:05:42, 26.52s/it] 39%|███▉      | 355/910 [2:37:45<4:05:40, 26.56s/it]                                                     {'loss': 0.453, 'grad_norm': 0.4435086356211361, 'learning_rate': 6.974946451154693e-05, 'epoch': 3.9}
 39%|███▉      | 355/910 [2:37:45<4:05:40, 26.56s/it] 39%|███▉      | 356/910 [2:38:11<4:04:52, 26.52s/it]                                                     {'loss': 0.3566, 'grad_norm': 0.8030267168369724, 'learning_rate': 6.958572640560492e-05, 'epoch': 3.91}
 39%|███▉      | 356/910 [2:38:11<4:04:52, 26.52s/it] 39%|███▉      | 357/910 [2:38:37<4:03:14, 26.39s/it]                                                     {'loss': 0.4195, 'grad_norm': 0.5352344370610839, 'learning_rate': 6.942173981373474e-05, 'epoch': 3.92}
 39%|███▉      | 357/910 [2:38:37<4:03:14, 26.39s/it] 39%|███▉      | 358/910 [2:39:04<4:02:58, 26.41s/it]                                                     {'loss': 0.4202, 'grad_norm': 0.8145598405337346, 'learning_rate': 6.925750681644953e-05, 'epoch': 3.93}
 39%|███▉      | 358/910 [2:39:04<4:02:58, 26.41s/it] 39%|███▉      | 359/910 [2:39:30<4:01:56, 26.35s/it]                                                     {'loss': 0.4186, 'grad_norm': 0.6384862564904112, 'learning_rate': 6.909302949738859e-05, 'epoch': 3.95}
 39%|███▉      | 359/910 [2:39:30<4:01:56, 26.35s/it] 40%|███▉      | 360/910 [2:39:56<4:00:49, 26.27s/it]                                                     {'loss': 0.4213, 'grad_norm': 0.43117870902011346, 'learning_rate': 6.89283099432909e-05, 'epoch': 3.96}
 40%|███▉      | 360/910 [2:39:56<4:00:49, 26.27s/it] 40%|███▉      | 361/910 [2:40:22<3:59:38, 26.19s/it]                                                     {'loss': 0.3701, 'grad_norm': 0.3983667789292055, 'learning_rate': 6.876335024396872e-05, 'epoch': 3.97}
 40%|███▉      | 361/910 [2:40:22<3:59:38, 26.19s/it] 40%|███▉      | 362/910 [2:40:48<3:58:56, 26.16s/it]                                                     {'loss': 0.4131, 'grad_norm': 0.8051435400670259, 'learning_rate': 6.859815249228106e-05, 'epoch': 3.98}
 40%|███▉      | 362/910 [2:40:48<3:58:56, 26.16s/it] 40%|███▉      | 363/910 [2:41:15<3:59:51, 26.31s/it]                                                     {'loss': 0.3364, 'grad_norm': 0.5882304579501695, 'learning_rate': 6.843271878410714e-05, 'epoch': 3.99}
 40%|███▉      | 363/910 [2:41:15<3:59:51, 26.31s/it] 40%|████      | 364/910 [2:41:42<4:03:04, 26.71s/it]                                                     {'loss': 0.3734, 'grad_norm': 0.6733800022583988, 'learning_rate': 6.826705121831976e-05, 'epoch': 4.0}
 40%|████      | 364/910 [2:41:42<4:03:04, 26.71s/it] 40%|████      | 365/910 [2:42:28<4:53:39, 32.33s/it]                                                     {'loss': 0.4307, 'grad_norm': 0.6370312051330438, 'learning_rate': 6.81011518967587e-05, 'epoch': 4.01}
 40%|████      | 365/910 [2:42:28<4:53:39, 32.33s/it] 40%|████      | 366/910 [2:42:55<4:38:13, 30.69s/it]                                                     {'loss': 0.3516, 'grad_norm': 0.9996438150342676, 'learning_rate': 6.793502292420402e-05, 'epoch': 4.02}
 40%|████      | 366/910 [2:42:55<4:38:13, 30.69s/it] 40%|████      | 367/910 [2:43:22<4:27:18, 29.54s/it]                                                     {'loss': 0.4356, 'grad_norm': 0.47346901083373744, 'learning_rate': 6.776866640834945e-05, 'epoch': 4.03}
 40%|████      | 367/910 [2:43:22<4:27:18, 29.54s/it] 40%|████      | 368/910 [2:43:48<4:18:57, 28.67s/it]                                                     {'loss': 0.3684, 'grad_norm': 0.5255484999578628, 'learning_rate': 6.760208445977551e-05, 'epoch': 4.04}
 40%|████      | 368/910 [2:43:48<4:18:57, 28.67s/it] 41%|████      | 369/910 [2:44:14<4:11:30, 27.89s/it]                                                     {'loss': 0.4289, 'grad_norm': 1.7147472583277321, 'learning_rate': 6.743527919192286e-05, 'epoch': 4.05}
 41%|████      | 369/910 [2:44:14<4:11:30, 27.89s/it] 41%|████      | 370/910 [2:44:40<4:06:22, 27.37s/it]                                                     {'loss': 0.3849, 'grad_norm': 1.5717328787642009, 'learning_rate': 6.726825272106538e-05, 'epoch': 4.07}
 41%|████      | 370/910 [2:44:40<4:06:22, 27.37s/it] 41%|████      | 371/910 [2:45:07<4:03:24, 27.09s/it]                                                     {'loss': 0.4087, 'grad_norm': 1.4907267504810708, 'learning_rate': 6.710100716628344e-05, 'epoch': 4.08}
 41%|████      | 371/910 [2:45:07<4:03:24, 27.09s/it] 41%|████      | 372/910 [2:45:33<4:00:24, 26.81s/it]                                                     {'loss': 0.3784, 'grad_norm': 0.5194142678066815, 'learning_rate': 6.693354464943688e-05, 'epoch': 4.09}
 41%|████      | 372/910 [2:45:33<4:00:24, 26.81s/it] 41%|████      | 373/910 [2:45:59<3:58:27, 26.64s/it]                                                     {'loss': 0.4593, 'grad_norm': 0.7101769322234797, 'learning_rate': 6.676586729513823e-05, 'epoch': 4.1}
 41%|████      | 373/910 [2:45:59<3:58:27, 26.64s/it] 41%|████      | 374/910 [2:46:26<3:57:09, 26.55s/it]                                                     {'loss': 0.4117, 'grad_norm': 0.4894695249013844, 'learning_rate': 6.659797723072558e-05, 'epoch': 4.11}
 41%|████      | 374/910 [2:46:26<3:57:09, 26.55s/it] 41%|████      | 375/910 [2:46:52<3:57:20, 26.62s/it]                                                     {'loss': 0.404, 'grad_norm': 0.7786732075756548, 'learning_rate': 6.64298765862358e-05, 'epoch': 4.12}
 41%|████      | 375/910 [2:46:52<3:57:20, 26.62s/it] 41%|████▏     | 376/910 [2:47:19<3:56:43, 26.60s/it]                                                     {'loss': 0.4719, 'grad_norm': 0.7837315391020382, 'learning_rate': 6.626156749437736e-05, 'epoch': 4.13}
 41%|████▏     | 376/910 [2:47:19<3:56:43, 26.60s/it] 41%|████▏     | 377/910 [2:47:46<3:56:27, 26.62s/it]                                                     {'loss': 0.3451, 'grad_norm': 0.5404226012622815, 'learning_rate': 6.609305209050332e-05, 'epoch': 4.14}
 41%|████▏     | 377/910 [2:47:46<3:56:27, 26.62s/it] 42%|████▏     | 378/910 [2:48:12<3:56:17, 26.65s/it]                                                     {'loss': 0.3688, 'grad_norm': 0.5824559662596333, 'learning_rate': 6.592433251258423e-05, 'epoch': 4.15}
 42%|████▏     | 378/910 [2:48:12<3:56:17, 26.65s/it] 42%|████▏     | 379/910 [2:48:39<3:55:48, 26.64s/it]                                                     {'loss': 0.4384, 'grad_norm': 1.4589809938934926, 'learning_rate': 6.575541090118105e-05, 'epoch': 4.16}
 42%|████▏     | 379/910 [2:48:39<3:55:48, 26.64s/it] 42%|████▏     | 380/910 [2:49:06<3:55:46, 26.69s/it]                                                     {'loss': 0.4253, 'grad_norm': 0.7522986330313137, 'learning_rate': 6.558628939941791e-05, 'epoch': 4.18}
 42%|████▏     | 380/910 [2:49:06<3:55:46, 26.69s/it] 42%|████▏     | 381/910 [2:49:32<3:55:10, 26.67s/it]                                                     {'loss': 0.3314, 'grad_norm': 2.2315552262208413, 'learning_rate': 6.541697015295503e-05, 'epoch': 4.19}
 42%|████▏     | 381/910 [2:49:32<3:55:10, 26.67s/it] 42%|████▏     | 382/910 [2:49:59<3:53:24, 26.52s/it]                                                     {'loss': 0.3919, 'grad_norm': 1.2003216560622867, 'learning_rate': 6.524745530996137e-05, 'epoch': 4.2}
 42%|████▏     | 382/910 [2:49:59<3:53:24, 26.52s/it] 42%|████▏     | 383/910 [2:50:25<3:51:54, 26.40s/it]                                                     {'loss': 0.4181, 'grad_norm': 0.7750756856311637, 'learning_rate': 6.507774702108747e-05, 'epoch': 4.21}
 42%|████▏     | 383/910 [2:50:25<3:51:54, 26.40s/it] 42%|████▏     | 384/910 [2:50:51<3:51:24, 26.40s/it]                                                     {'loss': 0.4498, 'grad_norm': 0.5845765244565376, 'learning_rate': 6.490784743943818e-05, 'epoch': 4.22}
 42%|████▏     | 384/910 [2:50:51<3:51:24, 26.40s/it] 42%|████▏     | 385/910 [2:51:17<3:50:36, 26.36s/it]                                                     {'loss': 0.3901, 'grad_norm': 0.6638155270022116, 'learning_rate': 6.473775872054521e-05, 'epoch': 4.23}
 42%|████▏     | 385/910 [2:51:17<3:50:36, 26.36s/it] 42%|████▏     | 386/910 [2:51:44<3:49:51, 26.32s/it]                                                     {'loss': 0.3298, 'grad_norm': 0.7582779321967911, 'learning_rate': 6.456748302233995e-05, 'epoch': 4.24}
 42%|████▏     | 386/910 [2:51:44<3:49:51, 26.32s/it] 43%|████▎     | 387/910 [2:52:10<3:49:37, 26.34s/it]                                                     {'loss': 0.4027, 'grad_norm': 0.7304148318172478, 'learning_rate': 6.439702250512596e-05, 'epoch': 4.25}
 43%|████▎     | 387/910 [2:52:10<3:49:37, 26.34s/it] 43%|████▎     | 388/910 [2:52:36<3:49:20, 26.36s/it]                                                     {'loss': 0.3878, 'grad_norm': 0.7375387979246094, 'learning_rate': 6.422637933155162e-05, 'epoch': 4.26}
 43%|████▎     | 388/910 [2:52:36<3:49:20, 26.36s/it] 43%|████▎     | 389/910 [2:53:03<3:49:47, 26.46s/it]                                                     {'loss': 0.4342, 'grad_norm': 0.6760423658330051, 'learning_rate': 6.405555566658276e-05, 'epoch': 4.27}
 43%|████▎     | 389/910 [2:53:03<3:49:47, 26.46s/it] 43%|████▎     | 390/910 [2:53:30<3:50:13, 26.56s/it]                                                     {'loss': 0.3944, 'grad_norm': 1.1178017299213954, 'learning_rate': 6.388455367747502e-05, 'epoch': 4.29}
 43%|████▎     | 390/910 [2:53:30<3:50:13, 26.56s/it] 43%|████▎     | 391/910 [2:53:56<3:49:30, 26.53s/it]                                                     {'loss': 0.3939, 'grad_norm': 1.5048863564184711, 'learning_rate': 6.371337553374652e-05, 'epoch': 4.3}
 43%|████▎     | 391/910 [2:53:56<3:49:30, 26.53s/it] 43%|████▎     | 392/910 [2:54:23<3:50:08, 26.66s/it]                                                     {'loss': 0.3919, 'grad_norm': 0.648844324665876, 'learning_rate': 6.354202340715026e-05, 'epoch': 4.31}
 43%|████▎     | 392/910 [2:54:23<3:50:08, 26.66s/it] 43%|████▎     | 393/910 [2:54:50<3:50:07, 26.71s/it]                                                     {'loss': 0.4127, 'grad_norm': 2.462119008226679, 'learning_rate': 6.337049947164656e-05, 'epoch': 4.32}
 43%|████▎     | 393/910 [2:54:50<3:50:07, 26.71s/it] 43%|████▎     | 394/910 [2:55:17<3:51:05, 26.87s/it]                                                     {'loss': 0.4089, 'grad_norm': 1.316543559740037, 'learning_rate': 6.319880590337549e-05, 'epoch': 4.33}
 43%|████▎     | 394/910 [2:55:17<3:51:05, 26.87s/it] 43%|████▎     | 395/910 [2:55:44<3:49:07, 26.69s/it]                                                     {'loss': 0.4185, 'grad_norm': 0.5893581123757079, 'learning_rate': 6.302694488062931e-05, 'epoch': 4.34}
 43%|████▎     | 395/910 [2:55:44<3:49:07, 26.69s/it] 44%|████▎     | 396/910 [2:56:10<3:46:52, 26.48s/it]                                                     {'loss': 0.3941, 'grad_norm': 1.4260929972678442, 'learning_rate': 6.285491858382475e-05, 'epoch': 4.35}
 44%|████▎     | 396/910 [2:56:10<3:46:52, 26.48s/it] 44%|████▎     | 397/910 [2:56:36<3:45:38, 26.39s/it]                                                     {'loss': 0.4456, 'grad_norm': 0.9677065950805007, 'learning_rate': 6.268272919547537e-05, 'epoch': 4.36}
 44%|████▎     | 397/910 [2:56:36<3:45:38, 26.39s/it] 44%|████▎     | 398/910 [2:57:02<3:44:53, 26.35s/it]                                                     {'loss': 0.4411, 'grad_norm': 0.6958862815627611, 'learning_rate': 6.251037890016395e-05, 'epoch': 4.37}
 44%|████▎     | 398/910 [2:57:02<3:44:53, 26.35s/it] 44%|████▍     | 399/910 [2:57:28<3:44:21, 26.34s/it]                                                     {'loss': 0.4026, 'grad_norm': 0.8380513940462336, 'learning_rate': 6.233786988451468e-05, 'epoch': 4.38}
 44%|████▍     | 399/910 [2:57:28<3:44:21, 26.34s/it] 44%|████▍     | 400/910 [2:57:55<3:44:28, 26.41s/it]                                                     {'loss': 0.3474, 'grad_norm': 0.656247140193838, 'learning_rate': 6.216520433716545e-05, 'epoch': 4.4}
 44%|████▍     | 400/910 [2:57:55<3:44:28, 26.41s/it] 44%|████▍     | 401/910 [2:58:21<3:43:36, 26.36s/it]                                                     {'loss': 0.3093, 'grad_norm': 0.7603914032921006, 'learning_rate': 6.199238444874005e-05, 'epoch': 4.41}
 44%|████▍     | 401/910 [2:58:21<3:43:36, 26.36s/it] 44%|████▍     | 402/910 [2:58:48<3:43:31, 26.40s/it]                                                     {'loss': 0.4532, 'grad_norm': 0.9102747220175128, 'learning_rate': 6.181941241182045e-05, 'epoch': 4.42}
 44%|████▍     | 402/910 [2:58:48<3:43:31, 26.40s/it] 44%|████▍     | 403/910 [2:59:14<3:43:24, 26.44s/it]                                                     {'loss': 0.3904, 'grad_norm': 0.7910543260839558, 'learning_rate': 6.164629042091893e-05, 'epoch': 4.43}
 44%|████▍     | 403/910 [2:59:14<3:43:24, 26.44s/it] 44%|████▍     | 404/910 [2:59:41<3:43:49, 26.54s/it]                                                     {'loss': 0.4161, 'grad_norm': 3.2415029840081884, 'learning_rate': 6.147302067245028e-05, 'epoch': 4.44}
 44%|████▍     | 404/910 [2:59:41<3:43:49, 26.54s/it] 45%|████▍     | 405/910 [3:00:08<3:43:52, 26.60s/it]                                                     {'loss': 0.3268, 'grad_norm': 0.544423382514688, 'learning_rate': 6.129960536470382e-05, 'epoch': 4.45}
 45%|████▍     | 405/910 [3:00:08<3:43:52, 26.60s/it] 45%|████▍     | 406/910 [3:00:34<3:43:35, 26.62s/it]                                                     {'loss': 0.4161, 'grad_norm': 1.5489422450120975, 'learning_rate': 6.112604669781572e-05, 'epoch': 4.46}
 45%|████▍     | 406/910 [3:00:34<3:43:35, 26.62s/it] 45%|████▍     | 407/910 [3:01:01<3:43:34, 26.67s/it]                                                     {'loss': 0.3782, 'grad_norm': 0.6223526188487968, 'learning_rate': 6.095234687374085e-05, 'epoch': 4.47}
 45%|████▍     | 407/910 [3:01:01<3:43:34, 26.67s/it] 45%|████▍     | 408/910 [3:01:28<3:43:14, 26.68s/it]                                                     {'loss': 0.5106, 'grad_norm': 1.3700900078315308, 'learning_rate': 6.0778508096224985e-05, 'epoch': 4.48}
 45%|████▍     | 408/910 [3:01:28<3:43:14, 26.68s/it] 45%|████▍     | 409/910 [3:01:54<3:41:32, 26.53s/it]                                                     {'loss': 0.2752, 'grad_norm': 1.6368550237672723, 'learning_rate': 6.060453257077685e-05, 'epoch': 4.49}
 45%|████▍     | 409/910 [3:01:54<3:41:32, 26.53s/it] 45%|████▌     | 410/910 [3:02:20<3:39:44, 26.37s/it]                                                     {'loss': 0.4101, 'grad_norm': 0.5114072435273541, 'learning_rate': 6.043042250464005e-05, 'epoch': 4.51}
 45%|████▌     | 410/910 [3:02:20<3:39:44, 26.37s/it] 45%|████▌     | 411/910 [3:02:46<3:39:00, 26.33s/it]                                                     {'loss': 0.3674, 'grad_norm': 0.7488658861927535, 'learning_rate': 6.025618010676516e-05, 'epoch': 4.52}
 45%|████▌     | 411/910 [3:02:46<3:39:00, 26.33s/it] 45%|████▌     | 412/910 [3:03:12<3:38:13, 26.29s/it]                                                     {'loss': 0.4799, 'grad_norm': 0.8267549425718286, 'learning_rate': 6.008180758778167e-05, 'epoch': 4.53}
 45%|████▌     | 412/910 [3:03:12<3:38:13, 26.29s/it] 45%|████▌     | 413/910 [3:03:39<3:38:04, 26.33s/it]                                                     {'loss': 0.3759, 'grad_norm': 0.8207859465292779, 'learning_rate': 5.9907307159969884e-05, 'epoch': 4.54}
 45%|████▌     | 413/910 [3:03:39<3:38:04, 26.33s/it] 45%|████▌     | 414/910 [3:04:05<3:37:33, 26.32s/it]                                                     {'loss': 0.3842, 'grad_norm': 0.9724570999258856, 'learning_rate': 5.973268103723293e-05, 'epoch': 4.55}
 45%|████▌     | 414/910 [3:04:05<3:37:33, 26.32s/it] 46%|████▌     | 415/910 [3:04:32<3:38:18, 26.46s/it]                                                     {'loss': 0.3767, 'grad_norm': 0.5890391271619249, 'learning_rate': 5.955793143506863e-05, 'epoch': 4.56}
 46%|████▌     | 415/910 [3:04:32<3:38:18, 26.46s/it] 46%|████▌     | 416/910 [3:04:59<3:38:14, 26.51s/it]                                                     {'loss': 0.3842, 'grad_norm': 0.6932780270755456, 'learning_rate': 5.9383060570541384e-05, 'epoch': 4.57}
 46%|████▌     | 416/910 [3:04:59<3:38:14, 26.51s/it] 46%|████▌     | 417/910 [3:05:25<3:38:20, 26.57s/it]                                                     {'loss': 0.4089, 'grad_norm': 1.209826643526422, 'learning_rate': 5.920807066225409e-05, 'epoch': 4.58}
 46%|████▌     | 417/910 [3:05:25<3:38:20, 26.57s/it] 46%|████▌     | 418/910 [3:05:52<3:38:40, 26.67s/it]                                                     {'loss': 0.3698, 'grad_norm': 1.2233401190946798, 'learning_rate': 5.903296393031995e-05, 'epoch': 4.59}
 46%|████▌     | 418/910 [3:05:52<3:38:40, 26.67s/it] 46%|████▌     | 419/910 [3:06:19<3:38:27, 26.69s/it]                                                     {'loss': 0.442, 'grad_norm': 0.8337279625961036, 'learning_rate': 5.885774259633432e-05, 'epoch': 4.6}
 46%|████▌     | 419/910 [3:06:19<3:38:27, 26.69s/it] 46%|████▌     | 420/910 [3:06:46<3:38:08, 26.71s/it]                                                     {'loss': 0.3975, 'grad_norm': 2.9215218399003016, 'learning_rate': 5.868240888334653e-05, 'epoch': 4.62}
 46%|████▌     | 420/910 [3:06:46<3:38:08, 26.71s/it] 46%|████▋     | 421/910 [3:07:13<3:38:14, 26.78s/it]                                                     {'loss': 0.4363, 'grad_norm': 0.853714416699814, 'learning_rate': 5.850696501583164e-05, 'epoch': 4.63}
 46%|████▋     | 421/910 [3:07:13<3:38:14, 26.78s/it] 46%|████▋     | 422/910 [3:07:39<3:36:22, 26.60s/it]                                                     {'loss': 0.5381, 'grad_norm': 1.0621869689016465, 'learning_rate': 5.833141321966229e-05, 'epoch': 4.64}
 46%|████▋     | 422/910 [3:07:39<3:36:22, 26.60s/it] 46%|████▋     | 423/910 [3:08:05<3:34:51, 26.47s/it]                                                     {'loss': 0.4147, 'grad_norm': 0.6439434935988103, 'learning_rate': 5.8155755722080415e-05, 'epoch': 4.65}
 46%|████▋     | 423/910 [3:08:05<3:34:51, 26.47s/it] 47%|████▋     | 424/910 [3:08:31<3:33:24, 26.35s/it]                                                     {'loss': 0.4083, 'grad_norm': 0.5190535268707986, 'learning_rate': 5.7979994751668964e-05, 'epoch': 4.66}
 47%|████▋     | 424/910 [3:08:31<3:33:24, 26.35s/it] 47%|████▋     | 425/910 [3:08:57<3:32:24, 26.28s/it]                                                     {'loss': 0.3778, 'grad_norm': 0.4247649984277909, 'learning_rate': 5.78041325383237e-05, 'epoch': 4.67}
 47%|████▋     | 425/910 [3:08:57<3:32:24, 26.28s/it] 47%|████▋     | 426/910 [3:09:23<3:31:23, 26.21s/it]                                                     {'loss': 0.4004, 'grad_norm': 0.537773258753826, 'learning_rate': 5.762817131322482e-05, 'epoch': 4.68}
 47%|████▋     | 426/910 [3:09:23<3:31:23, 26.21s/it] 47%|████▋     | 427/910 [3:09:50<3:31:25, 26.26s/it]                                                     {'loss': 0.4746, 'grad_norm': 0.8737703386080207, 'learning_rate': 5.745211330880872e-05, 'epoch': 4.69}
 47%|████▋     | 427/910 [3:09:50<3:31:25, 26.26s/it] 47%|████▋     | 428/910 [3:10:16<3:31:15, 26.30s/it]                                                     {'loss': 0.3954, 'grad_norm': 0.6607002315799325, 'learning_rate': 5.727596075873966e-05, 'epoch': 4.7}
 47%|████▋     | 428/910 [3:10:16<3:31:15, 26.30s/it] 47%|████▋     | 429/910 [3:10:43<3:32:00, 26.45s/it]                                                     {'loss': 0.3373, 'grad_norm': 0.620792784708969, 'learning_rate': 5.709971589788136e-05, 'epoch': 4.71}
 47%|████▋     | 429/910 [3:10:43<3:32:00, 26.45s/it] 47%|████▋     | 430/910 [3:11:09<3:31:27, 26.43s/it]                                                     {'loss': 0.4424, 'grad_norm': 1.2491579247064803, 'learning_rate': 5.69233809622687e-05, 'epoch': 4.73}
 47%|████▋     | 430/910 [3:11:09<3:31:27, 26.43s/it] 47%|████▋     | 431/910 [3:11:36<3:31:48, 26.53s/it]                                                     {'loss': 0.3558, 'grad_norm': 0.8476318172252435, 'learning_rate': 5.674695818907943e-05, 'epoch': 4.74}
 47%|████▋     | 431/910 [3:11:36<3:31:48, 26.53s/it] 47%|████▋     | 432/910 [3:12:03<3:32:00, 26.61s/it]                                                     {'loss': 0.4057, 'grad_norm': 0.5432439492191357, 'learning_rate': 5.6570449816605596e-05, 'epoch': 4.75}
 47%|████▋     | 432/910 [3:12:03<3:32:00, 26.61s/it] 48%|████▊     | 433/910 [3:12:30<3:32:15, 26.70s/it]                                                     {'loss': 0.372, 'grad_norm': 1.025554447781401, 'learning_rate': 5.6393858084225305e-05, 'epoch': 4.76}
 48%|████▊     | 433/910 [3:12:30<3:32:15, 26.70s/it] 48%|████▊     | 434/910 [3:12:57<3:32:34, 26.80s/it]                                                     {'loss': 0.4362, 'grad_norm': 1.7133165978768399, 'learning_rate': 5.621718523237427e-05, 'epoch': 4.77}
 48%|████▊     | 434/910 [3:12:57<3:32:34, 26.80s/it] 48%|████▊     | 435/910 [3:13:23<3:31:03, 26.66s/it]                                                     {'loss': 0.3708, 'grad_norm': 0.6129683949871407, 'learning_rate': 5.604043350251733e-05, 'epoch': 4.78}
 48%|████▊     | 435/910 [3:13:23<3:31:03, 26.66s/it] 48%|████▊     | 436/910 [3:13:49<3:29:19, 26.50s/it]                                                     {'loss': 0.6429, 'grad_norm': 1.3584881162407576, 'learning_rate': 5.58636051371201e-05, 'epoch': 4.79}
 48%|████▊     | 436/910 [3:13:49<3:29:19, 26.50s/it] 48%|████▊     | 437/910 [3:14:15<3:27:50, 26.37s/it]                                                     {'loss': 0.4351, 'grad_norm': 0.5470708325262359, 'learning_rate': 5.568670237962045e-05, 'epoch': 4.8}
 48%|████▊     | 437/910 [3:14:15<3:27:50, 26.37s/it] 48%|████▊     | 438/910 [3:14:41<3:27:06, 26.33s/it]                                                     {'loss': 0.3622, 'grad_norm': 0.6124465914664133, 'learning_rate': 5.550972747440006e-05, 'epoch': 4.81}
 48%|████▊     | 438/910 [3:14:41<3:27:06, 26.33s/it] 48%|████▊     | 439/910 [3:15:08<3:26:31, 26.31s/it]                                                     {'loss': 0.3696, 'grad_norm': 0.8490792367389043, 'learning_rate': 5.533268266675601e-05, 'epoch': 4.82}
 48%|████▊     | 439/910 [3:15:08<3:26:31, 26.31s/it] 48%|████▊     | 440/910 [3:15:34<3:26:26, 26.35s/it]                                                     {'loss': 0.387, 'grad_norm': 0.46647684165879905, 'learning_rate': 5.5155570202872186e-05, 'epoch': 4.84}
 48%|████▊     | 440/910 [3:15:34<3:26:26, 26.35s/it] 48%|████▊     | 441/910 [3:16:00<3:25:50, 26.33s/it]                                                     {'loss': 0.3993, 'grad_norm': 1.0709762268431677, 'learning_rate': 5.497839232979084e-05, 'epoch': 4.85}
 48%|████▊     | 441/910 [3:16:00<3:25:50, 26.33s/it] 49%|████▊     | 442/910 [3:16:27<3:25:47, 26.38s/it]                                                     {'loss': 0.3973, 'grad_norm': 2.6355342205577394, 'learning_rate': 5.480115129538409e-05, 'epoch': 4.86}
 49%|████▊     | 442/910 [3:16:27<3:25:47, 26.38s/it] 49%|████▊     | 443/910 [3:16:54<3:26:33, 26.54s/it]                                                     {'loss': 0.4494, 'grad_norm': 2.7900205452024203, 'learning_rate': 5.46238493483254e-05, 'epoch': 4.87}
 49%|████▊     | 443/910 [3:16:54<3:26:33, 26.54s/it] 49%|████▉     | 444/910 [3:17:20<3:26:15, 26.56s/it]                                                     {'loss': 0.3914, 'grad_norm': 0.9513671407884806, 'learning_rate': 5.444648873806101e-05, 'epoch': 4.88}
 49%|████▉     | 444/910 [3:17:20<3:26:15, 26.56s/it] 49%|████▉     | 445/910 [3:17:47<3:26:15, 26.61s/it]                                                     {'loss': 0.3618, 'grad_norm': 0.575387825544262, 'learning_rate': 5.426907171478143e-05, 'epoch': 4.89}
 49%|████▉     | 445/910 [3:17:47<3:26:15, 26.61s/it] 49%|████▉     | 446/910 [3:18:14<3:25:47, 26.61s/it]                                                     {'loss': 0.511, 'grad_norm': 0.7415042816926019, 'learning_rate': 5.409160052939292e-05, 'epoch': 4.9}
 49%|████▉     | 446/910 [3:18:14<3:25:47, 26.61s/it] 49%|████▉     | 447/910 [3:18:40<3:25:24, 26.62s/it]                                                     {'loss': 0.4332, 'grad_norm': 0.7213882470024536, 'learning_rate': 5.391407743348884e-05, 'epoch': 4.91}
 49%|████▉     | 447/910 [3:18:40<3:25:24, 26.62s/it] 49%|████▉     | 448/910 [3:19:07<3:24:53, 26.61s/it]                                                     {'loss': 0.3078, 'grad_norm': 0.5373345513682425, 'learning_rate': 5.373650467932122e-05, 'epoch': 4.92}
 49%|████▉     | 448/910 [3:19:07<3:24:53, 26.61s/it] 49%|████▉     | 449/910 [3:19:33<3:23:41, 26.51s/it]                                                     {'loss': 0.4132, 'grad_norm': 1.1503739796910375, 'learning_rate': 5.355888451977203e-05, 'epoch': 4.93}
 49%|████▉     | 449/910 [3:19:33<3:23:41, 26.51s/it] 49%|████▉     | 450/910 [3:19:59<3:22:26, 26.41s/it]                                                     {'loss': 0.4128, 'grad_norm': 0.5415737797836614, 'learning_rate': 5.338121920832475e-05, 'epoch': 4.95}
 49%|████▉     | 450/910 [3:19:59<3:22:26, 26.41s/it] 50%|████▉     | 451/910 [3:20:26<3:22:23, 26.46s/it]                                                     {'loss': 0.3546, 'grad_norm': 0.5071614452116423, 'learning_rate': 5.320351099903565e-05, 'epoch': 4.96}
 50%|████▉     | 451/910 [3:20:26<3:22:23, 26.46s/it] 50%|████▉     | 452/910 [3:20:52<3:21:19, 26.37s/it]                                                     {'loss': 0.5472, 'grad_norm': 0.6667452821392564, 'learning_rate': 5.302576214650528e-05, 'epoch': 4.97}
 50%|████▉     | 452/910 [3:20:52<3:21:19, 26.37s/it] 50%|████▉     | 453/910 [3:21:18<3:20:09, 26.28s/it]                                                     {'loss': 0.5266, 'grad_norm': 0.7347106510649036, 'learning_rate': 5.284797490584979e-05, 'epoch': 4.98}
 50%|████▉     | 453/910 [3:21:18<3:20:09, 26.28s/it] 50%|████▉     | 454/910 [3:21:45<3:19:41, 26.28s/it]                                                     {'loss': 0.3902, 'grad_norm': 0.5185608359903677, 'learning_rate': 5.267015153267245e-05, 'epoch': 4.99}
 50%|████▉     | 454/910 [3:21:45<3:19:41, 26.28s/it] 50%|█████     | 455/910 [3:22:12<3:21:42, 26.60s/it]                                                     {'loss': 0.4354, 'grad_norm': 0.9666996338278598, 'learning_rate': 5.249229428303486e-05, 'epoch': 5.0}
 50%|█████     | 455/910 [3:22:12<3:21:42, 26.60s/it] 50%|█████     | 456/910 [3:22:58<4:06:32, 32.58s/it]                                                     {'loss': 0.3729, 'grad_norm': 0.5026617937764737, 'learning_rate': 5.2314405413428456e-05, 'epoch': 5.01}
 50%|█████     | 456/910 [3:22:58<4:06:32, 32.58s/it] 50%|█████     | 457/910 [3:23:25<3:53:01, 30.86s/it]                                                     {'loss': 0.3885, 'grad_norm': 0.9408936425337195, 'learning_rate': 5.213648718074584e-05, 'epoch': 5.02}
 50%|█████     | 457/910 [3:23:25<3:53:01, 30.86s/it] 50%|█████     | 458/910 [3:23:52<3:42:55, 29.59s/it]                                                     {'loss': 0.4022, 'grad_norm': 0.8859230266324389, 'learning_rate': 5.195854184225214e-05, 'epoch': 5.03}
 50%|█████     | 458/910 [3:23:52<3:42:55, 29.59s/it] 50%|█████     | 459/910 [3:24:19<3:36:18, 28.78s/it]                                                     {'loss': 0.382, 'grad_norm': 0.7012914853913489, 'learning_rate': 5.1780571655556356e-05, 'epoch': 5.04}
 50%|█████     | 459/910 [3:24:19<3:36:18, 28.78s/it] 51%|█████     | 460/910 [3:24:45<3:30:49, 28.11s/it]                                                     {'loss': 0.3513, 'grad_norm': 1.193061059246261, 'learning_rate': 5.1602578878582776e-05, 'epoch': 5.05}
 51%|█████     | 460/910 [3:24:45<3:30:49, 28.11s/it] 51%|█████     | 461/910 [3:25:12<3:26:01, 27.53s/it]                                                     {'loss': 0.3664, 'grad_norm': 0.9043164517107565, 'learning_rate': 5.142456576954225e-05, 'epoch': 5.07}
 51%|█████     | 461/910 [3:25:12<3:26:01, 27.53s/it] 51%|█████     | 462/910 [3:25:38<3:22:21, 27.10s/it]                                                     {'loss': 0.4067, 'grad_norm': 0.6773463308405674, 'learning_rate': 5.124653458690365e-05, 'epoch': 5.08}
 51%|█████     | 462/910 [3:25:38<3:22:21, 27.10s/it] 51%|█████     | 463/910 [3:26:04<3:19:38, 26.80s/it]                                                     {'loss': 0.3376, 'grad_norm': 0.7828272141092409, 'learning_rate': 5.1068487589365076e-05, 'epoch': 5.09}
 51%|█████     | 463/910 [3:26:04<3:19:38, 26.80s/it] 51%|█████     | 464/910 [3:26:30<3:17:23, 26.56s/it]                                                     {'loss': 0.4577, 'grad_norm': 0.8522163319332062, 'learning_rate': 5.089042703582533e-05, 'epoch': 5.1}
 51%|█████     | 464/910 [3:26:30<3:17:23, 26.56s/it] 51%|█████     | 465/910 [3:26:56<3:16:16, 26.46s/it]                                                     {'loss': 0.3816, 'grad_norm': 0.6055996025522987, 'learning_rate': 5.0712355185355166e-05, 'epoch': 5.11}
 51%|█████     | 465/910 [3:26:56<3:16:16, 26.46s/it] 51%|█████     | 466/910 [3:27:22<3:15:51, 26.47s/it]                                                     {'loss': 0.3998, 'grad_norm': 0.5556293853170391, 'learning_rate': 5.053427429716867e-05, 'epoch': 5.12}
 51%|█████     | 466/910 [3:27:22<3:15:51, 26.47s/it] 51%|█████▏    | 467/910 [3:27:49<3:15:26, 26.47s/it]                                                     {'loss': 0.4401, 'grad_norm': 0.5732850540352642, 'learning_rate': 5.035618663059458e-05, 'epoch': 5.13}
 51%|█████▏    | 467/910 [3:27:49<3:15:26, 26.47s/it] 51%|█████▏    | 468/910 [3:28:15<3:14:51, 26.45s/it]                                                     {'loss': 0.399, 'grad_norm': 0.6690035742483939, 'learning_rate': 5.0178094445047675e-05, 'epoch': 5.14}
 51%|█████▏    | 468/910 [3:28:15<3:14:51, 26.45s/it] 52%|█████▏    | 469/910 [3:28:42<3:15:38, 26.62s/it]                                                     {'loss': 0.35, 'grad_norm': 0.7349800791835458, 'learning_rate': 5e-05, 'epoch': 5.15}
 52%|█████▏    | 469/910 [3:28:42<3:15:38, 26.62s/it] 52%|█████▏    | 470/910 [3:29:09<3:15:07, 26.61s/it]                                                     {'loss': 0.3645, 'grad_norm': 0.5792881366833131, 'learning_rate': 4.982190555495235e-05, 'epoch': 5.16}
 52%|█████▏    | 470/910 [3:29:09<3:15:07, 26.61s/it] 52%|█████▏    | 471/910 [3:29:36<3:15:10, 26.67s/it]                                                     {'loss': 0.4442, 'grad_norm': 1.4049229648563257, 'learning_rate': 4.964381336940542e-05, 'epoch': 5.18}
 52%|█████▏    | 471/910 [3:29:36<3:15:10, 26.67s/it] 52%|█████▏    | 472/910 [3:30:02<3:14:25, 26.63s/it]                                                     {'loss': 0.5118, 'grad_norm': 1.6120679919716738, 'learning_rate': 4.9465725702831346e-05, 'epoch': 5.19}
 52%|█████▏    | 472/910 [3:30:02<3:14:25, 26.63s/it] 52%|█████▏    | 473/910 [3:30:29<3:14:24, 26.69s/it]                                                     {'loss': 0.4286, 'grad_norm': 1.4386084802932702, 'learning_rate': 4.928764481464485e-05, 'epoch': 5.2}
 52%|█████▏    | 473/910 [3:30:29<3:14:24, 26.69s/it] 52%|█████▏    | 474/910 [3:30:55<3:13:10, 26.58s/it]                                                     {'loss': 0.3687, 'grad_norm': 1.4321723165226206, 'learning_rate': 4.9109572964174675e-05, 'epoch': 5.21}
 52%|█████▏    | 474/910 [3:30:55<3:13:10, 26.58s/it] 52%|█████▏    | 475/910 [3:31:22<3:11:53, 26.47s/it]                                                     {'loss': 0.3661, 'grad_norm': 0.7158371862270295, 'learning_rate': 4.893151241063493e-05, 'epoch': 5.22}
 52%|█████▏    | 475/910 [3:31:22<3:11:53, 26.47s/it] 52%|█████▏    | 476/910 [3:31:48<3:10:49, 26.38s/it]                                                     {'loss': 0.3501, 'grad_norm': 1.4836941041537122, 'learning_rate': 4.875346541309637e-05, 'epoch': 5.23}
 52%|█████▏    | 476/910 [3:31:48<3:10:49, 26.38s/it] 52%|█████▏    | 477/910 [3:32:14<3:09:41, 26.29s/it]                                                     {'loss': 0.4057, 'grad_norm': 0.7822690356308855, 'learning_rate': 4.8575434230457745e-05, 'epoch': 5.24}
 52%|█████▏    | 477/910 [3:32:14<3:09:41, 26.29s/it] 53%|█████▎    | 478/910 [3:32:40<3:08:55, 26.24s/it]                                                     {'loss': 0.4092, 'grad_norm': 0.9830288741124196, 'learning_rate': 4.839742112141724e-05, 'epoch': 5.25}
 53%|█████▎    | 478/910 [3:32:40<3:08:55, 26.24s/it] 53%|█████▎    | 479/910 [3:33:06<3:08:23, 26.23s/it]                                                     {'loss': 0.424, 'grad_norm': 1.1040801604748498, 'learning_rate': 4.821942834444366e-05, 'epoch': 5.26}
 53%|█████▎    | 479/910 [3:33:06<3:08:23, 26.23s/it] 53%|█████▎    | 480/910 [3:33:32<3:07:55, 26.22s/it]                                                     {'loss': 0.4057, 'grad_norm': 0.829308659532588, 'learning_rate': 4.804145815774787e-05, 'epoch': 5.27}
 53%|█████▎    | 480/910 [3:33:32<3:07:55, 26.22s/it] 53%|█████▎    | 481/910 [3:33:59<3:08:52, 26.42s/it]                                                     {'loss': 0.4042, 'grad_norm': 0.8882191113137673, 'learning_rate': 4.786351281925417e-05, 'epoch': 5.29}
 53%|█████▎    | 481/910 [3:33:59<3:08:52, 26.42s/it] 53%|█████▎    | 482/910 [3:34:26<3:09:09, 26.52s/it]                                                     {'loss': 0.3628, 'grad_norm': 1.1080078458663964, 'learning_rate': 4.7685594586571556e-05, 'epoch': 5.3}
 53%|█████▎    | 482/910 [3:34:26<3:09:09, 26.52s/it] 53%|█████▎    | 483/910 [3:34:53<3:09:55, 26.69s/it]                                                     {'loss': 0.4839, 'grad_norm': 0.9190945489538638, 'learning_rate': 4.750770571696514e-05, 'epoch': 5.31}
 53%|█████▎    | 483/910 [3:34:53<3:09:55, 26.69s/it] 53%|█████▎    | 484/910 [3:35:20<3:09:04, 26.63s/it]                                                     {'loss': 0.3725, 'grad_norm': 0.6009585921771233, 'learning_rate': 4.732984846732755e-05, 'epoch': 5.32}
 53%|█████▎    | 484/910 [3:35:20<3:09:04, 26.63s/it] 53%|█████▎    | 485/910 [3:35:46<3:08:52, 26.66s/it]                                                     {'loss': 0.437, 'grad_norm': 0.9048702601668949, 'learning_rate': 4.715202509415021e-05, 'epoch': 5.33}
 53%|█████▎    | 485/910 [3:35:46<3:08:52, 26.66s/it] 53%|█████▎    | 486/910 [3:36:14<3:09:32, 26.82s/it]                                                     {'loss': 0.4083, 'grad_norm': 1.261387228307249, 'learning_rate': 4.697423785349475e-05, 'epoch': 5.34}
 53%|█████▎    | 486/910 [3:36:14<3:09:32, 26.82s/it] 54%|█████▎    | 487/910 [3:36:40<3:07:49, 26.64s/it]                                                     {'loss': 0.3648, 'grad_norm': 2.3779708795804266, 'learning_rate': 4.679648900096436e-05, 'epoch': 5.35}
 54%|█████▎    | 487/910 [3:36:40<3:07:49, 26.64s/it] 54%|█████▎    | 488/910 [3:37:06<3:06:59, 26.59s/it]                                                     {'loss': 0.4405, 'grad_norm': 0.5687557526151452, 'learning_rate': 4.6618780791675265e-05, 'epoch': 5.36}
 54%|█████▎    | 488/910 [3:37:06<3:06:59, 26.59s/it] 54%|█████▎    | 489/910 [3:37:32<3:05:41, 26.47s/it]                                                     {'loss': 0.4003, 'grad_norm': 0.7724679581521968, 'learning_rate': 4.644111548022798e-05, 'epoch': 5.37}
 54%|█████▎    | 489/910 [3:37:32<3:05:41, 26.47s/it] 54%|█████▍    | 490/910 [3:37:59<3:04:31, 26.36s/it]                                                     {'loss': 0.3816, 'grad_norm': 0.9136528620521577, 'learning_rate': 4.626349532067879e-05, 'epoch': 5.38}
 54%|█████▍    | 490/910 [3:37:59<3:04:31, 26.36s/it] 54%|█████▍    | 491/910 [3:38:25<3:04:13, 26.38s/it]                                                     {'loss': 0.3821, 'grad_norm': 0.49995016027193867, 'learning_rate': 4.608592256651117e-05, 'epoch': 5.4}
 54%|█████▍    | 491/910 [3:38:25<3:04:13, 26.38s/it] 54%|█████▍    | 492/910 [3:38:51<3:03:13, 26.30s/it]                                                     {'loss': 0.347, 'grad_norm': 1.9913501219263512, 'learning_rate': 4.590839947060711e-05, 'epoch': 5.41}
 54%|█████▍    | 492/910 [3:38:51<3:03:13, 26.30s/it] 54%|█████▍    | 493/910 [3:39:17<3:02:50, 26.31s/it]                                                     {'loss': 0.4216, 'grad_norm': 2.060771301489962, 'learning_rate': 4.5730928285218575e-05, 'epoch': 5.42}
 54%|█████▍    | 493/910 [3:39:17<3:02:50, 26.31s/it] 54%|█████▍    | 494/910 [3:39:44<3:02:59, 26.39s/it]                                                     {'loss': 0.3627, 'grad_norm': 0.6416878426854191, 'learning_rate': 4.5553511261939e-05, 'epoch': 5.43}
 54%|█████▍    | 494/910 [3:39:44<3:02:59, 26.39s/it] 54%|█████▍    | 495/910 [3:40:11<3:03:05, 26.47s/it]                                                     {'loss': 0.3123, 'grad_norm': 0.5773410695088632, 'learning_rate': 4.5376150651674614e-05, 'epoch': 5.44}
 54%|█████▍    | 495/910 [3:40:11<3:03:05, 26.47s/it] 55%|█████▍    | 496/910 [3:40:37<3:02:54, 26.51s/it]                                                     {'loss': 0.3514, 'grad_norm': 0.5111754053660545, 'learning_rate': 4.5198848704615914e-05, 'epoch': 5.45}
 55%|█████▍    | 496/910 [3:40:37<3:02:54, 26.51s/it] 55%|█████▍    | 497/910 [3:41:04<3:02:14, 26.48s/it]                                                     {'loss': 0.3508, 'grad_norm': 0.6924842381439296, 'learning_rate': 4.502160767020918e-05, 'epoch': 5.46}
 55%|█████▍    | 497/910 [3:41:04<3:02:14, 26.48s/it] 55%|█████▍    | 498/910 [3:41:30<3:01:56, 26.50s/it]                                                     {'loss': 0.4, 'grad_norm': 0.6768969400766266, 'learning_rate': 4.484442979712783e-05, 'epoch': 5.47}
 55%|█████▍    | 498/910 [3:41:30<3:01:56, 26.50s/it] 55%|█████▍    | 499/910 [3:41:57<3:01:51, 26.55s/it]                                                     {'loss': 0.4278, 'grad_norm': 0.8150735398781773, 'learning_rate': 4.466731733324399e-05, 'epoch': 5.48}
 55%|█████▍    | 499/910 [3:41:57<3:01:51, 26.55s/it] 55%|█████▍    | 500/910 [3:42:24<3:02:13, 26.67s/it]                                                     {'loss': 0.3644, 'grad_norm': 0.7919160834550544, 'learning_rate': 4.449027252559994e-05, 'epoch': 5.49}
 55%|█████▍    | 500/910 [3:42:24<3:02:13, 26.67s/it] 55%|█████▌    | 501/910 [3:42:50<3:00:36, 26.49s/it]                                                     {'loss': 0.3496, 'grad_norm': 0.8001733434376979, 'learning_rate': 4.4313297620379575e-05, 'epoch': 5.51}
 55%|█████▌    | 501/910 [3:42:50<3:00:36, 26.49s/it] 55%|█████▌    | 502/910 [3:43:16<2:59:23, 26.38s/it]                                                     {'loss': 0.3811, 'grad_norm': 0.5784980542862396, 'learning_rate': 4.4136394862879914e-05, 'epoch': 5.52}
 55%|█████▌    | 502/910 [3:43:16<2:59:23, 26.38s/it] 55%|█████▌    | 503/910 [3:43:42<2:58:36, 26.33s/it]                                                     {'loss': 0.4157, 'grad_norm': 0.9079664121926071, 'learning_rate': 4.395956649748268e-05, 'epoch': 5.53}
 55%|█████▌    | 503/910 [3:43:42<2:58:36, 26.33s/it] 55%|█████▌    | 504/910 [3:44:09<2:58:37, 26.40s/it]                                                     {'loss': 0.3901, 'grad_norm': 0.5445454093784006, 'learning_rate': 4.378281476762576e-05, 'epoch': 5.54}
 55%|█████▌    | 504/910 [3:44:09<2:58:37, 26.40s/it] 55%|█████▌    | 505/910 [3:44:35<2:57:58, 26.37s/it]                                                     {'loss': 0.4478, 'grad_norm': 1.626219905971137, 'learning_rate': 4.3606141915774693e-05, 'epoch': 5.55}
 55%|█████▌    | 505/910 [3:44:35<2:57:58, 26.37s/it] 56%|█████▌    | 506/910 [3:45:01<2:57:14, 26.32s/it]                                                     {'loss': 0.3972, 'grad_norm': 0.7881358967757068, 'learning_rate': 4.3429550183394415e-05, 'epoch': 5.56}
 56%|█████▌    | 506/910 [3:45:01<2:57:14, 26.32s/it] 56%|█████▌    | 507/910 [3:45:28<2:56:57, 26.35s/it]                                                     {'loss': 0.4005, 'grad_norm': 0.5141417284147676, 'learning_rate': 4.325304181092059e-05, 'epoch': 5.57}
 56%|█████▌    | 507/910 [3:45:28<2:56:57, 26.35s/it] 56%|█████▌    | 508/910 [3:45:54<2:57:03, 26.43s/it]                                                     {'loss': 0.3675, 'grad_norm': 1.458159086736607, 'learning_rate': 4.307661903773129e-05, 'epoch': 5.58}
 56%|█████▌    | 508/910 [3:45:54<2:57:03, 26.43s/it] 56%|█████▌    | 509/910 [3:46:21<2:56:49, 26.46s/it]                                                     {'loss': 0.3739, 'grad_norm': 1.2172959626839228, 'learning_rate': 4.290028410211866e-05, 'epoch': 5.59}
 56%|█████▌    | 509/910 [3:46:21<2:56:49, 26.46s/it] 56%|█████▌    | 510/910 [3:46:48<2:56:57, 26.54s/it]                                                     {'loss': 0.3767, 'grad_norm': 0.7185026412650094, 'learning_rate': 4.272403924126035e-05, 'epoch': 5.6}
 56%|█████▌    | 510/910 [3:46:48<2:56:57, 26.54s/it] 56%|█████▌    | 511/910 [3:47:14<2:56:46, 26.58s/it]                                                     {'loss': 0.3833, 'grad_norm': 0.747005741964564, 'learning_rate': 4.254788669119127e-05, 'epoch': 5.62}
 56%|█████▌    | 511/910 [3:47:14<2:56:46, 26.58s/it] 56%|█████▋    | 512/910 [3:47:41<2:56:32, 26.61s/it]                                                     {'loss': 0.4045, 'grad_norm': 0.9971511380843567, 'learning_rate': 4.237182868677519e-05, 'epoch': 5.63}
 56%|█████▋    | 512/910 [3:47:41<2:56:32, 26.61s/it] 56%|█████▋    | 513/910 [3:48:08<2:56:39, 26.70s/it]                                                     {'loss': 0.3373, 'grad_norm': 0.5270019519006858, 'learning_rate': 4.219586746167632e-05, 'epoch': 5.64}
 56%|█████▋    | 513/910 [3:48:08<2:56:39, 26.70s/it] 56%|█████▋    | 514/910 [3:48:34<2:54:53, 26.50s/it]                                                     {'loss': 0.4474, 'grad_norm': 0.7628834776672829, 'learning_rate': 4.2020005248331054e-05, 'epoch': 5.65}
 56%|█████▋    | 514/910 [3:48:34<2:54:53, 26.50s/it] 57%|█████▋    | 515/910 [3:49:00<2:53:56, 26.42s/it]                                                     {'loss': 0.3694, 'grad_norm': 0.5825141505325324, 'learning_rate': 4.184424427791959e-05, 'epoch': 5.66}
 57%|█████▋    | 515/910 [3:49:00<2:53:56, 26.42s/it] 57%|█████▋    | 516/910 [3:49:26<2:53:01, 26.35s/it]                                                     {'loss': 0.3905, 'grad_norm': 0.8291808249153686, 'learning_rate': 4.166858678033771e-05, 'epoch': 5.67}
 57%|█████▋    | 516/910 [3:49:26<2:53:01, 26.35s/it] 57%|█████▋    | 517/910 [3:49:52<2:52:17, 26.30s/it]                                                     {'loss': 0.4208, 'grad_norm': 0.9135109930897266, 'learning_rate': 4.149303498416838e-05, 'epoch': 5.68}
 57%|█████▋    | 517/910 [3:49:52<2:52:17, 26.30s/it] 57%|█████▋    | 518/910 [3:50:18<2:51:03, 26.18s/it]                                                     {'loss': 0.4156, 'grad_norm': 0.6967459294412954, 'learning_rate': 4.131759111665349e-05, 'epoch': 5.69}
 57%|█████▋    | 518/910 [3:50:18<2:51:03, 26.18s/it] 57%|█████▋    | 519/910 [3:50:45<2:50:37, 26.18s/it]                                                     {'loss': 0.4595, 'grad_norm': 1.529888324369831, 'learning_rate': 4.114225740366569e-05, 'epoch': 5.7}
 57%|█████▋    | 519/910 [3:50:45<2:50:37, 26.18s/it] 57%|█████▋    | 520/910 [3:51:11<2:50:32, 26.24s/it]                                                     {'loss': 0.3814, 'grad_norm': 0.7780204712627984, 'learning_rate': 4.096703606968006e-05, 'epoch': 5.71}
 57%|█████▋    | 520/910 [3:51:11<2:50:32, 26.24s/it] 57%|█████▋    | 521/910 [3:51:38<2:51:16, 26.42s/it]                                                     {'loss': 0.359, 'grad_norm': 1.311894552642637, 'learning_rate': 4.0791929337745915e-05, 'epoch': 5.73}
 57%|█████▋    | 521/910 [3:51:38<2:51:16, 26.42s/it] 57%|█████▋    | 522/910 [3:52:04<2:50:58, 26.44s/it]                                                     {'loss': 0.3465, 'grad_norm': 1.0456644163288702, 'learning_rate': 4.061693942945863e-05, 'epoch': 5.74}
 57%|█████▋    | 522/910 [3:52:04<2:50:58, 26.44s/it] 57%|█████▋    | 523/910 [3:52:31<2:51:06, 26.53s/it]                                                     {'loss': 0.4293, 'grad_norm': 2.3222713315288255, 'learning_rate': 4.04420685649314e-05, 'epoch': 5.75}
 57%|█████▋    | 523/910 [3:52:31<2:51:06, 26.53s/it] 58%|█████▊    | 524/910 [3:52:57<2:50:29, 26.50s/it]                                                     {'loss': 0.3896, 'grad_norm': 0.790416105165053, 'learning_rate': 4.026731896276708e-05, 'epoch': 5.76}
 58%|█████▊    | 524/910 [3:52:57<2:50:29, 26.50s/it] 58%|█████▊    | 525/910 [3:53:24<2:50:53, 26.63s/it]                                                     {'loss': 0.3649, 'grad_norm': 0.5354483033000788, 'learning_rate': 4.0092692840030134e-05, 'epoch': 5.77}
 58%|█████▊    | 525/910 [3:53:24<2:50:53, 26.63s/it] 58%|█████▊    | 526/910 [3:53:51<2:50:22, 26.62s/it]                                                     {'loss': 0.4044, 'grad_norm': 0.7546474817597755, 'learning_rate': 3.991819241221835e-05, 'epoch': 5.78}
 58%|█████▊    | 526/910 [3:53:51<2:50:22, 26.62s/it] 58%|█████▊    | 527/910 [3:54:17<2:49:37, 26.57s/it]                                                     {'loss': 0.355, 'grad_norm': 0.665369231441649, 'learning_rate': 3.9743819893234836e-05, 'epoch': 5.79}
 58%|█████▊    | 527/910 [3:54:17<2:49:37, 26.57s/it] 58%|█████▊    | 528/910 [3:54:44<2:48:21, 26.44s/it]                                                     {'loss': 0.4173, 'grad_norm': 0.9765349747913985, 'learning_rate': 3.9569577495359964e-05, 'epoch': 5.8}
 58%|█████▊    | 528/910 [3:54:44<2:48:21, 26.44s/it] 58%|█████▊    | 529/910 [3:55:10<2:48:05, 26.47s/it]                                                     {'loss': 0.5959, 'grad_norm': 2.1047036753264163, 'learning_rate': 3.9395467429223174e-05, 'epoch': 5.81}
 58%|█████▊    | 529/910 [3:55:10<2:48:05, 26.47s/it] 58%|█████▊    | 530/910 [3:55:36<2:47:07, 26.39s/it]                                                     {'loss': 0.3619, 'grad_norm': 0.4427951793678545, 'learning_rate': 3.922149190377501e-05, 'epoch': 5.82}
 58%|█████▊    | 530/910 [3:55:36<2:47:07, 26.39s/it] 58%|█████▊    | 531/910 [3:56:02<2:46:15, 26.32s/it]                                                     {'loss': 0.3793, 'grad_norm': 0.8683709947976641, 'learning_rate': 3.904765312625916e-05, 'epoch': 5.84}
 58%|█████▊    | 531/910 [3:56:02<2:46:15, 26.32s/it] 58%|█████▊    | 532/910 [3:56:29<2:45:30, 26.27s/it]                                                     {'loss': 0.4171, 'grad_norm': 8.046454011939812, 'learning_rate': 3.887395330218429e-05, 'epoch': 5.85}
 58%|█████▊    | 532/910 [3:56:29<2:45:30, 26.27s/it] 59%|█████▊    | 533/910 [3:56:55<2:45:01, 26.26s/it]                                                     {'loss': 0.3888, 'grad_norm': 0.6368686166007934, 'learning_rate': 3.870039463529617e-05, 'epoch': 5.86}
 59%|█████▊    | 533/910 [3:56:55<2:45:01, 26.26s/it] 59%|█████▊    | 534/910 [3:57:21<2:45:06, 26.35s/it]                                                     {'loss': 0.3896, 'grad_norm': 0.6098967786471761, 'learning_rate': 3.8526979327549736e-05, 'epoch': 5.87}
 59%|█████▊    | 534/910 [3:57:21<2:45:06, 26.35s/it] 59%|█████▉    | 535/910 [3:57:48<2:45:10, 26.43s/it]                                                     {'loss': 0.3919, 'grad_norm': 0.8713251037485963, 'learning_rate': 3.8353709579081084e-05, 'epoch': 5.88}
 59%|█████▉    | 535/910 [3:57:48<2:45:10, 26.43s/it] 59%|█████▉    | 536/910 [3:58:14<2:44:46, 26.44s/it]                                                     {'loss': 0.3521, 'grad_norm': 0.5689684143565853, 'learning_rate': 3.818058758817956e-05, 'epoch': 5.89}
 59%|█████▉    | 536/910 [3:58:14<2:44:46, 26.44s/it] 59%|█████▉    | 537/910 [3:58:41<2:44:33, 26.47s/it]                                                     {'loss': 0.3835, 'grad_norm': 0.8075199593317478, 'learning_rate': 3.8007615551259965e-05, 'epoch': 5.9}
 59%|█████▉    | 537/910 [3:58:41<2:44:33, 26.47s/it] 59%|█████▉    | 538/910 [3:59:08<2:44:31, 26.54s/it]                                                     {'loss': 0.3636, 'grad_norm': 0.5823076431348401, 'learning_rate': 3.783479566283457e-05, 'epoch': 5.91}
 59%|█████▉    | 538/910 [3:59:08<2:44:31, 26.54s/it] 59%|█████▉    | 539/910 [3:59:35<2:44:34, 26.62s/it]                                                     {'loss': 0.3895, 'grad_norm': 0.90897495065224, 'learning_rate': 3.7662130115485314e-05, 'epoch': 5.92}
 59%|█████▉    | 539/910 [3:59:35<2:44:34, 26.62s/it] 59%|█████▉    | 540/910 [4:00:01<2:44:26, 26.67s/it]                                                     {'loss': 0.3944, 'grad_norm': 0.6127874033721599, 'learning_rate': 3.7489621099836045e-05, 'epoch': 5.93}
 59%|█████▉    | 540/910 [4:00:01<2:44:26, 26.67s/it] 59%|█████▉    | 541/910 [4:00:28<2:43:11, 26.53s/it]                                                     {'loss': 0.4224, 'grad_norm': 0.5801929386398333, 'learning_rate': 3.731727080452464e-05, 'epoch': 5.95}
 59%|█████▉    | 541/910 [4:00:28<2:43:11, 26.53s/it] 60%|█████▉    | 542/910 [4:00:54<2:42:23, 26.48s/it]                                                     {'loss': 0.3656, 'grad_norm': 0.6039193309485357, 'learning_rate': 3.7145081416175265e-05, 'epoch': 5.96}
 60%|█████▉    | 542/910 [4:00:54<2:42:23, 26.48s/it] 60%|█████▉    | 543/910 [4:01:20<2:41:05, 26.34s/it]                                                     {'loss': 0.3662, 'grad_norm': 0.812836554192295, 'learning_rate': 3.69730551193707e-05, 'epoch': 5.97}
 60%|█████▉    | 543/910 [4:01:20<2:41:05, 26.34s/it] 60%|█████▉    | 544/910 [4:01:46<2:40:36, 26.33s/it]                                                     {'loss': 0.3621, 'grad_norm': 1.1731032603713907, 'learning_rate': 3.680119409662452e-05, 'epoch': 5.98}
 60%|█████▉    | 544/910 [4:01:46<2:40:36, 26.33s/it] 60%|█████▉    | 545/910 [4:02:12<2:39:49, 26.27s/it]                                                     {'loss': 0.5134, 'grad_norm': 3.431491861472384, 'learning_rate': 3.662950052835346e-05, 'epoch': 5.99}
 60%|█████▉    | 545/910 [4:02:12<2:39:49, 26.27s/it] 60%|██████    | 546/910 [4:02:41<2:43:00, 26.87s/it]                                                     {'loss': 0.3744, 'grad_norm': 1.4824829211516217, 'learning_rate': 3.6457976592849754e-05, 'epoch': 6.0}
 60%|██████    | 546/910 [4:02:41<2:43:00, 26.87s/it] 60%|██████    | 547/910 [4:03:25<3:14:53, 32.21s/it]                                                     {'loss': 0.3895, 'grad_norm': 0.6096361242021139, 'learning_rate': 3.628662446625349e-05, 'epoch': 6.01}
 60%|██████    | 547/910 [4:03:25<3:14:53, 32.21s/it] 60%|██████    | 548/910 [4:03:52<3:04:05, 30.51s/it]                                                     {'loss': 0.3616, 'grad_norm': 0.5412543457854829, 'learning_rate': 3.6115446322525e-05, 'epoch': 6.02}
 60%|██████    | 548/910 [4:03:52<3:04:05, 30.51s/it] 60%|██████    | 549/910 [4:04:18<2:56:34, 29.35s/it]                                                     {'loss': 0.3646, 'grad_norm': 0.848576625842396, 'learning_rate': 3.594444433341725e-05, 'epoch': 6.03}
 60%|██████    | 549/910 [4:04:18<2:56:34, 29.35s/it] 60%|██████    | 550/910 [4:04:45<2:50:57, 28.49s/it]                                                     {'loss': 0.4528, 'grad_norm': 0.6213676211206236, 'learning_rate': 3.5773620668448384e-05, 'epoch': 6.04}
 60%|██████    | 550/910 [4:04:45<2:50:57, 28.49s/it] 61%|██████    | 551/910 [4:05:12<2:47:17, 27.96s/it]                                                     {'loss': 0.4016, 'grad_norm': 0.7628261340664241, 'learning_rate': 3.560297749487407e-05, 'epoch': 6.05}
 61%|██████    | 551/910 [4:05:12<2:47:17, 27.96s/it] 61%|██████    | 552/910 [4:05:38<2:44:44, 27.61s/it]                                                     {'loss': 0.4462, 'grad_norm': 1.578852732365049, 'learning_rate': 3.543251697766006e-05, 'epoch': 6.07}
 61%|██████    | 552/910 [4:05:38<2:44:44, 27.61s/it] 61%|██████    | 553/910 [4:06:05<2:41:41, 27.17s/it]                                                     {'loss': 0.4206, 'grad_norm': 1.017665643917283, 'learning_rate': 3.5262241279454785e-05, 'epoch': 6.08}
 61%|██████    | 553/910 [4:06:05<2:41:41, 27.17s/it] 61%|██████    | 554/910 [4:06:31<2:39:08, 26.82s/it]                                                     {'loss': 0.4014, 'grad_norm': 0.6014842647750867, 'learning_rate': 3.509215256056183e-05, 'epoch': 6.09}
 61%|██████    | 554/910 [4:06:31<2:39:08, 26.82s/it] 61%|██████    | 555/910 [4:06:57<2:37:40, 26.65s/it]                                                     {'loss': 0.4159, 'grad_norm': 1.254639634613203, 'learning_rate': 3.4922252978912526e-05, 'epoch': 6.1}
 61%|██████    | 555/910 [4:06:57<2:37:40, 26.65s/it] 61%|██████    | 556/910 [4:07:23<2:36:56, 26.60s/it]                                                     {'loss': 0.4653, 'grad_norm': 0.9201264007439526, 'learning_rate': 3.4752544690038647e-05, 'epoch': 6.11}
 61%|██████    | 556/910 [4:07:23<2:36:56, 26.60s/it] 61%|██████    | 557/910 [4:07:50<2:35:47, 26.48s/it]                                                     {'loss': 0.3544, 'grad_norm': 0.9420958322745513, 'learning_rate': 3.458302984704499e-05, 'epoch': 6.12}
 61%|██████    | 557/910 [4:07:50<2:35:47, 26.48s/it] 61%|██████▏   | 558/910 [4:08:16<2:34:47, 26.38s/it]                                                     {'loss': 0.395, 'grad_norm': 1.1583419011636586, 'learning_rate': 3.44137106005821e-05, 'epoch': 6.13}
 61%|██████▏   | 558/910 [4:08:16<2:34:47, 26.38s/it] 61%|██████▏   | 559/910 [4:08:42<2:34:12, 26.36s/it]                                                     {'loss': 0.4215, 'grad_norm': 0.622762558431272, 'learning_rate': 3.424458909881897e-05, 'epoch': 6.14}
 61%|██████▏   | 559/910 [4:08:42<2:34:12, 26.36s/it] 62%|██████▏   | 560/910 [4:09:09<2:34:22, 26.46s/it]                                                     {'loss': 0.2877, 'grad_norm': 0.5970529175602796, 'learning_rate': 3.4075667487415785e-05, 'epoch': 6.15}
 62%|██████▏   | 560/910 [4:09:09<2:34:22, 26.46s/it] 62%|██████▏   | 561/910 [4:09:35<2:33:59, 26.48s/it]                                                     {'loss': 0.4195, 'grad_norm': 1.348481383212787, 'learning_rate': 3.3906947909496695e-05, 'epoch': 6.16}
 62%|██████▏   | 561/910 [4:09:35<2:33:59, 26.48s/it] 62%|██████▏   | 562/910 [4:10:02<2:33:44, 26.51s/it]                                                     {'loss': 0.3306, 'grad_norm': 0.7445583682522935, 'learning_rate': 3.373843250562265e-05, 'epoch': 6.18}
 62%|██████▏   | 562/910 [4:10:02<2:33:44, 26.51s/it] 62%|██████▏   | 563/910 [4:10:29<2:33:58, 26.62s/it]                                                     {'loss': 0.4037, 'grad_norm': 1.500117743554879, 'learning_rate': 3.357012341376421e-05, 'epoch': 6.19}
 62%|██████▏   | 563/910 [4:10:29<2:33:58, 26.62s/it] 62%|██████▏   | 564/910 [4:10:55<2:33:28, 26.62s/it]                                                     {'loss': 0.4035, 'grad_norm': 1.5359617729447348, 'learning_rate': 3.3402022769274425e-05, 'epoch': 6.2}
 62%|██████▏   | 564/910 [4:10:55<2:33:28, 26.62s/it] 62%|██████▏   | 565/910 [4:11:22<2:33:53, 26.76s/it]                                                     {'loss': 0.307, 'grad_norm': 0.5524469352177057, 'learning_rate': 3.323413270486179e-05, 'epoch': 6.21}
 62%|██████▏   | 565/910 [4:11:22<2:33:53, 26.76s/it] 62%|██████▏   | 566/910 [4:11:49<2:32:18, 26.57s/it]                                                     {'loss': 0.403, 'grad_norm': 0.5665711315682433, 'learning_rate': 3.306645535056312e-05, 'epoch': 6.22}
 62%|██████▏   | 566/910 [4:11:49<2:32:18, 26.57s/it] 62%|██████▏   | 567/910 [4:12:15<2:31:17, 26.46s/it]                                                     {'loss': 0.3869, 'grad_norm': 0.6503480113034036, 'learning_rate': 3.289899283371657e-05, 'epoch': 6.23}
 62%|██████▏   | 567/910 [4:12:15<2:31:17, 26.46s/it] 62%|██████▏   | 568/910 [4:12:41<2:30:31, 26.41s/it]                                                     {'loss': 0.4126, 'grad_norm': 0.8191876541089286, 'learning_rate': 3.273174727893463e-05, 'epoch': 6.24}
 62%|██████▏   | 568/910 [4:12:41<2:30:31, 26.41s/it] 63%|██████▎   | 569/910 [4:13:07<2:30:00, 26.39s/it]                                                     {'loss': 0.4181, 'grad_norm': 0.6742109028982511, 'learning_rate': 3.256472080807716e-05, 'epoch': 6.25}
 63%|██████▎   | 569/910 [4:13:07<2:30:00, 26.39s/it] 63%|██████▎   | 570/910 [4:13:34<2:29:36, 26.40s/it]                                                     {'loss': 0.4071, 'grad_norm': 0.7076000198445814, 'learning_rate': 3.239791554022449e-05, 'epoch': 6.26}
 63%|██████▎   | 570/910 [4:13:34<2:29:36, 26.40s/it] 63%|██████▎   | 571/910 [4:14:00<2:28:52, 26.35s/it]                                                     {'loss': 0.4459, 'grad_norm': 1.2167231424123275, 'learning_rate': 3.223133359165056e-05, 'epoch': 6.27}
 63%|██████▎   | 571/910 [4:14:00<2:28:52, 26.35s/it] 63%|██████▎   | 572/910 [4:14:26<2:28:20, 26.33s/it]                                                     {'loss': 0.4776, 'grad_norm': 1.268739451642009, 'learning_rate': 3.206497707579599e-05, 'epoch': 6.29}
 63%|██████▎   | 572/910 [4:14:26<2:28:20, 26.33s/it] 63%|██████▎   | 573/910 [4:14:53<2:28:18, 26.40s/it]                                                     {'loss': 0.3607, 'grad_norm': 0.5719753211530584, 'learning_rate': 3.189884810324133e-05, 'epoch': 6.3}
 63%|██████▎   | 573/910 [4:14:53<2:28:18, 26.40s/it] 63%|██████▎   | 574/910 [4:15:19<2:27:53, 26.41s/it]                                                     {'loss': 0.3767, 'grad_norm': 5.273911904734989, 'learning_rate': 3.173294878168025e-05, 'epoch': 6.31}
 63%|██████▎   | 574/910 [4:15:19<2:27:53, 26.41s/it] 63%|██████▎   | 575/910 [4:15:46<2:28:15, 26.55s/it]                                                     {'loss': 0.3722, 'grad_norm': 1.483947415693908, 'learning_rate': 3.156728121589287e-05, 'epoch': 6.32}
 63%|██████▎   | 575/910 [4:15:46<2:28:15, 26.55s/it] 63%|██████▎   | 576/910 [4:16:13<2:27:46, 26.55s/it]                                                     {'loss': 0.4077, 'grad_norm': 0.5313556634014102, 'learning_rate': 3.140184750771895e-05, 'epoch': 6.33}
 63%|██████▎   | 576/910 [4:16:13<2:27:46, 26.55s/it] 63%|██████▎   | 577/910 [4:16:39<2:27:24, 26.56s/it]                                                     {'loss': 0.359, 'grad_norm': 0.7074777101374189, 'learning_rate': 3.12366497560313e-05, 'epoch': 6.34}
 63%|██████▎   | 577/910 [4:16:39<2:27:24, 26.56s/it] 64%|██████▎   | 578/910 [4:17:06<2:27:13, 26.61s/it]                                                     {'loss': 0.3911, 'grad_norm': 0.7641873963597989, 'learning_rate': 3.107169005670912e-05, 'epoch': 6.35}
 64%|██████▎   | 578/910 [4:17:06<2:27:13, 26.61s/it] 64%|██████▎   | 579/910 [4:17:33<2:26:49, 26.61s/it]                                                     {'loss': 0.3253, 'grad_norm': 2.257224945484902, 'learning_rate': 3.0906970502611426e-05, 'epoch': 6.36}
 64%|██████▎   | 579/910 [4:17:33<2:26:49, 26.61s/it] 64%|██████▎   | 580/910 [4:17:59<2:25:39, 26.48s/it]                                                     {'loss': 0.3865, 'grad_norm': 0.8150695419333857, 'learning_rate': 3.074249318355046e-05, 'epoch': 6.37}
 64%|██████▎   | 580/910 [4:17:59<2:25:39, 26.48s/it] 64%|██████▍   | 581/910 [4:18:25<2:24:16, 26.31s/it]                                                     {'loss': 0.4061, 'grad_norm': 1.3901342045196496, 'learning_rate': 3.0578260186265265e-05, 'epoch': 6.38}
 64%|██████▍   | 581/910 [4:18:25<2:24:16, 26.31s/it] 64%|██████▍   | 582/910 [4:18:51<2:23:34, 26.27s/it]                                                     {'loss': 0.3433, 'grad_norm': 0.9527058259816125, 'learning_rate': 3.0414273594395105e-05, 'epoch': 6.4}
 64%|██████▍   | 582/910 [4:18:51<2:23:34, 26.27s/it] 64%|██████▍   | 583/910 [4:19:17<2:23:18, 26.30s/it]                                                     {'loss': 0.3817, 'grad_norm': 2.6174771804110457, 'learning_rate': 3.0250535488453076e-05, 'epoch': 6.41}
 64%|██████▍   | 583/910 [4:19:17<2:23:18, 26.30s/it] 64%|██████▍   | 584/910 [4:19:44<2:23:02, 26.33s/it]                                                     {'loss': 0.4206, 'grad_norm': 0.8299919040664561, 'learning_rate': 3.008704794579973e-05, 'epoch': 6.42}
 64%|██████▍   | 584/910 [4:19:44<2:23:02, 26.33s/it] 64%|██████▍   | 585/910 [4:20:10<2:22:22, 26.28s/it]                                                     {'loss': 0.4052, 'grad_norm': 1.2912569028322352, 'learning_rate': 2.9923813040616682e-05, 'epoch': 6.43}
 64%|██████▍   | 585/910 [4:20:10<2:22:22, 26.28s/it] 64%|██████▍   | 586/910 [4:20:36<2:22:20, 26.36s/it]                                                     {'loss': 0.3713, 'grad_norm': 1.161573086749301, 'learning_rate': 2.976083284388031e-05, 'epoch': 6.44}
 64%|██████▍   | 586/910 [4:20:36<2:22:20, 26.36s/it] 65%|██████▍   | 587/910 [4:21:03<2:22:37, 26.49s/it]                                                     {'loss': 0.4404, 'grad_norm': 0.9409102040575262, 'learning_rate': 2.959810942333552e-05, 'epoch': 6.45}
 65%|██████▍   | 587/910 [4:21:03<2:22:37, 26.49s/it] 65%|██████▍   | 588/910 [4:21:30<2:22:24, 26.53s/it]                                                     {'loss': 0.3772, 'grad_norm': 0.6927232745346203, 'learning_rate': 2.9435644843469436e-05, 'epoch': 6.46}
 65%|██████▍   | 588/910 [4:21:30<2:22:24, 26.53s/it] 65%|██████▍   | 589/910 [4:21:56<2:22:08, 26.57s/it]                                                     {'loss': 0.3737, 'grad_norm': 0.7562096046223247, 'learning_rate': 2.9273441165485225e-05, 'epoch': 6.47}
 65%|██████▍   | 589/910 [4:21:56<2:22:08, 26.57s/it] 65%|██████▍   | 590/910 [4:22:23<2:22:19, 26.69s/it]                                                     {'loss': 0.3604, 'grad_norm': 0.54471334444378, 'learning_rate': 2.9111500447276053e-05, 'epoch': 6.48}
 65%|██████▍   | 590/910 [4:22:23<2:22:19, 26.69s/it] 65%|██████▍   | 591/910 [4:22:50<2:21:53, 26.69s/it]                                                     {'loss': 0.3306, 'grad_norm': 0.9202366430763398, 'learning_rate': 2.8949824743398802e-05, 'epoch': 6.49}
 65%|██████▍   | 591/910 [4:22:50<2:21:53, 26.69s/it] 65%|██████▌   | 592/910 [4:23:17<2:21:44, 26.75s/it]                                                     {'loss': 0.4465, 'grad_norm': 1.4921134693793543, 'learning_rate': 2.8788416105048122e-05, 'epoch': 6.51}
 65%|██████▌   | 592/910 [4:23:17<2:21:44, 26.75s/it] 65%|██████▌   | 593/910 [4:23:43<2:20:36, 26.61s/it]                                                     {'loss': 0.4035, 'grad_norm': 0.5227519285792164, 'learning_rate': 2.8627276580030423e-05, 'epoch': 6.52}
 65%|██████▌   | 593/910 [4:23:43<2:20:36, 26.61s/it] 65%|██████▌   | 594/910 [4:24:09<2:19:23, 26.47s/it]                                                     {'loss': 0.3657, 'grad_norm': 0.6610413044605451, 'learning_rate': 2.8466408212737777e-05, 'epoch': 6.53}
 65%|██████▌   | 594/910 [4:24:09<2:19:23, 26.47s/it] 65%|██████▌   | 595/910 [4:24:36<2:18:21, 26.35s/it]                                                     {'loss': 0.4137, 'grad_norm': 1.821800940247901, 'learning_rate': 2.8305813044122097e-05, 'epoch': 6.54}
 65%|██████▌   | 595/910 [4:24:36<2:18:21, 26.35s/it] 65%|██████▌   | 596/910 [4:25:01<2:17:18, 26.24s/it]                                                     {'loss': 0.3625, 'grad_norm': 1.0011871328029986, 'learning_rate': 2.8145493111669186e-05, 'epoch': 6.55}
 65%|██████▌   | 596/910 [4:25:02<2:17:18, 26.24s/it] 66%|██████▌   | 597/910 [4:25:28<2:16:32, 26.17s/it]                                                     {'loss': 0.4338, 'grad_norm': 0.6527785307922398, 'learning_rate': 2.79854504493729e-05, 'epoch': 6.56}
 66%|██████▌   | 597/910 [4:25:28<2:16:32, 26.17s/it] 66%|██████▌   | 598/910 [4:25:54<2:16:16, 26.21s/it]                                                     {'loss': 0.3978, 'grad_norm': 0.9304170661114497, 'learning_rate': 2.7825687087709328e-05, 'epoch': 6.57}
 66%|██████▌   | 598/910 [4:25:54<2:16:16, 26.21s/it] 66%|██████▌   | 599/910 [4:26:20<2:16:12, 26.28s/it]                                                     {'loss': 0.3429, 'grad_norm': 0.803368538866052, 'learning_rate': 2.7666205053611094e-05, 'epoch': 6.58}
 66%|██████▌   | 599/910 [4:26:20<2:16:12, 26.28s/it] 66%|██████▌   | 600/910 [4:26:47<2:15:56, 26.31s/it]                                                     {'loss': 0.3603, 'grad_norm': 0.5735372649826628, 'learning_rate': 2.7507006370441558e-05, 'epoch': 6.59}
 66%|██████▌   | 600/910 [4:26:47<2:15:56, 26.31s/it] 66%|██████▌   | 601/910 [4:27:13<2:15:57, 26.40s/it]                                                     {'loss': 0.3952, 'grad_norm': 1.3333575675335791, 'learning_rate': 2.734809305796915e-05, 'epoch': 6.6}
 66%|██████▌   | 601/910 [4:27:13<2:15:57, 26.40s/it] 66%|██████▌   | 602/910 [4:27:40<2:16:28, 26.58s/it]                                                     {'loss': 0.4264, 'grad_norm': 1.2002245259184756, 'learning_rate': 2.718946713234185e-05, 'epoch': 6.62}
 66%|██████▌   | 602/910 [4:27:40<2:16:28, 26.58s/it] 66%|██████▋   | 603/910 [4:28:07<2:16:09, 26.61s/it]                                                     {'loss': 0.3941, 'grad_norm': 1.539800546791808, 'learning_rate': 2.7031130606061484e-05, 'epoch': 6.63}
 66%|██████▋   | 603/910 [4:28:07<2:16:09, 26.61s/it] 66%|██████▋   | 604/910 [4:28:33<2:15:37, 26.59s/it]                                                     {'loss': 0.349, 'grad_norm': 0.7121195057075025, 'learning_rate': 2.687308548795825e-05, 'epoch': 6.64}
 66%|██████▋   | 604/910 [4:28:33<2:15:37, 26.59s/it] 66%|██████▋   | 605/910 [4:29:00<2:15:31, 26.66s/it]                                                     {'loss': 0.4744, 'grad_norm': 1.364678733496107, 'learning_rate': 2.6715333783165198e-05, 'epoch': 6.65}
 66%|██████▋   | 605/910 [4:29:00<2:15:31, 26.66s/it] 67%|██████▋   | 606/910 [4:29:27<2:14:40, 26.58s/it]                                                     {'loss': 0.4382, 'grad_norm': 0.8748013413704062, 'learning_rate': 2.6557877493092887e-05, 'epoch': 6.66}
 67%|██████▋   | 606/910 [4:29:27<2:14:40, 26.58s/it] 67%|██████▋   | 607/910 [4:29:53<2:13:33, 26.45s/it]                                                     {'loss': 0.514, 'grad_norm': 1.0199205391156734, 'learning_rate': 2.640071861540385e-05, 'epoch': 6.67}
 67%|██████▋   | 607/910 [4:29:53<2:13:33, 26.45s/it] 67%|██████▋   | 608/910 [4:30:19<2:12:53, 26.40s/it]                                                     {'loss': 0.3871, 'grad_norm': 0.6369095082886059, 'learning_rate': 2.624385914398737e-05, 'epoch': 6.68}
 67%|██████▋   | 608/910 [4:30:19<2:12:53, 26.40s/it] 67%|██████▋   | 609/910 [4:30:46<2:12:32, 26.42s/it]                                                     {'loss': 0.3573, 'grad_norm': 0.6004585435066646, 'learning_rate': 2.6087301068934106e-05, 'epoch': 6.69}
 67%|██████▋   | 609/910 [4:30:46<2:12:32, 26.42s/it] 67%|██████▋   | 610/910 [4:31:12<2:11:44, 26.35s/it]                                                     {'loss': 0.3432, 'grad_norm': 0.6881859454643576, 'learning_rate': 2.5931046376510877e-05, 'epoch': 6.7}
 67%|██████▋   | 610/910 [4:31:12<2:11:44, 26.35s/it] 67%|██████▋   | 611/910 [4:31:38<2:11:12, 26.33s/it]                                                     {'loss': 0.3891, 'grad_norm': 0.9662855222537388, 'learning_rate': 2.5775097049135445e-05, 'epoch': 6.71}
 67%|██████▋   | 611/910 [4:31:38<2:11:12, 26.33s/it] 67%|██████▋   | 612/910 [4:32:04<2:10:46, 26.33s/it]                                                     {'loss': 0.3812, 'grad_norm': 0.7893217319285138, 'learning_rate': 2.561945506535144e-05, 'epoch': 6.73}
 67%|██████▋   | 612/910 [4:32:04<2:10:46, 26.33s/it] 67%|██████▋   | 613/910 [4:32:31<2:10:42, 26.40s/it]                                                     {'loss': 0.3922, 'grad_norm': 0.7472264533639085, 'learning_rate': 2.5464122399803125e-05, 'epoch': 6.74}
 67%|██████▋   | 613/910 [4:32:31<2:10:42, 26.40s/it] 67%|██████▋   | 614/910 [4:32:57<2:10:15, 26.40s/it]                                                     {'loss': 0.3734, 'grad_norm': 0.7149674467932808, 'learning_rate': 2.5309101023210425e-05, 'epoch': 6.75}
 67%|██████▋   | 614/910 [4:32:57<2:10:15, 26.40s/it] 68%|██████▊   | 615/910 [4:33:24<2:10:12, 26.48s/it]                                                     {'loss': 0.4561, 'grad_norm': 1.1210439565138821, 'learning_rate': 2.5154392902343964e-05, 'epoch': 6.76}
 68%|██████▊   | 615/910 [4:33:24<2:10:12, 26.48s/it] 68%|██████▊   | 616/910 [4:33:50<2:09:40, 26.46s/it]                                                     {'loss': 0.3676, 'grad_norm': 0.9835385177144009, 'learning_rate': 2.500000000000001e-05, 'epoch': 6.77}
 68%|██████▊   | 616/910 [4:33:50<2:09:40, 26.46s/it] 68%|██████▊   | 617/910 [4:34:17<2:09:30, 26.52s/it]                                                     {'loss': 0.4138, 'grad_norm': 0.5731986214793264, 'learning_rate': 2.4845924274975624e-05, 'epoch': 6.78}
 68%|██████▊   | 617/910 [4:34:17<2:09:30, 26.52s/it] 68%|██████▊   | 618/910 [4:34:44<2:09:04, 26.52s/it]                                                     {'loss': 0.3409, 'grad_norm': 0.6404852935091151, 'learning_rate': 2.4692167682043855e-05, 'epoch': 6.79}
 68%|██████▊   | 618/910 [4:34:44<2:09:04, 26.52s/it] 68%|██████▊   | 619/910 [4:35:10<2:08:54, 26.58s/it]                                                     {'loss': 0.3687, 'grad_norm': 0.6493623398433255, 'learning_rate': 2.4538732171928847e-05, 'epoch': 6.8}
 68%|██████▊   | 619/910 [4:35:10<2:08:54, 26.58s/it] 68%|██████▊   | 620/910 [4:35:37<2:08:06, 26.51s/it]                                                     {'loss': 0.4209, 'grad_norm': 0.9031073793905168, 'learning_rate': 2.4385619691281143e-05, 'epoch': 6.81}
 68%|██████▊   | 620/910 [4:35:37<2:08:06, 26.51s/it] 68%|██████▊   | 621/910 [4:36:03<2:07:28, 26.47s/it]                                                     {'loss': 0.38, 'grad_norm': 0.7794677508143325, 'learning_rate': 2.4232832182653016e-05, 'epoch': 6.82}
 68%|██████▊   | 621/910 [4:36:03<2:07:28, 26.47s/it] 68%|██████▊   | 622/910 [4:36:29<2:06:41, 26.40s/it]                                                     {'loss': 0.4116, 'grad_norm': 1.494580393139594, 'learning_rate': 2.4080371584473748e-05, 'epoch': 6.84}
 68%|██████▊   | 622/910 [4:36:29<2:06:41, 26.40s/it] 68%|██████▊   | 623/910 [4:36:56<2:06:01, 26.35s/it]                                                     {'loss': 0.4376, 'grad_norm': 1.0383202740161541, 'learning_rate': 2.39282398310251e-05, 'epoch': 6.85}
 68%|██████▊   | 623/910 [4:36:56<2:06:01, 26.35s/it] 69%|██████▊   | 624/910 [4:37:22<2:05:43, 26.38s/it]                                                     {'loss': 0.4417, 'grad_norm': 3.3682556370755217, 'learning_rate': 2.3776438852416745e-05, 'epoch': 6.86}
 69%|██████▊   | 624/910 [4:37:22<2:05:43, 26.38s/it] 69%|██████▊   | 625/910 [4:37:48<2:04:54, 26.30s/it]                                                     {'loss': 0.382, 'grad_norm': 1.536466273533858, 'learning_rate': 2.3624970574561774e-05, 'epoch': 6.87}
 69%|██████▊   | 625/910 [4:37:48<2:04:54, 26.30s/it] 69%|██████▉   | 626/910 [4:38:14<2:04:35, 26.32s/it]                                                     {'loss': 0.3716, 'grad_norm': 1.0624740478492634, 'learning_rate': 2.3473836919152264e-05, 'epoch': 6.88}
 69%|██████▉   | 626/910 [4:38:14<2:04:35, 26.32s/it] 69%|██████▉   | 627/910 [4:38:41<2:04:24, 26.38s/it]                                                     {'loss': 0.3412, 'grad_norm': 0.6415351972769348, 'learning_rate': 2.332303980363497e-05, 'epoch': 6.89}
 69%|██████▉   | 627/910 [4:38:41<2:04:24, 26.38s/it] 69%|██████▉   | 628/910 [4:39:08<2:04:40, 26.53s/it]                                                     {'loss': 0.3519, 'grad_norm': 0.5441519713613217, 'learning_rate': 2.317258114118686e-05, 'epoch': 6.9}
 69%|██████▉   | 628/910 [4:39:08<2:04:40, 26.53s/it] 69%|██████▉   | 629/910 [4:39:34<2:04:10, 26.51s/it]                                                     {'loss': 0.3478, 'grad_norm': 0.9336891207477778, 'learning_rate': 2.3022462840690935e-05, 'epoch': 6.91}
 69%|██████▉   | 629/910 [4:39:34<2:04:10, 26.51s/it] 69%|██████▉   | 630/910 [4:40:01<2:04:06, 26.59s/it]                                                     {'loss': 0.4067, 'grad_norm': 1.2373522177646972, 'learning_rate': 2.2872686806712035e-05, 'epoch': 6.92}
 69%|██████▉   | 630/910 [4:40:01<2:04:06, 26.59s/it] 69%|██████▉   | 631/910 [4:40:28<2:03:59, 26.66s/it]                                                     {'loss': 0.4098, 'grad_norm': 1.6153542508712981, 'learning_rate': 2.272325493947257e-05, 'epoch': 6.93}
 69%|██████▉   | 631/910 [4:40:28<2:03:59, 26.66s/it] 69%|██████▉   | 632/910 [4:40:55<2:03:39, 26.69s/it]                                                     {'loss': 0.4171, 'grad_norm': 0.9291728342478643, 'learning_rate': 2.2574169134828526e-05, 'epoch': 6.95}
 69%|██████▉   | 632/910 [4:40:55<2:03:39, 26.69s/it] 70%|██████▉   | 633/910 [4:41:21<2:02:28, 26.53s/it]                                                     {'loss': 0.354, 'grad_norm': 0.6289468156232032, 'learning_rate': 2.2425431284245302e-05, 'epoch': 6.96}
 70%|██████▉   | 633/910 [4:41:21<2:02:28, 26.53s/it] 70%|██████▉   | 634/910 [4:41:47<2:01:36, 26.44s/it]                                                     {'loss': 0.3892, 'grad_norm': 0.9217433770758021, 'learning_rate': 2.2277043274773857e-05, 'epoch': 6.97}
 70%|██████▉   | 634/910 [4:41:47<2:01:36, 26.44s/it] 70%|██████▉   | 635/910 [4:42:13<2:01:06, 26.42s/it]                                                     {'loss': 0.4013, 'grad_norm': 2.8683389600795937, 'learning_rate': 2.2129006989026614e-05, 'epoch': 6.98}
 70%|██████▉   | 635/910 [4:42:13<2:01:06, 26.42s/it] 70%|██████▉   | 636/910 [4:42:40<2:00:25, 26.37s/it]                                                     {'loss': 0.3762, 'grad_norm': 0.6678270969774102, 'learning_rate': 2.1981324305153643e-05, 'epoch': 6.99}
 70%|██████▉   | 636/910 [4:42:40<2:00:25, 26.37s/it] 70%|███████   | 637/910 [4:43:07<2:01:19, 26.67s/it]                                                     {'loss': 0.4443, 'grad_norm': 1.6773905845594737, 'learning_rate': 2.1833997096818898e-05, 'epoch': 7.0}
 70%|███████   | 637/910 [4:43:07<2:01:19, 26.67s/it] 70%|███████   | 638/910 [4:43:51<2:24:53, 31.96s/it]                                                     {'loss': 0.3923, 'grad_norm': 1.3395862122310846, 'learning_rate': 2.168702723317632e-05, 'epoch': 7.01}
 70%|███████   | 638/910 [4:43:51<2:24:53, 31.96s/it] 70%|███████   | 639/910 [4:44:18<2:17:13, 30.38s/it]                                                     {'loss': 0.3725, 'grad_norm': 2.5470095501295194, 'learning_rate': 2.1540416578846207e-05, 'epoch': 7.02}
 70%|███████   | 639/910 [4:44:18<2:17:13, 30.38s/it] 70%|███████   | 640/910 [4:44:44<2:11:23, 29.20s/it]                                                     {'loss': 0.4013, 'grad_norm': 0.6505902405411623, 'learning_rate': 2.139416699389153e-05, 'epoch': 7.03}
 70%|███████   | 640/910 [4:44:45<2:11:23, 29.20s/it] 70%|███████   | 641/910 [4:45:11<2:07:26, 28.43s/it]                                                     {'loss': 0.3606, 'grad_norm': 0.8146881441383379, 'learning_rate': 2.1248280333794346e-05, 'epoch': 7.04}
 70%|███████   | 641/910 [4:45:11<2:07:26, 28.43s/it] 71%|███████   | 642/910 [4:45:38<2:04:51, 27.95s/it]                                                     {'loss': 0.3757, 'grad_norm': 0.6505997466231307, 'learning_rate': 2.1102758449432232e-05, 'epoch': 7.05}
 71%|███████   | 642/910 [4:45:38<2:04:51, 27.95s/it] 71%|███████   | 643/910 [4:46:05<2:02:40, 27.57s/it]                                                     {'loss': 0.3735, 'grad_norm': 0.5603070083341954, 'learning_rate': 2.095760318705487e-05, 'epoch': 7.07}
 71%|███████   | 643/910 [4:46:05<2:02:40, 27.57s/it] 71%|███████   | 644/910 [4:46:31<2:01:11, 27.34s/it]                                                     {'loss': 0.3969, 'grad_norm': 1.5001917497626422, 'learning_rate': 2.0812816388260518e-05, 'epoch': 7.08}
 71%|███████   | 644/910 [4:46:31<2:01:11, 27.34s/it] 71%|███████   | 645/910 [4:46:58<1:59:35, 27.08s/it]                                                     {'loss': 0.4468, 'grad_norm': 1.6272042585422546, 'learning_rate': 2.0668399889972717e-05, 'epoch': 7.09}
 71%|███████   | 645/910 [4:46:58<1:59:35, 27.08s/it] 71%|███████   | 646/910 [4:47:24<1:57:56, 26.80s/it]                                                     {'loss': 0.3228, 'grad_norm': 0.6656356079193468, 'learning_rate': 2.0524355524417017e-05, 'epoch': 7.1}
 71%|███████   | 646/910 [4:47:24<1:57:56, 26.80s/it] 71%|███████   | 647/910 [4:47:50<1:56:24, 26.56s/it]                                                     {'loss': 0.3677, 'grad_norm': 0.684707857715552, 'learning_rate': 2.038068511909762e-05, 'epoch': 7.11}
 71%|███████   | 647/910 [4:47:50<1:56:24, 26.56s/it] 71%|███████   | 648/910 [4:48:16<1:55:39, 26.49s/it]                                                     {'loss': 0.3746, 'grad_norm': 2.0821673651542882, 'learning_rate': 2.0237390496774283e-05, 'epoch': 7.12}
 71%|███████   | 648/910 [4:48:16<1:55:39, 26.49s/it] 71%|███████▏  | 649/910 [4:48:42<1:54:41, 26.37s/it]                                                     {'loss': 0.3551, 'grad_norm': 0.4405049965594782, 'learning_rate': 2.0094473475439202e-05, 'epoch': 7.13}
 71%|███████▏  | 649/910 [4:48:42<1:54:41, 26.37s/it] 71%|███████▏  | 650/910 [4:49:09<1:54:04, 26.32s/it]                                                     {'loss': 0.3677, 'grad_norm': 1.040516708832277, 'learning_rate': 1.995193586829387e-05, 'epoch': 7.14}
 71%|███████▏  | 650/910 [4:49:09<1:54:04, 26.32s/it] 72%|███████▏  | 651/910 [4:49:35<1:53:37, 26.32s/it]                                                     {'loss': 0.3903, 'grad_norm': 0.7827073385417054, 'learning_rate': 1.980977948372612e-05, 'epoch': 7.15}
 72%|███████▏  | 651/910 [4:49:35<1:53:37, 26.32s/it] 72%|███████▏  | 652/910 [4:50:01<1:53:23, 26.37s/it]                                                     {'loss': 0.3962, 'grad_norm': 0.8568527176185473, 'learning_rate': 1.966800612528723e-05, 'epoch': 7.16}
 72%|███████▏  | 652/910 [4:50:01<1:53:23, 26.37s/it] 72%|███████▏  | 653/910 [4:50:28<1:53:25, 26.48s/it]                                                     {'loss': 0.3423, 'grad_norm': 0.9184979853167907, 'learning_rate': 1.9526617591668926e-05, 'epoch': 7.18}
 72%|███████▏  | 653/910 [4:50:28<1:53:25, 26.48s/it] 72%|███████▏  | 654/910 [4:50:55<1:52:58, 26.48s/it]                                                     {'loss': 0.4424, 'grad_norm': 2.3906396518896647, 'learning_rate': 1.9385615676680663e-05, 'epoch': 7.19}
 72%|███████▏  | 654/910 [4:50:55<1:52:58, 26.48s/it] 72%|███████▏  | 655/910 [4:51:21<1:52:51, 26.56s/it]                                                     {'loss': 0.3595, 'grad_norm': 0.7611229604362885, 'learning_rate': 1.924500216922681e-05, 'epoch': 7.2}
 72%|███████▏  | 655/910 [4:51:21<1:52:51, 26.56s/it] 72%|███████▏  | 656/910 [4:51:48<1:52:44, 26.63s/it]                                                     {'loss': 0.4081, 'grad_norm': 0.5841820780515842, 'learning_rate': 1.910477885328399e-05, 'epoch': 7.21}
 72%|███████▏  | 656/910 [4:51:48<1:52:44, 26.63s/it] 72%|███████▏  | 657/910 [4:52:15<1:52:17, 26.63s/it]                                                     {'loss': 0.3791, 'grad_norm': 0.9154617695429055, 'learning_rate': 1.89649475078784e-05, 'epoch': 7.22}
 72%|███████▏  | 657/910 [4:52:15<1:52:17, 26.63s/it] 72%|███████▏  | 658/910 [4:52:42<1:51:57, 26.66s/it]                                                     {'loss': 0.3747, 'grad_norm': 0.46651461694090346, 'learning_rate': 1.8825509907063327e-05, 'epoch': 7.23}
 72%|███████▏  | 658/910 [4:52:42<1:51:57, 26.66s/it] 72%|███████▏  | 659/910 [4:53:07<1:50:33, 26.43s/it]                                                     {'loss': 0.3852, 'grad_norm': 0.9315589409519082, 'learning_rate': 1.868646781989654e-05, 'epoch': 7.24}
 72%|███████▏  | 659/910 [4:53:07<1:50:33, 26.43s/it] 73%|███████▎  | 660/910 [4:53:34<1:49:46, 26.34s/it]                                                     {'loss': 0.405, 'grad_norm': 0.6665509381407734, 'learning_rate': 1.8547823010417877e-05, 'epoch': 7.25}
 73%|███████▎  | 660/910 [4:53:34<1:49:46, 26.34s/it] 73%|███████▎  | 661/910 [4:54:00<1:49:08, 26.30s/it]                                                     {'loss': 0.3814, 'grad_norm': 0.591293256080635, 'learning_rate': 1.8409577237626936e-05, 'epoch': 7.26}
 73%|███████▎  | 661/910 [4:54:00<1:49:08, 26.30s/it] 73%|███████▎  | 662/910 [4:54:26<1:48:46, 26.32s/it]                                                     {'loss': 0.4489, 'grad_norm': 4.593345608700777, 'learning_rate': 1.8271732255460645e-05, 'epoch': 7.27}
 73%|███████▎  | 662/910 [4:54:26<1:48:46, 26.32s/it] 73%|███████▎  | 663/910 [4:54:52<1:48:16, 26.30s/it]                                                     {'loss': 0.3928, 'grad_norm': 7.84077904661652, 'learning_rate': 1.8134289812771078e-05, 'epoch': 7.29}
 73%|███████▎  | 663/910 [4:54:52<1:48:16, 26.30s/it] 73%|███████▎  | 664/910 [4:55:19<1:47:55, 26.32s/it]                                                     {'loss': 0.3855, 'grad_norm': 1.2904190580611927, 'learning_rate': 1.7997251653303248e-05, 'epoch': 7.3}
 73%|███████▎  | 664/910 [4:55:19<1:47:55, 26.32s/it] 73%|███████▎  | 665/910 [4:55:45<1:47:42, 26.38s/it]                                                     {'loss': 0.363, 'grad_norm': 0.7352034054403962, 'learning_rate': 1.7860619515673033e-05, 'epoch': 7.31}
 73%|███████▎  | 665/910 [4:55:45<1:47:42, 26.38s/it] 73%|███████▎  | 666/910 [4:56:12<1:47:44, 26.49s/it]                                                     {'loss': 0.4492, 'grad_norm': 1.645242629979223, 'learning_rate': 1.7724395133345025e-05, 'epoch': 7.32}
 73%|███████▎  | 666/910 [4:56:12<1:47:44, 26.49s/it] 73%|███████▎  | 667/910 [4:56:39<1:47:21, 26.51s/it]                                                     {'loss': 0.3127, 'grad_norm': 0.5717011469269118, 'learning_rate': 1.758858023461059e-05, 'epoch': 7.33}
 73%|███████▎  | 667/910 [4:56:39<1:47:21, 26.51s/it] 73%|███████▎  | 668/910 [4:57:05<1:47:03, 26.54s/it]                                                     {'loss': 0.4111, 'grad_norm': 1.210089755823, 'learning_rate': 1.7453176542565957e-05, 'epoch': 7.34}
 73%|███████▎  | 668/910 [4:57:05<1:47:03, 26.54s/it] 74%|███████▎  | 669/910 [4:57:32<1:46:38, 26.55s/it]                                                     {'loss': 0.4097, 'grad_norm': 0.9112811274964928, 'learning_rate': 1.7318185775090335e-05, 'epoch': 7.35}
 74%|███████▎  | 669/910 [4:57:32<1:46:38, 26.55s/it] 74%|███████▎  | 670/910 [4:57:59<1:46:24, 26.60s/it]                                                     {'loss': 0.3443, 'grad_norm': 0.7432682942836362, 'learning_rate': 1.7183609644824096e-05, 'epoch': 7.36}
 74%|███████▎  | 670/910 [4:57:59<1:46:24, 26.60s/it] 74%|███████▎  | 671/910 [4:58:25<1:46:10, 26.65s/it]                                                     {'loss': 0.3936, 'grad_norm': 0.7110574074493079, 'learning_rate': 1.704944985914712e-05, 'epoch': 7.37}
 74%|███████▎  | 671/910 [4:58:25<1:46:10, 26.65s/it] 74%|███████▍  | 672/910 [4:58:52<1:45:12, 26.52s/it]                                                     {'loss': 0.4383, 'grad_norm': 0.7682617519729057, 'learning_rate': 1.691570812015704e-05, 'epoch': 7.38}
 74%|███████▍  | 672/910 [4:58:52<1:45:12, 26.52s/it] 74%|███████▍  | 673/910 [4:59:18<1:44:32, 26.47s/it]                                                     {'loss': 0.3387, 'grad_norm': 0.5334314549825611, 'learning_rate': 1.6782386124647697e-05, 'epoch': 7.4}
 74%|███████▍  | 673/910 [4:59:18<1:44:32, 26.47s/it] 74%|███████▍  | 674/910 [4:59:44<1:43:43, 26.37s/it]                                                     {'loss': 0.3738, 'grad_norm': 0.8722518350110309, 'learning_rate': 1.6649485564087645e-05, 'epoch': 7.41}
 74%|███████▍  | 674/910 [4:59:44<1:43:43, 26.37s/it] 74%|███████▍  | 675/910 [5:00:10<1:42:56, 26.28s/it]                                                     {'loss': 0.3441, 'grad_norm': 1.1900293496224452, 'learning_rate': 1.651700812459862e-05, 'epoch': 7.42}
 74%|███████▍  | 675/910 [5:00:10<1:42:56, 26.28s/it] 74%|███████▍  | 676/910 [5:00:37<1:43:04, 26.43s/it]                                                     {'loss': 0.3315, 'grad_norm': 1.3128513174907823, 'learning_rate': 1.6384955486934156e-05, 'epoch': 7.43}
 74%|███████▍  | 676/910 [5:00:37<1:43:04, 26.43s/it] 74%|███████▍  | 677/910 [5:01:03<1:42:33, 26.41s/it]                                                     {'loss': 0.373, 'grad_norm': 0.7503022204415615, 'learning_rate': 1.6253329326458365e-05, 'epoch': 7.44}
 74%|███████▍  | 677/910 [5:01:03<1:42:33, 26.41s/it] 75%|███████▍  | 678/910 [5:01:30<1:42:23, 26.48s/it]                                                     {'loss': 0.4033, 'grad_norm': 0.9484679474907877, 'learning_rate': 1.6122131313124537e-05, 'epoch': 7.45}
 75%|███████▍  | 678/910 [5:01:30<1:42:23, 26.48s/it] 75%|███████▍  | 679/910 [5:01:56<1:41:57, 26.48s/it]                                                     {'loss': 0.3164, 'grad_norm': 0.9491729166588977, 'learning_rate': 1.599136311145402e-05, 'epoch': 7.46}
 75%|███████▍  | 679/910 [5:01:56<1:41:57, 26.48s/it] 75%|███████▍  | 680/910 [5:02:23<1:41:52, 26.58s/it]                                                     {'loss': 0.3599, 'grad_norm': 0.6921880356675106, 'learning_rate': 1.5861026380515166e-05, 'epoch': 7.47}
 75%|███████▍  | 680/910 [5:02:23<1:41:52, 26.58s/it] 75%|███████▍  | 681/910 [5:02:50<1:41:35, 26.62s/it]                                                     {'loss': 0.3121, 'grad_norm': 0.6597544548624511, 'learning_rate': 1.5731122773902145e-05, 'epoch': 7.48}
 75%|███████▍  | 681/910 [5:02:50<1:41:35, 26.62s/it] 75%|███████▍  | 682/910 [5:03:17<1:41:10, 26.62s/it]                                                     {'loss': 0.3692, 'grad_norm': 0.8848444858631432, 'learning_rate': 1.5601653939714074e-05, 'epoch': 7.49}
 75%|███████▍  | 682/910 [5:03:17<1:41:10, 26.62s/it] 75%|███████▌  | 683/910 [5:03:44<1:41:15, 26.76s/it]                                                     {'loss': 0.3629, 'grad_norm': 0.6195957765836624, 'learning_rate': 1.5472621520534058e-05, 'epoch': 7.51}
 75%|███████▌  | 683/910 [5:03:44<1:41:15, 26.76s/it] 75%|███████▌  | 684/910 [5:04:11<1:40:57, 26.80s/it]                                                     {'loss': 0.4147, 'grad_norm': 1.059215031301528, 'learning_rate': 1.5344027153408375e-05, 'epoch': 7.52}
 75%|███████▌  | 684/910 [5:04:11<1:40:57, 26.80s/it] 75%|███████▌  | 685/910 [5:04:37<1:40:02, 26.68s/it]                                                     {'loss': 0.3601, 'grad_norm': 0.990635489916341, 'learning_rate': 1.5215872469825682e-05, 'epoch': 7.53}
 75%|███████▌  | 685/910 [5:04:37<1:40:02, 26.68s/it] 75%|███████▌  | 686/910 [5:05:03<1:38:59, 26.52s/it]                                                     {'loss': 0.3993, 'grad_norm': 1.2888984555917449, 'learning_rate': 1.5088159095696363e-05, 'epoch': 7.54}
 75%|███████▌  | 686/910 [5:05:03<1:38:59, 26.52s/it] 75%|███████▌  | 687/910 [5:05:29<1:38:18, 26.45s/it]                                                     {'loss': 0.4, 'grad_norm': 0.7892124133462008, 'learning_rate': 1.4960888651331834e-05, 'epoch': 7.55}
 75%|███████▌  | 687/910 [5:05:29<1:38:18, 26.45s/it] 76%|███████▌  | 688/910 [5:05:56<1:37:35, 26.38s/it]                                                     {'loss': 0.491, 'grad_norm': 2.6368694796168217, 'learning_rate': 1.4834062751424015e-05, 'epoch': 7.56}
 76%|███████▌  | 688/910 [5:05:56<1:37:35, 26.38s/it] 76%|███████▌  | 689/910 [5:06:22<1:36:56, 26.32s/it]                                                     {'loss': 0.397, 'grad_norm': 0.7625943795669293, 'learning_rate': 1.4707683005024898e-05, 'epoch': 7.57}
 76%|███████▌  | 689/910 [5:06:22<1:36:56, 26.32s/it] 76%|███████▌  | 690/910 [5:06:48<1:36:23, 26.29s/it]                                                     {'loss': 0.447, 'grad_norm': 1.2527123036126537, 'learning_rate': 1.4581751015526035e-05, 'epoch': 7.58}
 76%|███████▌  | 690/910 [5:06:48<1:36:23, 26.29s/it] 76%|███████▌  | 691/910 [5:07:14<1:35:56, 26.28s/it]                                                     {'loss': 0.3688, 'grad_norm': 0.7917235842916143, 'learning_rate': 1.445626838063826e-05, 'epoch': 7.59}
 76%|███████▌  | 691/910 [5:07:14<1:35:56, 26.28s/it] 76%|███████▌  | 692/910 [5:07:41<1:36:01, 26.43s/it]                                                     {'loss': 0.3644, 'grad_norm': 1.7349437279150994, 'learning_rate': 1.4331236692371386e-05, 'epoch': 7.6}
 76%|███████▌  | 692/910 [5:07:41<1:36:01, 26.43s/it] 76%|███████▌  | 693/910 [5:08:08<1:36:04, 26.56s/it]                                                     {'loss': 0.3388, 'grad_norm': 0.577545652274361, 'learning_rate': 1.4206657537014079e-05, 'epoch': 7.62}
 76%|███████▌  | 693/910 [5:08:08<1:36:04, 26.56s/it] 76%|███████▋  | 694/910 [5:08:35<1:35:44, 26.59s/it]                                                     {'loss': 0.384, 'grad_norm': 0.9563009610652499, 'learning_rate': 1.4082532495113626e-05, 'epoch': 7.63}
 76%|███████▋  | 694/910 [5:08:35<1:35:44, 26.59s/it] 76%|███████▋  | 695/910 [5:09:01<1:35:37, 26.69s/it]                                                     {'loss': 0.3678, 'grad_norm': 0.6896536027852619, 'learning_rate': 1.3958863141455935e-05, 'epoch': 7.64}
 76%|███████▋  | 695/910 [5:09:01<1:35:37, 26.69s/it] 76%|███████▋  | 696/910 [5:09:28<1:35:06, 26.66s/it]                                                     {'loss': 0.3949, 'grad_norm': 0.8921953663786162, 'learning_rate': 1.38356510450456e-05, 'epoch': 7.65}
 76%|███████▋  | 696/910 [5:09:28<1:35:06, 26.66s/it] 77%|███████▋  | 697/910 [5:09:55<1:34:52, 26.73s/it]                                                     {'loss': 0.391, 'grad_norm': 1.0781870622119478, 'learning_rate': 1.3712897769085903e-05, 'epoch': 7.66}
 77%|███████▋  | 697/910 [5:09:55<1:34:52, 26.73s/it] 77%|███████▋  | 698/910 [5:10:22<1:34:28, 26.74s/it]                                                     {'loss': 0.3434, 'grad_norm': 0.7245734517591631, 'learning_rate': 1.3590604870959045e-05, 'epoch': 7.67}
 77%|███████▋  | 698/910 [5:10:22<1:34:28, 26.74s/it] 77%|███████▋  | 699/910 [5:10:48<1:33:22, 26.55s/it]                                                     {'loss': 0.3743, 'grad_norm': 0.8214074819920604, 'learning_rate': 1.3468773902206378e-05, 'epoch': 7.68}
 77%|███████▋  | 699/910 [5:10:48<1:33:22, 26.55s/it] 77%|███████▋  | 700/910 [5:11:14<1:32:38, 26.47s/it]                                                     {'loss': 0.4743, 'grad_norm': 1.896635173117853, 'learning_rate': 1.3347406408508695e-05, 'epoch': 7.69}
 77%|███████▋  | 700/910 [5:11:14<1:32:38, 26.47s/it] 77%|███████▋  | 701/910 [5:11:40<1:31:43, 26.33s/it]                                                     {'loss': 0.4381, 'grad_norm': 1.151266997710496, 'learning_rate': 1.322650392966665e-05, 'epoch': 7.7}
 77%|███████▋  | 701/910 [5:11:40<1:31:43, 26.33s/it] 77%|███████▋  | 702/910 [5:12:06<1:31:12, 26.31s/it]                                                     {'loss': 0.3412, 'grad_norm': 0.7352280936642751, 'learning_rate': 1.3106067999581222e-05, 'epoch': 7.71}
 77%|███████▋  | 702/910 [5:12:06<1:31:12, 26.31s/it] 77%|███████▋  | 703/910 [5:12:33<1:30:41, 26.29s/it]                                                     {'loss': 0.4558, 'grad_norm': 1.415101397721356, 'learning_rate': 1.2986100146234232e-05, 'epoch': 7.73}
 77%|███████▋  | 703/910 [5:12:33<1:30:41, 26.29s/it] 77%|███████▋  | 704/910 [5:12:59<1:30:17, 26.30s/it]                                                     {'loss': 0.392, 'grad_norm': 0.77093073193527, 'learning_rate': 1.2866601891668945e-05, 'epoch': 7.74}
 77%|███████▋  | 704/910 [5:12:59<1:30:17, 26.30s/it] 77%|███████▋  | 705/910 [5:13:25<1:29:59, 26.34s/it]                                                     {'loss': 0.3452, 'grad_norm': 1.436673207014797, 'learning_rate': 1.2747574751970826e-05, 'epoch': 7.75}
 77%|███████▋  | 705/910 [5:13:25<1:29:59, 26.34s/it] 78%|███████▊  | 706/910 [5:13:52<1:29:34, 26.34s/it]                                                     {'loss': 0.3531, 'grad_norm': 0.7972696965442427, 'learning_rate': 1.262902023724824e-05, 'epoch': 7.76}
 78%|███████▊  | 706/910 [5:13:52<1:29:34, 26.34s/it] 78%|███████▊  | 707/910 [5:14:18<1:29:18, 26.40s/it]                                                     {'loss': 0.3425, 'grad_norm': 0.8938191351787368, 'learning_rate': 1.2510939851613285e-05, 'epoch': 7.77}
 78%|███████▊  | 707/910 [5:14:18<1:29:18, 26.40s/it] 78%|███████▊  | 708/910 [5:14:45<1:28:59, 26.43s/it]                                                     {'loss': 0.409, 'grad_norm': 0.7956441610261432, 'learning_rate': 1.239333509316281e-05, 'epoch': 7.78}
 78%|███████▊  | 708/910 [5:14:45<1:28:59, 26.43s/it] 78%|███████▊  | 709/910 [5:15:12<1:29:02, 26.58s/it]                                                     {'loss': 0.4289, 'grad_norm': 0.6350043191608561, 'learning_rate': 1.2276207453959282e-05, 'epoch': 7.79}
 78%|███████▊  | 709/910 [5:15:12<1:29:02, 26.58s/it] 78%|███████▊  | 710/910 [5:15:38<1:28:30, 26.55s/it]                                                     {'loss': 0.37, 'grad_norm': 0.7503764598015494, 'learning_rate': 1.2159558420011907e-05, 'epoch': 7.8}
 78%|███████▊  | 710/910 [5:15:38<1:28:30, 26.55s/it] 78%|███████▊  | 711/910 [5:16:05<1:28:36, 26.72s/it]                                                     {'loss': 0.3807, 'grad_norm': 0.935841816253562, 'learning_rate': 1.2043389471257833e-05, 'epoch': 7.81}
 78%|███████▊  | 711/910 [5:16:05<1:28:36, 26.72s/it] 78%|███████▊  | 712/910 [5:16:31<1:27:27, 26.50s/it]                                                     {'loss': 0.3391, 'grad_norm': 0.7205058741182746, 'learning_rate': 1.1927702081543279e-05, 'epoch': 7.82}
 78%|███████▊  | 712/910 [5:16:31<1:27:27, 26.50s/it] 78%|███████▊  | 713/910 [5:16:58<1:26:48, 26.44s/it]                                                     {'loss': 0.3844, 'grad_norm': 1.3122312439200927, 'learning_rate': 1.1812497718604886e-05, 'epoch': 7.84}
 78%|███████▊  | 713/910 [5:16:58<1:26:48, 26.44s/it] 78%|███████▊  | 714/910 [5:17:24<1:26:30, 26.48s/it]                                                     {'loss': 0.4024, 'grad_norm': 0.8366265371040302, 'learning_rate': 1.1697777844051105e-05, 'epoch': 7.85}
 78%|███████▊  | 714/910 [5:17:24<1:26:30, 26.48s/it] 79%|███████▊  | 715/910 [5:17:50<1:25:46, 26.39s/it]                                                     {'loss': 0.3937, 'grad_norm': 0.6261537911062234, 'learning_rate': 1.1583543913343619e-05, 'epoch': 7.86}
 79%|███████▊  | 715/910 [5:17:50<1:25:46, 26.39s/it] 79%|███████▊  | 716/910 [5:18:16<1:25:09, 26.34s/it]                                                     {'loss': 0.3452, 'grad_norm': 1.9002584182714266, 'learning_rate': 1.1469797375778901e-05, 'epoch': 7.87}
 79%|███████▊  | 716/910 [5:18:17<1:25:09, 26.34s/it] 79%|███████▉  | 717/910 [5:18:43<1:24:56, 26.41s/it]                                                     {'loss': 0.3806, 'grad_norm': 1.2378628809869303, 'learning_rate': 1.1356539674469851e-05, 'epoch': 7.88}
 79%|███████▉  | 717/910 [5:18:43<1:24:56, 26.41s/it] 79%|███████▉  | 718/910 [5:19:09<1:24:25, 26.38s/it]                                                     {'loss': 0.4142, 'grad_norm': 1.6324311904477882, 'learning_rate': 1.1243772246327416e-05, 'epoch': 7.89}
 79%|███████▉  | 718/910 [5:19:09<1:24:25, 26.38s/it] 79%|███████▉  | 719/910 [5:19:36<1:24:07, 26.43s/it]                                                     {'loss': 0.3948, 'grad_norm': 0.9310625685660306, 'learning_rate': 1.1131496522042424e-05, 'epoch': 7.9}
 79%|███████▉  | 719/910 [5:19:36<1:24:07, 26.43s/it] 79%|███████▉  | 720/910 [5:20:02<1:23:48, 26.47s/it]                                                     {'loss': 0.3292, 'grad_norm': 0.5482914900711515, 'learning_rate': 1.1019713926067394e-05, 'epoch': 7.91}
 79%|███████▉  | 720/910 [5:20:02<1:23:48, 26.47s/it] 79%|███████▉  | 721/910 [5:20:29<1:23:28, 26.50s/it]                                                     {'loss': 0.38, 'grad_norm': 1.3884267462080573, 'learning_rate': 1.090842587659851e-05, 'epoch': 7.92}
 79%|███████▉  | 721/910 [5:20:29<1:23:28, 26.50s/it] 79%|███████▉  | 722/910 [5:20:56<1:23:01, 26.50s/it]                                                     {'loss': 0.3947, 'grad_norm': 0.7359200277248789, 'learning_rate': 1.0797633785557581e-05, 'epoch': 7.93}
 79%|███████▉  | 722/910 [5:20:56<1:23:01, 26.50s/it] 79%|███████▉  | 723/910 [5:21:23<1:23:07, 26.67s/it]                                                     {'loss': 0.4058, 'grad_norm': 0.8223386261176981, 'learning_rate': 1.0687339058574131e-05, 'epoch': 7.95}
 79%|███████▉  | 723/910 [5:21:23<1:23:07, 26.67s/it] 80%|███████▉  | 724/910 [5:21:49<1:22:37, 26.65s/it]                                                     {'loss': 0.4233, 'grad_norm': 1.2246336040458843, 'learning_rate': 1.0577543094967612e-05, 'epoch': 7.96}
 80%|███████▉  | 724/910 [5:21:49<1:22:37, 26.65s/it] 80%|███████▉  | 725/910 [5:22:16<1:22:02, 26.61s/it]                                                     {'loss': 0.3782, 'grad_norm': 0.7569798000676828, 'learning_rate': 1.0468247287729594e-05, 'epoch': 7.97}
 80%|███████▉  | 725/910 [5:22:16<1:22:02, 26.61s/it] 80%|███████▉  | 726/910 [5:22:42<1:21:06, 26.45s/it]                                                     {'loss': 0.3436, 'grad_norm': 0.7632812803872856, 'learning_rate': 1.0359453023506121e-05, 'epoch': 7.98}
 80%|███████▉  | 726/910 [5:22:42<1:21:06, 26.45s/it] 80%|███████▉  | 727/910 [5:23:08<1:20:21, 26.35s/it]                                                     {'loss': 0.4753, 'grad_norm': 1.5883632423347194, 'learning_rate': 1.0251161682580124e-05, 'epoch': 7.99}
 80%|███████▉  | 727/910 [5:23:08<1:20:21, 26.35s/it] 80%|████████  | 728/910 [5:23:35<1:20:52, 26.66s/it]                                                     {'loss': 0.4035, 'grad_norm': 1.05595316481506, 'learning_rate': 1.0143374638853891e-05, 'epoch': 8.0}
 80%|████████  | 728/910 [5:23:35<1:20:52, 26.66s/it] 80%|████████  | 729/910 [5:24:19<1:35:31, 31.66s/it]                                                     {'loss': 0.4417, 'grad_norm': 1.0007345940870243, 'learning_rate': 1.0036093259831625e-05, 'epoch': 8.01}
 80%|████████  | 729/910 [5:24:19<1:35:31, 31.66s/it] 80%|████████  | 730/910 [5:24:45<1:30:18, 30.10s/it]                                                     {'loss': 0.3935, 'grad_norm': 1.3902093975567658, 'learning_rate': 9.929318906602175e-06, 'epoch': 8.02}
 80%|████████  | 730/910 [5:24:45<1:30:18, 30.10s/it] 80%|████████  | 731/910 [5:25:12<1:26:50, 29.11s/it]                                                     {'loss': 0.3494, 'grad_norm': 0.6588488542216792, 'learning_rate': 9.823052933821642e-06, 'epoch': 8.03}
 80%|████████  | 731/910 [5:25:12<1:26:50, 29.11s/it] 80%|████████  | 732/910 [5:25:39<1:24:21, 28.44s/it]                                                     {'loss': 0.3932, 'grad_norm': 1.3210612902107164, 'learning_rate': 9.717296689696281e-06, 'epoch': 8.04}
 80%|████████  | 732/910 [5:25:39<1:24:21, 28.44s/it] 81%|████████  | 733/910 [5:26:05<1:22:19, 27.91s/it]                                                     {'loss': 0.4033, 'grad_norm': 1.4766791904550634, 'learning_rate': 9.612051515965387e-06, 'epoch': 8.05}
 81%|████████  | 733/910 [5:26:05<1:22:19, 27.91s/it] 81%|████████  | 734/910 [5:26:32<1:20:44, 27.53s/it]                                                     {'loss': 0.3194, 'grad_norm': 0.5184082719619328, 'learning_rate': 9.507318747884241e-06, 'epoch': 8.07}
 81%|████████  | 734/910 [5:26:32<1:20:44, 27.53s/it] 81%|████████  | 735/910 [5:26:59<1:19:22, 27.22s/it]                                                     {'loss': 0.4335, 'grad_norm': 2.076015524832887, 'learning_rate': 9.403099714207175e-06, 'epoch': 8.08}
 81%|████████  | 735/910 [5:26:59<1:19:22, 27.22s/it] 81%|████████  | 736/910 [5:27:26<1:18:46, 27.16s/it]                                                     {'loss': 0.4439, 'grad_norm': 2.7884486612788124, 'learning_rate': 9.299395737170757e-06, 'epoch': 8.09}
 81%|████████  | 736/910 [5:27:26<1:18:46, 27.16s/it] 81%|████████  | 737/910 [5:27:52<1:17:44, 26.96s/it]                                                     {'loss': 0.4036, 'grad_norm': 0.6601214708554839, 'learning_rate': 9.196208132476963e-06, 'epoch': 8.1}
 81%|████████  | 737/910 [5:27:52<1:17:44, 26.96s/it] 81%|████████  | 738/910 [5:28:18<1:16:37, 26.73s/it]                                                     {'loss': 0.3725, 'grad_norm': 1.150957347736631, 'learning_rate': 9.093538209276487e-06, 'epoch': 8.11}
 81%|████████  | 738/910 [5:28:18<1:16:37, 26.73s/it] 81%|████████  | 739/910 [5:28:44<1:15:40, 26.55s/it]                                                     {'loss': 0.3925, 'grad_norm': 9.913825352796936, 'learning_rate': 8.991387270152201e-06, 'epoch': 8.12}
 81%|████████  | 739/910 [5:28:44<1:15:40, 26.55s/it] 81%|████████▏ | 740/910 [5:29:11<1:14:53, 26.43s/it]                                                     {'loss': 0.4125, 'grad_norm': 0.8795140376727373, 'learning_rate': 8.88975661110254e-06, 'epoch': 8.13}
 81%|████████▏ | 740/910 [5:29:11<1:14:53, 26.43s/it] 81%|████████▏ | 741/910 [5:29:37<1:14:25, 26.42s/it]                                                     {'loss': 0.3486, 'grad_norm': 2.483995351590952, 'learning_rate': 8.78864752152509e-06, 'epoch': 8.14}
 81%|████████▏ | 741/910 [5:29:37<1:14:25, 26.42s/it] 82%|████████▏ | 742/910 [5:30:03<1:13:58, 26.42s/it]                                                     {'loss': 0.3321, 'grad_norm': 0.9222010579987301, 'learning_rate': 8.688061284200266e-06, 'epoch': 8.15}
 82%|████████▏ | 742/910 [5:30:03<1:13:58, 26.42s/it] 82%|████████▏ | 743/910 [5:30:30<1:13:24, 26.38s/it]                                                     {'loss': 0.338, 'grad_norm': 1.117361209682829, 'learning_rate': 8.587999175274985e-06, 'epoch': 8.16}
 82%|████████▏ | 743/910 [5:30:30<1:13:24, 26.38s/it] 82%|████████▏ | 744/910 [5:30:56<1:13:07, 26.43s/it]                                                     {'loss': 0.3342, 'grad_norm': 1.2614353464098336, 'learning_rate': 8.488462464246495e-06, 'epoch': 8.18}
 82%|████████▏ | 744/910 [5:30:56<1:13:07, 26.43s/it] 82%|████████▏ | 745/910 [5:31:23<1:12:52, 26.50s/it]                                                     {'loss': 0.3676, 'grad_norm': 0.5923015291701158, 'learning_rate': 8.389452413946314e-06, 'epoch': 8.19}
 82%|████████▏ | 745/910 [5:31:23<1:12:52, 26.50s/it] 82%|████████▏ | 746/910 [5:31:49<1:12:29, 26.52s/it]                                                     {'loss': 0.2996, 'grad_norm': 0.8032205889220602, 'learning_rate': 8.290970280524124e-06, 'epoch': 8.2}
 82%|████████▏ | 746/910 [5:31:49<1:12:29, 26.52s/it] 82%|████████▏ | 747/910 [5:32:16<1:12:03, 26.53s/it]                                                     {'loss': 0.4157, 'grad_norm': 1.5087905825366201, 'learning_rate': 8.193017313431871e-06, 'epoch': 8.21}
 82%|████████▏ | 747/910 [5:32:16<1:12:03, 26.53s/it] 82%|████████▏ | 748/910 [5:32:43<1:11:56, 26.65s/it]                                                     {'loss': 0.3491, 'grad_norm': 0.6665925829204712, 'learning_rate': 8.09559475540797e-06, 'epoch': 8.22}
 82%|████████▏ | 748/910 [5:32:43<1:11:56, 26.65s/it] 82%|████████▏ | 749/910 [5:33:10<1:11:32, 26.66s/it]                                                     {'loss': 0.3339, 'grad_norm': 1.087919383878087, 'learning_rate': 7.998703842461431e-06, 'epoch': 8.23}
 82%|████████▏ | 749/910 [5:33:10<1:11:32, 26.66s/it] 82%|████████▏ | 750/910 [5:33:36<1:10:51, 26.57s/it]                                                     {'loss': 0.368, 'grad_norm': 0.7184598331467414, 'learning_rate': 7.902345803856265e-06, 'epoch': 8.24}
 82%|████████▏ | 750/910 [5:33:36<1:10:51, 26.57s/it] 83%|████████▎ | 751/910 [5:34:02<1:09:59, 26.41s/it]                                                     {'loss': 0.3677, 'grad_norm': 0.6812936489928808, 'learning_rate': 7.806521862095834e-06, 'epoch': 8.25}
 83%|████████▎ | 751/910 [5:34:02<1:09:59, 26.41s/it] 83%|████████▎ | 752/910 [5:34:28<1:09:18, 26.32s/it]                                                     {'loss': 0.3782, 'grad_norm': 0.6273400365862862, 'learning_rate': 7.7112332329074e-06, 'epoch': 8.26}
 83%|████████▎ | 752/910 [5:34:28<1:09:18, 26.32s/it] 83%|████████▎ | 753/910 [5:34:54<1:08:42, 26.26s/it]                                                     {'loss': 0.3912, 'grad_norm': 0.7097565019536193, 'learning_rate': 7.616481125226632e-06, 'epoch': 8.27}
 83%|████████▎ | 753/910 [5:34:54<1:08:42, 26.26s/it] 83%|████████▎ | 754/910 [5:35:20<1:08:02, 26.17s/it]                                                     {'loss': 0.4246, 'grad_norm': 1.5190119607437256, 'learning_rate': 7.522266741182305e-06, 'epoch': 8.29}
 83%|████████▎ | 754/910 [5:35:20<1:08:02, 26.17s/it] 83%|████████▎ | 755/910 [5:35:47<1:07:46, 26.24s/it]                                                     {'loss': 0.436, 'grad_norm': 1.4781272704356552, 'learning_rate': 7.42859127608106e-06, 'epoch': 8.3}
 83%|████████▎ | 755/910 [5:35:47<1:07:46, 26.24s/it] 83%|████████▎ | 756/910 [5:36:13<1:07:22, 26.25s/it]                                                     {'loss': 0.3876, 'grad_norm': 1.5078030305228058, 'learning_rate': 7.33545591839222e-06, 'epoch': 8.31}
 83%|████████▎ | 756/910 [5:36:13<1:07:22, 26.25s/it] 83%|████████▎ | 757/910 [5:36:39<1:06:57, 26.26s/it]                                                     {'loss': 0.3465, 'grad_norm': 1.1579821554249743, 'learning_rate': 7.242861849732696e-06, 'epoch': 8.32}
 83%|████████▎ | 757/910 [5:36:39<1:06:57, 26.26s/it] 83%|████████▎ | 758/910 [5:37:06<1:06:52, 26.40s/it]                                                     {'loss': 0.3833, 'grad_norm': 0.8047556321771014, 'learning_rate': 7.150810244852035e-06, 'epoch': 8.33}
 83%|████████▎ | 758/910 [5:37:06<1:06:52, 26.40s/it] 83%|████████▎ | 759/910 [5:37:32<1:06:31, 26.43s/it]                                                     {'loss': 0.354, 'grad_norm': 0.8568922116298726, 'learning_rate': 7.059302271617485e-06, 'epoch': 8.34}
 83%|████████▎ | 759/910 [5:37:32<1:06:31, 26.43s/it] 84%|████████▎ | 760/910 [5:37:59<1:06:08, 26.46s/it]                                                     {'loss': 0.3627, 'grad_norm': 0.8158271749305306, 'learning_rate': 6.968339090999187e-06, 'epoch': 8.35}
 84%|████████▎ | 760/910 [5:37:59<1:06:08, 26.46s/it] 84%|████████▎ | 761/910 [5:38:26<1:06:03, 26.60s/it]                                                     {'loss': 0.4186, 'grad_norm': 0.6399975113666868, 'learning_rate': 6.8779218570554745e-06, 'epoch': 8.36}
 84%|████████▎ | 761/910 [5:38:26<1:06:03, 26.60s/it] 84%|████████▎ | 762/910 [5:38:53<1:05:42, 26.64s/it]                                                     {'loss': 0.435, 'grad_norm': 1.0608773674777983, 'learning_rate': 6.78805171691817e-06, 'epoch': 8.37}
 84%|████████▎ | 762/910 [5:38:53<1:05:42, 26.64s/it] 84%|████████▍ | 763/910 [5:39:20<1:05:32, 26.75s/it]                                                     {'loss': 0.3815, 'grad_norm': 0.7566089086775108, 'learning_rate': 6.698729810778065e-06, 'epoch': 8.38}
 84%|████████▍ | 763/910 [5:39:20<1:05:32, 26.75s/it] 84%|████████▍ | 764/910 [5:39:46<1:04:42, 26.59s/it]                                                     {'loss': 0.3908, 'grad_norm': 1.1112512995392863, 'learning_rate': 6.609957271870504e-06, 'epoch': 8.4}
 84%|████████▍ | 764/910 [5:39:46<1:04:42, 26.59s/it] 84%|████████▍ | 765/910 [5:40:12<1:03:59, 26.48s/it]                                                     {'loss': 0.3617, 'grad_norm': 0.8931408309759077, 'learning_rate': 6.521735226460901e-06, 'epoch': 8.41}
 84%|████████▍ | 765/910 [5:40:12<1:03:59, 26.48s/it] 84%|████████▍ | 766/910 [5:40:38<1:03:12, 26.34s/it]                                                     {'loss': 0.5112, 'grad_norm': 0.6366536510409326, 'learning_rate': 6.43406479383053e-06, 'epoch': 8.42}
 84%|████████▍ | 766/910 [5:40:38<1:03:12, 26.34s/it] 84%|████████▍ | 767/910 [5:41:04<1:02:29, 26.22s/it]                                                     {'loss': 0.3913, 'grad_norm': 1.0664306539764181, 'learning_rate': 6.346947086262323e-06, 'epoch': 8.43}
 84%|████████▍ | 767/910 [5:41:04<1:02:29, 26.22s/it] 84%|████████▍ | 768/910 [5:41:30<1:01:55, 26.16s/it]                                                     {'loss': 0.3899, 'grad_norm': 0.9276507423714062, 'learning_rate': 6.260383209026704e-06, 'epoch': 8.44}
 84%|████████▍ | 768/910 [5:41:30<1:01:55, 26.16s/it] 85%|████████▍ | 769/910 [5:41:56<1:01:30, 26.18s/it]                                                     {'loss': 0.3788, 'grad_norm': 0.6937587041123445, 'learning_rate': 6.1743742603676105e-06, 'epoch': 8.45}
 85%|████████▍ | 769/910 [5:41:56<1:01:30, 26.18s/it] 85%|████████▍ | 770/910 [5:42:23<1:01:19, 26.28s/it]                                                     {'loss': 0.3537, 'grad_norm': 1.042095747694295, 'learning_rate': 6.088921331488568e-06, 'epoch': 8.46}
 85%|████████▍ | 770/910 [5:42:23<1:01:19, 26.28s/it] 85%|████████▍ | 771/910 [5:42:49<1:01:09, 26.40s/it]                                                     {'loss': 0.4135, 'grad_norm': 0.6270935782456588, 'learning_rate': 6.0040255065388125e-06, 'epoch': 8.47}
 85%|████████▍ | 771/910 [5:42:49<1:01:09, 26.40s/it] 85%|████████▍ | 772/910 [5:43:16<1:00:46, 26.43s/it]                                                     {'loss': 0.37, 'grad_norm': 1.7998275934872885, 'learning_rate': 5.919687862599549e-06, 'epoch': 8.48}
 85%|████████▍ | 772/910 [5:43:16<1:00:46, 26.43s/it] 85%|████████▍ | 773/910 [5:43:43<1:00:42, 26.59s/it]                                                     {'loss': 0.4366, 'grad_norm': 0.7222145724331386, 'learning_rate': 5.835909469670292e-06, 'epoch': 8.49}
 85%|████████▍ | 773/910 [5:43:43<1:00:42, 26.59s/it] 85%|████████▌ | 774/910 [5:44:10<1:00:19, 26.62s/it]                                                     {'loss': 0.3788, 'grad_norm': 1.8136232791993563, 'learning_rate': 5.752691390655279e-06, 'epoch': 8.51}
 85%|████████▌ | 774/910 [5:44:10<1:00:19, 26.62s/it] 85%|████████▌ | 775/910 [5:44:36<59:57, 26.65s/it]                                                     {'loss': 0.3542, 'grad_norm': 0.7529152890529573, 'learning_rate': 5.670034681349995e-06, 'epoch': 8.52}
 85%|████████▌ | 775/910 [5:44:36<59:57, 26.65s/it] 85%|████████▌ | 776/910 [5:45:03<59:44, 26.75s/it]                                                   {'loss': 0.3675, 'grad_norm': 0.6875581166015177, 'learning_rate': 5.587940390427804e-06, 'epoch': 8.53}
 85%|████████▌ | 776/910 [5:45:03<59:44, 26.75s/it] 85%|████████▌ | 777/910 [5:45:30<59:05, 26.66s/it]                                                   {'loss': 0.4282, 'grad_norm': 0.8098789181902658, 'learning_rate': 5.506409559426573e-06, 'epoch': 8.54}
 85%|████████▌ | 777/910 [5:45:30<59:05, 26.66s/it] 85%|████████▌ | 778/910 [5:45:56<58:19, 26.51s/it]                                                   {'loss': 0.4138, 'grad_norm': 0.7780359381697362, 'learning_rate': 5.425443222735527e-06, 'epoch': 8.55}
 85%|████████▌ | 778/910 [5:45:56<58:19, 26.51s/it] 86%|████████▌ | 779/910 [5:46:22<57:40, 26.42s/it]                                                   {'loss': 0.3649, 'grad_norm': 0.8864438015344984, 'learning_rate': 5.345042407582079e-06, 'epoch': 8.56}
 86%|████████▌ | 779/910 [5:46:22<57:40, 26.42s/it] 86%|████████▌ | 780/910 [5:46:48<57:13, 26.41s/it]                                                   {'loss': 0.3288, 'grad_norm': 0.6081976566866214, 'learning_rate': 5.265208134018851e-06, 'epoch': 8.57}
 86%|████████▌ | 780/910 [5:46:48<57:13, 26.41s/it] 86%|████████▌ | 781/910 [5:47:15<56:38, 26.34s/it]                                                   {'loss': 0.3793, 'grad_norm': 1.3014888144152237, 'learning_rate': 5.1859414149106725e-06, 'epoch': 8.58}
 86%|████████▌ | 781/910 [5:47:15<56:38, 26.34s/it] 86%|████████▌ | 782/910 [5:47:41<56:10, 26.34s/it]                                                   {'loss': 0.3765, 'grad_norm': 0.6172722190776413, 'learning_rate': 5.107243255921745e-06, 'epoch': 8.59}
 86%|████████▌ | 782/910 [5:47:41<56:10, 26.34s/it] 86%|████████▌ | 783/910 [5:48:07<55:33, 26.25s/it]                                                   {'loss': 0.3309, 'grad_norm': 0.6379463230788459, 'learning_rate': 5.029114655502937e-06, 'epoch': 8.6}
 86%|████████▌ | 783/910 [5:48:07<55:33, 26.25s/it] 86%|████████▌ | 784/910 [5:48:34<55:25, 26.39s/it]                                                   {'loss': 0.3747, 'grad_norm': 1.2153115919366018, 'learning_rate': 4.951556604879048e-06, 'epoch': 8.62}
 86%|████████▌ | 784/910 [5:48:34<55:25, 26.39s/it] 86%|████████▋ | 785/910 [5:49:00<55:02, 26.42s/it]                                                   {'loss': 0.377, 'grad_norm': 0.5261542655325585, 'learning_rate': 4.874570088036251e-06, 'epoch': 8.63}
 86%|████████▋ | 785/910 [5:49:00<55:02, 26.42s/it] 86%|████████▋ | 786/910 [5:49:27<54:41, 26.47s/it]                                                   {'loss': 0.3818, 'grad_norm': 0.6591618396273905, 'learning_rate': 4.798156081709637e-06, 'epoch': 8.64}
 86%|████████▋ | 786/910 [5:49:27<54:41, 26.47s/it] 86%|████████▋ | 787/910 [5:49:54<54:27, 26.57s/it]                                                   {'loss': 0.3835, 'grad_norm': 0.9244276917482129, 'learning_rate': 4.722315555370793e-06, 'epoch': 8.65}
 86%|████████▋ | 787/910 [5:49:54<54:27, 26.57s/it] 87%|████████▋ | 788/910 [5:50:20<54:08, 26.63s/it]                                                   {'loss': 0.3299, 'grad_norm': 0.48010350529881474, 'learning_rate': 4.647049471215498e-06, 'epoch': 8.66}
 87%|████████▋ | 788/910 [5:50:20<54:08, 26.63s/it] 87%|████████▋ | 789/910 [5:50:47<53:46, 26.66s/it]                                                   {'loss': 0.3678, 'grad_norm': 0.6369936170297138, 'learning_rate': 4.572358784151571e-06, 'epoch': 8.67}
 87%|████████▋ | 789/910 [5:50:47<53:46, 26.66s/it] 87%|████████▋ | 790/910 [5:51:14<53:23, 26.70s/it]                                                   {'loss': 0.4048, 'grad_norm': 1.2233127236774683, 'learning_rate': 4.498244441786675e-06, 'epoch': 8.68}
 87%|████████▋ | 790/910 [5:51:14<53:23, 26.70s/it] 87%|████████▋ | 791/910 [5:51:40<52:38, 26.54s/it]                                                   {'loss': 0.3941, 'grad_norm': 1.068273037995496, 'learning_rate': 4.424707384416344e-06, 'epoch': 8.69}
 87%|████████▋ | 791/910 [5:51:40<52:38, 26.54s/it] 87%|████████▋ | 792/910 [5:52:06<51:53, 26.38s/it]                                                   {'loss': 0.3469, 'grad_norm': 1.3483874310206498, 'learning_rate': 4.351748545012058e-06, 'epoch': 8.7}
 87%|████████▋ | 792/910 [5:52:06<51:53, 26.38s/it] 87%|████████▋ | 793/910 [5:52:33<51:27, 26.39s/it]                                                   {'loss': 0.3321, 'grad_norm': 0.8348725951545151, 'learning_rate': 4.279368849209381e-06, 'epoch': 8.71}
 87%|████████▋ | 793/910 [5:52:33<51:27, 26.39s/it] 87%|████████▋ | 794/910 [5:52:59<50:52, 26.31s/it]                                                   {'loss': 0.4888, 'grad_norm': 1.0207258241602093, 'learning_rate': 4.207569215296214e-06, 'epoch': 8.73}
 87%|████████▋ | 794/910 [5:52:59<50:52, 26.31s/it] 87%|████████▋ | 795/910 [5:53:25<50:17, 26.24s/it]                                                   {'loss': 0.4032, 'grad_norm': 0.6756205978016258, 'learning_rate': 4.136350554201196e-06, 'epoch': 8.74}
 87%|████████▋ | 795/910 [5:53:25<50:17, 26.24s/it] 87%|████████▋ | 796/910 [5:53:51<49:51, 26.25s/it]                                                   {'loss': 0.3615, 'grad_norm': 0.9657544357989524, 'learning_rate': 4.065713769482082e-06, 'epoch': 8.75}
 87%|████████▋ | 796/910 [5:53:51<49:51, 26.25s/it] 88%|████████▊ | 797/910 [5:54:17<49:27, 26.26s/it]                                                   {'loss': 0.3445, 'grad_norm': 0.7337125445804307, 'learning_rate': 3.995659757314296e-06, 'epoch': 8.76}
 88%|████████▊ | 797/910 [5:54:17<49:27, 26.26s/it] 88%|████████▊ | 798/910 [5:54:44<49:13, 26.37s/it]                                                   {'loss': 0.3908, 'grad_norm': 0.6082495592842607, 'learning_rate': 3.9261894064796135e-06, 'epoch': 8.77}
 88%|████████▊ | 798/910 [5:54:44<49:13, 26.37s/it] 88%|████████▊ | 799/910 [5:55:10<48:52, 26.42s/it]                                                   {'loss': 0.3637, 'grad_norm': 0.7282056771061081, 'learning_rate': 3.857303598354817e-06, 'epoch': 8.78}
 88%|████████▊ | 799/910 [5:55:10<48:52, 26.42s/it] 88%|████████▊ | 800/910 [5:55:37<48:32, 26.48s/it]                                                   {'loss': 0.37, 'grad_norm': 1.0307484202415118, 'learning_rate': 3.7890032069005375e-06, 'epoch': 8.79}
 88%|████████▊ | 800/910 [5:55:37<48:32, 26.48s/it] 88%|████████▊ | 801/910 [5:56:04<48:21, 26.62s/it]                                                   {'loss': 0.3989, 'grad_norm': 0.7462704885342976, 'learning_rate': 3.721289098650177e-06, 'epoch': 8.8}
 88%|████████▊ | 801/910 [5:56:04<48:21, 26.62s/it] 88%|████████▊ | 802/910 [5:56:31<47:54, 26.61s/it]                                                   {'loss': 0.4023, 'grad_norm': 0.7237996438759043, 'learning_rate': 3.654162132698918e-06, 'epoch': 8.81}
 88%|████████▊ | 802/910 [5:56:31<47:54, 26.61s/it] 88%|████████▊ | 803/910 [5:56:58<47:37, 26.70s/it]                                                   {'loss': 0.5436, 'grad_norm': 1.8518724180449089, 'learning_rate': 3.5876231606927937e-06, 'epoch': 8.82}
 88%|████████▊ | 803/910 [5:56:58<47:37, 26.70s/it] 88%|████████▊ | 804/910 [5:57:24<46:50, 26.51s/it]                                                   {'loss': 0.338, 'grad_norm': 0.7538840270649876, 'learning_rate': 3.5216730268179343e-06, 'epoch': 8.84}
 88%|████████▊ | 804/910 [5:57:24<46:50, 26.51s/it] 88%|████████▊ | 805/910 [5:57:50<46:15, 26.43s/it]                                                   {'loss': 0.3816, 'grad_norm': 0.8270736957469849, 'learning_rate': 3.4563125677897932e-06, 'epoch': 8.85}
 88%|████████▊ | 805/910 [5:57:50<46:15, 26.43s/it] 89%|████████▊ | 806/910 [5:58:16<45:38, 26.33s/it]                                                   {'loss': 0.3576, 'grad_norm': 0.5204715330496283, 'learning_rate': 3.391542612842574e-06, 'epoch': 8.86}
 89%|████████▊ | 806/910 [5:58:16<45:38, 26.33s/it] 89%|████████▊ | 807/910 [5:58:42<45:06, 26.28s/it]                                                   {'loss': 0.3852, 'grad_norm': 1.4475356380847095, 'learning_rate': 3.327363983718723e-06, 'epoch': 8.87}
 89%|████████▊ | 807/910 [5:58:42<45:06, 26.28s/it] 89%|████████▉ | 808/910 [5:59:08<44:39, 26.27s/it]                                                   {'loss': 0.3621, 'grad_norm': 0.712180914827079, 'learning_rate': 3.2637774946584486e-06, 'epoch': 8.88}
 89%|████████▉ | 808/910 [5:59:08<44:39, 26.27s/it] 89%|████████▉ | 809/910 [5:59:35<44:11, 26.26s/it]                                                   {'loss': 0.3839, 'grad_norm': 0.8004070849808375, 'learning_rate': 3.200783952389447e-06, 'epoch': 8.89}
 89%|████████▉ | 809/910 [5:59:35<44:11, 26.26s/it] 89%|████████▉ | 810/910 [6:00:01<43:52, 26.33s/it]                                                   {'loss': 0.3665, 'grad_norm': 0.8057093454579806, 'learning_rate': 3.138384156116614e-06, 'epoch': 8.9}
 89%|████████▉ | 810/910 [6:00:01<43:52, 26.33s/it] 89%|████████▉ | 811/910 [6:00:28<43:35, 26.42s/it]                                                   {'loss': 0.332, 'grad_norm': 0.9100374580286558, 'learning_rate': 3.076578897511978e-06, 'epoch': 8.91}
 89%|████████▉ | 811/910 [6:00:28<43:35, 26.42s/it] 89%|████████▉ | 812/910 [6:00:54<43:17, 26.51s/it]                                                   {'loss': 0.3862, 'grad_norm': 1.088529803493513, 'learning_rate': 3.0153689607045845e-06, 'epoch': 8.92}
 89%|████████▉ | 812/910 [6:00:54<43:17, 26.51s/it] 89%|████████▉ | 813/910 [6:01:21<42:53, 26.53s/it]                                                   {'loss': 0.396, 'grad_norm': 0.7774666617031434, 'learning_rate': 2.954755122270564e-06, 'epoch': 8.93}
 89%|████████▉ | 813/910 [6:01:21<42:53, 26.53s/it] 89%|████████▉ | 814/910 [6:01:48<42:28, 26.54s/it]                                                   {'loss': 0.3749, 'grad_norm': 1.135559249863782, 'learning_rate': 2.894738151223331e-06, 'epoch': 8.95}
 89%|████████▉ | 814/910 [6:01:48<42:28, 26.54s/it] 90%|████████▉ | 815/910 [6:02:14<42:11, 26.65s/it]                                                   {'loss': 0.4084, 'grad_norm': 0.7536512365229068, 'learning_rate': 2.835318809003751e-06, 'epoch': 8.96}
 90%|████████▉ | 815/910 [6:02:14<42:11, 26.65s/it] 90%|████████▉ | 816/910 [6:02:41<41:48, 26.69s/it]                                                   {'loss': 0.3893, 'grad_norm': 0.8021913950895325, 'learning_rate': 2.776497849470544e-06, 'epoch': 8.97}
 90%|████████▉ | 816/910 [6:02:41<41:48, 26.69s/it] 90%|████████▉ | 817/910 [6:03:08<41:18, 26.66s/it]                                                   {'loss': 0.3671, 'grad_norm': 0.7489248880918207, 'learning_rate': 2.71827601889067e-06, 'epoch': 8.98}
 90%|████████▉ | 817/910 [6:03:08<41:18, 26.66s/it] 90%|████████▉ | 818/910 [6:03:34<40:36, 26.48s/it]                                                   {'loss': 0.3691, 'grad_norm': 1.0790055503091962, 'learning_rate': 2.6606540559298953e-06, 'epoch': 8.99}
 90%|████████▉ | 818/910 [6:03:34<40:36, 26.48s/it] 90%|█████████ | 819/910 [6:04:01<40:38, 26.79s/it]                                                   {'loss': 0.3297, 'grad_norm': 2.8617353156042524, 'learning_rate': 2.603632691643415e-06, 'epoch': 9.0}
 90%|█████████ | 819/910 [6:04:01<40:38, 26.79s/it] 90%|█████████ | 820/910 [6:04:46<48:08, 32.09s/it]                                                   {'loss': 0.4257, 'grad_norm': 0.997417365684743, 'learning_rate': 2.547212649466568e-06, 'epoch': 9.01}
 90%|█████████ | 820/910 [6:04:46<48:08, 32.09s/it] 90%|█████████ | 821/910 [6:05:12<45:01, 30.35s/it]                                                   {'loss': 0.3856, 'grad_norm': 0.5841298816725561, 'learning_rate': 2.4913946452056693e-06, 'epoch': 9.02}
 90%|█████████ | 821/910 [6:05:12<45:01, 30.35s/it] 90%|█████████ | 822/910 [6:05:39<42:55, 29.27s/it]                                                   {'loss': 0.3388, 'grad_norm': 0.5852709790278706, 'learning_rate': 2.436179387028903e-06, 'epoch': 9.03}
 90%|█████████ | 822/910 [6:05:39<42:55, 29.27s/it] 90%|█████████ | 823/910 [6:06:06<41:21, 28.52s/it]                                                   {'loss': 0.4163, 'grad_norm': 1.0235332057123547, 'learning_rate': 2.3815675754573885e-06, 'epoch': 9.04}
 90%|█████████ | 823/910 [6:06:06<41:21, 28.52s/it] 91%|█████████ | 824/910 [6:06:32<40:06, 27.98s/it]                                                   {'loss': 0.5442, 'grad_norm': 2.2109269848434767, 'learning_rate': 2.327559903356241e-06, 'epoch': 9.05}
 91%|█████████ | 824/910 [6:06:32<40:06, 27.98s/it] 91%|█████████ | 825/910 [6:06:59<39:01, 27.55s/it]                                                   {'loss': 0.4543, 'grad_norm': 1.3921555724602264, 'learning_rate': 2.274157055925802e-06, 'epoch': 9.07}
 91%|█████████ | 825/910 [6:06:59<39:01, 27.55s/it] 91%|█████████ | 826/910 [6:07:26<38:13, 27.31s/it]                                                   {'loss': 0.4286, 'grad_norm': 3.3651552978009303, 'learning_rate': 2.221359710692961e-06, 'epoch': 9.08}
 91%|█████████ | 826/910 [6:07:26<38:13, 27.31s/it] 91%|█████████ | 827/910 [6:07:53<37:36, 27.19s/it]                                                   {'loss': 0.4237, 'grad_norm': 0.965021494756213, 'learning_rate': 2.169168537502536e-06, 'epoch': 9.09}
 91%|█████████ | 827/910 [6:07:53<37:36, 27.19s/it] 91%|█████████ | 828/910 [6:08:19<36:58, 27.05s/it]                                                   {'loss': 0.4203, 'grad_norm': 1.1012997156852689, 'learning_rate': 2.1175841985087707e-06, 'epoch': 9.1}
 91%|█████████ | 828/910 [6:08:19<36:58, 27.05s/it] 91%|█████████ | 829/910 [6:08:46<36:28, 27.01s/it]                                                   {'loss': 0.3127, 'grad_norm': 0.6817016594454022, 'learning_rate': 2.066607348166971e-06, 'epoch': 9.11}
 91%|█████████ | 829/910 [6:08:46<36:28, 27.01s/it] 91%|█████████ | 830/910 [6:09:13<35:45, 26.82s/it]                                                   {'loss': 0.3237, 'grad_norm': 0.9036792487306519, 'learning_rate': 2.0162386332251648e-06, 'epoch': 9.12}
 91%|█████████ | 830/910 [6:09:13<35:45, 26.82s/it] 91%|█████████▏| 831/910 [6:09:39<34:59, 26.57s/it]                                                   {'loss': 0.3556, 'grad_norm': 0.5917171301650395, 'learning_rate': 1.9664786927159062e-06, 'epoch': 9.13}
 91%|█████████▏| 831/910 [6:09:39<34:59, 26.57s/it] 91%|█████████▏| 832/910 [6:10:05<34:24, 26.47s/it]                                                   {'loss': 0.442, 'grad_norm': 1.444085723456088, 'learning_rate': 1.9173281579481892e-06, 'epoch': 9.14}
 91%|█████████▏| 832/910 [6:10:05<34:24, 26.47s/it] 92%|█████████▏| 833/910 [6:10:31<33:52, 26.40s/it]                                                   {'loss': 0.3426, 'grad_norm': 0.4684117868502638, 'learning_rate': 1.8687876524993987e-06, 'epoch': 9.15}
 92%|█████████▏| 833/910 [6:10:31<33:52, 26.40s/it] 92%|█████████▏| 834/910 [6:10:57<33:19, 26.31s/it]                                                   {'loss': 0.3625, 'grad_norm': 0.6201015242353882, 'learning_rate': 1.820857792207431e-06, 'epoch': 9.16}
 92%|█████████▏| 834/910 [6:10:57<33:19, 26.31s/it] 92%|█████████▏| 835/910 [6:11:23<32:49, 26.26s/it]                                                   {'loss': 0.3563, 'grad_norm': 0.5928230089995619, 'learning_rate': 1.7735391851628813e-06, 'epoch': 9.18}
 92%|█████████▏| 835/910 [6:11:23<32:49, 26.26s/it] 92%|█████████▏| 836/910 [6:11:50<32:40, 26.49s/it]                                                   {'loss': 0.3995, 'grad_norm': 0.7949329289930578, 'learning_rate': 1.7268324317012975e-06, 'epoch': 9.19}
 92%|█████████▏| 836/910 [6:11:50<32:40, 26.49s/it] 92%|█████████▏| 837/910 [6:12:17<32:13, 26.49s/it]                                                   {'loss': 0.3651, 'grad_norm': 1.0717358796300795, 'learning_rate': 1.6807381243955977e-06, 'epoch': 9.2}
 92%|█████████▏| 837/910 [6:12:17<32:13, 26.49s/it] 92%|█████████▏| 838/910 [6:12:43<31:46, 26.48s/it]                                                   {'loss': 0.5537, 'grad_norm': 0.9384352434362634, 'learning_rate': 1.6352568480485276e-06, 'epoch': 9.21}
 92%|█████████▏| 838/910 [6:12:43<31:46, 26.48s/it] 92%|█████████▏| 839/910 [6:13:10<31:22, 26.52s/it]                                                   {'loss': 0.3092, 'grad_norm': 0.457847464420505, 'learning_rate': 1.5903891796852754e-06, 'epoch': 9.22}
 92%|█████████▏| 839/910 [6:13:10<31:22, 26.52s/it] 92%|█████████▏| 840/910 [6:13:37<31:03, 26.62s/it]                                                   {'loss': 0.397, 'grad_norm': 0.8098903208711922, 'learning_rate': 1.5461356885461075e-06, 'epoch': 9.23}
 92%|█████████▏| 840/910 [6:13:37<31:03, 26.62s/it] 92%|█████████▏| 841/910 [6:14:03<30:38, 26.64s/it]                                                   {'loss': 0.3367, 'grad_norm': 0.620336197918451, 'learning_rate': 1.5024969360791564e-06, 'epoch': 9.24}
 92%|█████████▏| 841/910 [6:14:03<30:38, 26.64s/it] 93%|█████████▎| 842/910 [6:14:31<30:20, 26.77s/it]                                                   {'loss': 0.4152, 'grad_norm': 3.3323610551557876, 'learning_rate': 1.4594734759333483e-06, 'epoch': 9.25}
 93%|█████████▎| 842/910 [6:14:31<30:20, 26.77s/it] 93%|█████████▎| 843/910 [6:14:57<29:41, 26.59s/it]                                                   {'loss': 0.3378, 'grad_norm': 0.9363094633655985, 'learning_rate': 1.4170658539512994e-06, 'epoch': 9.26}
 93%|█████████▎| 843/910 [6:14:57<29:41, 26.59s/it] 93%|█████████▎| 844/910 [6:15:23<29:05, 26.44s/it]                                                   {'loss': 0.3721, 'grad_norm': 0.7162012236716803, 'learning_rate': 1.3752746081624467e-06, 'epoch': 9.27}
 93%|█████████▎| 844/910 [6:15:23<29:05, 26.44s/it] 93%|█████████▎| 845/910 [6:15:49<28:34, 26.38s/it]                                                   {'loss': 0.6376, 'grad_norm': 4.827269253678325, 'learning_rate': 1.3341002687762062e-06, 'epoch': 9.29}
 93%|█████████▎| 845/910 [6:15:49<28:34, 26.38s/it] 93%|█████████▎| 846/910 [6:16:15<28:04, 26.32s/it]                                                   {'loss': 0.3788, 'grad_norm': 0.7439753021025483, 'learning_rate': 1.2935433581752364e-06, 'epoch': 9.3}
 93%|█████████▎| 846/910 [6:16:15<28:04, 26.32s/it] 93%|█████████▎| 847/910 [6:16:41<27:37, 26.31s/it]                                                   {'loss': 0.3801, 'grad_norm': 0.893045676127842, 'learning_rate': 1.2536043909088191e-06, 'epoch': 9.31}
 93%|█████████▎| 847/910 [6:16:41<27:37, 26.31s/it] 93%|█████████▎| 848/910 [6:17:08<27:13, 26.34s/it]                                                   {'loss': 0.3542, 'grad_norm': 0.9953315932663133, 'learning_rate': 1.2142838736863559e-06, 'epoch': 9.32}
 93%|█████████▎| 848/910 [6:17:08<27:13, 26.34s/it] 93%|█████████▎| 849/910 [6:17:34<26:46, 26.34s/it]                                                   {'loss': 0.3372, 'grad_norm': 0.8805653626512817, 'learning_rate': 1.175582305370887e-06, 'epoch': 9.33}
 93%|█████████▎| 849/910 [6:17:34<26:46, 26.34s/it] 93%|█████████▎| 850/910 [6:18:01<26:26, 26.44s/it]                                                   {'loss': 0.3804, 'grad_norm': 0.5489473110634397, 'learning_rate': 1.1375001769727999e-06, 'epoch': 9.34}
 93%|█████████▎| 850/910 [6:18:01<26:26, 26.44s/it] 94%|█████████▎| 851/910 [6:18:28<26:05, 26.53s/it]                                                   {'loss': 0.4285, 'grad_norm': 1.4335681843661137, 'learning_rate': 1.1000379716435916e-06, 'epoch': 9.35}
 94%|█████████▎| 851/910 [6:18:28<26:05, 26.53s/it] 94%|█████████▎| 852/910 [6:18:54<25:40, 26.56s/it]                                                   {'loss': 0.4536, 'grad_norm': 0.7061970470898764, 'learning_rate': 1.0631961646697387e-06, 'epoch': 9.36}
 94%|█████████▎| 852/910 [6:18:54<25:40, 26.56s/it] 94%|█████████▎| 853/910 [6:19:21<25:18, 26.64s/it]                                                   {'loss': 0.3361, 'grad_norm': 0.770238112303094, 'learning_rate': 1.026975223466664e-06, 'epoch': 9.37}
 94%|█████████▎| 853/910 [6:19:21<25:18, 26.64s/it] 94%|█████████▍| 854/910 [6:19:48<24:50, 26.61s/it]                                                   {'loss': 0.3991, 'grad_norm': 0.8204765921718492, 'learning_rate': 9.913756075728087e-07, 'epoch': 9.38}
 94%|█████████▍| 854/910 [6:19:48<24:50, 26.61s/it] 94%|█████████▍| 855/910 [6:20:15<24:31, 26.75s/it]                                                   {'loss': 0.3992, 'grad_norm': 0.8056287587530037, 'learning_rate': 9.56397768643802e-07, 'epoch': 9.4}
 94%|█████████▍| 855/910 [6:20:15<24:31, 26.75s/it] 94%|█████████▍| 856/910 [6:20:41<24:03, 26.73s/it]                                                   {'loss': 0.3928, 'grad_norm': 3.464145831340217, 'learning_rate': 9.220421504467281e-07, 'epoch': 9.41}
 94%|█████████▍| 856/910 [6:20:41<24:03, 26.73s/it] 94%|█████████▍| 857/910 [6:21:08<23:27, 26.57s/it]                                                   {'loss': 0.3389, 'grad_norm': 0.6294382919614999, 'learning_rate': 8.883091888545136e-07, 'epoch': 9.42}
 94%|█████████▍| 857/910 [6:21:08<23:27, 26.57s/it] 94%|█████████▍| 858/910 [6:21:34<22:57, 26.50s/it]                                                   {'loss': 0.268, 'grad_norm': 0.7963176923723043, 'learning_rate': 8.551993118403657e-07, 'epoch': 9.43}
 94%|█████████▍| 858/910 [6:21:34<22:57, 26.50s/it] 94%|█████████▍| 859/910 [6:22:00<22:24, 26.36s/it]                                                   {'loss': 0.3913, 'grad_norm': 0.8011377072564687, 'learning_rate': 8.227129394723642e-07, 'epoch': 9.44}
 94%|█████████▍| 859/910 [6:22:00<22:24, 26.36s/it] 95%|█████████▍| 860/910 [6:22:26<21:52, 26.24s/it]                                                   {'loss': 0.38, 'grad_norm': 0.9531976582088844, 'learning_rate': 7.908504839081343e-07, 'epoch': 9.45}
 95%|█████████▍| 860/910 [6:22:26<21:52, 26.24s/it] 95%|█████████▍| 861/910 [6:22:52<21:25, 26.23s/it]                                                   {'loss': 0.3234, 'grad_norm': 1.090232577138408, 'learning_rate': 7.596123493895991e-07, 'epoch': 9.46}
 95%|█████████▍| 861/910 [6:22:52<21:25, 26.23s/it] 95%|█████████▍| 862/910 [6:23:18<20:58, 26.22s/it]                                                   {'loss': 0.3217, 'grad_norm': 0.6803351506818935, 'learning_rate': 7.289989322378732e-07, 'epoch': 9.47}
 95%|█████████▍| 862/910 [6:23:18<20:58, 26.22s/it] 95%|█████████▍| 863/910 [6:23:45<20:37, 26.32s/it]                                                   {'loss': 0.3765, 'grad_norm': 1.0601308846837967, 'learning_rate': 6.990106208482228e-07, 'epoch': 9.48}
 95%|█████████▍| 863/910 [6:23:45<20:37, 26.32s/it] 95%|█████████▍| 864/910 [6:24:12<20:17, 26.46s/it]                                                   {'loss': 0.3697, 'grad_norm': 0.5127133503821472, 'learning_rate': 6.696477956851355e-07, 'epoch': 9.49}
 95%|█████████▍| 864/910 [6:24:12<20:17, 26.46s/it] 95%|█████████▌| 865/910 [6:24:38<19:50, 26.46s/it]                                                   {'loss': 0.3665, 'grad_norm': 1.173476655810167, 'learning_rate': 6.409108292774913e-07, 'epoch': 9.51}
 95%|█████████▌| 865/910 [6:24:38<19:50, 26.46s/it] 95%|█████████▌| 866/910 [6:25:05<19:26, 26.50s/it]                                                   {'loss': 0.3849, 'grad_norm': 1.5314282474392769, 'learning_rate': 6.128000862138661e-07, 'epoch': 9.52}
 95%|█████████▌| 866/910 [6:25:05<19:26, 26.50s/it] 95%|█████████▌| 867/910 [6:25:32<19:03, 26.58s/it]                                                   {'loss': 0.3728, 'grad_norm': 1.4166533173601763, 'learning_rate': 5.853159231378469e-07, 'epoch': 9.53}
 95%|█████████▌| 867/910 [6:25:32<19:03, 26.58s/it] 95%|█████████▌| 868/910 [6:25:58<18:40, 26.67s/it]                                                   {'loss': 0.3719, 'grad_norm': 0.8735665371353791, 'learning_rate': 5.584586887435739e-07, 'epoch': 9.54}
 95%|█████████▌| 868/910 [6:25:58<18:40, 26.67s/it] 95%|█████████▌| 869/910 [6:26:25<18:10, 26.60s/it]                                                   {'loss': 0.42, 'grad_norm': 1.470195388787714, 'learning_rate': 5.322287237712665e-07, 'epoch': 9.55}
 95%|█████████▌| 869/910 [6:26:25<18:10, 26.60s/it] 96%|█████████▌| 870/910 [6:26:51<17:39, 26.48s/it]                                                   {'loss': 0.3564, 'grad_norm': 0.6392224127235416, 'learning_rate': 5.06626361002921e-07, 'epoch': 9.56}
 96%|█████████▌| 870/910 [6:26:51<17:39, 26.48s/it] 96%|█████████▌| 871/910 [6:27:17<17:08, 26.38s/it]                                                   {'loss': 0.3783, 'grad_norm': 0.6662630721287154, 'learning_rate': 4.816519252580976e-07, 'epoch': 9.57}
 96%|█████████▌| 871/910 [6:27:17<17:08, 26.38s/it] 96%|█████████▌| 872/910 [6:27:43<16:38, 26.29s/it]                                                   {'loss': 0.3526, 'grad_norm': 1.1258689240882382, 'learning_rate': 4.573057333897679e-07, 'epoch': 9.58}
 96%|█████████▌| 872/910 [6:27:43<16:38, 26.29s/it] 96%|█████████▌| 873/910 [6:28:10<16:13, 26.32s/it]                                                   {'loss': 0.322, 'grad_norm': 0.62259545108166, 'learning_rate': 4.335880942803405e-07, 'epoch': 9.59}
 96%|█████████▌| 873/910 [6:28:10<16:13, 26.32s/it] 96%|█████████▌| 874/910 [6:28:36<15:48, 26.35s/it]                                                   {'loss': 0.3517, 'grad_norm': 4.455739741597988, 'learning_rate': 4.104993088376974e-07, 'epoch': 9.6}
 96%|█████████▌| 874/910 [6:28:36<15:48, 26.35s/it] 96%|█████████▌| 875/910 [6:29:02<15:20, 26.29s/it]                                                   {'loss': 0.3713, 'grad_norm': 3.1477941957969935, 'learning_rate': 3.8803966999139684e-07, 'epoch': 9.62}
 96%|█████████▌| 875/910 [6:29:02<15:20, 26.29s/it] 96%|█████████▋| 876/910 [6:29:29<14:57, 26.40s/it]                                                   {'loss': 0.3519, 'grad_norm': 1.0131527123632367, 'learning_rate': 3.662094626889656e-07, 'epoch': 9.63}
 96%|█████████▋| 876/910 [6:29:29<14:57, 26.40s/it] 96%|█████████▋| 877/910 [6:29:55<14:31, 26.40s/it]                                                   {'loss': 0.3941, 'grad_norm': 0.9408392719323904, 'learning_rate': 3.4500896389227376e-07, 'epoch': 9.64}
 96%|█████████▋| 877/910 [6:29:55<14:31, 26.40s/it] 96%|█████████▋| 878/910 [6:30:22<14:06, 26.45s/it]                                                   {'loss': 0.3622, 'grad_norm': 0.8477148144717753, 'learning_rate': 3.2443844257400434e-07, 'epoch': 9.65}
 96%|█████████▋| 878/910 [6:30:22<14:06, 26.45s/it] 97%|█████████▋| 879/910 [6:30:49<13:43, 26.58s/it]                                                   {'loss': 0.4062, 'grad_norm': 0.6801340046908676, 'learning_rate': 3.0449815971428377e-07, 'epoch': 9.66}
 97%|█████████▋| 879/910 [6:30:49<13:43, 26.58s/it] 97%|█████████▋| 880/910 [6:31:15<13:18, 26.60s/it]                                                   {'loss': 0.3352, 'grad_norm': 0.6738917303718419, 'learning_rate': 2.851883682973233e-07, 'epoch': 9.67}
 97%|█████████▋| 880/910 [6:31:15<13:18, 26.60s/it] 97%|█████████▋| 881/910 [6:31:42<12:51, 26.60s/it]                                                   {'loss': 0.446, 'grad_norm': 0.9549914550010922, 'learning_rate': 2.6650931330823303e-07, 'epoch': 9.68}
 97%|█████████▋| 881/910 [6:31:42<12:51, 26.60s/it] 97%|█████████▋| 882/910 [6:32:08<12:23, 26.56s/it]                                                   {'loss': 0.4134, 'grad_norm': 0.8931303074711412, 'learning_rate': 2.4846123172992954e-07, 'epoch': 9.69}
 97%|█████████▋| 882/910 [6:32:08<12:23, 26.56s/it] 97%|█████████▋| 883/910 [6:32:35<11:53, 26.43s/it]                                                   {'loss': 0.3768, 'grad_norm': 0.8257285502815932, 'learning_rate': 2.310443525400885e-07, 'epoch': 9.7}
 97%|█████████▋| 883/910 [6:32:35<11:53, 26.43s/it] 97%|█████████▋| 884/910 [6:33:01<11:25, 26.35s/it]                                                   {'loss': 0.4203, 'grad_norm': 0.8041016167606483, 'learning_rate': 2.1425889670827482e-07, 'epoch': 9.71}
 97%|█████████▋| 884/910 [6:33:01<11:25, 26.35s/it] 97%|█████████▋| 885/910 [6:33:27<10:57, 26.29s/it]                                                   {'loss': 0.3874, 'grad_norm': 0.9858556223647185, 'learning_rate': 1.981050771931281e-07, 'epoch': 9.73}
 97%|█████████▋| 885/910 [6:33:27<10:57, 26.29s/it] 97%|█████████▋| 886/910 [6:33:53<10:29, 26.24s/it]                                                   {'loss': 0.4412, 'grad_norm': 1.1866726738658178, 'learning_rate': 1.8258309893965375e-07, 'epoch': 9.74}
 97%|█████████▋| 886/910 [6:33:53<10:29, 26.24s/it] 97%|█████████▋| 887/910 [6:34:19<10:03, 26.22s/it]                                                   {'loss': 0.3503, 'grad_norm': 0.6996706879229693, 'learning_rate': 1.6769315887662506e-07, 'epoch': 9.75}
 97%|█████████▋| 887/910 [6:34:19<10:03, 26.22s/it] 98%|█████████▊| 888/910 [6:34:45<09:37, 26.24s/it]                                                   {'loss': 0.3691, 'grad_norm': 1.1467067362668624, 'learning_rate': 1.534354459140963e-07, 'epoch': 9.76}
 98%|█████████▊| 888/910 [6:34:45<09:37, 26.24s/it] 98%|█████████▊| 889/910 [6:35:12<09:12, 26.31s/it]                                                   {'loss': 0.3107, 'grad_norm': 0.6329320987526426, 'learning_rate': 1.3981014094099353e-07, 'epoch': 9.77}
 98%|█████████▊| 889/910 [6:35:12<09:12, 26.31s/it] 98%|█████████▊| 890/910 [6:35:39<08:48, 26.41s/it]                                                   {'loss': 0.3649, 'grad_norm': 0.7690598068439777, 'learning_rate': 1.2681741682282754e-07, 'epoch': 9.78}
 98%|█████████▊| 890/910 [6:35:39<08:48, 26.41s/it] 98%|█████████▊| 891/910 [6:36:05<08:24, 26.55s/it]                                                   {'loss': 0.2907, 'grad_norm': 2.9749354740551928, 'learning_rate': 1.1445743839949008e-07, 'epoch': 9.79}
 98%|█████████▊| 891/910 [6:36:05<08:24, 26.55s/it] 98%|█████████▊| 892/910 [6:36:32<07:57, 26.55s/it]                                                   {'loss': 0.38, 'grad_norm': 0.7501574572885187, 'learning_rate': 1.0273036248318324e-07, 'epoch': 9.8}
 98%|█████████▊| 892/910 [6:36:32<07:57, 26.55s/it] 98%|█████████▊| 893/910 [6:36:59<07:31, 26.57s/it]                                                   {'loss': 0.3588, 'grad_norm': 0.6697300938450677, 'learning_rate': 9.163633785639891e-08, 'epoch': 9.81}
 98%|█████████▊| 893/910 [6:36:59<07:31, 26.57s/it] 98%|█████████▊| 894/910 [6:37:25<07:05, 26.60s/it]                                                   {'loss': 0.3695, 'grad_norm': 0.5218007748567256, 'learning_rate': 8.117550527005912e-08, 'epoch': 9.82}
 98%|█████████▊| 894/910 [6:37:25<07:05, 26.60s/it] 98%|█████████▊| 895/910 [6:37:52<06:39, 26.67s/it]                                                   {'loss': 0.376, 'grad_norm': 0.8126394274829117, 'learning_rate': 7.134799744171749e-08, 'epoch': 9.84}
 98%|█████████▊| 895/910 [6:37:52<06:39, 26.67s/it] 98%|█████████▊| 896/910 [6:38:18<06:11, 26.51s/it]                                                   {'loss': 0.3899, 'grad_norm': 0.9917640206275264, 'learning_rate': 6.215393905388278e-08, 'epoch': 9.85}
 98%|█████████▊| 896/910 [6:38:18<06:11, 26.51s/it] 99%|█████████▊| 897/910 [6:38:45<05:43, 26.45s/it]                                                   {'loss': 0.4072, 'grad_norm': 0.822013320402771, 'learning_rate': 5.359344675242017e-08, 'epoch': 9.86}
 99%|█████████▊| 897/910 [6:38:45<05:43, 26.45s/it] 99%|█████████▊| 898/910 [6:39:11<05:16, 26.39s/it]                                                   {'loss': 0.3303, 'grad_norm': 0.8947682682795072, 'learning_rate': 4.566662914508579e-08, 'epoch': 9.87}
 99%|█████████▊| 898/910 [6:39:11<05:16, 26.39s/it] 99%|█████████▉| 899/910 [6:39:37<04:49, 26.32s/it]                                                   {'loss': 0.372, 'grad_norm': 0.6588780367532449, 'learning_rate': 3.837358680016112e-08, 'epoch': 9.88}
 99%|█████████▉| 899/910 [6:39:37<04:49, 26.32s/it] 99%|█████████▉| 900/910 [6:40:03<04:23, 26.31s/it]                                                   {'loss': 0.3508, 'grad_norm': 0.7058943048473549, 'learning_rate': 3.171441224514848e-08, 'epoch': 9.89}
 99%|█████████▉| 900/910 [6:40:03<04:23, 26.31s/it] 99%|█████████▉| 901/910 [6:40:30<03:56, 26.29s/it]                                                   {'loss': 0.3095, 'grad_norm': 1.658438999436532, 'learning_rate': 2.568918996560532e-08, 'epoch': 9.9}
 99%|█████████▉| 901/910 [6:40:30<03:56, 26.29s/it] 99%|█████████▉| 902/910 [6:40:56<03:30, 26.37s/it]                                                   {'loss': 0.3447, 'grad_norm': 0.6864368501158845, 'learning_rate': 2.029799640409502e-08, 'epoch': 9.91}
 99%|█████████▉| 902/910 [6:40:56<03:30, 26.37s/it] 99%|█████████▉| 903/910 [6:41:23<03:04, 26.42s/it]                                                   {'loss': 0.4138, 'grad_norm': 1.1922355921823338, 'learning_rate': 1.5540899959187727e-08, 'epoch': 9.92}
 99%|█████████▉| 903/910 [6:41:23<03:04, 26.42s/it] 99%|█████████▉| 904/910 [6:41:49<02:38, 26.44s/it]                                                   {'loss': 0.38, 'grad_norm': 2.5167397787087182, 'learning_rate': 1.1417960984605458e-08, 'epoch': 9.93}
 99%|█████████▉| 904/910 [6:41:49<02:38, 26.44s/it] 99%|█████████▉| 905/910 [6:42:16<02:12, 26.57s/it]                                                   {'loss': 0.3977, 'grad_norm': 0.8247455714792817, 'learning_rate': 7.92923178845606e-09, 'epoch': 9.95}
 99%|█████████▉| 905/910 [6:42:16<02:12, 26.57s/it]100%|█████████▉| 906/910 [6:42:43<01:46, 26.59s/it]                                                   {'loss': 0.3586, 'grad_norm': 0.9504339180751709, 'learning_rate': 5.074756632572619e-09, 'epoch': 9.96}
100%|█████████▉| 906/910 [6:42:43<01:46, 26.59s/it]100%|█████████▉| 907/910 [6:43:09<01:19, 26.57s/it]                                                   {'loss': 0.3932, 'grad_norm': 2.323917097311571, 'learning_rate': 2.854571731947253e-09, 'epoch': 9.97}
100%|█████████▉| 907/910 [6:43:09<01:19, 26.57s/it]100%|█████████▉| 908/910 [6:43:36<00:53, 26.65s/it]                                                   {'loss': 0.3198, 'grad_norm': 0.5648887834155293, 'learning_rate': 1.2687052542759147e-09, 'epoch': 9.98}
100%|█████████▉| 908/910 [6:43:36<00:53, 26.65s/it]100%|█████████▉| 909/910 [6:44:03<00:26, 26.63s/it]                                                   {'loss': 0.3814, 'grad_norm': 0.8817224388625787, 'learning_rate': 3.171773195809191e-10, 'epoch': 9.99}
100%|█████████▉| 909/910 [6:44:03<00:26, 26.63s/it]100%|██████████| 910/910 [6:44:31<00:00, 27.11s/it]                                                   {'loss': 0.3484, 'grad_norm': 0.5567719395543657, 'learning_rate': 0.0, 'epoch': 10.0}
100%|██████████| 910/910 [6:44:31<00:00, 27.11s/it]                                                   {'train_runtime': 24286.1484, 'train_samples_per_second': 1.799, 'train_steps_per_second': 0.037, 'train_loss': 0.4265837345476989, 'epoch': 10.0}
100%|██████████| 910/910 [6:44:46<00:00, 27.11s/it]100%|██████████| 910/910 [6:44:46<00:00, 26.69s/it]
Rank 0:  Model saved to exp/llada_v_finetune
