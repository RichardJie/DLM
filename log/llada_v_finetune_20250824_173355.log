[2025-08-24 17:33:59,882] torch.distributed.run: [WARNING] 
[2025-08-24 17:33:59,882] torch.distributed.run: [WARNING] *****************************************
[2025-08-24 17:33:59,882] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2025-08-24 17:33:59,882] torch.distributed.run: [WARNING] *****************************************
[2025-08-24 17:34:04,672] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-24 17:34:04,674] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-24 17:34:04,674] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Please install pyav to use video processing functions.
/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Please install pyav to use video processing functions.
/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Please install pyav to use video processing functions.
/hpc2hdd/home/yuxuanzhao/miniconda3/envs/dllm/lib/python3.9/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
OpenCLIP not installed
OpenCLIP not installed
OpenCLIP not installed
[2025-08-24 17:34:11,676] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-08-24 17:34:11,676] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-08-24 17:34:11,695] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-08-24 17:34:11,718] [INFO] [comm.py:637:init_distributed] cdb=None
You are using a model of type llava_llada to instantiate a model of type llada. This is not supported for all configurations of models and can yield errors.
Rank 0:  Overwriting config with {'use_pos_skipping': False, 'pos_skipping_range': 4096, 'mm_spatial_pool_mode': 'bilinear'}
You are using a model of type llava_llada to instantiate a model of type llada. This is not supported for all configurations of models and can yield errors.
You are using a model of type llava_llada to instantiate a model of type llada. This is not supported for all configurations of models and can yield errors.
Rank 0:  Loading vision tower: google/siglip2-so400m-patch14-384
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:03<00:15,  3.17s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:03<00:15,  3.13s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:03<00:15,  3.20s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:06<00:13,  3.26s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:06<00:13,  3.29s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:06<00:12,  3.24s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:09<00:09,  3.12s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:09<00:09,  3.13s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:09<00:09,  3.10s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:12<00:06,  3.12s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:12<00:06,  3.14s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:12<00:06,  3.14s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:15<00:03,  3.16s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:15<00:03,  3.15s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:15<00:03,  3.12s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:17<00:00,  2.76s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:17<00:00,  2.96s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:17<00:00,  2.78s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:17<00:00,  2.97s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:17<00:00,  2.76s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:17<00:00,  2.96s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Rank 0:  Prompt version: llava_llada
Rank 0:  google/siglip2-so400m-patch14-384 is already loaded, `load_model` called again, skipping.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Rank 0:  Using mm_tunable_parts: mm_mlp_adapter
Rank 0:  Total parameters: ~8433.89 MB)
Rank 0:  Trainable parameters: ~21.50 MB)
Rank 0:  Loading data using traditional JSON format
Rank 0:  Loading /hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/dataset/textvqa_bbox_coords_384/textvqa_bbox_coords_llava_384.json
Rank 0:  Loaded 4370 samples from /hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/dataset/textvqa_bbox_coords_384/textvqa_bbox_coords_llava_384.json
Rank 0:  Loaded 4370 samples from /hpc2ssd/JH_DATA/spooler/yuxuanzhao/lijungang/wujie/LLaDA-V/dataset/textvqa_bbox_coords_384/textvqa_bbox_coords_llava_384.json
Rank 0:  Formatting inputs...Skip in lazy mode
Rank 0:  Setting NCCL timeout to INF to avoid running errors.
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Installed CUDA version 12.2 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination
Using /hpc2hdd/home/yuxuanzhao/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Installed CUDA version 12.2 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combinationInstalled CUDA version 12.2 does not match the version torch was compiled with 12.1 but since the APIs are compatible, accepting this combination

Using /hpc2hdd/home/yuxuanzhao/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Using /hpc2hdd/home/yuxuanzhao/.cache/torch_extensions/py39_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /hpc2hdd/home/yuxuanzhao/.cache/torch_extensions/py39_cu121/fused_adam/build.ninja...
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module fused_adam...
Loading extension module fused_adam...
Loading extension module fused_adam...
Time to load fused_adam op: 0.5118722915649414 seconds
Time to load fused_adam op: 0.513606071472168 seconds
Time to load fused_adam op: 0.5292558670043945 seconds
  0%|          | 0/1456 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
  0%|          | 1/1456 [00:12<4:52:29, 12.06s/it]                                                  {'loss': 1.1776, 'grad_norm': 3.986598452831824, 'learning_rate': 1.1363636363636364e-07, 'epoch': 0.0}
  0%|          | 1/1456 [00:12<4:52:29, 12.06s/it]  0%|          | 2/1456 [00:17<3:21:39,  8.32s/it]                                                  {'loss': 1.6354, 'grad_norm': 3.540333635373347, 'learning_rate': 2.2727272727272729e-07, 'epoch': 0.01}
  0%|          | 2/1456 [00:17<3:21:39,  8.32s/it]  0%|          | 3/1456 [00:23<2:48:24,  6.95s/it]                                                  {'loss': 2.3386, 'grad_norm': 4.814998424050459, 'learning_rate': 3.409090909090909e-07, 'epoch': 0.01}
  0%|          | 3/1456 [00:23<2:48:24,  6.95s/it]  0%|          | 4/1456 [00:28<2:29:08,  6.16s/it]                                                  {'loss': 1.8952, 'grad_norm': 2.845481261727064, 'learning_rate': 4.5454545454545457e-07, 'epoch': 0.01}
  0%|          | 4/1456 [00:28<2:29:08,  6.16s/it]  0%|          | 5/1456 [00:33<2:19:16,  5.76s/it]                                                  {'loss': 1.4199, 'grad_norm': 6.618699442640655, 'learning_rate': 5.681818181818182e-07, 'epoch': 0.01}
  0%|          | 5/1456 [00:33<2:19:16,  5.76s/it]  0%|          | 6/1456 [00:38<2:12:32,  5.48s/it]                                                  {'loss': 1.7766, 'grad_norm': 6.971695213444856, 'learning_rate': 6.818181818181818e-07, 'epoch': 0.02}
  0%|          | 6/1456 [00:38<2:12:32,  5.48s/it]  0%|          | 7/1456 [00:43<2:09:19,  5.36s/it]                                                  {'loss': 1.7724, 'grad_norm': 11.240645185531466, 'learning_rate': 7.954545454545455e-07, 'epoch': 0.02}
  0%|          | 7/1456 [00:43<2:09:19,  5.36s/it]  1%|          | 8/1456 [00:48<2:06:08,  5.23s/it]                                                  {'loss': 0.8709, 'grad_norm': 3.845109900601682, 'learning_rate': 9.090909090909091e-07, 'epoch': 0.02}
  1%|          | 8/1456 [00:48<2:06:08,  5.23s/it]  1%|          | 9/1456 [00:53<2:04:41,  5.17s/it]                                                  {'loss': 1.3814, 'grad_norm': 2.6697653310853346, 'learning_rate': 1.0227272727272729e-06, 'epoch': 0.02}
  1%|          | 9/1456 [00:53<2:04:41,  5.17s/it]  1%|          | 10/1456 [00:58<2:03:38,  5.13s/it]                                                   {'loss': 1.0436, 'grad_norm': 13.215398557486003, 'learning_rate': 1.1363636363636364e-06, 'epoch': 0.03}
  1%|          | 10/1456 [00:58<2:03:38,  5.13s/it]  1%|          | 11/1456 [01:03<2:02:32,  5.09s/it]                                                   {'loss': 1.8478, 'grad_norm': 5.674103774500324, 'learning_rate': 1.25e-06, 'epoch': 0.03}
  1%|          | 11/1456 [01:03<2:02:32,  5.09s/it]  1%|          | 12/1456 [01:08<2:01:58,  5.07s/it]                                                   {'loss': 1.9108, 'grad_norm': 5.632653687840099, 'learning_rate': 1.3636363636363636e-06, 'epoch': 0.03}
  1%|          | 12/1456 [01:08<2:01:58,  5.07s/it]  1%|          | 13/1456 [01:13<2:01:37,  5.06s/it]                                                   {'loss': 1.8205, 'grad_norm': 7.5942578557994125, 'learning_rate': 1.4772727272727275e-06, 'epoch': 0.04}
  1%|          | 13/1456 [01:13<2:01:37,  5.06s/it]  1%|          | 14/1456 [01:18<2:01:26,  5.05s/it]                                                   {'loss': 1.3787, 'grad_norm': 4.291657876805067, 'learning_rate': 1.590909090909091e-06, 'epoch': 0.04}
  1%|          | 14/1456 [01:18<2:01:26,  5.05s/it]  1%|          | 15/1456 [01:23<2:00:58,  5.04s/it]                                                   {'loss': 1.599, 'grad_norm': 1.4512702836648932, 'learning_rate': 1.7045454545454546e-06, 'epoch': 0.04}
  1%|          | 15/1456 [01:23<2:00:58,  5.04s/it]  1%|          | 16/1456 [01:28<2:01:59,  5.08s/it]                                                   {'loss': 1.3656, 'grad_norm': 7.076179152718449, 'learning_rate': 1.8181818181818183e-06, 'epoch': 0.04}
  1%|          | 16/1456 [01:28<2:01:59,  5.08s/it]  1%|          | 17/1456 [01:33<2:00:59,  5.05s/it]                                                   {'loss': 1.4002, 'grad_norm': 2.448118994176888, 'learning_rate': 1.931818181818182e-06, 'epoch': 0.05}
  1%|          | 17/1456 [01:33<2:00:59,  5.05s/it]  1%|          | 18/1456 [01:38<2:00:51,  5.04s/it]                                                   {'loss': 1.0049, 'grad_norm': 2.4949378260814363, 'learning_rate': 2.0454545454545457e-06, 'epoch': 0.05}
  1%|          | 18/1456 [01:38<2:00:51,  5.04s/it]  1%|▏         | 19/1456 [01:43<1:59:58,  5.01s/it]                                                   {'loss': 1.3731, 'grad_norm': 2.7716479908430007, 'learning_rate': 2.1590909090909092e-06, 'epoch': 0.05}
  1%|▏         | 19/1456 [01:43<1:59:58,  5.01s/it]  1%|▏         | 20/1456 [01:48<2:00:26,  5.03s/it]                                                   {'loss': 1.5414, 'grad_norm': 3.2538602351750927, 'learning_rate': 2.2727272727272728e-06, 'epoch': 0.05}
  1%|▏         | 20/1456 [01:48<2:00:26,  5.03s/it]  1%|▏         | 21/1456 [01:53<2:00:10,  5.02s/it]                                                   {'loss': 0.9649, 'grad_norm': 2.7700893770527246, 'learning_rate': 2.3863636363636367e-06, 'epoch': 0.06}
  1%|▏         | 21/1456 [01:53<2:00:10,  5.02s/it]  2%|▏         | 22/1456 [01:58<2:00:51,  5.06s/it]                                                   {'loss': 1.249, 'grad_norm': 5.25841556168399, 'learning_rate': 2.5e-06, 'epoch': 0.06}
  2%|▏         | 22/1456 [01:58<2:00:51,  5.06s/it]  2%|▏         | 23/1456 [02:03<1:59:49,  5.02s/it]                                                   {'loss': 1.2252, 'grad_norm': 3.537851021001557, 'learning_rate': 2.6136363636363637e-06, 'epoch': 0.06}
  2%|▏         | 23/1456 [02:03<1:59:49,  5.02s/it]  2%|▏         | 24/1456 [02:08<1:59:48,  5.02s/it]                                                   {'loss': 0.7904, 'grad_norm': 2.5290556450179036, 'learning_rate': 2.7272727272727272e-06, 'epoch': 0.07}
  2%|▏         | 24/1456 [02:08<1:59:48,  5.02s/it]  2%|▏         | 25/1456 [02:13<1:59:49,  5.02s/it]                                                   {'loss': 1.857, 'grad_norm': 7.9102389559719475, 'learning_rate': 2.8409090909090916e-06, 'epoch': 0.07}
  2%|▏         | 25/1456 [02:13<1:59:49,  5.02s/it]  2%|▏         | 26/1456 [02:18<1:59:41,  5.02s/it]                                                   {'loss': 1.6035, 'grad_norm': 15.177112433572107, 'learning_rate': 2.954545454545455e-06, 'epoch': 0.07}
  2%|▏         | 26/1456 [02:18<1:59:41,  5.02s/it]  2%|▏         | 27/1456 [02:23<1:59:44,  5.03s/it]                                                   {'loss': 1.3023, 'grad_norm': 2.241604825647566, 'learning_rate': 3.0681818181818186e-06, 'epoch': 0.07}
  2%|▏         | 27/1456 [02:23<1:59:44,  5.03s/it]  2%|▏         | 28/1456 [02:28<1:59:45,  5.03s/it]                                                   {'loss': 1.1902, 'grad_norm': 10.838799921588846, 'learning_rate': 3.181818181818182e-06, 'epoch': 0.08}
  2%|▏         | 28/1456 [02:28<1:59:45,  5.03s/it]  2%|▏         | 29/1456 [02:33<1:59:45,  5.04s/it]                                                   {'loss': 1.8709, 'grad_norm': 16.739596196161568, 'learning_rate': 3.2954545454545456e-06, 'epoch': 0.08}
  2%|▏         | 29/1456 [02:33<1:59:45,  5.04s/it]  2%|▏         | 30/1456 [02:38<1:59:09,  5.01s/it]                                                   {'loss': 1.5757, 'grad_norm': 9.846917505635608, 'learning_rate': 3.409090909090909e-06, 'epoch': 0.08}
  2%|▏         | 30/1456 [02:38<1:59:09,  5.01s/it]  2%|▏         | 31/1456 [02:43<1:59:37,  5.04s/it]                                                   {'loss': 2.5528, 'grad_norm': 8.803625955028682, 'learning_rate': 3.522727272727273e-06, 'epoch': 0.09}
  2%|▏         | 31/1456 [02:43<1:59:37,  5.04s/it]  2%|▏         | 32/1456 [02:48<1:58:40,  5.00s/it]                                                   {'loss': 1.0444, 'grad_norm': 3.424658631625065, 'learning_rate': 3.6363636363636366e-06, 'epoch': 0.09}
  2%|▏         | 32/1456 [02:48<1:58:40,  5.00s/it]  2%|▏         | 33/1456 [02:53<1:59:06,  5.02s/it]                                                   {'loss': 1.957, 'grad_norm': 8.709603930292042, 'learning_rate': 3.7500000000000005e-06, 'epoch': 0.09}
  2%|▏         | 33/1456 [02:53<1:59:06,  5.02s/it]  2%|▏         | 34/1456 [02:58<1:58:49,  5.01s/it]                                                   {'loss': 1.7689, 'grad_norm': 2.618785950771279, 'learning_rate': 3.863636363636364e-06, 'epoch': 0.09}
  2%|▏         | 34/1456 [02:58<1:58:49,  5.01s/it]  2%|▏         | 35/1456 [03:03<1:59:28,  5.04s/it]                                                   {'loss': 1.9491, 'grad_norm': 3.8910085956259914, 'learning_rate': 3.9772727272727275e-06, 'epoch': 0.1}
  2%|▏         | 35/1456 [03:03<1:59:28,  5.04s/it]  2%|▏         | 36/1456 [03:08<1:59:02,  5.03s/it]                                                   {'loss': 1.8286, 'grad_norm': 2.8942356962595377, 'learning_rate': 4.0909090909090915e-06, 'epoch': 0.1}
  2%|▏         | 36/1456 [03:08<1:59:02,  5.03s/it]  3%|▎         | 37/1456 [03:13<1:59:35,  5.06s/it]                                                   {'loss': 1.4664, 'grad_norm': 3.032458035146458, 'learning_rate': 4.204545454545455e-06, 'epoch': 0.1}
  3%|▎         | 37/1456 [03:13<1:59:35,  5.06s/it]  3%|▎         | 38/1456 [03:18<1:58:59,  5.03s/it]                                                   {'loss': 1.6667, 'grad_norm': 3.9493749872501334, 'learning_rate': 4.3181818181818185e-06, 'epoch': 0.1}
  3%|▎         | 38/1456 [03:18<1:58:59,  5.03s/it]  3%|▎         | 39/1456 [03:24<1:58:53,  5.03s/it]                                                   {'loss': 1.5515, 'grad_norm': 15.133638295421251, 'learning_rate': 4.4318181818181824e-06, 'epoch': 0.11}
  3%|▎         | 39/1456 [03:24<1:58:53,  5.03s/it]  3%|▎         | 40/1456 [03:28<1:58:15,  5.01s/it]                                                   {'loss': 1.7882, 'grad_norm': 9.154610861441029, 'learning_rate': 4.5454545454545455e-06, 'epoch': 0.11}
  3%|▎         | 40/1456 [03:28<1:58:15,  5.01s/it]  3%|▎         | 41/1456 [03:33<1:58:20,  5.02s/it]                                                   {'loss': 1.5559, 'grad_norm': 31.062273051547695, 'learning_rate': 4.6590909090909095e-06, 'epoch': 0.11}
  3%|▎         | 41/1456 [03:34<1:58:20,  5.02s/it]  3%|▎         | 42/1456 [03:39<1:58:15,  5.02s/it]                                                   {'loss': 2.5015, 'grad_norm': 4.747408310425127, 'learning_rate': 4.772727272727273e-06, 'epoch': 0.12}
  3%|▎         | 42/1456 [03:39<1:58:15,  5.02s/it]  3%|▎         | 43/1456 [03:43<1:57:05,  4.97s/it]                                                   {'loss': 1.3325, 'grad_norm': 1.5741989096628919, 'learning_rate': 4.8863636363636365e-06, 'epoch': 0.12}
  3%|▎         | 43/1456 [03:43<1:57:05,  4.97s/it]  3%|▎         | 44/1456 [03:48<1:57:37,  5.00s/it]                                                   {'loss': 1.6534, 'grad_norm': 3.954240242072908, 'learning_rate': 5e-06, 'epoch': 0.12}
  3%|▎         | 44/1456 [03:48<1:57:37,  5.00s/it]  3%|▎         | 45/1456 [03:53<1:57:43,  5.01s/it]                                                   {'loss': 1.8729, 'grad_norm': 6.655363355156513, 'learning_rate': 4.9999938121441815e-06, 'epoch': 0.12}
  3%|▎         | 45/1456 [03:53<1:57:43,  5.01s/it]  3%|▎         | 46/1456 [03:58<1:57:40,  5.01s/it]                                                   {'loss': 1.8341, 'grad_norm': 2.1152231034729696, 'learning_rate': 4.999975248607356e-06, 'epoch': 0.13}
  3%|▎         | 46/1456 [03:58<1:57:40,  5.01s/it]  3%|▎         | 47/1456 [04:03<1:57:41,  5.01s/it]                                                   {'loss': 1.0344, 'grad_norm': 2.7133215719182124, 'learning_rate': 4.9999443094814195e-06, 'epoch': 0.13}
  3%|▎         | 47/1456 [04:04<1:57:41,  5.01s/it]  3%|▎         | 48/1456 [04:09<1:57:49,  5.02s/it]                                                   {'loss': 1.6562, 'grad_norm': 4.305875029384476, 'learning_rate': 4.999900994919527e-06, 'epoch': 0.13}
  3%|▎         | 48/1456 [04:09<1:57:49,  5.02s/it]  3%|▎         | 49/1456 [04:14<1:58:07,  5.04s/it]                                                   {'loss': 1.8166, 'grad_norm': 3.013863953596136, 'learning_rate': 4.9998453051361016e-06, 'epoch': 0.13}
  3%|▎         | 49/1456 [04:14<1:58:07,  5.04s/it]  3%|▎         | 50/1456 [04:19<1:58:36,  5.06s/it]                                                   {'loss': 1.3583, 'grad_norm': 2.1472834036224495, 'learning_rate': 4.999777240406821e-06, 'epoch': 0.14}
  3%|▎         | 50/1456 [04:19<1:58:36,  5.06s/it]  4%|▎         | 51/1456 [04:24<1:58:37,  5.07s/it]                                                   {'loss': 1.2624, 'grad_norm': 3.471315552061971, 'learning_rate': 4.999696801068626e-06, 'epoch': 0.14}
  4%|▎         | 51/1456 [04:24<1:58:37,  5.07s/it]  4%|▎         | 52/1456 [04:29<1:58:27,  5.06s/it]                                                   {'loss': 2.7244, 'grad_norm': 9.67796673693048, 'learning_rate': 4.9996039875197146e-06, 'epoch': 0.14}
  4%|▎         | 52/1456 [04:29<1:58:27,  5.06s/it]  4%|▎         | 53/1456 [04:34<1:58:26,  5.07s/it]                                                   {'loss': 1.3431, 'grad_norm': 4.6947874261185065, 'learning_rate': 4.999498800219539e-06, 'epoch': 0.15}
  4%|▎         | 53/1456 [04:34<1:58:26,  5.07s/it]  4%|▎         | 54/1456 [04:39<1:58:04,  5.05s/it]                                                   {'loss': 1.8728, 'grad_norm': 3.0776366800159645, 'learning_rate': 4.9993812396888065e-06, 'epoch': 0.15}
  4%|▎         | 54/1456 [04:39<1:58:04,  5.05s/it]  4%|▍         | 55/1456 [04:44<1:58:13,  5.06s/it]                                                   {'loss': 1.3833, 'grad_norm': 6.646020613595619, 'learning_rate': 4.999251306509476e-06, 'epoch': 0.15}
  4%|▍         | 55/1456 [04:44<1:58:13,  5.06s/it]  4%|▍         | 56/1456 [04:49<1:57:17,  5.03s/it]                                                   {'loss': 1.5301, 'grad_norm': 2.6328849442926314, 'learning_rate': 4.999109001324753e-06, 'epoch': 0.15}
  4%|▍         | 56/1456 [04:49<1:57:17,  5.03s/it]  4%|▍         | 57/1456 [04:54<1:57:47,  5.05s/it]                                                   {'loss': 0.9934, 'grad_norm': 2.7505794261510483, 'learning_rate': 4.99895432483909e-06, 'epoch': 0.16}
  4%|▍         | 57/1456 [04:54<1:57:47,  5.05s/it]  4%|▍         | 58/1456 [04:59<1:57:48,  5.06s/it]                                                   {'loss': 2.1405, 'grad_norm': 3.8950135019482137, 'learning_rate': 4.998787277818178e-06, 'epoch': 0.16}
  4%|▍         | 58/1456 [04:59<1:57:48,  5.06s/it]  4%|▍         | 59/1456 [05:04<1:57:30,  5.05s/it]                                                   {'loss': 2.3262, 'grad_norm': 4.871398769394576, 'learning_rate': 4.998607861088947e-06, 'epoch': 0.16}
  4%|▍         | 59/1456 [05:04<1:57:30,  5.05s/it]  4%|▍         | 60/1456 [05:09<1:57:23,  5.05s/it]                                                   {'loss': 1.2725, 'grad_norm': 3.9029210668817123, 'learning_rate': 4.998416075539564e-06, 'epoch': 0.16}
  4%|▍         | 60/1456 [05:09<1:57:23,  5.05s/it]  4%|▍         | 61/1456 [05:14<1:57:29,  5.05s/it]                                                   {'loss': 1.728, 'grad_norm': 3.8716921069628154, 'learning_rate': 4.998211922119418e-06, 'epoch': 0.17}
  4%|▍         | 61/1456 [05:14<1:57:29,  5.05s/it]  4%|▍         | 62/1456 [05:19<1:56:47,  5.03s/it]                                                   {'loss': 1.6776, 'grad_norm': 7.084680885337766, 'learning_rate': 4.997995401839129e-06, 'epoch': 0.17}
  4%|▍         | 62/1456 [05:19<1:56:47,  5.03s/it]  4%|▍         | 63/1456 [05:24<1:57:35,  5.06s/it]                                                   {'loss': 1.4721, 'grad_norm': 10.719097699011659, 'learning_rate': 4.9977665157705344e-06, 'epoch': 0.17}
  4%|▍         | 63/1456 [05:24<1:57:35,  5.06s/it]  4%|▍         | 64/1456 [05:29<1:56:39,  5.03s/it]                                                   {'loss': 1.554, 'grad_norm': 5.1521693873311225, 'learning_rate': 4.997525265046683e-06, 'epoch': 0.18}
  4%|▍         | 64/1456 [05:29<1:56:39,  5.03s/it]  4%|▍         | 65/1456 [05:34<1:57:13,  5.06s/it]                                                   {'loss': 1.4892, 'grad_norm': 2.8368128747014274, 'learning_rate': 4.997271650861837e-06, 'epoch': 0.18}
  4%|▍         | 65/1456 [05:34<1:57:13,  5.06s/it]  5%|▍         | 66/1456 [05:39<1:56:41,  5.04s/it]                                                   {'loss': 1.574, 'grad_norm': 3.0689069719431714, 'learning_rate': 4.9970056744714575e-06, 'epoch': 0.18}
  5%|▍         | 66/1456 [05:39<1:56:41,  5.04s/it]  5%|▍         | 67/1456 [05:45<1:56:57,  5.05s/it]                                                   {'loss': 1.0883, 'grad_norm': 2.751445477069708, 'learning_rate': 4.996727337192204e-06, 'epoch': 0.18}
  5%|▍         | 67/1456 [05:45<1:56:57,  5.05s/it]  5%|▍         | 68/1456 [05:50<1:56:04,  5.02s/it]                                                   {'loss': 1.9084, 'grad_norm': 69.35795821091838, 'learning_rate': 4.996436640401924e-06, 'epoch': 0.19}
  5%|▍         | 68/1456 [05:50<1:56:04,  5.02s/it]  5%|▍         | 69/1456 [05:55<1:56:35,  5.04s/it]                                                   {'loss': 1.3509, 'grad_norm': 2.957329718620538, 'learning_rate': 4.996133585539651e-06, 'epoch': 0.19}
  5%|▍         | 69/1456 [05:55<1:56:35,  5.04s/it]  5%|▍         | 70/1456 [06:00<1:56:40,  5.05s/it]                                                   {'loss': 1.6536, 'grad_norm': 6.296569665363931, 'learning_rate': 4.9958181741055926e-06, 'epoch': 0.19}
  5%|▍         | 70/1456 [06:00<1:56:40,  5.05s/it]  5%|▍         | 71/1456 [06:05<1:56:12,  5.03s/it]                                                   {'loss': 0.8446, 'grad_norm': 3.5546994387248003, 'learning_rate': 4.995490407661123e-06, 'epoch': 0.2}
  5%|▍         | 71/1456 [06:05<1:56:12,  5.03s/it]  5%|▍         | 72/1456 [06:10<1:56:09,  5.04s/it]                                                   {'loss': 1.4352, 'grad_norm': 2.391891144198879, 'learning_rate': 4.995150287828783e-06, 'epoch': 0.2}
  5%|▍         | 72/1456 [06:10<1:56:09,  5.04s/it]  5%|▌         | 73/1456 [06:15<1:55:53,  5.03s/it]                                                   {'loss': 2.2719, 'grad_norm': 8.373412479990376, 'learning_rate': 4.994797816292259e-06, 'epoch': 0.2}
  5%|▌         | 73/1456 [06:15<1:55:53,  5.03s/it]  5%|▌         | 74/1456 [06:20<1:55:49,  5.03s/it]                                                   {'loss': 2.0916, 'grad_norm': 17.327118468569093, 'learning_rate': 4.994432994796389e-06, 'epoch': 0.2}
  5%|▌         | 74/1456 [06:20<1:55:49,  5.03s/it]  5%|▌         | 75/1456 [06:25<1:55:42,  5.03s/it]                                                   {'loss': 1.4609, 'grad_norm': 3.0959877629395574, 'learning_rate': 4.994055825147139e-06, 'epoch': 0.21}
  5%|▌         | 75/1456 [06:25<1:55:42,  5.03s/it]  5%|▌         | 76/1456 [06:30<1:55:41,  5.03s/it]                                                   {'loss': 2.0288, 'grad_norm': 8.93501343182289, 'learning_rate': 4.993666309211611e-06, 'epoch': 0.21}
  5%|▌         | 76/1456 [06:30<1:55:41,  5.03s/it]  5%|▌         | 77/1456 [06:35<1:55:13,  5.01s/it]                                                   {'loss': 1.3279, 'grad_norm': 2.7045624720050427, 'learning_rate': 4.993264448918016e-06, 'epoch': 0.21}
  5%|▌         | 77/1456 [06:35<1:55:13,  5.01s/it]  5%|▌         | 78/1456 [06:40<1:55:48,  5.04s/it]                                                   {'loss': 1.5968, 'grad_norm': 5.561420293024002, 'learning_rate': 4.992850246255678e-06, 'epoch': 0.21}
  5%|▌         | 78/1456 [06:40<1:55:48,  5.04s/it]  5%|▌         | 79/1456 [06:45<1:55:31,  5.03s/it]                                                   {'loss': 1.0383, 'grad_norm': 7.92379177763108, 'learning_rate': 4.992423703275018e-06, 'epoch': 0.22}
  5%|▌         | 79/1456 [06:45<1:55:31,  5.03s/it]  5%|▌         | 80/1456 [06:50<1:55:50,  5.05s/it]                                                   {'loss': 0.6808, 'grad_norm': 2.1887275521234515, 'learning_rate': 4.991984822087546e-06, 'epoch': 0.22}
  5%|▌         | 80/1456 [06:50<1:55:50,  5.05s/it]  6%|▌         | 81/1456 [06:55<1:55:34,  5.04s/it]                                                   {'loss': 1.3757, 'grad_norm': 1.934556139721242, 'learning_rate': 4.991533604865848e-06, 'epoch': 0.22}
  6%|▌         | 81/1456 [06:55<1:55:34,  5.04s/it]  6%|▌         | 82/1456 [07:00<1:55:16,  5.03s/it]                                                   {'loss': 1.6434, 'grad_norm': 3.6439751530961124, 'learning_rate': 4.991070053843578e-06, 'epoch': 0.23}
  6%|▌         | 82/1456 [07:00<1:55:16,  5.03s/it]  6%|▌         | 83/1456 [07:05<1:54:44,  5.01s/it]                                                   {'loss': 1.5308, 'grad_norm': 1.6286093901031722, 'learning_rate': 4.990594171315445e-06, 'epoch': 0.23}
  6%|▌         | 83/1456 [07:05<1:54:44,  5.01s/it]  6%|▌         | 84/1456 [07:10<1:55:00,  5.03s/it]                                                   {'loss': 1.6047, 'grad_norm': 3.6333662369897652, 'learning_rate': 4.990105959637203e-06, 'epoch': 0.23}
  6%|▌         | 84/1456 [07:10<1:55:00,  5.03s/it]  6%|▌         | 85/1456 [07:15<1:54:30,  5.01s/it]                                                   {'loss': 0.6443, 'grad_norm': 3.55044711883621, 'learning_rate': 4.989605421225641e-06, 'epoch': 0.23}
  6%|▌         | 85/1456 [07:15<1:54:30,  5.01s/it]  6%|▌         | 86/1456 [07:20<1:54:45,  5.03s/it]                                                   {'loss': 1.8647, 'grad_norm': 8.061802560374506, 'learning_rate': 4.989092558558563e-06, 'epoch': 0.24}
  6%|▌         | 86/1456 [07:20<1:54:45,  5.03s/it]  6%|▌         | 87/1456 [07:25<1:54:20,  5.01s/it]                                                   {'loss': 0.8702, 'grad_norm': 10.239655648044389, 'learning_rate': 4.988567374174787e-06, 'epoch': 0.24}
  6%|▌         | 87/1456 [07:25<1:54:20,  5.01s/it]  6%|▌         | 88/1456 [07:30<1:55:05,  5.05s/it]                                                   {'loss': 2.6003, 'grad_norm': 4.815039621033665, 'learning_rate': 4.988029870674126e-06, 'epoch': 0.24}
  6%|▌         | 88/1456 [07:30<1:55:05,  5.05s/it]  6%|▌         | 89/1456 [07:35<1:54:17,  5.02s/it]                                                   {'loss': 2.083, 'grad_norm': 4.264871048582261, 'learning_rate': 4.987480050717374e-06, 'epoch': 0.24}
  6%|▌         | 89/1456 [07:35<1:54:17,  5.02s/it]  6%|▌         | 90/1456 [07:40<1:53:57,  5.01s/it]                                                   {'loss': 1.6552, 'grad_norm': 3.262071199848099, 'learning_rate': 4.986917917026296e-06, 'epoch': 0.25}
  6%|▌         | 90/1456 [07:40<1:53:57,  5.01s/it]  6%|▋         | 91/1456 [07:45<1:54:11,  5.02s/it]                                                   {'loss': 1.571, 'grad_norm': 7.060211080794334, 'learning_rate': 4.9863434723836155e-06, 'epoch': 0.25}
  6%|▋         | 91/1456 [07:45<1:54:11,  5.02s/it]  6%|▋         | 92/1456 [07:50<1:53:54,  5.01s/it]                                                   {'loss': 1.8146, 'grad_norm': 2.8813826987600706, 'learning_rate': 4.985756719632996e-06, 'epoch': 0.25}
  6%|▋         | 92/1456 [07:50<1:53:54,  5.01s/it]  6%|▋         | 93/1456 [07:55<1:53:53,  5.01s/it]                                                   {'loss': 1.3058, 'grad_norm': 42.26670227370181, 'learning_rate': 4.9851576616790305e-06, 'epoch': 0.26}
  6%|▋         | 93/1456 [07:55<1:53:53,  5.01s/it]  6%|▋         | 94/1456 [08:00<1:53:46,  5.01s/it]                                                   {'loss': 1.8865, 'grad_norm': 4.430811825113478, 'learning_rate': 4.9845463014872265e-06, 'epoch': 0.26}
  6%|▋         | 94/1456 [08:00<1:53:46,  5.01s/it]  7%|▋         | 95/1456 [08:05<1:53:53,  5.02s/it]                                                   {'loss': 1.2397, 'grad_norm': 4.5805505569910885, 'learning_rate': 4.9839226420839905e-06, 'epoch': 0.26}
  7%|▋         | 95/1456 [08:05<1:53:53,  5.02s/it]  7%|▋         | 96/1456 [08:10<1:53:41,  5.02s/it]                                                   {'loss': 1.6805, 'grad_norm': 4.64081693823922, 'learning_rate': 4.983286686556615e-06, 'epoch': 0.26}
  7%|▋         | 96/1456 [08:10<1:53:41,  5.02s/it]  7%|▋         | 97/1456 [08:15<1:53:50,  5.03s/it]                                                   {'loss': 1.3461, 'grad_norm': 4.0992864778746005, 'learning_rate': 4.982638438053262e-06, 'epoch': 0.27}
  7%|▋         | 97/1456 [08:15<1:53:50,  5.03s/it]  7%|▋         | 98/1456 [08:20<1:53:40,  5.02s/it]                                                   {'loss': 1.8238, 'grad_norm': 9.104487526227622, 'learning_rate': 4.9819778997829425e-06, 'epoch': 0.27}
  7%|▋         | 98/1456 [08:20<1:53:40,  5.02s/it]  7%|▋         | 99/1456 [08:25<1:53:22,  5.01s/it]                                                   {'loss': 1.6011, 'grad_norm': 6.138023699076106, 'learning_rate': 4.9813050750155125e-06, 'epoch': 0.27}
  7%|▋         | 99/1456 [08:25<1:53:22,  5.01s/it]  7%|▋         | 100/1456 [08:30<1:53:19,  5.01s/it]                                                    {'loss': 1.6097, 'grad_norm': 5.815323994762673, 'learning_rate': 4.980619967081645e-06, 'epoch': 0.27}
  7%|▋         | 100/1456 [08:30<1:53:19,  5.01s/it]  7%|▋         | 101/1456 [08:35<1:53:50,  5.04s/it]                                                    {'loss': 0.9311, 'grad_norm': 1.8025146879531566, 'learning_rate': 4.9799225793728175e-06, 'epoch': 0.28}
  7%|▋         | 101/1456 [08:35<1:53:50,  5.04s/it]  7%|▋         | 102/1456 [08:40<1:53:30,  5.03s/it]                                                    {'loss': 1.0866, 'grad_norm': 5.072184024781633, 'learning_rate': 4.9792129153413e-06, 'epoch': 0.28}
  7%|▋         | 102/1456 [08:40<1:53:30,  5.03s/it]  7%|▋         | 103/1456 [08:45<1:53:33,  5.04s/it]                                                    {'loss': 1.7319, 'grad_norm': 5.958554172647014, 'learning_rate': 4.9784909785001306e-06, 'epoch': 0.28}
  7%|▋         | 103/1456 [08:45<1:53:33,  5.04s/it]  7%|▋         | 104/1456 [08:50<1:52:54,  5.01s/it]                                                    {'loss': 1.7492, 'grad_norm': 5.020044584038315, 'learning_rate': 4.977756772423103e-06, 'epoch': 0.29}
  7%|▋         | 104/1456 [08:50<1:52:54,  5.01s/it]  7%|▋         | 105/1456 [08:55<1:52:45,  5.01s/it]                                                    {'loss': 1.0101, 'grad_norm': 5.735726927339704, 'learning_rate': 4.977010300744744e-06, 'epoch': 0.29}
  7%|▋         | 105/1456 [08:55<1:52:45,  5.01s/it]  7%|▋         | 106/1456 [09:00<1:52:15,  4.99s/it]                                                    {'loss': 1.7148, 'grad_norm': 2.9954008770930387, 'learning_rate': 4.976251567160303e-06, 'epoch': 0.29}
  7%|▋         | 106/1456 [09:00<1:52:15,  4.99s/it]  7%|▋         | 107/1456 [09:05<1:52:58,  5.03s/it]                                                    {'loss': 1.8472, 'grad_norm': 3.8955791750874478, 'learning_rate': 4.975480575425727e-06, 'epoch': 0.29}
  7%|▋         | 107/1456 [09:05<1:52:58,  5.03s/it]  7%|▋         | 108/1456 [09:10<1:52:02,  4.99s/it]                                                    {'loss': 1.7546, 'grad_norm': 7.971831559885686, 'learning_rate': 4.974697329357644e-06, 'epoch': 0.3}
  7%|▋         | 108/1456 [09:10<1:52:02,  4.99s/it]  7%|▋         | 109/1456 [09:15<1:52:19,  5.00s/it]                                                    {'loss': 1.668, 'grad_norm': 11.335986630880782, 'learning_rate': 4.973901832833345e-06, 'epoch': 0.3}
  7%|▋         | 109/1456 [09:15<1:52:19,  5.00s/it]  8%|▊         | 110/1456 [09:20<1:52:31,  5.02s/it]                                                    {'loss': 1.292, 'grad_norm': 2.992476088349456, 'learning_rate': 4.9730940897907645e-06, 'epoch': 0.3}
  8%|▊         | 110/1456 [09:20<1:52:31,  5.02s/it]  8%|▊         | 111/1456 [09:25<1:52:00,  5.00s/it]                                                    {'loss': 2.0201, 'grad_norm': 16.530860478043216, 'learning_rate': 4.97227410422846e-06, 'epoch': 0.3}
  8%|▊         | 111/1456 [09:25<1:52:00,  5.00s/it]  8%|▊         | 112/1456 [09:30<1:51:20,  4.97s/it]                                                    {'loss': 1.6021, 'grad_norm': 7.736007117488076, 'learning_rate': 4.971441880205594e-06, 'epoch': 0.31}
  8%|▊         | 112/1456 [09:30<1:51:20,  4.97s/it]  8%|▊         | 113/1456 [09:35<1:51:16,  4.97s/it]                                                    {'loss': 1.2922, 'grad_norm': 7.232880472987469, 'learning_rate': 4.970597421841913e-06, 'epoch': 0.31}
  8%|▊         | 113/1456 [09:35<1:51:16,  4.97s/it]  8%|▊         | 114/1456 [09:40<1:51:56,  5.00s/it]                                                    {'loss': 1.115, 'grad_norm': 10.42308501807144, 'learning_rate': 4.969740733317724e-06, 'epoch': 0.31}
  8%|▊         | 114/1456 [09:40<1:51:56,  5.00s/it]  8%|▊         | 115/1456 [09:45<1:51:07,  4.97s/it]                                                    {'loss': 1.5944, 'grad_norm': 5.419857826198135, 'learning_rate': 4.968871818873881e-06, 'epoch': 0.32}
  8%|▊         | 115/1456 [09:45<1:51:07,  4.97s/it]  8%|▊         | 116/1456 [09:50<1:51:29,  4.99s/it]                                                    {'loss': 1.1516, 'grad_norm': 4.878908986563484, 'learning_rate': 4.967990682811758e-06, 'epoch': 0.32}
  8%|▊         | 116/1456 [09:50<1:51:29,  4.99s/it]  8%|▊         | 117/1456 [09:55<1:51:50,  5.01s/it]                                                    {'loss': 2.0151, 'grad_norm': 5.085594153937135, 'learning_rate': 4.967097329493228e-06, 'epoch': 0.32}
  8%|▊         | 117/1456 [09:55<1:51:50,  5.01s/it]  8%|▊         | 118/1456 [10:00<1:51:55,  5.02s/it]                                                    {'loss': 2.8007, 'grad_norm': 7.039496574608569, 'learning_rate': 4.966191763340645e-06, 'epoch': 0.32}
  8%|▊         | 118/1456 [10:00<1:51:55,  5.02s/it]  8%|▊         | 119/1456 [10:05<1:51:44,  5.01s/it]                                                    {'loss': 1.6624, 'grad_norm': 6.541580717975964, 'learning_rate': 4.965273988836819e-06, 'epoch': 0.33}
  8%|▊         | 119/1456 [10:05<1:51:44,  5.01s/it]  8%|▊         | 120/1456 [10:11<1:52:13,  5.04s/it]                                                    {'loss': 1.9933, 'grad_norm': 3.7948227347687626, 'learning_rate': 4.9643440105249955e-06, 'epoch': 0.33}
  8%|▊         | 120/1456 [10:11<1:52:13,  5.04s/it]  8%|▊         | 121/1456 [10:16<1:51:52,  5.03s/it]                                                    {'loss': 1.8296, 'grad_norm': 6.021934470183447, 'learning_rate': 4.963401833008832e-06, 'epoch': 0.33}
  8%|▊         | 121/1456 [10:16<1:51:52,  5.03s/it]  8%|▊         | 122/1456 [10:21<1:51:35,  5.02s/it]                                                    {'loss': 2.2097, 'grad_norm': 4.316601116217852, 'learning_rate': 4.962447460952374e-06, 'epoch': 0.34}
  8%|▊         | 122/1456 [10:21<1:51:35,  5.02s/it]  8%|▊         | 123/1456 [10:26<1:51:28,  5.02s/it]                                                    {'loss': 1.5617, 'grad_norm': 5.414553577340844, 'learning_rate': 4.961480899080035e-06, 'epoch': 0.34}
  8%|▊         | 123/1456 [10:26<1:51:28,  5.02s/it]  9%|▊         | 124/1456 [10:30<1:50:50,  4.99s/it]                                                    {'loss': 2.2682, 'grad_norm': 5.514833561036327, 'learning_rate': 4.960502152176574e-06, 'epoch': 0.34}
  9%|▊         | 124/1456 [10:30<1:50:50,  4.99s/it]  9%|▊         | 125/1456 [10:36<1:51:18,  5.02s/it]                                                    {'loss': 2.1112, 'grad_norm': 7.811629590184627, 'learning_rate': 4.959511225087063e-06, 'epoch': 0.34}
  9%|▊         | 125/1456 [10:36<1:51:18,  5.02s/it]  9%|▊         | 126/1456 [10:41<1:50:51,  5.00s/it]                                                    {'loss': 1.3577, 'grad_norm': 3.6444408409622904, 'learning_rate': 4.9585081227168775e-06, 'epoch': 0.35}
  9%|▊         | 126/1456 [10:41<1:50:51,  5.00s/it]  9%|▊         | 127/1456 [10:46<1:51:00,  5.01s/it]                                                    {'loss': 2.0666, 'grad_norm': 5.991696015535011, 'learning_rate': 4.957492850031656e-06, 'epoch': 0.35}
  9%|▊         | 127/1456 [10:46<1:51:00,  5.01s/it]  9%|▉         | 128/1456 [10:51<1:51:07,  5.02s/it]                                                    {'loss': 1.7006, 'grad_norm': 2.6881289078933066, 'learning_rate': 4.9564654120572884e-06, 'epoch': 0.35}
  9%|▉         | 128/1456 [10:51<1:51:07,  5.02s/it]  9%|▉         | 129/1456 [10:56<1:51:25,  5.04s/it]                                                    {'loss': 1.5177, 'grad_norm': 3.8052672271529033, 'learning_rate': 4.955425813879886e-06, 'epoch': 0.35}
  9%|▉         | 129/1456 [10:56<1:51:25,  5.04s/it]  9%|▉         | 130/1456 [11:01<1:50:38,  5.01s/it]                                                    {'loss': 1.5286, 'grad_norm': 2.7227719253639386, 'learning_rate': 4.954374060645755e-06, 'epoch': 0.36}
  9%|▉         | 130/1456 [11:01<1:50:38,  5.01s/it]  9%|▉         | 131/1456 [11:06<1:50:30,  5.00s/it]                                                    {'loss': 1.8572, 'grad_norm': 3.9280373841971503, 'learning_rate': 4.953310157561373e-06, 'epoch': 0.36}
  9%|▉         | 131/1456 [11:06<1:50:30,  5.00s/it]  9%|▉         | 132/1456 [11:11<1:49:53,  4.98s/it]                                                    {'loss': 1.8539, 'grad_norm': 84.74653154775716, 'learning_rate': 4.952234109893364e-06, 'epoch': 0.36}
  9%|▉         | 132/1456 [11:11<1:49:53,  4.98s/it]  9%|▉         | 133/1456 [11:16<1:50:43,  5.02s/it]                                                    {'loss': 1.5179, 'grad_norm': 2.9972310002948417, 'learning_rate': 4.951145922968469e-06, 'epoch': 0.37}
  9%|▉         | 133/1456 [11:16<1:50:43,  5.02s/it]  9%|▉         | 134/1456 [11:21<1:50:04,  5.00s/it]                                                    {'loss': 2.2032, 'grad_norm': 8.497088663011015, 'learning_rate': 4.950045602173524e-06, 'epoch': 0.37}
  9%|▉         | 134/1456 [11:21<1:50:04,  5.00s/it]  9%|▉         | 135/1456 [11:26<1:51:01,  5.04s/it]                                                    {'loss': 1.0406, 'grad_norm': 8.11268551089776, 'learning_rate': 4.9489331529554304e-06, 'epoch': 0.37}
  9%|▉         | 135/1456 [11:26<1:51:01,  5.04s/it]  9%|▉         | 136/1456 [11:31<1:50:24,  5.02s/it]                                                    {'loss': 1.0333, 'grad_norm': 3.264407282214461, 'learning_rate': 4.947808580821129e-06, 'epoch': 0.37}
  9%|▉         | 136/1456 [11:31<1:50:24,  5.02s/it]  9%|▉         | 137/1456 [11:36<1:50:30,  5.03s/it]                                                    {'loss': 1.7547, 'grad_norm': 2.9232169756755044, 'learning_rate': 4.946671891337569e-06, 'epoch': 0.38}
  9%|▉         | 137/1456 [11:36<1:50:30,  5.03s/it]  9%|▉         | 138/1456 [11:41<1:50:59,  5.05s/it]                                                    {'loss': 2.3262, 'grad_norm': 6.968641613857238, 'learning_rate': 4.945523090131691e-06, 'epoch': 0.38}
  9%|▉         | 138/1456 [11:41<1:50:59,  5.05s/it] 10%|▉         | 139/1456 [11:46<1:51:39,  5.09s/it]                                                    {'loss': 1.4224, 'grad_norm': 7.081372995815103, 'learning_rate': 4.944362182890384e-06, 'epoch': 0.38}
 10%|▉         | 139/1456 [11:46<1:51:39,  5.09s/it] 10%|▉         | 140/1456 [11:51<1:51:03,  5.06s/it]                                                    {'loss': 1.0058, 'grad_norm': 4.540793635366978, 'learning_rate': 4.943189175360472e-06, 'epoch': 0.38}
 10%|▉         | 140/1456 [11:51<1:51:03,  5.06s/it] 10%|▉         | 141/1456 [11:56<1:50:55,  5.06s/it]                                                    {'loss': 1.6569, 'grad_norm': 4.548844058580939, 'learning_rate': 4.942004073348676e-06, 'epoch': 0.39}
 10%|▉         | 141/1456 [11:56<1:50:55,  5.06s/it] 10%|▉         | 142/1456 [12:01<1:50:33,  5.05s/it]                                                    {'loss': 1.9089, 'grad_norm': 95.07641868846869, 'learning_rate': 4.940806882721587e-06, 'epoch': 0.39}
 10%|▉         | 142/1456 [12:01<1:50:33,  5.05s/it] 10%|▉         | 143/1456 [12:06<1:50:28,  5.05s/it]                                                    {'loss': 1.539, 'grad_norm': 7.532042149081939, 'learning_rate': 4.939597609405641e-06, 'epoch': 0.39}
 10%|▉         | 143/1456 [12:06<1:50:28,  5.05s/it] 10%|▉         | 144/1456 [12:11<1:50:34,  5.06s/it]                                                    {'loss': 1.1602, 'grad_norm': 10.450301491800667, 'learning_rate': 4.9383762593870834e-06, 'epoch': 0.4}
 10%|▉         | 144/1456 [12:11<1:50:34,  5.06s/it] 10%|▉         | 145/1456 [12:16<1:50:34,  5.06s/it]                                                    {'loss': 1.6915, 'grad_norm': 4.604281854123606, 'learning_rate': 4.937142838711945e-06, 'epoch': 0.4}
 10%|▉         | 145/1456 [12:16<1:50:34,  5.06s/it] 10%|█         | 146/1456 [12:21<1:49:34,  5.02s/it]                                                    {'loss': 1.7166, 'grad_norm': 7.714499349512128, 'learning_rate': 4.93589735348601e-06, 'epoch': 0.4}
 10%|█         | 146/1456 [12:21<1:49:34,  5.02s/it] 10%|█         | 147/1456 [12:26<1:49:20,  5.01s/it]                                                    {'loss': 1.6199, 'grad_norm': 2.803495445992064, 'learning_rate': 4.934639809874785e-06, 'epoch': 0.4}
 10%|█         | 147/1456 [12:26<1:49:20,  5.01s/it] 10%|█         | 148/1456 [12:31<1:48:58,  5.00s/it]                                                    {'loss': 0.9013, 'grad_norm': 2.5199922361708436, 'learning_rate': 4.933370214103467e-06, 'epoch': 0.41}
 10%|█         | 148/1456 [12:31<1:48:58,  5.00s/it] 10%|█         | 149/1456 [12:36<1:49:39,  5.03s/it]                                                    {'loss': 1.2096, 'grad_norm': 3.781966716843824, 'learning_rate': 4.932088572456919e-06, 'epoch': 0.41}
 10%|█         | 149/1456 [12:36<1:49:39,  5.03s/it] 10%|█         | 150/1456 [12:41<1:49:12,  5.02s/it]                                                    {'loss': 1.5839, 'grad_norm': 4.132864189185268, 'learning_rate': 4.93079489127963e-06, 'epoch': 0.41}
 10%|█         | 150/1456 [12:41<1:49:12,  5.02s/it] 10%|█         | 151/1456 [12:46<1:49:48,  5.05s/it]                                                    {'loss': 1.642, 'grad_norm': 4.359344591697821, 'learning_rate': 4.92948917697569e-06, 'epoch': 0.41}
 10%|█         | 151/1456 [12:46<1:49:48,  5.05s/it] 10%|█         | 152/1456 [12:51<1:49:11,  5.02s/it]                                                    {'loss': 1.3431, 'grad_norm': 6.6024214146309195, 'learning_rate': 4.928171436008757e-06, 'epoch': 0.42}
 10%|█         | 152/1456 [12:51<1:49:11,  5.02s/it] 11%|█         | 153/1456 [12:56<1:49:26,  5.04s/it]                                                    {'loss': 2.5161, 'grad_norm': 16.48708138328499, 'learning_rate': 4.926841674902025e-06, 'epoch': 0.42}
 11%|█         | 153/1456 [12:56<1:49:26,  5.04s/it] 11%|█         | 154/1456 [13:01<1:48:41,  5.01s/it]                                                    {'loss': 1.4411, 'grad_norm': 3.9819993061043992, 'learning_rate': 4.92549990023819e-06, 'epoch': 0.42}
 11%|█         | 154/1456 [13:01<1:48:41,  5.01s/it] 11%|█         | 155/1456 [13:06<1:49:11,  5.04s/it]                                                    {'loss': 1.5658, 'grad_norm': 10.126058264163715, 'learning_rate': 4.924146118659415e-06, 'epoch': 0.43}
 11%|█         | 155/1456 [13:06<1:49:11,  5.04s/it] 11%|█         | 156/1456 [13:11<1:48:24,  5.00s/it]                                                    {'loss': 1.2037, 'grad_norm': 3.885626097788356, 'learning_rate': 4.922780336867309e-06, 'epoch': 0.43}
 11%|█         | 156/1456 [13:11<1:48:24,  5.00s/it] 11%|█         | 157/1456 [13:16<1:48:38,  5.02s/it]                                                    {'loss': 1.8515, 'grad_norm': 7.298536744501589, 'learning_rate': 4.921402561622878e-06, 'epoch': 0.43}
 11%|█         | 157/1456 [13:16<1:48:38,  5.02s/it] 11%|█         | 158/1456 [13:21<1:48:39,  5.02s/it]                                                    {'loss': 2.8507, 'grad_norm': 9.7732216546659, 'learning_rate': 4.920012799746501e-06, 'epoch': 0.43}
 11%|█         | 158/1456 [13:21<1:48:39,  5.02s/it] 11%|█         | 159/1456 [13:27<1:48:51,  5.04s/it]                                                    {'loss': 1.0301, 'grad_norm': 3.6546168143949913, 'learning_rate': 4.918611058117897e-06, 'epoch': 0.44}
 11%|█         | 159/1456 [13:27<1:48:51,  5.04s/it] 11%|█         | 160/1456 [13:32<1:48:56,  5.04s/it]                                                    {'loss': 1.6121, 'grad_norm': 3.9186036345725572, 'learning_rate': 4.917197343676084e-06, 'epoch': 0.44}
 11%|█         | 160/1456 [13:32<1:48:56,  5.04s/it] 11%|█         | 161/1456 [13:37<1:48:50,  5.04s/it]                                                    {'loss': 1.6092, 'grad_norm': 6.621716531366874, 'learning_rate': 4.915771663419354e-06, 'epoch': 0.44}
 11%|█         | 161/1456 [13:37<1:48:50,  5.04s/it] 11%|█         | 162/1456 [13:42<1:48:51,  5.05s/it]                                                    {'loss': 1.6274, 'grad_norm': 12.229114400220151, 'learning_rate': 4.914334024405226e-06, 'epoch': 0.45}
 11%|█         | 162/1456 [13:42<1:48:51,  5.05s/it] 11%|█         | 163/1456 [13:47<1:48:40,  5.04s/it]                                                    {'loss': 1.5873, 'grad_norm': 4.443683238540671, 'learning_rate': 4.912884433750425e-06, 'epoch': 0.45}
 11%|█         | 163/1456 [13:47<1:48:40,  5.04s/it] 11%|█▏        | 164/1456 [13:52<1:48:37,  5.04s/it]                                                    {'loss': 1.6658, 'grad_norm': 3.63532627871419, 'learning_rate': 4.911422898630838e-06, 'epoch': 0.45}
 11%|█▏        | 164/1456 [13:52<1:48:37,  5.04s/it] 11%|█▏        | 165/1456 [13:57<1:47:21,  4.99s/it]                                                    {'loss': 1.9801, 'grad_norm': 4.534025197434041, 'learning_rate': 4.909949426281477e-06, 'epoch': 0.45}
 11%|█▏        | 165/1456 [13:57<1:47:21,  4.99s/it] 11%|█▏        | 166/1456 [14:02<1:47:37,  5.01s/it]                                                    {'loss': 1.0618, 'grad_norm': 2.621959924061348, 'learning_rate': 4.908464023996452e-06, 'epoch': 0.46}
 11%|█▏        | 166/1456 [14:02<1:47:37,  5.01s/it] 11%|█▏        | 167/1456 [14:07<1:47:35,  5.01s/it]                                                    {'loss': 1.0957, 'grad_norm': 5.797206324236829, 'learning_rate': 4.906966699128926e-06, 'epoch': 0.46}
 11%|█▏        | 167/1456 [14:07<1:47:35,  5.01s/it] 12%|█▏        | 168/1456 [14:12<1:47:58,  5.03s/it]                                                    {'loss': 0.9071, 'grad_norm': 3.526254141344345, 'learning_rate': 4.905457459091084e-06, 'epoch': 0.46}
 12%|█▏        | 168/1456 [14:12<1:47:58,  5.03s/it] 12%|█▏        | 169/1456 [14:17<1:47:47,  5.03s/it]                                                    {'loss': 1.6441, 'grad_norm': 4.174762997781609, 'learning_rate': 4.9039363113540935e-06, 'epoch': 0.46}
 12%|█▏        | 169/1456 [14:17<1:47:47,  5.03s/it] 12%|█▏        | 170/1456 [14:22<1:47:53,  5.03s/it]                                                    {'loss': 1.281, 'grad_norm': 2.4441923555761993, 'learning_rate': 4.902403263448069e-06, 'epoch': 0.47}
 12%|█▏        | 170/1456 [14:22<1:47:53,  5.03s/it] 12%|█▏        | 171/1456 [14:27<1:47:07,  5.00s/it]                                                    {'loss': 1.3151, 'grad_norm': 4.037842320908595, 'learning_rate': 4.900858322962033e-06, 'epoch': 0.47}
 12%|█▏        | 171/1456 [14:27<1:47:07,  5.00s/it] 12%|█▏        | 172/1456 [14:32<1:47:54,  5.04s/it]                                                    {'loss': 1.8739, 'grad_norm': 3.6359672384517214, 'learning_rate': 4.899301497543882e-06, 'epoch': 0.47}
 12%|█▏        | 172/1456 [14:32<1:47:54,  5.04s/it] 12%|█▏        | 173/1456 [14:37<1:47:38,  5.03s/it]                                                    {'loss': 1.3815, 'grad_norm': 5.894488860951793, 'learning_rate': 4.897732794900344e-06, 'epoch': 0.48}
 12%|█▏        | 173/1456 [14:37<1:47:38,  5.03s/it] 12%|█▏        | 174/1456 [14:42<1:48:14,  5.07s/it]                                                    {'loss': 1.7564, 'grad_norm': 2.1152535364581087, 'learning_rate': 4.896152222796945e-06, 'epoch': 0.48}
 12%|█▏        | 174/1456 [14:42<1:48:14,  5.07s/it] 12%|█▏        | 175/1456 [14:47<1:48:19,  5.07s/it]                                                    {'loss': 1.278, 'grad_norm': 5.8094208467756205, 'learning_rate': 4.894559789057965e-06, 'epoch': 0.48}
 12%|█▏        | 175/1456 [14:47<1:48:19,  5.07s/it] 12%|█▏        | 176/1456 [14:52<1:48:17,  5.08s/it]                                                    {'loss': 1.2119, 'grad_norm': 4.098613616265804, 'learning_rate': 4.892955501566406e-06, 'epoch': 0.48}
 12%|█▏        | 176/1456 [14:52<1:48:17,  5.08s/it] 12%|█▏        | 177/1456 [14:57<1:48:13,  5.08s/it]                                                    {'loss': 1.5001, 'grad_norm': 3.7066513847703852, 'learning_rate': 4.891339368263946e-06, 'epoch': 0.49}
 12%|█▏        | 177/1456 [14:57<1:48:13,  5.08s/it] 12%|█▏        | 178/1456 [15:02<1:47:05,  5.03s/it]                                                    {'loss': 1.562, 'grad_norm': 4.150634873327762, 'learning_rate': 4.889711397150906e-06, 'epoch': 0.49}
 12%|█▏        | 178/1456 [15:02<1:47:05,  5.03s/it] 12%|█▏        | 179/1456 [15:07<1:47:16,  5.04s/it]                                                    {'loss': 0.8471, 'grad_norm': 2.7878007358781307, 'learning_rate': 4.888071596286207e-06, 'epoch': 0.49}
 12%|█▏        | 179/1456 [15:07<1:47:16,  5.04s/it] 12%|█▏        | 180/1456 [15:12<1:46:17,  5.00s/it]                                                    {'loss': 1.7794, 'grad_norm': 8.348804100422202, 'learning_rate': 4.886419973787329e-06, 'epoch': 0.49}
 12%|█▏        | 180/1456 [15:12<1:46:17,  5.00s/it] 12%|█▏        | 181/1456 [15:17<1:47:02,  5.04s/it]                                                    {'loss': 2.0984, 'grad_norm': 5.138640510582256, 'learning_rate': 4.884756537830274e-06, 'epoch': 0.5}
 12%|█▏        | 181/1456 [15:17<1:47:02,  5.04s/it] 12%|█▎        | 182/1456 [15:22<1:46:38,  5.02s/it]                                                    {'loss': 1.2303, 'grad_norm': 6.603413086585591, 'learning_rate': 4.883081296649523e-06, 'epoch': 0.5}
 12%|█▎        | 182/1456 [15:22<1:46:38,  5.02s/it] 13%|█▎        | 183/1456 [15:27<1:46:38,  5.03s/it]                                                    {'loss': 1.1335, 'grad_norm': 3.1406298585161423, 'learning_rate': 4.881394258537997e-06, 'epoch': 0.5}
 13%|█▎        | 183/1456 [15:27<1:46:38,  5.03s/it] 13%|█▎        | 184/1456 [15:32<1:45:56,  5.00s/it]                                                    {'loss': 0.963, 'grad_norm': 2.2430515020259714, 'learning_rate': 4.879695431847015e-06, 'epoch': 0.51}
 13%|█▎        | 184/1456 [15:32<1:45:56,  5.00s/it] 13%|█▎        | 185/1456 [15:37<1:46:09,  5.01s/it]                                                    {'loss': 1.7973, 'grad_norm': 5.27144421240258, 'learning_rate': 4.8779848249862535e-06, 'epoch': 0.51}
 13%|█▎        | 185/1456 [15:37<1:46:09,  5.01s/it] 13%|█▎        | 186/1456 [15:42<1:46:19,  5.02s/it]                                                    {'loss': 2.1565, 'grad_norm': 6.083783416123299, 'learning_rate': 4.876262446423701e-06, 'epoch': 0.51}
 13%|█▎        | 186/1456 [15:42<1:46:19,  5.02s/it] 13%|█▎        | 187/1456 [15:47<1:46:30,  5.04s/it]                                                    {'loss': 1.0446, 'grad_norm': 5.188565064444939, 'learning_rate': 4.874528304685624e-06, 'epoch': 0.51}
 13%|█▎        | 187/1456 [15:47<1:46:30,  5.04s/it] 13%|█▎        | 188/1456 [15:53<1:46:35,  5.04s/it]                                                    {'loss': 1.5324, 'grad_norm': 4.582143640725188, 'learning_rate': 4.872782408356517e-06, 'epoch': 0.52}
 13%|█▎        | 188/1456 [15:53<1:46:35,  5.04s/it] 13%|█▎        | 189/1456 [15:58<1:47:17,  5.08s/it]                                                    {'loss': 1.6059, 'grad_norm': 4.922685828859416, 'learning_rate': 4.871024766079064e-06, 'epoch': 0.52}
 13%|█▎        | 189/1456 [15:58<1:47:17,  5.08s/it] 13%|█▎        | 190/1456 [16:03<1:46:39,  5.05s/it]                                                    {'loss': 1.7662, 'grad_norm': 6.815606764988072, 'learning_rate': 4.869255386554094e-06, 'epoch': 0.52}
 13%|█▎        | 190/1456 [16:03<1:46:39,  5.05s/it] 13%|█▎        | 191/1456 [16:08<1:47:08,  5.08s/it]                                                    {'loss': 2.0002, 'grad_norm': 10.265063869985555, 'learning_rate': 4.86747427854054e-06, 'epoch': 0.52}
 13%|█▎        | 191/1456 [16:08<1:47:08,  5.08s/it] 13%|█▎        | 192/1456 [16:13<1:46:24,  5.05s/it]                                                    {'loss': 1.5276, 'grad_norm': 8.225613241321328, 'learning_rate': 4.865681450855392e-06, 'epoch': 0.53}
 13%|█▎        | 192/1456 [16:13<1:46:24,  5.05s/it] 13%|█▎        | 193/1456 [16:18<1:46:41,  5.07s/it]                                                    {'loss': 1.1263, 'grad_norm': 2.7179648482384327, 'learning_rate': 4.8638769123736595e-06, 'epoch': 0.53}
 13%|█▎        | 193/1456 [16:18<1:46:41,  5.07s/it] 13%|█▎        | 194/1456 [16:23<1:46:14,  5.05s/it]                                                    {'loss': 1.7615, 'grad_norm': 3.1336890918243228, 'learning_rate': 4.8620606720283215e-06, 'epoch': 0.53}
 13%|█▎        | 194/1456 [16:23<1:46:14,  5.05s/it] 13%|█▎        | 195/1456 [16:28<1:46:09,  5.05s/it]                                                    {'loss': 1.3631, 'grad_norm': 3.671077950186459, 'learning_rate': 4.860232738810283e-06, 'epoch': 0.54}
 13%|█▎        | 195/1456 [16:28<1:46:09,  5.05s/it] 13%|█▎        | 196/1456 [16:33<1:45:05,  5.00s/it]                                                    {'loss': 0.8712, 'grad_norm': 4.06715220591018, 'learning_rate': 4.858393121768336e-06, 'epoch': 0.54}
 13%|█▎        | 196/1456 [16:33<1:45:05,  5.00s/it] 14%|█▎        | 197/1456 [16:38<1:45:52,  5.05s/it]                                                    {'loss': 1.4284, 'grad_norm': 9.889601716294424, 'learning_rate': 4.856541830009106e-06, 'epoch': 0.54}
 14%|█▎        | 197/1456 [16:38<1:45:52,  5.05s/it] 14%|█▎        | 198/1456 [16:43<1:44:40,  4.99s/it]                                                    {'loss': 1.4374, 'grad_norm': 3.2537629277972324, 'learning_rate': 4.8546788726970165e-06, 'epoch': 0.54}
 14%|█▎        | 198/1456 [16:43<1:44:40,  4.99s/it] 14%|█▎        | 199/1456 [16:48<1:45:20,  5.03s/it]                                                    {'loss': 1.4916, 'grad_norm': 16.27553395041446, 'learning_rate': 4.8528042590542345e-06, 'epoch': 0.55}
 14%|█▎        | 199/1456 [16:48<1:45:20,  5.03s/it] 14%|█▎        | 200/1456 [16:53<1:44:44,  5.00s/it]                                                    {'loss': 1.3196, 'grad_norm': 7.765201058127506, 'learning_rate': 4.8509179983606335e-06, 'epoch': 0.55}
 14%|█▎        | 200/1456 [16:53<1:44:44,  5.00s/it] 14%|█▍        | 201/1456 [16:58<1:44:56,  5.02s/it]                                                    {'loss': 1.0601, 'grad_norm': 4.553925910209641, 'learning_rate': 4.849020099953739e-06, 'epoch': 0.55}
 14%|█▍        | 201/1456 [16:58<1:44:56,  5.02s/it] 14%|█▍        | 202/1456 [17:03<1:44:26,  5.00s/it]                                                    {'loss': 1.5181, 'grad_norm': 2.711803902465299, 'learning_rate': 4.847110573228689e-06, 'epoch': 0.55}
 14%|█▍        | 202/1456 [17:03<1:44:26,  5.00s/it] 14%|█▍        | 203/1456 [17:08<1:44:51,  5.02s/it]                                                    {'loss': 1.072, 'grad_norm': 3.470424488498647, 'learning_rate': 4.845189427638183e-06, 'epoch': 0.56}
 14%|█▍        | 203/1456 [17:08<1:44:51,  5.02s/it] 14%|█▍        | 204/1456 [17:13<1:44:25,  5.00s/it]                                                    {'loss': 2.3078, 'grad_norm': 4.449203102680452, 'learning_rate': 4.84325667269244e-06, 'epoch': 0.56}
 14%|█▍        | 204/1456 [17:13<1:44:25,  5.00s/it] 14%|█▍        | 205/1456 [17:18<1:44:51,  5.03s/it]                                                    {'loss': 1.6183, 'grad_norm': 16.655055362880816, 'learning_rate': 4.841312317959148e-06, 'epoch': 0.56}
 14%|█▍        | 205/1456 [17:18<1:44:51,  5.03s/it] 14%|█▍        | 206/1456 [17:23<1:44:37,  5.02s/it]                                                    {'loss': 2.0959, 'grad_norm': 3.9159309967866185, 'learning_rate': 4.8393563730634155e-06, 'epoch': 0.57}
 14%|█▍        | 206/1456 [17:23<1:44:37,  5.02s/it] 14%|█▍        | 207/1456 [17:28<1:44:59,  5.04s/it]                                                    {'loss': 1.7853, 'grad_norm': 2.2862549316953733, 'learning_rate': 4.837388847687725e-06, 'epoch': 0.57}
 14%|█▍        | 207/1456 [17:28<1:44:59,  5.04s/it] 14%|█▍        | 208/1456 [17:33<1:44:39,  5.03s/it]                                                    {'loss': 1.9817, 'grad_norm': 4.209632119168533, 'learning_rate': 4.83540975157189e-06, 'epoch': 0.57}
 14%|█▍        | 208/1456 [17:33<1:44:39,  5.03s/it] 14%|█▍        | 209/1456 [17:38<1:43:57,  5.00s/it]                                                    {'loss': 1.5229, 'grad_norm': 3.4656472290536957, 'learning_rate': 4.833419094512997e-06, 'epoch': 0.57}
 14%|█▍        | 209/1456 [17:38<1:43:57,  5.00s/it] 14%|█▍        | 210/1456 [17:43<1:44:29,  5.03s/it]                                                    {'loss': 2.1361, 'grad_norm': 6.067979990454054, 'learning_rate': 4.8314168863653665e-06, 'epoch': 0.58}
 14%|█▍        | 210/1456 [17:43<1:44:29,  5.03s/it] 14%|█▍        | 211/1456 [17:48<1:43:20,  4.98s/it]                                                    {'loss': 1.9839, 'grad_norm': 6.18793216313547, 'learning_rate': 4.829403137040499e-06, 'epoch': 0.58}
 14%|█▍        | 211/1456 [17:48<1:43:20,  4.98s/it] 15%|█▍        | 212/1456 [17:53<1:43:24,  4.99s/it]                                                    {'loss': 2.0718, 'grad_norm': 4.472620854799903, 'learning_rate': 4.827377856507026e-06, 'epoch': 0.58}
 15%|█▍        | 212/1456 [17:53<1:43:24,  4.99s/it] 15%|█▍        | 213/1456 [17:58<1:42:46,  4.96s/it]                                                    {'loss': 1.2289, 'grad_norm': 2.8027425413644096, 'learning_rate': 4.825341054790663e-06, 'epoch': 0.59}
 15%|█▍        | 213/1456 [17:58<1:42:46,  4.96s/it] 15%|█▍        | 214/1456 [18:03<1:43:20,  4.99s/it]                                                    {'loss': 1.4766, 'grad_norm': 7.615963192874858, 'learning_rate': 4.823292741974158e-06, 'epoch': 0.59}
 15%|█▍        | 214/1456 [18:03<1:43:20,  4.99s/it] 15%|█▍        | 215/1456 [18:08<1:42:54,  4.98s/it]                                                    {'loss': 1.1599, 'grad_norm': 2.6223425356244956, 'learning_rate': 4.821232928197244e-06, 'epoch': 0.59}
 15%|█▍        | 215/1456 [18:08<1:42:54,  4.98s/it] 15%|█▍        | 216/1456 [18:13<1:43:30,  5.01s/it]                                                    {'loss': 1.8068, 'grad_norm': 3.444087703921706, 'learning_rate': 4.819161623656583e-06, 'epoch': 0.59}
 15%|█▍        | 216/1456 [18:13<1:43:30,  5.01s/it] 15%|█▍        | 217/1456 [18:18<1:43:30,  5.01s/it]                                                    {'loss': 1.0504, 'grad_norm': 2.141361750210289, 'learning_rate': 4.817078838605724e-06, 'epoch': 0.6}
 15%|█▍        | 217/1456 [18:18<1:43:30,  5.01s/it] 15%|█▍        | 218/1456 [18:23<1:44:08,  5.05s/it]                                                    {'loss': 0.9455, 'grad_norm': 1.486755149343607, 'learning_rate': 4.814984583355046e-06, 'epoch': 0.6}
 15%|█▍        | 218/1456 [18:23<1:44:08,  5.05s/it] 15%|█▌        | 219/1456 [18:28<1:43:33,  5.02s/it]                                                    {'loss': 2.4142, 'grad_norm': 14.25948673817304, 'learning_rate': 4.812878868271706e-06, 'epoch': 0.6}
 15%|█▌        | 219/1456 [18:28<1:43:33,  5.02s/it] 15%|█▌        | 220/1456 [18:33<1:43:44,  5.04s/it]                                                    {'loss': 3.2973, 'grad_norm': 27.15998967346085, 'learning_rate': 4.810761703779597e-06, 'epoch': 0.6}
 15%|█▌        | 220/1456 [18:33<1:43:44,  5.04s/it] 15%|█▌        | 221/1456 [18:38<1:43:27,  5.03s/it]                                                    {'loss': 1.0496, 'grad_norm': 2.2354416868641134, 'learning_rate': 4.808633100359283e-06, 'epoch': 0.61}
 15%|█▌        | 221/1456 [18:38<1:43:27,  5.03s/it] 15%|█▌        | 222/1456 [18:43<1:43:01,  5.01s/it]                                                    {'loss': 0.9884, 'grad_norm': 2.5769906987713314, 'learning_rate': 4.806493068547958e-06, 'epoch': 0.61}
 15%|█▌        | 222/1456 [18:43<1:43:01,  5.01s/it] 15%|█▌        | 223/1456 [18:48<1:42:51,  5.01s/it]                                                    {'loss': 1.5569, 'grad_norm': 3.7375594730812427, 'learning_rate': 4.804341618939387e-06, 'epoch': 0.61}
 15%|█▌        | 223/1456 [18:48<1:42:51,  5.01s/it] 15%|█▌        | 224/1456 [18:53<1:42:15,  4.98s/it]                                                    {'loss': 1.7029, 'grad_norm': 6.549745790629969, 'learning_rate': 4.802178762183861e-06, 'epoch': 0.62}
 15%|█▌        | 224/1456 [18:53<1:42:15,  4.98s/it] 15%|█▌        | 225/1456 [18:58<1:42:30,  5.00s/it]                                                    {'loss': 1.0719, 'grad_norm': 4.126627052088226, 'learning_rate': 4.8000045089881355e-06, 'epoch': 0.62}
 15%|█▌        | 225/1456 [18:58<1:42:30,  5.00s/it] 16%|█▌        | 226/1456 [19:03<1:42:14,  4.99s/it]                                                    {'loss': 0.8865, 'grad_norm': 3.1817530266171974, 'learning_rate': 4.797818870115381e-06, 'epoch': 0.62}
 16%|█▌        | 226/1456 [19:03<1:42:14,  4.99s/it] 16%|█▌        | 227/1456 [19:08<1:42:28,  5.00s/it]                                                    {'loss': 1.2391, 'grad_norm': 3.7556694407253213, 'learning_rate': 4.795621856385134e-06, 'epoch': 0.62}
 16%|█▌        | 227/1456 [19:08<1:42:28,  5.00s/it] 16%|█▌        | 228/1456 [19:13<1:42:01,  4.99s/it]                                                    {'loss': 1.3214, 'grad_norm': 12.298420403010287, 'learning_rate': 4.793413478673237e-06, 'epoch': 0.63}
 16%|█▌        | 228/1456 [19:13<1:42:01,  4.99s/it] 16%|█▌        | 229/1456 [19:18<1:42:34,  5.02s/it]                                                    {'loss': 1.7612, 'grad_norm': 4.065099266125864, 'learning_rate': 4.791193747911787e-06, 'epoch': 0.63}
 16%|█▌        | 229/1456 [19:18<1:42:34,  5.02s/it] 16%|█▌        | 230/1456 [19:23<1:42:34,  5.02s/it]                                                    {'loss': 1.2708, 'grad_norm': 2.7028956674303344, 'learning_rate': 4.788962675089086e-06, 'epoch': 0.63}
 16%|█▌        | 230/1456 [19:23<1:42:34,  5.02s/it] 16%|█▌        | 231/1456 [19:28<1:43:13,  5.06s/it]                                                    {'loss': 1.3966, 'grad_norm': 17.196158153047133, 'learning_rate': 4.786720271249578e-06, 'epoch': 0.63}
 16%|█▌        | 231/1456 [19:28<1:43:13,  5.06s/it] 16%|█▌        | 232/1456 [19:33<1:42:47,  5.04s/it]                                                    {'loss': 2.0286, 'grad_norm': 10.471872712319767, 'learning_rate': 4.7844665474938e-06, 'epoch': 0.64}
 16%|█▌        | 232/1456 [19:33<1:42:47,  5.04s/it] 16%|█▌        | 233/1456 [19:38<1:42:53,  5.05s/it]                                                    {'loss': 1.9921, 'grad_norm': 4.969680986815731, 'learning_rate': 4.782201514978327e-06, 'epoch': 0.64}
 16%|█▌        | 233/1456 [19:38<1:42:53,  5.05s/it] 16%|█▌        | 234/1456 [19:43<1:42:11,  5.02s/it]                                                    {'loss': 1.68, 'grad_norm': 16.26562781430091, 'learning_rate': 4.779925184915714e-06, 'epoch': 0.64}
 16%|█▌        | 234/1456 [19:43<1:42:11,  5.02s/it] 16%|█▌        | 235/1456 [19:49<1:43:02,  5.06s/it]                                                    {'loss': 2.6869, 'grad_norm': 7.1984069333380765, 'learning_rate': 4.777637568574444e-06, 'epoch': 0.65}
 16%|█▌        | 235/1456 [19:49<1:43:02,  5.06s/it] 16%|█▌        | 236/1456 [19:54<1:42:16,  5.03s/it]                                                    {'loss': 1.7191, 'grad_norm': 6.180099531440077, 'learning_rate': 4.775338677278867e-06, 'epoch': 0.65}
 16%|█▌        | 236/1456 [19:54<1:42:16,  5.03s/it] 16%|█▋        | 237/1456 [19:59<1:42:24,  5.04s/it]                                                    {'loss': 1.3292, 'grad_norm': 7.417702106104835, 'learning_rate': 4.7730285224091514e-06, 'epoch': 0.65}
 16%|█▋        | 237/1456 [19:59<1:42:24,  5.04s/it] 16%|█▋        | 238/1456 [20:04<1:42:02,  5.03s/it]                                                    {'loss': 2.0832, 'grad_norm': 4.525502736526689, 'learning_rate': 4.77070711540122e-06, 'epoch': 0.65}
 16%|█▋        | 238/1456 [20:04<1:42:02,  5.03s/it] 16%|█▋        | 239/1456 [20:09<1:42:26,  5.05s/it]                                                    {'loss': 1.3385, 'grad_norm': 3.078514113254609, 'learning_rate': 4.768374467746698e-06, 'epoch': 0.66}
 16%|█▋        | 239/1456 [20:09<1:42:26,  5.05s/it] 16%|█▋        | 240/1456 [20:14<1:42:03,  5.04s/it]                                                    {'loss': 1.5736, 'grad_norm': 3.0175743325218884, 'learning_rate': 4.7660305909928564e-06, 'epoch': 0.66}
 16%|█▋        | 240/1456 [20:14<1:42:03,  5.04s/it] 17%|█▋        | 241/1456 [20:19<1:41:06,  4.99s/it]                                                    {'loss': 1.2811, 'grad_norm': 4.850906303122121, 'learning_rate': 4.763675496742552e-06, 'epoch': 0.66}
 17%|█▋        | 241/1456 [20:19<1:41:06,  4.99s/it] 17%|█▋        | 242/1456 [20:24<1:41:19,  5.01s/it]                                                    {'loss': 1.6205, 'grad_norm': 4.401410414316518, 'learning_rate': 4.761309196654172e-06, 'epoch': 0.66}
 17%|█▋        | 242/1456 [20:24<1:41:19,  5.01s/it] 17%|█▋        | 243/1456 [20:29<1:41:05,  5.00s/it]                                                    {'loss': 2.0936, 'grad_norm': 4.124949368252829, 'learning_rate': 4.758931702441575e-06, 'epoch': 0.67}
 17%|█▋        | 243/1456 [20:29<1:41:05,  5.00s/it] 17%|█▋        | 244/1456 [20:34<1:41:53,  5.04s/it]                                                    {'loss': 2.4189, 'grad_norm': 12.426615644140101, 'learning_rate': 4.7565430258740345e-06, 'epoch': 0.67}
 17%|█▋        | 244/1456 [20:34<1:41:53,  5.04s/it] 17%|█▋        | 245/1456 [20:39<1:41:16,  5.02s/it]                                                    {'loss': 2.3097, 'grad_norm': 6.515966904998156, 'learning_rate': 4.754143178776178e-06, 'epoch': 0.67}
 17%|█▋        | 245/1456 [20:39<1:41:16,  5.02s/it] 17%|█▋        | 246/1456 [20:44<1:41:34,  5.04s/it]                                                    {'loss': 2.1073, 'grad_norm': 7.460629697512029, 'learning_rate': 4.751732173027935e-06, 'epoch': 0.68}
 17%|█▋        | 246/1456 [20:44<1:41:34,  5.04s/it] 17%|█▋        | 247/1456 [20:49<1:41:12,  5.02s/it]                                                    {'loss': 1.1872, 'grad_norm': 1.7820813430776208, 'learning_rate': 4.749310020564466e-06, 'epoch': 0.68}
 17%|█▋        | 247/1456 [20:49<1:41:12,  5.02s/it] 17%|█▋        | 248/1456 [20:54<1:41:41,  5.05s/it]                                                    {'loss': 1.9017, 'grad_norm': 6.593235954025837, 'learning_rate': 4.746876733376118e-06, 'epoch': 0.68}
 17%|█▋        | 248/1456 [20:54<1:41:41,  5.05s/it] 17%|█▋        | 249/1456 [20:59<1:41:08,  5.03s/it]                                                    {'loss': 1.922, 'grad_norm': 15.023814307222072, 'learning_rate': 4.744432323508355e-06, 'epoch': 0.68}
 17%|█▋        | 249/1456 [20:59<1:41:08,  5.03s/it] 17%|█▋        | 250/1456 [21:04<1:41:03,  5.03s/it]                                                    {'loss': 1.8009, 'grad_norm': 8.209705322032537, 'learning_rate': 4.741976803061701e-06, 'epoch': 0.69}
 17%|█▋        | 250/1456 [21:04<1:41:03,  5.03s/it] 17%|█▋        | 251/1456 [21:09<1:41:07,  5.04s/it]                                                    {'loss': 1.0935, 'grad_norm': 4.393813309410087, 'learning_rate': 4.739510184191682e-06, 'epoch': 0.69}
 17%|█▋        | 251/1456 [21:09<1:41:07,  5.04s/it] 17%|█▋        | 252/1456 [21:14<1:40:51,  5.03s/it]                                                    {'loss': 1.6233, 'grad_norm': 5.352065370419914, 'learning_rate': 4.737032479108762e-06, 'epoch': 0.69}
 17%|█▋        | 252/1456 [21:14<1:40:51,  5.03s/it] 17%|█▋        | 253/1456 [21:19<1:40:29,  5.01s/it]                                                    {'loss': 1.1653, 'grad_norm': 2.584822953320441, 'learning_rate': 4.734543700078288e-06, 'epoch': 0.7}
 17%|█▋        | 253/1456 [21:19<1:40:29,  5.01s/it] 17%|█▋        | 254/1456 [21:24<1:40:09,  5.00s/it]                                                    {'loss': 1.6824, 'grad_norm': 4.291277204205638, 'learning_rate': 4.7320438594204245e-06, 'epoch': 0.7}
 17%|█▋        | 254/1456 [21:24<1:40:09,  5.00s/it] 18%|█▊        | 255/1456 [21:29<1:40:22,  5.01s/it]                                                    {'loss': 1.4129, 'grad_norm': 4.499744408024619, 'learning_rate': 4.729532969510093e-06, 'epoch': 0.7}
 18%|█▊        | 255/1456 [21:29<1:40:22,  5.01s/it] 18%|█▊        | 256/1456 [21:34<1:40:11,  5.01s/it]                                                    {'loss': 0.9175, 'grad_norm': 4.696882902482645, 'learning_rate': 4.7270110427769145e-06, 'epoch': 0.7}
 18%|█▊        | 256/1456 [21:34<1:40:11,  5.01s/it] 18%|█▊        | 257/1456 [21:39<1:40:32,  5.03s/it]                                                    {'loss': 1.9341, 'grad_norm': 5.3312086204362945, 'learning_rate': 4.724478091705144e-06, 'epoch': 0.71}
 18%|█▊        | 257/1456 [21:39<1:40:32,  5.03s/it] 18%|█▊        | 258/1456 [21:44<1:40:34,  5.04s/it]                                                    {'loss': 1.4537, 'grad_norm': 14.151592237844154, 'learning_rate': 4.721934128833611e-06, 'epoch': 0.71}
 18%|█▊        | 258/1456 [21:44<1:40:34,  5.04s/it] 18%|█▊        | 259/1456 [21:49<1:40:34,  5.04s/it]                                                    {'loss': 1.2139, 'grad_norm': 8.929067621884796, 'learning_rate': 4.719379166755654e-06, 'epoch': 0.71}
 18%|█▊        | 259/1456 [21:49<1:40:34,  5.04s/it] 18%|█▊        | 260/1456 [21:54<1:40:31,  5.04s/it]                                                    {'loss': 1.5153, 'grad_norm': 2.3664247398120093, 'learning_rate': 4.716813218119064e-06, 'epoch': 0.71}
 18%|█▊        | 260/1456 [21:54<1:40:31,  5.04s/it] 18%|█▊        | 261/1456 [21:59<1:40:44,  5.06s/it]                                                    {'loss': 1.2379, 'grad_norm': 2.6823578366509517, 'learning_rate': 4.714236295626017e-06, 'epoch': 0.72}
 18%|█▊        | 261/1456 [21:59<1:40:44,  5.06s/it] 18%|█▊        | 262/1456 [22:04<1:40:25,  5.05s/it]                                                    {'loss': 1.961, 'grad_norm': 7.654598135737036, 'learning_rate': 4.711648412033013e-06, 'epoch': 0.72}
 18%|█▊        | 262/1456 [22:04<1:40:25,  5.05s/it] 18%|█▊        | 263/1456 [22:09<1:40:50,  5.07s/it]                                                    {'loss': 1.5057, 'grad_norm': 3.494092042179019, 'learning_rate': 4.709049580150812e-06, 'epoch': 0.72}
 18%|█▊        | 263/1456 [22:09<1:40:50,  5.07s/it] 18%|█▊        | 264/1456 [22:14<1:40:28,  5.06s/it]                                                    {'loss': 1.1426, 'grad_norm': 6.255321526012778, 'learning_rate': 4.706439812844371e-06, 'epoch': 0.73}
 18%|█▊        | 264/1456 [22:14<1:40:28,  5.06s/it] 18%|█▊        | 265/1456 [22:20<1:40:40,  5.07s/it]                                                    {'loss': 1.1971, 'grad_norm': 2.7509261219084458, 'learning_rate': 4.7038191230327825e-06, 'epoch': 0.73}
 18%|█▊        | 265/1456 [22:20<1:40:40,  5.07s/it] 18%|█▊        | 266/1456 [22:24<1:39:48,  5.03s/it]                                                    {'loss': 2.2967, 'grad_norm': 10.475506506716782, 'learning_rate': 4.701187523689207e-06, 'epoch': 0.73}
 18%|█▊        | 266/1456 [22:24<1:39:48,  5.03s/it] 18%|█▊        | 267/1456 [22:30<1:40:27,  5.07s/it]                                                    {'loss': 1.7722, 'grad_norm': 4.759750597855331, 'learning_rate': 4.698545027840808e-06, 'epoch': 0.73}
 18%|█▊        | 267/1456 [22:30<1:40:27,  5.07s/it] 18%|█▊        | 268/1456 [22:35<1:39:55,  5.05s/it]                                                    {'loss': 0.5313, 'grad_norm': 1.8573117388975868, 'learning_rate': 4.695891648568696e-06, 'epoch': 0.74}
 18%|█▊        | 268/1456 [22:35<1:39:55,  5.05s/it] 18%|█▊        | 269/1456 [22:40<1:39:20,  5.02s/it]                                                    {'loss': 2.2375, 'grad_norm': 5.046283699095101, 'learning_rate': 4.69322739900785e-06, 'epoch': 0.74}
 18%|█▊        | 269/1456 [22:40<1:39:20,  5.02s/it] 19%|█▊        | 270/1456 [22:45<1:39:48,  5.05s/it]                                                    {'loss': 1.3357, 'grad_norm': 11.691884569859637, 'learning_rate': 4.690552292347066e-06, 'epoch': 0.74}
 19%|█▊        | 270/1456 [22:45<1:39:48,  5.05s/it] 19%|█▊        | 271/1456 [22:50<1:39:26,  5.04s/it]                                                    {'loss': 1.4678, 'grad_norm': 5.676267830140874, 'learning_rate': 4.687866341828882e-06, 'epoch': 0.74}
 19%|█▊        | 271/1456 [22:50<1:39:26,  5.04s/it] 19%|█▊        | 272/1456 [22:55<1:39:29,  5.04s/it]                                                    {'loss': 1.8165, 'grad_norm': 12.025406961831115, 'learning_rate': 4.685169560749519e-06, 'epoch': 0.75}
 19%|█▊        | 272/1456 [22:55<1:39:29,  5.04s/it] 19%|█▉        | 273/1456 [23:00<1:39:07,  5.03s/it]                                                    {'loss': 1.4601, 'grad_norm': 3.29345105893871, 'learning_rate': 4.682461962458809e-06, 'epoch': 0.75}
 19%|█▉        | 273/1456 [23:00<1:39:07,  5.03s/it] 19%|█▉        | 274/1456 [23:05<1:39:51,  5.07s/it]                                                    {'loss': 1.2274, 'grad_norm': 3.5642125882025284, 'learning_rate': 4.679743560360138e-06, 'epoch': 0.75}
 19%|█▉        | 274/1456 [23:05<1:39:51,  5.07s/it] 19%|█▉        | 275/1456 [23:10<1:39:19,  5.05s/it]                                                    {'loss': 1.296, 'grad_norm': 6.742631351717667, 'learning_rate': 4.677014367910366e-06, 'epoch': 0.76}
 19%|█▉        | 275/1456 [23:10<1:39:19,  5.05s/it] 19%|█▉        | 276/1456 [23:15<1:40:00,  5.09s/it]                                                    {'loss': 2.7813, 'grad_norm': 10.244882189853838, 'learning_rate': 4.674274398619776e-06, 'epoch': 0.76}
 19%|█▉        | 276/1456 [23:15<1:40:00,  5.09s/it] 19%|█▉        | 277/1456 [23:20<1:38:57,  5.04s/it]                                                    {'loss': 1.2365, 'grad_norm': 9.936223169987128, 'learning_rate': 4.671523666051993e-06, 'epoch': 0.76}
 19%|█▉        | 277/1456 [23:20<1:38:57,  5.04s/it] 19%|█▉        | 278/1456 [23:25<1:39:32,  5.07s/it]                                                    {'loss': 1.9133, 'grad_norm': 7.282261070158452, 'learning_rate': 4.668762183823927e-06, 'epoch': 0.76}
 19%|█▉        | 278/1456 [23:25<1:39:32,  5.07s/it] 19%|█▉        | 279/1456 [23:30<1:39:12,  5.06s/it]                                                    {'loss': 1.1768, 'grad_norm': 3.958089372579053, 'learning_rate': 4.665989965605703e-06, 'epoch': 0.77}
 19%|█▉        | 279/1456 [23:30<1:39:12,  5.06s/it] 19%|█▉        | 280/1456 [23:35<1:39:10,  5.06s/it]                                                    {'loss': 1.6854, 'grad_norm': 6.386588838988386, 'learning_rate': 4.663207025120588e-06, 'epoch': 0.77}
 19%|█▉        | 280/1456 [23:35<1:39:10,  5.06s/it] 19%|█▉        | 281/1456 [23:40<1:38:33,  5.03s/it]                                                    {'loss': 1.6199, 'grad_norm': 3.546740021006802, 'learning_rate': 4.660413376144931e-06, 'epoch': 0.77}
 19%|█▉        | 281/1456 [23:40<1:38:33,  5.03s/it] 19%|█▉        | 282/1456 [23:45<1:38:47,  5.05s/it]                                                    {'loss': 1.6122, 'grad_norm': 11.150642588620629, 'learning_rate': 4.657609032508088e-06, 'epoch': 0.77}
 19%|█▉        | 282/1456 [23:45<1:38:47,  5.05s/it] 19%|█▉        | 283/1456 [23:50<1:38:08,  5.02s/it]                                                    {'loss': 1.8196, 'grad_norm': 4.986327168710739, 'learning_rate': 4.654794008092361e-06, 'epoch': 0.78}
 19%|█▉        | 283/1456 [23:50<1:38:08,  5.02s/it] 20%|█▉        | 284/1456 [23:55<1:38:30,  5.04s/it]                                                    {'loss': 1.6942, 'grad_norm': 7.946414057196378, 'learning_rate': 4.65196831683292e-06, 'epoch': 0.78}
 20%|█▉        | 284/1456 [23:55<1:38:30,  5.04s/it] 20%|█▉        | 285/1456 [24:00<1:37:53,  5.02s/it]                                                    {'loss': 1.7756, 'grad_norm': 4.281603944724166, 'learning_rate': 4.649131972717741e-06, 'epoch': 0.78}
 20%|█▉        | 285/1456 [24:00<1:37:53,  5.02s/it] 20%|█▉        | 286/1456 [24:05<1:38:07,  5.03s/it]                                                    {'loss': 1.9024, 'grad_norm': 4.017591655376463, 'learning_rate': 4.646284989787536e-06, 'epoch': 0.79}
 20%|█▉        | 286/1456 [24:05<1:38:07,  5.03s/it] 20%|█▉        | 287/1456 [24:10<1:37:44,  5.02s/it]                                                    {'loss': 1.2782, 'grad_norm': 5.112857296870232, 'learning_rate': 4.64342738213568e-06, 'epoch': 0.79}
 20%|█▉        | 287/1456 [24:10<1:37:44,  5.02s/it] 20%|█▉        | 288/1456 [24:16<1:38:23,  5.05s/it]                                                    {'loss': 1.3481, 'grad_norm': 2.911345905642235, 'learning_rate': 4.640559163908145e-06, 'epoch': 0.79}
 20%|█▉        | 288/1456 [24:16<1:38:23,  5.05s/it] 20%|█▉        | 289/1456 [24:20<1:37:42,  5.02s/it]                                                    {'loss': 1.0872, 'grad_norm': 3.238510951970852, 'learning_rate': 4.637680349303427e-06, 'epoch': 0.79}
 20%|█▉        | 289/1456 [24:20<1:37:42,  5.02s/it] 20%|█▉        | 290/1456 [24:26<1:38:07,  5.05s/it]                                                    {'loss': 1.94, 'grad_norm': 3.7111637729124056, 'learning_rate': 4.6347909525724785e-06, 'epoch': 0.8}
 20%|█▉        | 290/1456 [24:26<1:38:07,  5.05s/it] 20%|█▉        | 291/1456 [24:31<1:37:41,  5.03s/it]                                                    {'loss': 1.0709, 'grad_norm': 3.826956434366233, 'learning_rate': 4.631890988018634e-06, 'epoch': 0.8}
 20%|█▉        | 291/1456 [24:31<1:37:41,  5.03s/it] 20%|██        | 292/1456 [24:36<1:38:20,  5.07s/it]                                                    {'loss': 1.9045, 'grad_norm': 4.320597468492201, 'learning_rate': 4.628980469997547e-06, 'epoch': 0.8}
 20%|██        | 292/1456 [24:36<1:38:20,  5.07s/it] 20%|██        | 293/1456 [24:41<1:37:37,  5.04s/it]                                                    {'loss': 1.1561, 'grad_norm': 4.203099587516114, 'learning_rate': 4.6260594129171065e-06, 'epoch': 0.8}
 20%|██        | 293/1456 [24:41<1:37:37,  5.04s/it] 20%|██        | 294/1456 [24:46<1:37:51,  5.05s/it]                                                    {'loss': 1.7543, 'grad_norm': 5.016275999418667, 'learning_rate': 4.623127831237379e-06, 'epoch': 0.81}
 20%|██        | 294/1456 [24:46<1:37:51,  5.05s/it] 20%|██        | 295/1456 [24:50<1:35:37,  4.94s/it]                                                    {'loss': 2.5672, 'grad_norm': 33.41489269339253, 'learning_rate': 4.620185739470527e-06, 'epoch': 0.81}
 20%|██        | 295/1456 [24:50<1:35:37,  4.94s/it] 20%|██        | 296/1456 [24:54<1:30:08,  4.66s/it]                                                    {'loss': 1.9532, 'grad_norm': 3.949265959898026, 'learning_rate': 4.617233152180744e-06, 'epoch': 0.81}
 20%|██        | 296/1456 [24:54<1:30:08,  4.66s/it] 20%|██        | 297/1456 [25:00<1:32:18,  4.78s/it]                                                    {'loss': 1.2282, 'grad_norm': 3.749355260736947, 'learning_rate': 4.614270083984174e-06, 'epoch': 0.82}
 20%|██        | 297/1456 [25:00<1:32:18,  4.78s/it] 20%|██        | 298/1456 [25:05<1:33:54,  4.87s/it]                                                    {'loss': 0.8829, 'grad_norm': 3.2148529460492714, 'learning_rate': 4.611296549548851e-06, 'epoch': 0.82}
 20%|██        | 298/1456 [25:05<1:33:54,  4.87s/it] 21%|██        | 299/1456 [25:10<1:34:33,  4.90s/it]                                                    {'loss': 1.2185, 'grad_norm': 2.7566506853605213, 'learning_rate': 4.608312563594617e-06, 'epoch': 0.82}
 21%|██        | 299/1456 [25:10<1:34:33,  4.90s/it] 21%|██        | 300/1456 [25:15<1:35:01,  4.93s/it]                                                    {'loss': 1.4022, 'grad_norm': 2.250942880374357, 'learning_rate': 4.6053181408930505e-06, 'epoch': 0.82}
 21%|██        | 300/1456 [25:15<1:35:01,  4.93s/it] 21%|██        | 301/1456 [25:20<1:35:49,  4.98s/it]                                                    {'loss': 1.3665, 'grad_norm': 5.155553597325651, 'learning_rate': 4.602313296267396e-06, 'epoch': 0.83}
 21%|██        | 301/1456 [25:20<1:35:49,  4.98s/it] 21%|██        | 302/1456 [25:25<1:35:38,  4.97s/it]                                                    {'loss': 1.959, 'grad_norm': 3.8737627330668003, 'learning_rate': 4.599298044592491e-06, 'epoch': 0.83}
 21%|██        | 302/1456 [25:25<1:35:38,  4.97s/it] 21%|██        | 303/1456 [25:30<1:36:12,  5.01s/it]                                                    {'loss': 2.5105, 'grad_norm': 6.893619639183491, 'learning_rate': 4.59627240079469e-06, 'epoch': 0.83}
 21%|██        | 303/1456 [25:30<1:36:12,  5.01s/it] 21%|██        | 304/1456 [25:35<1:36:26,  5.02s/it]                                                    {'loss': 2.048, 'grad_norm': 5.889171309666549, 'learning_rate': 4.59323637985179e-06, 'epoch': 0.84}
 21%|██        | 304/1456 [25:35<1:36:26,  5.02s/it] 21%|██        | 305/1456 [25:40<1:36:39,  5.04s/it]                                                    {'loss': 1.5365, 'grad_norm': 2.8434833778900335, 'learning_rate': 4.590189996792959e-06, 'epoch': 0.84}
 21%|██        | 305/1456 [25:40<1:36:39,  5.04s/it] 21%|██        | 306/1456 [25:45<1:36:29,  5.03s/it]                                                    {'loss': 2.3796, 'grad_norm': 5.806112081246796, 'learning_rate': 4.58713326669866e-06, 'epoch': 0.84}
 21%|██        | 306/1456 [25:45<1:36:29,  5.03s/it] 21%|██        | 307/1456 [25:50<1:36:39,  5.05s/it]                                                    {'loss': 1.3585, 'grad_norm': 3.5541888547490226, 'learning_rate': 4.584066204700577e-06, 'epoch': 0.84}
 21%|██        | 307/1456 [25:50<1:36:39,  5.05s/it] 21%|██        | 308/1456 [25:55<1:35:44,  5.00s/it]                                                    {'loss': 1.4112, 'grad_norm': 3.907252190774485, 'learning_rate': 4.580988825981541e-06, 'epoch': 0.85}
 21%|██        | 308/1456 [25:55<1:35:44,  5.00s/it] 21%|██        | 309/1456 [26:00<1:35:18,  4.99s/it]                                                    {'loss': 1.1867, 'grad_norm': 3.9951279294343487, 'learning_rate': 4.577901145775452e-06, 'epoch': 0.85}
 21%|██        | 309/1456 [26:00<1:35:18,  4.99s/it] 21%|██▏       | 310/1456 [26:05<1:35:43,  5.01s/it]                                                    {'loss': 1.1115, 'grad_norm': 17.677553864845986, 'learning_rate': 4.574803179367206e-06, 'epoch': 0.85}
 21%|██▏       | 310/1456 [26:05<1:35:43,  5.01s/it] 21%|██▏       | 311/1456 [26:10<1:35:10,  4.99s/it]                                                    {'loss': 1.3114, 'grad_norm': 5.5858826961363155, 'learning_rate': 4.571694942092618e-06, 'epoch': 0.85}
 21%|██▏       | 311/1456 [26:10<1:35:10,  4.99s/it] 21%|██▏       | 312/1456 [26:15<1:35:23,  5.00s/it]                                                    {'loss': 1.9169, 'grad_norm': 3.8636944649147518, 'learning_rate': 4.568576449338349e-06, 'epoch': 0.86}
 21%|██▏       | 312/1456 [26:15<1:35:23,  5.00s/it] 21%|██▏       | 313/1456 [26:20<1:34:55,  4.98s/it]                                                    {'loss': 2.6972, 'grad_norm': 11.91245058255588, 'learning_rate': 4.5654477165418235e-06, 'epoch': 0.86}
 21%|██▏       | 313/1456 [26:20<1:34:55,  4.98s/it] 22%|██▏       | 314/1456 [26:25<1:35:38,  5.02s/it]                                                    {'loss': 1.6989, 'grad_norm': 5.694696254383327, 'learning_rate': 4.562308759191162e-06, 'epoch': 0.86}
 22%|██▏       | 314/1456 [26:25<1:35:38,  5.02s/it] 22%|██▏       | 315/1456 [26:30<1:35:17,  5.01s/it]                                                    {'loss': 1.6759, 'grad_norm': 4.403323019758261, 'learning_rate': 4.559159592825094e-06, 'epoch': 0.87}
 22%|██▏       | 315/1456 [26:30<1:35:17,  5.01s/it] 22%|██▏       | 316/1456 [26:35<1:35:33,  5.03s/it]                                                    {'loss': 1.1892, 'grad_norm': 3.4372217239103575, 'learning_rate': 4.556000233032892e-06, 'epoch': 0.87}
 22%|██▏       | 316/1456 [26:35<1:35:33,  5.03s/it] 22%|██▏       | 317/1456 [26:40<1:35:06,  5.01s/it]                                                    {'loss': 2.5118, 'grad_norm': 10.672659223793598, 'learning_rate': 4.552830695454285e-06, 'epoch': 0.87}
 22%|██▏       | 317/1456 [26:40<1:35:06,  5.01s/it] 22%|██▏       | 318/1456 [26:45<1:35:01,  5.01s/it]                                                    {'loss': 1.8464, 'grad_norm': 4.787624921239613, 'learning_rate': 4.549650995779386e-06, 'epoch': 0.87}
 22%|██▏       | 318/1456 [26:45<1:35:01,  5.01s/it] 22%|██▏       | 319/1456 [26:50<1:35:12,  5.02s/it]                                                    {'loss': 1.5591, 'grad_norm': 4.604461844577912, 'learning_rate': 4.546461149748615e-06, 'epoch': 0.88}
 22%|██▏       | 319/1456 [26:50<1:35:12,  5.02s/it] 22%|██▏       | 320/1456 [26:55<1:35:28,  5.04s/it]                                                    {'loss': 1.9571, 'grad_norm': 5.203619123027651, 'learning_rate': 4.5432611731526165e-06, 'epoch': 0.88}
 22%|██▏       | 320/1456 [26:55<1:35:28,  5.04s/it] 22%|██▏       | 321/1456 [27:00<1:35:10,  5.03s/it]                                                    {'loss': 2.0748, 'grad_norm': 7.710643635167863, 'learning_rate': 4.540051081832186e-06, 'epoch': 0.88}
 22%|██▏       | 321/1456 [27:00<1:35:10,  5.03s/it] 22%|██▏       | 322/1456 [27:05<1:34:22,  4.99s/it]                                                    {'loss': 2.0885, 'grad_norm': 6.871159816161918, 'learning_rate': 4.536830891678189e-06, 'epoch': 0.88}
 22%|██▏       | 322/1456 [27:05<1:34:22,  4.99s/it] 22%|██▏       | 323/1456 [27:10<1:34:34,  5.01s/it]                                                    {'loss': 1.4091, 'grad_norm': 1.7447065266195718, 'learning_rate': 4.533600618631484e-06, 'epoch': 0.89}
 22%|██▏       | 323/1456 [27:10<1:34:34,  5.01s/it] 22%|██▏       | 324/1456 [27:15<1:34:12,  4.99s/it]                                                    {'loss': 1.0204, 'grad_norm': 4.863890092724798, 'learning_rate': 4.5303602786828415e-06, 'epoch': 0.89}
 22%|██▏       | 324/1456 [27:15<1:34:12,  4.99s/it] 22%|██▏       | 325/1456 [27:20<1:34:36,  5.02s/it]                                                    {'loss': 2.0895, 'grad_norm': 23.18275094561148, 'learning_rate': 4.527109887872867e-06, 'epoch': 0.89}
 22%|██▏       | 325/1456 [27:20<1:34:36,  5.02s/it] 22%|██▏       | 326/1456 [27:25<1:34:40,  5.03s/it]                                                    {'loss': 1.0542, 'grad_norm': 5.018062011384242, 'learning_rate': 4.52384946229192e-06, 'epoch': 0.9}
 22%|██▏       | 326/1456 [27:25<1:34:40,  5.03s/it] 22%|██▏       | 327/1456 [27:30<1:34:22,  5.02s/it]                                                    {'loss': 1.8593, 'grad_norm': 8.815094694341907, 'learning_rate': 4.520579018080035e-06, 'epoch': 0.9}
 22%|██▏       | 327/1456 [27:30<1:34:22,  5.02s/it] 23%|██▎       | 328/1456 [27:35<1:34:29,  5.03s/it]                                                    {'loss': 1.6116, 'grad_norm': 2.3711100393926663, 'learning_rate': 4.517298571426843e-06, 'epoch': 0.9}
 23%|██▎       | 328/1456 [27:35<1:34:29,  5.03s/it] 23%|██▎       | 329/1456 [27:40<1:34:20,  5.02s/it]                                                    {'loss': 1.3366, 'grad_norm': 2.0886063664816463, 'learning_rate': 4.514008138571486e-06, 'epoch': 0.9}
 23%|██▎       | 329/1456 [27:40<1:34:20,  5.02s/it] 23%|██▎       | 330/1456 [27:45<1:34:33,  5.04s/it]                                                    {'loss': 1.677, 'grad_norm': 2.8008482431568957, 'learning_rate': 4.510707735802547e-06, 'epoch': 0.91}
 23%|██▎       | 330/1456 [27:45<1:34:33,  5.04s/it] 23%|██▎       | 331/1456 [27:50<1:34:14,  5.03s/it]                                                    {'loss': 1.3864, 'grad_norm': 18.930254969826905, 'learning_rate': 4.507397379457957e-06, 'epoch': 0.91}
 23%|██▎       | 331/1456 [27:50<1:34:14,  5.03s/it] 23%|██▎       | 332/1456 [27:55<1:34:40,  5.05s/it]                                                    {'loss': 1.5113, 'grad_norm': 3.796537282233402, 'learning_rate': 4.5040770859249214e-06, 'epoch': 0.91}
 23%|██▎       | 332/1456 [27:55<1:34:40,  5.05s/it] 23%|██▎       | 333/1456 [28:00<1:34:22,  5.04s/it]                                                    {'loss': 2.0357, 'grad_norm': 13.94004517995335, 'learning_rate': 4.5007468716398405e-06, 'epoch': 0.91}
 23%|██▎       | 333/1456 [28:00<1:34:22,  5.04s/it] 23%|██▎       | 334/1456 [28:05<1:34:09,  5.04s/it]                                                    {'loss': 0.6786, 'grad_norm': 3.3697250964955803, 'learning_rate': 4.4974067530882225e-06, 'epoch': 0.92}
 23%|██▎       | 334/1456 [28:05<1:34:09,  5.04s/it] 23%|██▎       | 335/1456 [28:10<1:33:35,  5.01s/it]                                                    {'loss': 1.8239, 'grad_norm': 5.609126433494241, 'learning_rate': 4.494056746804604e-06, 'epoch': 0.92}
 23%|██▎       | 335/1456 [28:10<1:33:35,  5.01s/it] 23%|██▎       | 336/1456 [28:15<1:33:39,  5.02s/it]                                                    {'loss': 1.9848, 'grad_norm': 7.667708063576899, 'learning_rate': 4.49069686937247e-06, 'epoch': 0.92}
 23%|██▎       | 336/1456 [28:15<1:33:39,  5.02s/it] 23%|██▎       | 337/1456 [28:20<1:33:58,  5.04s/it]                                                    {'loss': 1.1475, 'grad_norm': 1.9638274884491325, 'learning_rate': 4.487327137424169e-06, 'epoch': 0.93}
 23%|██▎       | 337/1456 [28:20<1:33:58,  5.04s/it] 23%|██▎       | 338/1456 [28:25<1:33:26,  5.01s/it]                                                    {'loss': 3.4492, 'grad_norm': 3.289095989428302, 'learning_rate': 4.483947567640836e-06, 'epoch': 0.93}
 23%|██▎       | 338/1456 [28:25<1:33:26,  5.01s/it] 23%|██▎       | 339/1456 [28:31<1:33:49,  5.04s/it]                                                    {'loss': 1.7336, 'grad_norm': 10.450850485912916, 'learning_rate': 4.480558176752302e-06, 'epoch': 0.93}
 23%|██▎       | 339/1456 [28:31<1:33:49,  5.04s/it] 23%|██▎       | 340/1456 [28:36<1:33:34,  5.03s/it]                                                    {'loss': 1.5304, 'grad_norm': 4.555752507012576, 'learning_rate': 4.4771589815370175e-06, 'epoch': 0.93}
 23%|██▎       | 340/1456 [28:36<1:33:34,  5.03s/it] 23%|██▎       | 341/1456 [28:41<1:33:41,  5.04s/it]                                                    {'loss': 1.2864, 'grad_norm': 4.63984195768929, 'learning_rate': 4.473749998821965e-06, 'epoch': 0.94}
 23%|██▎       | 341/1456 [28:41<1:33:41,  5.04s/it] 23%|██▎       | 342/1456 [28:46<1:33:27,  5.03s/it]                                                    {'loss': 2.8567, 'grad_norm': 13.307850200281223, 'learning_rate': 4.47033124548258e-06, 'epoch': 0.94}
 23%|██▎       | 342/1456 [28:46<1:33:27,  5.03s/it] 24%|██▎       | 343/1456 [28:51<1:33:47,  5.06s/it]                                                    {'loss': 1.4635, 'grad_norm': 18.823193726631846, 'learning_rate': 4.466902738442665e-06, 'epoch': 0.94}
 24%|██▎       | 343/1456 [28:51<1:33:47,  5.06s/it] 24%|██▎       | 344/1456 [28:56<1:32:51,  5.01s/it]                                                    {'loss': 1.0862, 'grad_norm': 3.2006527175403363, 'learning_rate': 4.463464494674306e-06, 'epoch': 0.95}
 24%|██▎       | 344/1456 [28:56<1:32:51,  5.01s/it] 24%|██▎       | 345/1456 [29:01<1:32:46,  5.01s/it]                                                    {'loss': 1.2454, 'grad_norm': 7.034394641850493, 'learning_rate': 4.460016531197788e-06, 'epoch': 0.95}
 24%|██▎       | 345/1456 [29:01<1:32:46,  5.01s/it] 24%|██▍       | 346/1456 [29:06<1:32:36,  5.01s/it]                                                    {'loss': 1.403, 'grad_norm': 3.673643554723714, 'learning_rate': 4.456558865081511e-06, 'epoch': 0.95}
 24%|██▍       | 346/1456 [29:06<1:32:36,  5.01s/it] 24%|██▍       | 347/1456 [29:11<1:32:38,  5.01s/it]                                                    {'loss': 1.193, 'grad_norm': 5.5363589038934, 'learning_rate': 4.453091513441907e-06, 'epoch': 0.95}
 24%|██▍       | 347/1456 [29:11<1:32:38,  5.01s/it] 24%|██▍       | 348/1456 [29:16<1:32:22,  5.00s/it]                                                    {'loss': 1.6238, 'grad_norm': 21.389979417531517, 'learning_rate': 4.4496144934433545e-06, 'epoch': 0.96}
 24%|██▍       | 348/1456 [29:16<1:32:22,  5.00s/it] 24%|██▍       | 349/1456 [29:21<1:32:24,  5.01s/it]                                                    {'loss': 1.448, 'grad_norm': 5.756591998781023, 'learning_rate': 4.446127822298091e-06, 'epoch': 0.96}
 24%|██▍       | 349/1456 [29:21<1:32:24,  5.01s/it] 24%|██▍       | 350/1456 [29:26<1:31:53,  4.98s/it]                                                    {'loss': 1.3873, 'grad_norm': 12.13493019187662, 'learning_rate': 4.442631517266131e-06, 'epoch': 0.96}
 24%|██▍       | 350/1456 [29:26<1:31:53,  4.98s/it] 24%|██▍       | 351/1456 [29:31<1:32:09,  5.00s/it]                                                    {'loss': 1.4708, 'grad_norm': 4.977651048837117, 'learning_rate': 4.439125595655182e-06, 'epoch': 0.96}
 24%|██▍       | 351/1456 [29:31<1:32:09,  5.00s/it] 24%|██▍       | 352/1456 [29:36<1:31:58,  5.00s/it]                                                    {'loss': 2.2936, 'grad_norm': 5.5037863442847375, 'learning_rate': 4.435610074820551e-06, 'epoch': 0.97}
 24%|██▍       | 352/1456 [29:36<1:31:58,  5.00s/it] 24%|██▍       | 353/1456 [29:41<1:32:08,  5.01s/it]                                                    {'loss': 1.8553, 'grad_norm': 16.56362024513361, 'learning_rate': 4.4320849721650685e-06, 'epoch': 0.97}
 24%|██▍       | 353/1456 [29:41<1:32:08,  5.01s/it] 24%|██▍       | 354/1456 [29:46<1:31:39,  4.99s/it]                                                    {'loss': 2.1807, 'grad_norm': 3.961747246611363, 'learning_rate': 4.4285503051389954e-06, 'epoch': 0.97}
 24%|██▍       | 354/1456 [29:46<1:31:39,  4.99s/it] 24%|██▍       | 355/1456 [29:51<1:31:58,  5.01s/it]                                                    {'loss': 1.599, 'grad_norm': 3.413251627773656, 'learning_rate': 4.425006091239941e-06, 'epoch': 0.98}
 24%|██▍       | 355/1456 [29:51<1:31:58,  5.01s/it] 24%|██▍       | 356/1456 [29:56<1:31:44,  5.00s/it]                                                    {'loss': 1.9465, 'grad_norm': 5.3032048306500545, 'learning_rate': 4.421452348012771e-06, 'epoch': 0.98}
 24%|██▍       | 356/1456 [29:56<1:31:44,  5.00s/it] 25%|██▍       | 357/1456 [30:01<1:32:22,  5.04s/it]                                                    {'loss': 1.4084, 'grad_norm': 4.958460680611171, 'learning_rate': 4.4178890930495275e-06, 'epoch': 0.98}
 25%|██▍       | 357/1456 [30:01<1:32:22,  5.04s/it] 25%|██▍       | 358/1456 [30:06<1:31:27,  5.00s/it]                                                    {'loss': 1.8767, 'grad_norm': 4.9701311603025475, 'learning_rate': 4.414316343989335e-06, 'epoch': 0.98}
 25%|██▍       | 358/1456 [30:06<1:31:27,  5.00s/it] 25%|██▍       | 359/1456 [30:11<1:32:00,  5.03s/it]                                                    {'loss': 1.4279, 'grad_norm': 18.21856657953338, 'learning_rate': 4.410734118518321e-06, 'epoch': 0.99}
 25%|██▍       | 359/1456 [30:11<1:32:00,  5.03s/it] 25%|██▍       | 360/1456 [30:16<1:31:36,  5.01s/it]                                                    {'loss': 0.9783, 'grad_norm': 3.867867828020262, 'learning_rate': 4.407142434369519e-06, 'epoch': 0.99}
 25%|██▍       | 360/1456 [30:16<1:31:36,  5.01s/it] 25%|██▍       | 361/1456 [30:21<1:31:25,  5.01s/it]                                                    {'loss': 1.5979, 'grad_norm': 10.077077222665434, 'learning_rate': 4.403541309322789e-06, 'epoch': 0.99}
 25%|██▍       | 361/1456 [30:21<1:31:25,  5.01s/it] 25%|██▍       | 362/1456 [30:26<1:31:17,  5.01s/it]                                                    {'loss': 2.1845, 'grad_norm': 3.5381347248568407, 'learning_rate': 4.3999307612047246e-06, 'epoch': 0.99}
 25%|██▍       | 362/1456 [30:26<1:31:17,  5.01s/it] 25%|██▍       | 363/1456 [30:31<1:30:52,  4.99s/it]                                                    {'loss': 1.804, 'grad_norm': 5.2926429789046265, 'learning_rate': 4.396310807888568e-06, 'epoch': 1.0}
 25%|██▍       | 363/1456 [30:31<1:30:52,  4.99s/it] 25%|██▌       | 364/1456 [30:37<1:38:01,  5.39s/it]                                                    {'loss': 1.8854, 'grad_norm': 8.106355373194752, 'learning_rate': 4.392681467294117e-06, 'epoch': 1.0}
 25%|██▌       | 364/1456 [30:37<1:38:01,  5.39s/it] 25%|██▌       | 365/1456 [30:46<1:54:57,  6.32s/it]                                                    {'loss': 1.9898, 'grad_norm': 7.931835406066842, 'learning_rate': 4.389042757387642e-06, 'epoch': 1.0}
 25%|██▌       | 365/1456 [30:46<1:54:57,  6.32s/it] 25%|██▌       | 366/1456 [30:51<1:47:52,  5.94s/it]                                                    {'loss': 1.8242, 'grad_norm': 3.8898455593566914, 'learning_rate': 4.385394696181791e-06, 'epoch': 1.01}
 25%|██▌       | 366/1456 [30:51<1:47:52,  5.94s/it] 25%|██▌       | 367/1456 [30:55<1:42:14,  5.63s/it]                                                    {'loss': 1.1835, 'grad_norm': 3.9308143653328416, 'learning_rate': 4.381737301735505e-06, 'epoch': 1.01}
 25%|██▌       | 367/1456 [30:55<1:42:14,  5.63s/it] 25%|██▌       | 368/1456 [31:01<1:39:25,  5.48s/it]                                                    {'loss': 1.1129, 'grad_norm': 1.9271489793748289, 'learning_rate': 4.378070592153933e-06, 'epoch': 1.01}
 25%|██▌       | 368/1456 [31:01<1:39:25,  5.48s/it] 25%|██▌       | 369/1456 [31:06<1:36:28,  5.32s/it]                                                    {'loss': 2.0519, 'grad_norm': 5.512845384499591, 'learning_rate': 4.374394585588324e-06, 'epoch': 1.01}
 25%|██▌       | 369/1456 [31:06<1:36:28,  5.32s/it] 25%|██▌       | 370/1456 [31:11<1:34:55,  5.24s/it]                                                    {'loss': 1.7581, 'grad_norm': 3.7823922189709944, 'learning_rate': 4.370709300235961e-06, 'epoch': 1.02}
 25%|██▌       | 370/1456 [31:11<1:34:55,  5.24s/it] 25%|██▌       | 371/1456 [31:16<1:33:44,  5.18s/it]                                                    {'loss': 1.7873, 'grad_norm': 4.657729969745921, 'learning_rate': 4.367014754340056e-06, 'epoch': 1.02}
 25%|██▌       | 371/1456 [31:16<1:33:44,  5.18s/it] 26%|██▌       | 372/1456 [31:21<1:32:28,  5.12s/it]                                                    {'loss': 2.5309, 'grad_norm': 20.12130949881905, 'learning_rate': 4.3633109661896595e-06, 'epoch': 1.02}
 26%|██▌       | 372/1456 [31:21<1:32:28,  5.12s/it] 26%|██▌       | 373/1456 [31:26<1:32:00,  5.10s/it]                                                    {'loss': 1.213, 'grad_norm': 5.202523961449674, 'learning_rate': 4.35959795411958e-06, 'epoch': 1.02}
 26%|██▌       | 373/1456 [31:26<1:32:00,  5.10s/it] 26%|██▌       | 374/1456 [31:31<1:30:54,  5.04s/it]                                                    {'loss': 1.121, 'grad_norm': 4.729787284471433, 'learning_rate': 4.355875736510283e-06, 'epoch': 1.03}
 26%|██▌       | 374/1456 [31:31<1:30:54,  5.04s/it] 26%|██▌       | 375/1456 [31:36<1:31:01,  5.05s/it]                                                    {'loss': 1.402, 'grad_norm': 3.688156974587939, 'learning_rate': 4.352144331787806e-06, 'epoch': 1.03}
 26%|██▌       | 375/1456 [31:36<1:31:01,  5.05s/it] 26%|██▌       | 376/1456 [31:41<1:31:05,  5.06s/it]                                                    {'loss': 0.9955, 'grad_norm': 4.056728782669319, 'learning_rate': 4.348403758423665e-06, 'epoch': 1.03}
 26%|██▌       | 376/1456 [31:41<1:31:05,  5.06s/it] 26%|██▌       | 377/1456 [31:46<1:31:04,  5.06s/it]                                                    {'loss': 1.406, 'grad_norm': 7.864185961522168, 'learning_rate': 4.34465403493476e-06, 'epoch': 1.04}
 26%|██▌       | 377/1456 [31:46<1:31:04,  5.06s/it] 26%|██▌       | 378/1456 [31:51<1:30:50,  5.06s/it]                                                    {'loss': 1.9623, 'grad_norm': 5.117864526122126, 'learning_rate': 4.340895179883293e-06, 'epoch': 1.04}
 26%|██▌       | 378/1456 [31:51<1:30:50,  5.06s/it] 26%|██▌       | 379/1456 [31:56<1:30:39,  5.05s/it]                                                    {'loss': 2.0436, 'grad_norm': 3.9441736976103607, 'learning_rate': 4.337127211876665e-06, 'epoch': 1.04}
 26%|██▌       | 379/1456 [31:56<1:30:39,  5.05s/it] 26%|██▌       | 380/1456 [32:01<1:29:34,  4.99s/it]                                                    {'loss': 1.4631, 'grad_norm': 4.540216033433764, 'learning_rate': 4.33335014956739e-06, 'epoch': 1.04}
 26%|██▌       | 380/1456 [32:01<1:29:34,  4.99s/it] 26%|██▌       | 381/1456 [32:06<1:30:00,  5.02s/it]                                                    {'loss': 1.7345, 'grad_norm': 16.18694572530786, 'learning_rate': 4.329564011653002e-06, 'epoch': 1.05}
 26%|██▌       | 381/1456 [32:06<1:30:00,  5.02s/it] 26%|██▌       | 382/1456 [32:11<1:29:27,  5.00s/it]                                                    {'loss': 2.2607, 'grad_norm': 7.68378389682743, 'learning_rate': 4.325768816875961e-06, 'epoch': 1.05}
 26%|██▌       | 382/1456 [32:11<1:29:27,  5.00s/it] 26%|██▋       | 383/1456 [32:16<1:30:04,  5.04s/it]                                                    {'loss': 2.1022, 'grad_norm': 18.1971020078576, 'learning_rate': 4.321964584023563e-06, 'epoch': 1.05}
 26%|██▋       | 383/1456 [32:16<1:30:04,  5.04s/it] 26%|██▋       | 384/1456 [32:21<1:29:32,  5.01s/it]                                                    {'loss': 1.1975, 'grad_norm': 13.60076204296708, 'learning_rate': 4.318151331927841e-06, 'epoch': 1.05}
 26%|██▋       | 384/1456 [32:21<1:29:32,  5.01s/it] 26%|██▋       | 385/1456 [32:26<1:28:55,  4.98s/it]                                                    {'loss': 1.8101, 'grad_norm': 6.227294878803184, 'learning_rate': 4.3143290794654815e-06, 'epoch': 1.06}
 26%|██▋       | 385/1456 [32:26<1:28:55,  4.98s/it] 27%|██▋       | 386/1456 [32:31<1:28:59,  4.99s/it]                                                    {'loss': 1.378, 'grad_norm': 11.095669604497422, 'learning_rate': 4.310497845557718e-06, 'epoch': 1.06}
 27%|██▋       | 386/1456 [32:31<1:28:59,  4.99s/it] 27%|██▋       | 387/1456 [32:36<1:28:46,  4.98s/it]                                                    {'loss': 1.3808, 'grad_norm': 5.5066500255404085, 'learning_rate': 4.3066576491702526e-06, 'epoch': 1.06}
 27%|██▋       | 387/1456 [32:36<1:28:46,  4.98s/it] 27%|██▋       | 388/1456 [32:41<1:29:28,  5.03s/it]                                                    {'loss': 2.194, 'grad_norm': 6.440269689184887, 'learning_rate': 4.30280850931315e-06, 'epoch': 1.07}
 27%|██▋       | 388/1456 [32:41<1:29:28,  5.03s/it] 27%|██▋       | 389/1456 [32:46<1:28:53,  5.00s/it]                                                    {'loss': 2.8668, 'grad_norm': 12.275849142440972, 'learning_rate': 4.298950445040747e-06, 'epoch': 1.07}
 27%|██▋       | 389/1456 [32:46<1:28:53,  5.00s/it] 27%|██▋       | 390/1456 [32:51<1:29:32,  5.04s/it]                                                    {'loss': 1.5967, 'grad_norm': 8.391330113965424, 'learning_rate': 4.29508347545156e-06, 'epoch': 1.07}
 27%|██▋       | 390/1456 [32:51<1:29:32,  5.04s/it] 27%|██▋       | 391/1456 [32:56<1:29:24,  5.04s/it]                                                    {'loss': 1.4018, 'grad_norm': 3.1826679779335563, 'learning_rate': 4.291207619688189e-06, 'epoch': 1.07}
 27%|██▋       | 391/1456 [32:56<1:29:24,  5.04s/it] 27%|██▋       | 392/1456 [33:01<1:29:34,  5.05s/it]                                                    {'loss': 2.2844, 'grad_norm': 5.255340403121909, 'learning_rate': 4.287322896937225e-06, 'epoch': 1.08}
 27%|██▋       | 392/1456 [33:01<1:29:34,  5.05s/it] 27%|██▋       | 393/1456 [33:06<1:29:10,  5.03s/it]                                                    {'loss': 1.7827, 'grad_norm': 10.248231316533966, 'learning_rate': 4.2834293264291495e-06, 'epoch': 1.08}
 27%|██▋       | 393/1456 [33:06<1:29:10,  5.03s/it] 27%|██▋       | 394/1456 [33:11<1:28:45,  5.01s/it]                                                    {'loss': 1.7206, 'grad_norm': 3.6387342528536797, 'learning_rate': 4.279526927438247e-06, 'epoch': 1.08}
 27%|██▋       | 394/1456 [33:11<1:28:45,  5.01s/it] 27%|██▋       | 395/1456 [33:16<1:28:44,  5.02s/it]                                                    {'loss': 1.7395, 'grad_norm': 5.646666780822344, 'learning_rate': 4.275615719282501e-06, 'epoch': 1.09}
 27%|██▋       | 395/1456 [33:16<1:28:44,  5.02s/it] 27%|██▋       | 396/1456 [33:21<1:28:48,  5.03s/it]                                                    {'loss': 1.1215, 'grad_norm': 3.0057124745820913, 'learning_rate': 4.271695721323507e-06, 'epoch': 1.09}
 27%|██▋       | 396/1456 [33:21<1:28:48,  5.03s/it] 27%|██▋       | 397/1456 [33:26<1:28:53,  5.04s/it]                                                    {'loss': 1.6656, 'grad_norm': 26.162476157493316, 'learning_rate': 4.267766952966369e-06, 'epoch': 1.09}
 27%|██▋       | 397/1456 [33:26<1:28:53,  5.04s/it] 27%|██▋       | 398/1456 [33:31<1:29:31,  5.08s/it]                                                    {'loss': 1.262, 'grad_norm': 2.9012278160946527, 'learning_rate': 4.263829433659611e-06, 'epoch': 1.09}
 27%|██▋       | 398/1456 [33:31<1:29:31,  5.08s/it] 27%|██▋       | 399/1456 [33:36<1:28:40,  5.03s/it]                                                    {'loss': 1.9166, 'grad_norm': 5.234000030296014, 'learning_rate': 4.259883182895071e-06, 'epoch': 1.1}
 27%|██▋       | 399/1456 [33:36<1:28:40,  5.03s/it] 27%|██▋       | 400/1456 [33:41<1:28:24,  5.02s/it]                                                    {'loss': 1.7627, 'grad_norm': 4.607140571703508, 'learning_rate': 4.2559282202078175e-06, 'epoch': 1.1}
 27%|██▋       | 400/1456 [33:41<1:28:24,  5.02s/it] 28%|██▊       | 401/1456 [33:46<1:28:19,  5.02s/it]                                                    {'loss': 0.9164, 'grad_norm': 2.5263804939311827, 'learning_rate': 4.25196456517604e-06, 'epoch': 1.1}
 28%|██▊       | 401/1456 [33:46<1:28:19,  5.02s/it] 28%|██▊       | 402/1456 [33:51<1:27:34,  4.98s/it]                                                    {'loss': 0.5808, 'grad_norm': 1.1438311105119496, 'learning_rate': 4.247992237420959e-06, 'epoch': 1.1}
 28%|██▊       | 402/1456 [33:51<1:27:34,  4.98s/it] 28%|██▊       | 403/1456 [33:56<1:27:34,  4.99s/it]                                                    {'loss': 1.0325, 'grad_norm': 3.072459938030239, 'learning_rate': 4.244011256606727e-06, 'epoch': 1.11}
 28%|██▊       | 403/1456 [33:56<1:27:34,  4.99s/it] 28%|██▊       | 404/1456 [34:01<1:27:09,  4.97s/it]                                                    {'loss': 2.1712, 'grad_norm': 5.224701736917247, 'learning_rate': 4.240021642440333e-06, 'epoch': 1.11}
 28%|██▊       | 404/1456 [34:01<1:27:09,  4.97s/it] 28%|██▊       | 405/1456 [34:06<1:27:38,  5.00s/it]                                                    {'loss': 0.8403, 'grad_norm': 3.4909542901732618, 'learning_rate': 4.2360234146715025e-06, 'epoch': 1.11}
 28%|██▊       | 405/1456 [34:06<1:27:38,  5.00s/it] 28%|██▊       | 406/1456 [34:11<1:27:14,  4.99s/it]                                                    {'loss': 2.1664, 'grad_norm': 9.424034769431255, 'learning_rate': 4.232016593092602e-06, 'epoch': 1.12}
 28%|██▊       | 406/1456 [34:11<1:27:14,  4.99s/it] 28%|██▊       | 407/1456 [34:16<1:27:25,  5.00s/it]                                                    {'loss': 1.6732, 'grad_norm': 6.981651235881967, 'learning_rate': 4.228001197538537e-06, 'epoch': 1.12}
 28%|██▊       | 407/1456 [34:16<1:27:25,  5.00s/it] 28%|██▊       | 408/1456 [34:21<1:27:22,  5.00s/it]                                                    {'loss': 1.6302, 'grad_norm': 5.026674073379955, 'learning_rate': 4.22397724788666e-06, 'epoch': 1.12}
 28%|██▊       | 408/1456 [34:21<1:27:22,  5.00s/it] 28%|██▊       | 409/1456 [34:26<1:27:43,  5.03s/it]                                                    {'loss': 2.2363, 'grad_norm': 4.6052444830494315, 'learning_rate': 4.219944764056667e-06, 'epoch': 1.12}
 28%|██▊       | 409/1456 [34:26<1:27:43,  5.03s/it] 28%|██▊       | 410/1456 [34:31<1:27:09,  5.00s/it]                                                    {'loss': 1.7924, 'grad_norm': 8.895693870958059, 'learning_rate': 4.215903766010501e-06, 'epoch': 1.13}
 28%|██▊       | 410/1456 [34:31<1:27:09,  5.00s/it] 28%|██▊       | 411/1456 [34:36<1:27:36,  5.03s/it]                                                    {'loss': 1.2496, 'grad_norm': 3.13943139923427, 'learning_rate': 4.2118542737522515e-06, 'epoch': 1.13}
 28%|██▊       | 411/1456 [34:36<1:27:36,  5.03s/it] 28%|██▊       | 412/1456 [34:41<1:27:18,  5.02s/it]                                                    {'loss': 1.379, 'grad_norm': 4.385203642515148, 'learning_rate': 4.207796307328059e-06, 'epoch': 1.13}
 28%|██▊       | 412/1456 [34:41<1:27:18,  5.02s/it] 28%|██▊       | 413/1456 [34:46<1:27:38,  5.04s/it]                                                    {'loss': 1.5713, 'grad_norm': 2.783796195035327, 'learning_rate': 4.203729886826012e-06, 'epoch': 1.13}
 28%|██▊       | 413/1456 [34:46<1:27:38,  5.04s/it] 28%|██▊       | 414/1456 [34:51<1:26:52,  5.00s/it]                                                    {'loss': 1.8483, 'grad_norm': 5.768950704966036, 'learning_rate': 4.19965503237605e-06, 'epoch': 1.14}
 28%|██▊       | 414/1456 [34:51<1:26:52,  5.00s/it] 29%|██▊       | 415/1456 [34:56<1:26:59,  5.01s/it]                                                    {'loss': 1.2593, 'grad_norm': 6.438040997633289, 'learning_rate': 4.195571764149862e-06, 'epoch': 1.14}
 29%|██▊       | 415/1456 [34:56<1:26:59,  5.01s/it] 29%|██▊       | 416/1456 [35:01<1:26:36,  5.00s/it]                                                    {'loss': 0.8216, 'grad_norm': 9.18039059807387, 'learning_rate': 4.191480102360787e-06, 'epoch': 1.14}
 29%|██▊       | 416/1456 [35:01<1:26:36,  5.00s/it] 29%|██▊       | 417/1456 [35:06<1:26:46,  5.01s/it]                                                    {'loss': 1.6626, 'grad_norm': 2.6353178244489133, 'learning_rate': 4.187380067263719e-06, 'epoch': 1.15}
 29%|██▊       | 417/1456 [35:06<1:26:46,  5.01s/it] 29%|██▊       | 418/1456 [35:11<1:26:58,  5.03s/it]                                                    {'loss': 1.1925, 'grad_norm': 2.6717331162643205, 'learning_rate': 4.183271679154994e-06, 'epoch': 1.15}
 29%|██▊       | 418/1456 [35:11<1:26:58,  5.03s/it] 29%|██▉       | 419/1456 [35:16<1:26:49,  5.02s/it]                                                    {'loss': 1.1996, 'grad_norm': 5.602362624820039, 'learning_rate': 4.179154958372307e-06, 'epoch': 1.15}
 29%|██▉       | 419/1456 [35:16<1:26:49,  5.02s/it] 29%|██▉       | 420/1456 [35:21<1:26:47,  5.03s/it]                                                    {'loss': 1.6507, 'grad_norm': 3.7930489560102476, 'learning_rate': 4.1750299252945945e-06, 'epoch': 1.15}
 29%|██▉       | 420/1456 [35:21<1:26:47,  5.03s/it] 29%|██▉       | 421/1456 [35:26<1:25:59,  4.98s/it]                                                    {'loss': 1.2586, 'grad_norm': 2.792296684875586, 'learning_rate': 4.170896600341947e-06, 'epoch': 1.16}
 29%|██▉       | 421/1456 [35:26<1:25:59,  4.98s/it] 29%|██▉       | 422/1456 [35:31<1:26:34,  5.02s/it]                                                    {'loss': 1.3221, 'grad_norm': 4.373917363952987, 'learning_rate': 4.166755003975497e-06, 'epoch': 1.16}
 29%|██▉       | 422/1456 [35:31<1:26:34,  5.02s/it] 29%|██▉       | 423/1456 [35:36<1:26:29,  5.02s/it]                                                    {'loss': 1.8336, 'grad_norm': 7.6546424890874025, 'learning_rate': 4.162605156697328e-06, 'epoch': 1.16}
 29%|██▉       | 423/1456 [35:36<1:26:29,  5.02s/it] 29%|██▉       | 424/1456 [35:42<1:26:40,  5.04s/it]                                                    {'loss': 2.0957, 'grad_norm': 8.362165495108197, 'learning_rate': 4.158447079050364e-06, 'epoch': 1.16}
 29%|██▉       | 424/1456 [35:42<1:26:40,  5.04s/it] 29%|██▉       | 425/1456 [35:47<1:26:55,  5.06s/it]                                                    {'loss': 2.3883, 'grad_norm': 10.585270821949878, 'learning_rate': 4.154280791618273e-06, 'epoch': 1.17}
 29%|██▉       | 425/1456 [35:47<1:26:55,  5.06s/it] 29%|██▉       | 426/1456 [35:52<1:26:48,  5.06s/it]                                                    {'loss': 2.3303, 'grad_norm': 4.513314365439139, 'learning_rate': 4.150106315025363e-06, 'epoch': 1.17}
 29%|██▉       | 426/1456 [35:52<1:26:48,  5.06s/it] 29%|██▉       | 427/1456 [35:57<1:26:44,  5.06s/it]                                                    {'loss': 1.8145, 'grad_norm': 7.8660130159186465, 'learning_rate': 4.145923669936483e-06, 'epoch': 1.17}
 29%|██▉       | 427/1456 [35:57<1:26:44,  5.06s/it] 29%|██▉       | 428/1456 [36:02<1:25:44,  5.00s/it]                                                    {'loss': 1.3915, 'grad_norm': 4.819501663342278, 'learning_rate': 4.141732877056916e-06, 'epoch': 1.18}
 29%|██▉       | 428/1456 [36:02<1:25:44,  5.00s/it] 29%|██▉       | 429/1456 [36:07<1:26:20,  5.04s/it]                                                    {'loss': 1.0963, 'grad_norm': 19.076352548705426, 'learning_rate': 4.137533957132279e-06, 'epoch': 1.18}
 29%|██▉       | 429/1456 [36:07<1:26:20,  5.04s/it] 30%|██▉       | 430/1456 [36:12<1:25:52,  5.02s/it]                                                    {'loss': 2.3726, 'grad_norm': 9.859499971350402, 'learning_rate': 4.133326930948422e-06, 'epoch': 1.18}
 30%|██▉       | 430/1456 [36:12<1:25:52,  5.02s/it] 30%|██▉       | 431/1456 [36:17<1:25:53,  5.03s/it]                                                    {'loss': 1.4986, 'grad_norm': 4.196866846822288, 'learning_rate': 4.129111819331322e-06, 'epoch': 1.18}
 30%|██▉       | 431/1456 [36:17<1:25:53,  5.03s/it] 30%|██▉       | 432/1456 [36:22<1:25:41,  5.02s/it]                                                    {'loss': 1.0966, 'grad_norm': 6.248737055014785, 'learning_rate': 4.12488864314698e-06, 'epoch': 1.19}
 30%|██▉       | 432/1456 [36:22<1:25:41,  5.02s/it] 30%|██▉       | 433/1456 [36:27<1:25:09,  5.00s/it]                                                    {'loss': 2.0282, 'grad_norm': 7.015649196523558, 'learning_rate': 4.120657423301323e-06, 'epoch': 1.19}
 30%|██▉       | 433/1456 [36:27<1:25:09,  5.00s/it] 30%|██▉       | 434/1456 [36:32<1:25:37,  5.03s/it]                                                    {'loss': 2.1414, 'grad_norm': 7.701974779030776, 'learning_rate': 4.116418180740091e-06, 'epoch': 1.19}
 30%|██▉       | 434/1456 [36:32<1:25:37,  5.03s/it] 30%|██▉       | 435/1456 [36:37<1:24:47,  4.98s/it]                                                    {'loss': 1.8088, 'grad_norm': 3.216370378858981, 'learning_rate': 4.1121709364487435e-06, 'epoch': 1.2}
 30%|██▉       | 435/1456 [36:37<1:24:47,  4.98s/it] 30%|██▉       | 436/1456 [36:42<1:25:05,  5.01s/it]                                                    {'loss': 1.8581, 'grad_norm': 5.789370221030293, 'learning_rate': 4.107915711452347e-06, 'epoch': 1.2}
 30%|██▉       | 436/1456 [36:42<1:25:05,  5.01s/it] 30%|███       | 437/1456 [36:47<1:25:04,  5.01s/it]                                                    {'loss': 1.4999, 'grad_norm': 3.006926329227548, 'learning_rate': 4.103652526815477e-06, 'epoch': 1.2}
 30%|███       | 437/1456 [36:47<1:25:04,  5.01s/it] 30%|███       | 438/1456 [36:52<1:25:13,  5.02s/it]                                                    {'loss': 1.0364, 'grad_norm': 4.464466950143744, 'learning_rate': 4.099381403642112e-06, 'epoch': 1.2}
 30%|███       | 438/1456 [36:52<1:25:13,  5.02s/it] 30%|███       | 439/1456 [36:57<1:25:21,  5.04s/it]                                                    {'loss': 0.8387, 'grad_norm': 2.7665131430562777, 'learning_rate': 4.095102363075526e-06, 'epoch': 1.21}
 30%|███       | 439/1456 [36:57<1:25:21,  5.04s/it] 30%|███       | 440/1456 [37:02<1:25:00,  5.02s/it]                                                    {'loss': 1.4165, 'grad_norm': 6.034451124362054, 'learning_rate': 4.090815426298189e-06, 'epoch': 1.21}
 30%|███       | 440/1456 [37:02<1:25:00,  5.02s/it] 30%|███       | 441/1456 [37:07<1:25:11,  5.04s/it]                                                    {'loss': 1.1762, 'grad_norm': 2.3968526468639677, 'learning_rate': 4.086520614531657e-06, 'epoch': 1.21}
 30%|███       | 441/1456 [37:07<1:25:11,  5.04s/it] 30%|███       | 442/1456 [37:12<1:24:41,  5.01s/it]                                                    {'loss': 1.7432, 'grad_norm': 83.20879822207806, 'learning_rate': 4.0822179490364735e-06, 'epoch': 1.21}
 30%|███       | 442/1456 [37:12<1:24:41,  5.01s/it] 30%|███       | 443/1456 [37:17<1:24:50,  5.02s/it]                                                    {'loss': 0.7999, 'grad_norm': 3.4341154602671415, 'learning_rate': 4.077907451112054e-06, 'epoch': 1.22}
 30%|███       | 443/1456 [37:17<1:24:50,  5.02s/it] 30%|███       | 444/1456 [37:22<1:24:18,  5.00s/it]                                                    {'loss': 2.1225, 'grad_norm': 14.752771149577184, 'learning_rate': 4.073589142096592e-06, 'epoch': 1.22}
 30%|███       | 444/1456 [37:22<1:24:18,  5.00s/it] 31%|███       | 445/1456 [37:27<1:24:37,  5.02s/it]                                                    {'loss': 2.5803, 'grad_norm': 5.786929088800777, 'learning_rate': 4.069263043366947e-06, 'epoch': 1.22}
 31%|███       | 445/1456 [37:27<1:24:37,  5.02s/it] 31%|███       | 446/1456 [37:32<1:23:53,  4.98s/it]                                                    {'loss': 1.7648, 'grad_norm': 3.7108137571885162, 'learning_rate': 4.0649291763385385e-06, 'epoch': 1.23}
 31%|███       | 446/1456 [37:32<1:23:53,  4.98s/it] 31%|███       | 447/1456 [37:37<1:24:04,  5.00s/it]                                                    {'loss': 1.4411, 'grad_norm': 4.8913197374332125, 'learning_rate': 4.0605875624652414e-06, 'epoch': 1.23}
 31%|███       | 447/1456 [37:37<1:24:04,  5.00s/it] 31%|███       | 448/1456 [37:42<1:23:34,  4.97s/it]                                                    {'loss': 2.1102, 'grad_norm': 4.7626908071346845, 'learning_rate': 4.0562382232392805e-06, 'epoch': 1.23}
 31%|███       | 448/1456 [37:42<1:23:34,  4.97s/it] 31%|███       | 449/1456 [37:47<1:24:13,  5.02s/it]                                                    {'loss': 0.9045, 'grad_norm': 2.346548215665381, 'learning_rate': 4.051881180191124e-06, 'epoch': 1.23}
 31%|███       | 449/1456 [37:47<1:24:13,  5.02s/it] 31%|███       | 450/1456 [37:52<1:24:00,  5.01s/it]                                                    {'loss': 1.9253, 'grad_norm': 3.2021850695525904, 'learning_rate': 4.047516454889374e-06, 'epoch': 1.24}
 31%|███       | 450/1456 [37:52<1:24:00,  5.01s/it] 31%|███       | 451/1456 [37:57<1:24:29,  5.04s/it]                                                    {'loss': 1.2271, 'grad_norm': 2.22438440700856, 'learning_rate': 4.043144068940663e-06, 'epoch': 1.24}
 31%|███       | 451/1456 [37:57<1:24:29,  5.04s/it] 31%|███       | 452/1456 [38:02<1:23:08,  4.97s/it]                                                    {'loss': 1.584, 'grad_norm': 10.289367254171218, 'learning_rate': 4.038764043989547e-06, 'epoch': 1.24}
 31%|███       | 452/1456 [38:02<1:23:08,  4.97s/it] 31%|███       | 453/1456 [38:07<1:23:53,  5.02s/it]                                                    {'loss': 2.0003, 'grad_norm': 19.37870034598836, 'learning_rate': 4.0343764017183976e-06, 'epoch': 1.24}
 31%|███       | 453/1456 [38:07<1:23:53,  5.02s/it] 31%|███       | 454/1456 [38:12<1:23:20,  4.99s/it]                                                    {'loss': 1.5503, 'grad_norm': 4.610093917386502, 'learning_rate': 4.0299811638472895e-06, 'epoch': 1.25}
 31%|███       | 454/1456 [38:12<1:23:20,  4.99s/it] 31%|███▏      | 455/1456 [38:17<1:23:58,  5.03s/it]                                                    {'loss': 1.7635, 'grad_norm': 29.938865933087296, 'learning_rate': 4.0255783521339035e-06, 'epoch': 1.25}
 31%|███▏      | 455/1456 [38:17<1:23:58,  5.03s/it] 31%|███▏      | 456/1456 [38:22<1:23:42,  5.02s/it]                                                    {'loss': 1.7121, 'grad_norm': 35.62893687128659, 'learning_rate': 4.021167988373411e-06, 'epoch': 1.25}
 31%|███▏      | 456/1456 [38:22<1:23:42,  5.02s/it] 31%|███▏      | 457/1456 [38:27<1:23:43,  5.03s/it]                                                    {'loss': 1.5557, 'grad_norm': 2.7600000798874995, 'learning_rate': 4.016750094398369e-06, 'epoch': 1.26}
 31%|███▏      | 457/1456 [38:27<1:23:43,  5.03s/it] 31%|███▏      | 458/1456 [38:32<1:23:44,  5.03s/it]                                                    {'loss': 1.512, 'grad_norm': 2.867520596231527, 'learning_rate': 4.012324692078606e-06, 'epoch': 1.26}
 31%|███▏      | 458/1456 [38:32<1:23:44,  5.03s/it] 32%|███▏      | 459/1456 [38:37<1:22:50,  4.99s/it]                                                    {'loss': 1.2114, 'grad_norm': 2.3733023549140504, 'learning_rate': 4.007891803321128e-06, 'epoch': 1.26}
 32%|███▏      | 459/1456 [38:37<1:22:50,  4.99s/it] 32%|███▏      | 460/1456 [38:42<1:23:08,  5.01s/it]                                                    {'loss': 1.6375, 'grad_norm': 2.550243093085792, 'learning_rate': 4.003451450069994e-06, 'epoch': 1.26}
 32%|███▏      | 460/1456 [38:42<1:23:08,  5.01s/it] 32%|███▏      | 461/1456 [38:47<1:22:41,  4.99s/it]                                                    {'loss': 1.2216, 'grad_norm': 8.141326464049842, 'learning_rate': 3.999003654306217e-06, 'epoch': 1.27}
 32%|███▏      | 461/1456 [38:47<1:22:41,  4.99s/it] 32%|███▏      | 462/1456 [38:52<1:23:16,  5.03s/it]                                                    {'loss': 1.579, 'grad_norm': 58.90826007843679, 'learning_rate': 3.994548438047652e-06, 'epoch': 1.27}
 32%|███▏      | 462/1456 [38:52<1:23:16,  5.03s/it] 32%|███▏      | 463/1456 [38:57<1:22:56,  5.01s/it]                                                    {'loss': 1.5567, 'grad_norm': 3.9292369303618524, 'learning_rate': 3.990085823348887e-06, 'epoch': 1.27}
 32%|███▏      | 463/1456 [38:57<1:22:56,  5.01s/it] 32%|███▏      | 464/1456 [39:02<1:23:21,  5.04s/it]                                                    {'loss': 1.842, 'grad_norm': 20.63736016949903, 'learning_rate': 3.9856158323011366e-06, 'epoch': 1.27}
 32%|███▏      | 464/1456 [39:02<1:23:21,  5.04s/it] 32%|███▏      | 465/1456 [39:07<1:22:41,  5.01s/it]                                                    {'loss': 1.81, 'grad_norm': 4.835180368146041, 'learning_rate': 3.9811384870321265e-06, 'epoch': 1.28}
 32%|███▏      | 465/1456 [39:07<1:22:41,  5.01s/it] 32%|███▏      | 466/1456 [39:12<1:23:12,  5.04s/it]                                                    {'loss': 1.5525, 'grad_norm': 3.4024349861744665, 'learning_rate': 3.9766538097059935e-06, 'epoch': 1.28}
 32%|███▏      | 466/1456 [39:12<1:23:12,  5.04s/it] 32%|███▏      | 467/1456 [39:17<1:22:48,  5.02s/it]                                                    {'loss': 2.4562, 'grad_norm': 14.825598997009099, 'learning_rate': 3.9721618225231645e-06, 'epoch': 1.28}
 32%|███▏      | 467/1456 [39:17<1:22:48,  5.02s/it] 32%|███▏      | 468/1456 [39:22<1:23:23,  5.06s/it]                                                    {'loss': 1.7723, 'grad_norm': 4.220959346254637, 'learning_rate': 3.967662547720256e-06, 'epoch': 1.29}
 32%|███▏      | 468/1456 [39:22<1:23:23,  5.06s/it] 32%|███▏      | 469/1456 [39:27<1:22:39,  5.02s/it]                                                    {'loss': 1.4559, 'grad_norm': 3.384956085957013, 'learning_rate': 3.963156007569957e-06, 'epoch': 1.29}
 32%|███▏      | 469/1456 [39:27<1:22:39,  5.02s/it] 32%|███▏      | 470/1456 [39:32<1:22:33,  5.02s/it]                                                    {'loss': 1.781, 'grad_norm': 2.674111930102324, 'learning_rate': 3.958642224380927e-06, 'epoch': 1.29}
 32%|███▏      | 470/1456 [39:32<1:22:33,  5.02s/it] 32%|███▏      | 471/1456 [39:37<1:22:34,  5.03s/it]                                                    {'loss': 1.3409, 'grad_norm': 8.920433128344477, 'learning_rate': 3.954121220497675e-06, 'epoch': 1.29}
 32%|███▏      | 471/1456 [39:37<1:22:34,  5.03s/it] 32%|███▏      | 472/1456 [39:42<1:22:33,  5.03s/it]                                                    {'loss': 1.2535, 'grad_norm': 5.233986546920028, 'learning_rate': 3.94959301830046e-06, 'epoch': 1.3}
 32%|███▏      | 472/1456 [39:42<1:22:33,  5.03s/it] 32%|███▏      | 473/1456 [39:48<1:22:35,  5.04s/it]                                                    {'loss': 0.8563, 'grad_norm': 5.6359045507336685, 'learning_rate': 3.9450576402051685e-06, 'epoch': 1.3}
 32%|███▏      | 473/1456 [39:48<1:22:35,  5.04s/it] 33%|███▎      | 474/1456 [39:53<1:22:20,  5.03s/it]                                                    {'loss': 1.9764, 'grad_norm': 3.872649064171831, 'learning_rate': 3.940515108663216e-06, 'epoch': 1.3}
 33%|███▎      | 474/1456 [39:53<1:22:20,  5.03s/it] 33%|███▎      | 475/1456 [39:58<1:22:16,  5.03s/it]                                                    {'loss': 1.8707, 'grad_norm': 6.941153998828237, 'learning_rate': 3.935965446161425e-06, 'epoch': 1.3}
 33%|███▎      | 475/1456 [39:58<1:22:16,  5.03s/it] 33%|███▎      | 476/1456 [40:02<1:21:33,  4.99s/it]                                                    {'loss': 2.2602, 'grad_norm': 6.1937018245359345, 'learning_rate': 3.93140867522192e-06, 'epoch': 1.31}
 33%|███▎      | 476/1456 [40:02<1:21:33,  4.99s/it] 33%|███▎      | 477/1456 [40:08<1:22:14,  5.04s/it]                                                    {'loss': 3.8451, 'grad_norm': 16.069731394452234, 'learning_rate': 3.926844818402015e-06, 'epoch': 1.31}
 33%|███▎      | 477/1456 [40:08<1:22:14,  5.04s/it] 33%|███▎      | 478/1456 [40:13<1:21:38,  5.01s/it]                                                    {'loss': 1.095, 'grad_norm': 5.07399584226998, 'learning_rate': 3.9222738982941e-06, 'epoch': 1.31}
 33%|███▎      | 478/1456 [40:13<1:21:38,  5.01s/it] 33%|███▎      | 479/1456 [40:18<1:22:06,  5.04s/it]                                                    {'loss': 2.3461, 'grad_norm': 5.451747775025018, 'learning_rate': 3.917695937525531e-06, 'epoch': 1.32}
 33%|███▎      | 479/1456 [40:18<1:22:06,  5.04s/it] 33%|███▎      | 480/1456 [40:23<1:21:23,  5.00s/it]                                                    {'loss': 2.0494, 'grad_norm': 5.477207466925293, 'learning_rate': 3.913110958758517e-06, 'epoch': 1.32}
 33%|███▎      | 480/1456 [40:23<1:21:23,  5.00s/it] 33%|███▎      | 481/1456 [40:28<1:22:26,  5.07s/it]                                                    {'loss': 1.5081, 'grad_norm': 2.679458830838733, 'learning_rate': 3.908518984690008e-06, 'epoch': 1.32}
 33%|███▎      | 481/1456 [40:28<1:22:26,  5.07s/it] 33%|███▎      | 482/1456 [40:33<1:21:53,  5.04s/it]                                                    {'loss': 2.4019, 'grad_norm': 4.881976881623373, 'learning_rate': 3.903920038051581e-06, 'epoch': 1.32}
 33%|███▎      | 482/1456 [40:33<1:21:53,  5.04s/it] 33%|███▎      | 483/1456 [40:38<1:22:20,  5.08s/it]                                                    {'loss': 2.3513, 'grad_norm': 4.987698107922279, 'learning_rate': 3.899314141609333e-06, 'epoch': 1.33}
 33%|███▎      | 483/1456 [40:38<1:22:20,  5.08s/it] 33%|███▎      | 484/1456 [40:43<1:22:06,  5.07s/it]                                                    {'loss': 1.6408, 'grad_norm': 2.5878193165293517, 'learning_rate': 3.894701318163763e-06, 'epoch': 1.33}
 33%|███▎      | 484/1456 [40:43<1:22:06,  5.07s/it] 33%|███▎      | 485/1456 [40:48<1:22:01,  5.07s/it]                                                    {'loss': 1.4534, 'grad_norm': 5.991600196833995, 'learning_rate': 3.890081590549658e-06, 'epoch': 1.33}
 33%|███▎      | 485/1456 [40:48<1:22:01,  5.07s/it] 33%|███▎      | 486/1456 [40:53<1:21:31,  5.04s/it]                                                    {'loss': 2.3013, 'grad_norm': 5.959403984427417, 'learning_rate': 3.885454981635986e-06, 'epoch': 1.34}
 33%|███▎      | 486/1456 [40:53<1:21:31,  5.04s/it] 33%|███▎      | 487/1456 [40:58<1:21:39,  5.06s/it]                                                    {'loss': 1.4022, 'grad_norm': 3.555493609233161, 'learning_rate': 3.8808215143257774e-06, 'epoch': 1.34}
 33%|███▎      | 487/1456 [40:58<1:21:39,  5.06s/it] 34%|███▎      | 488/1456 [41:03<1:21:34,  5.06s/it]                                                    {'loss': 1.015, 'grad_norm': 12.215916766109839, 'learning_rate': 3.876181211556016e-06, 'epoch': 1.34}
 34%|███▎      | 488/1456 [41:03<1:21:34,  5.06s/it] 34%|███▎      | 489/1456 [41:08<1:21:17,  5.04s/it]                                                    {'loss': 1.6791, 'grad_norm': 4.739761762788628, 'learning_rate': 3.8715340962975205e-06, 'epoch': 1.34}
 34%|███▎      | 489/1456 [41:08<1:21:17,  5.04s/it] 34%|███▎      | 490/1456 [41:13<1:21:01,  5.03s/it]                                                    {'loss': 2.0073, 'grad_norm': 6.981616266899964, 'learning_rate': 3.866880191554833e-06, 'epoch': 1.35}
 34%|███▎      | 490/1456 [41:13<1:21:01,  5.03s/it] 34%|███▎      | 491/1456 [41:18<1:20:50,  5.03s/it]                                                    {'loss': 1.1606, 'grad_norm': 4.596918790752607, 'learning_rate': 3.862219520366107e-06, 'epoch': 1.35}
 34%|███▎      | 491/1456 [41:18<1:20:50,  5.03s/it] 34%|███▍      | 492/1456 [41:23<1:20:30,  5.01s/it]                                                    {'loss': 1.5501, 'grad_norm': 4.116715637615891, 'learning_rate': 3.8575521058029935e-06, 'epoch': 1.35}
 34%|███▍      | 492/1456 [41:23<1:20:30,  5.01s/it] 34%|███▍      | 493/1456 [41:28<1:20:43,  5.03s/it]                                                    {'loss': 1.9124, 'grad_norm': 10.807350299476994, 'learning_rate': 3.852877970970522e-06, 'epoch': 1.35}
 34%|███▍      | 493/1456 [41:28<1:20:43,  5.03s/it] 34%|███▍      | 494/1456 [41:33<1:20:25,  5.02s/it]                                                    {'loss': 1.7573, 'grad_norm': 16.622306892419633, 'learning_rate': 3.8481971390069895e-06, 'epoch': 1.36}
 34%|███▍      | 494/1456 [41:33<1:20:25,  5.02s/it] 34%|███▍      | 495/1456 [41:38<1:20:16,  5.01s/it]                                                    {'loss': 2.1248, 'grad_norm': 6.215803972508962, 'learning_rate': 3.843509633083848e-06, 'epoch': 1.36}
 34%|███▍      | 495/1456 [41:38<1:20:16,  5.01s/it] 34%|███▍      | 496/1456 [41:43<1:20:11,  5.01s/it]                                                    {'loss': 1.7144, 'grad_norm': 7.197245749209326, 'learning_rate': 3.838815476405586e-06, 'epoch': 1.36}
 34%|███▍      | 496/1456 [41:43<1:20:11,  5.01s/it] 34%|███▍      | 497/1456 [41:48<1:19:44,  4.99s/it]                                                    {'loss': 1.7398, 'grad_norm': 5.212890076163797, 'learning_rate': 3.834114692209615e-06, 'epoch': 1.37}
 34%|███▍      | 497/1456 [41:48<1:19:44,  4.99s/it] 34%|███▍      | 498/1456 [41:53<1:19:58,  5.01s/it]                                                    {'loss': 1.4923, 'grad_norm': 11.680132986905452, 'learning_rate': 3.829407303766155e-06, 'epoch': 1.37}
 34%|███▍      | 498/1456 [41:53<1:19:58,  5.01s/it] 34%|███▍      | 499/1456 [41:58<1:19:47,  5.00s/it]                                                    {'loss': 1.507, 'grad_norm': 3.204292196353862, 'learning_rate': 3.824693334378118e-06, 'epoch': 1.37}
 34%|███▍      | 499/1456 [41:58<1:19:47,  5.00s/it] 34%|███▍      | 500/1456 [42:03<1:20:17,  5.04s/it]                                                    {'loss': 2.4853, 'grad_norm': 10.00788759058968, 'learning_rate': 3.819972807380995e-06, 'epoch': 1.37}
 34%|███▍      | 500/1456 [42:03<1:20:17,  5.04s/it] 34%|███▍      | 501/1456 [42:08<1:20:01,  5.03s/it]                                                    {'loss': 1.4008, 'grad_norm': 3.001578551472405, 'learning_rate': 3.815245746142739e-06, 'epoch': 1.38}
 34%|███▍      | 501/1456 [42:08<1:20:01,  5.03s/it] 34%|███▍      | 502/1456 [42:14<1:20:34,  5.07s/it]                                                    {'loss': 1.6943, 'grad_norm': 4.042259146664036, 'learning_rate': 3.8105121740636474e-06, 'epoch': 1.38}
 34%|███▍      | 502/1456 [42:14<1:20:34,  5.07s/it] 35%|███▍      | 503/1456 [42:19<1:20:14,  5.05s/it]                                                    {'loss': 2.0451, 'grad_norm': 5.771905719074318, 'learning_rate': 3.8057721145762504e-06, 'epoch': 1.38}
 35%|███▍      | 503/1456 [42:19<1:20:14,  5.05s/it] 35%|███▍      | 504/1456 [42:24<1:20:27,  5.07s/it]                                                    {'loss': 2.1427, 'grad_norm': 4.904104164436116, 'learning_rate': 3.801025591145191e-06, 'epoch': 1.38}
 35%|███▍      | 504/1456 [42:24<1:20:27,  5.07s/it] 35%|███▍      | 505/1456 [42:29<1:19:38,  5.02s/it]                                                    {'loss': 1.0624, 'grad_norm': 2.3505374537350248, 'learning_rate': 3.7962726272671117e-06, 'epoch': 1.39}
 35%|███▍      | 505/1456 [42:29<1:19:38,  5.02s/it] 35%|███▍      | 506/1456 [42:34<1:19:40,  5.03s/it]                                                    {'loss': 1.0676, 'grad_norm': 1.8618511733944034, 'learning_rate': 3.7915132464705374e-06, 'epoch': 1.39}
 35%|███▍      | 506/1456 [42:34<1:19:40,  5.03s/it] 35%|███▍      | 507/1456 [42:39<1:19:08,  5.00s/it]                                                    {'loss': 0.9736, 'grad_norm': 5.270395172764525, 'learning_rate': 3.7867474723157565e-06, 'epoch': 1.39}
 35%|███▍      | 507/1456 [42:39<1:19:08,  5.00s/it] 35%|███▍      | 508/1456 [42:44<1:19:08,  5.01s/it]                                                    {'loss': 1.9299, 'grad_norm': 5.687953385946752, 'learning_rate': 3.781975328394708e-06, 'epoch': 1.4}
 35%|███▍      | 508/1456 [42:44<1:19:08,  5.01s/it] 35%|███▍      | 509/1456 [42:49<1:19:23,  5.03s/it]                                                    {'loss': 3.0402, 'grad_norm': 8.105636293449127, 'learning_rate': 3.777196838330863e-06, 'epoch': 1.4}
 35%|███▍      | 509/1456 [42:49<1:19:23,  5.03s/it] 35%|███▌      | 510/1456 [42:54<1:19:30,  5.04s/it]                                                    {'loss': 2.479, 'grad_norm': 7.559761245025342, 'learning_rate': 3.7724120257791085e-06, 'epoch': 1.4}
 35%|███▌      | 510/1456 [42:54<1:19:30,  5.04s/it] 35%|███▌      | 511/1456 [42:59<1:19:09,  5.03s/it]                                                    {'loss': 0.5138, 'grad_norm': 3.8715933314743176, 'learning_rate': 3.767620914425627e-06, 'epoch': 1.4}
 35%|███▌      | 511/1456 [42:59<1:19:09,  5.03s/it] 35%|███▌      | 512/1456 [43:04<1:19:14,  5.04s/it]                                                    {'loss': 1.6003, 'grad_norm': 6.770441538894771, 'learning_rate': 3.7628235279877833e-06, 'epoch': 1.41}
 35%|███▌      | 512/1456 [43:04<1:19:14,  5.04s/it] 35%|███▌      | 513/1456 [43:09<1:18:53,  5.02s/it]                                                    {'loss': 1.1631, 'grad_norm': 3.78903796001235, 'learning_rate': 3.7580198902140073e-06, 'epoch': 1.41}
 35%|███▌      | 513/1456 [43:09<1:18:53,  5.02s/it] 35%|███▌      | 514/1456 [43:14<1:18:22,  4.99s/it]                                                    {'loss': 1.3001, 'grad_norm': 5.10129143314599, 'learning_rate': 3.7532100248836737e-06, 'epoch': 1.41}
 35%|███▌      | 514/1456 [43:14<1:18:22,  4.99s/it] 35%|███▌      | 515/1456 [43:19<1:18:43,  5.02s/it]                                                    {'loss': 2.1729, 'grad_norm': 12.452661828745441, 'learning_rate': 3.7483939558069837e-06, 'epoch': 1.41}
 35%|███▌      | 515/1456 [43:19<1:18:43,  5.02s/it] 35%|███▌      | 516/1456 [43:24<1:18:32,  5.01s/it]                                                    {'loss': 1.7044, 'grad_norm': 67.89638388981037, 'learning_rate': 3.74357170682485e-06, 'epoch': 1.42}
 35%|███▌      | 516/1456 [43:24<1:18:32,  5.01s/it] 36%|███▌      | 517/1456 [43:29<1:18:57,  5.05s/it]                                                    {'loss': 1.1731, 'grad_norm': 1.8693191937298657, 'learning_rate': 3.7387433018087794e-06, 'epoch': 1.42}
 36%|███▌      | 517/1456 [43:29<1:18:57,  5.05s/it] 36%|███▌      | 518/1456 [43:34<1:18:12,  5.00s/it]                                                    {'loss': 1.3087, 'grad_norm': 1.895994459019383, 'learning_rate': 3.733908764660749e-06, 'epoch': 1.42}
 36%|███▌      | 518/1456 [43:34<1:18:12,  5.00s/it] 36%|███▌      | 519/1456 [43:39<1:18:26,  5.02s/it]                                                    {'loss': 1.3583, 'grad_norm': 2.4765438235568453, 'learning_rate': 3.7290681193130956e-06, 'epoch': 1.43}
 36%|███▌      | 519/1456 [43:39<1:18:26,  5.02s/it] 36%|███▌      | 520/1456 [43:44<1:18:18,  5.02s/it]                                                    {'loss': 1.2725, 'grad_norm': 2.0968500218275237, 'learning_rate': 3.7242213897283906e-06, 'epoch': 1.43}
 36%|███▌      | 520/1456 [43:44<1:18:18,  5.02s/it] 36%|███▌      | 521/1456 [43:49<1:18:29,  5.04s/it]                                                    {'loss': 1.3835, 'grad_norm': 4.224030531310511, 'learning_rate': 3.719368599899326e-06, 'epoch': 1.43}
 36%|███▌      | 521/1456 [43:49<1:18:29,  5.04s/it] 36%|███▌      | 522/1456 [43:54<1:18:13,  5.03s/it]                                                    {'loss': 0.8378, 'grad_norm': 3.659923436140522, 'learning_rate': 3.714509773848592e-06, 'epoch': 1.43}
 36%|███▌      | 522/1456 [43:54<1:18:13,  5.03s/it] 36%|███▌      | 523/1456 [43:59<1:18:11,  5.03s/it]                                                    {'loss': 1.4004, 'grad_norm': 6.406277093597433, 'learning_rate': 3.7096449356287603e-06, 'epoch': 1.44}
 36%|███▌      | 523/1456 [43:59<1:18:11,  5.03s/it] 36%|███▌      | 524/1456 [44:04<1:17:45,  5.01s/it]                                                    {'loss': 1.2729, 'grad_norm': 1.9612998475644345, 'learning_rate': 3.704774109322166e-06, 'epoch': 1.44}
 36%|███▌      | 524/1456 [44:04<1:17:45,  5.01s/it] 36%|███▌      | 525/1456 [44:09<1:18:16,  5.04s/it]                                                    {'loss': 1.5968, 'grad_norm': 7.491340724600022, 'learning_rate': 3.699897319040785e-06, 'epoch': 1.44}
 36%|███▌      | 525/1456 [44:09<1:18:16,  5.04s/it] 36%|███▌      | 526/1456 [44:14<1:17:52,  5.02s/it]                                                    {'loss': 2.9282, 'grad_norm': 14.387543885854278, 'learning_rate': 3.6950145889261185e-06, 'epoch': 1.45}
 36%|███▌      | 526/1456 [44:14<1:17:52,  5.02s/it] 36%|███▌      | 527/1456 [44:19<1:17:04,  4.98s/it]                                                    {'loss': 1.3643, 'grad_norm': 3.386436301028391, 'learning_rate': 3.6901259431490687e-06, 'epoch': 1.45}
 36%|███▌      | 527/1456 [44:19<1:17:04,  4.98s/it] 36%|███▋      | 528/1456 [44:24<1:17:32,  5.01s/it]                                                    {'loss': 1.3108, 'grad_norm': 3.272277626542916, 'learning_rate': 3.6852314059098254e-06, 'epoch': 1.45}
 36%|███▋      | 528/1456 [44:24<1:17:32,  5.01s/it] 36%|███▋      | 529/1456 [44:29<1:17:05,  4.99s/it]                                                    {'loss': 1.9567, 'grad_norm': 6.082644001125957, 'learning_rate': 3.680331001437741e-06, 'epoch': 1.45}
 36%|███▋      | 529/1456 [44:29<1:17:05,  4.99s/it] 36%|███▋      | 530/1456 [44:34<1:17:42,  5.04s/it]                                                    {'loss': 1.2532, 'grad_norm': 3.4626000675655964, 'learning_rate': 3.67542475399121e-06, 'epoch': 1.46}
 36%|███▋      | 530/1456 [44:34<1:17:42,  5.04s/it] 36%|███▋      | 531/1456 [44:39<1:17:01,  5.00s/it]                                                    {'loss': 2.0132, 'grad_norm': 22.65957006923689, 'learning_rate': 3.670512687857558e-06, 'epoch': 1.46}
 36%|███▋      | 531/1456 [44:39<1:17:01,  5.00s/it] 37%|███▋      | 532/1456 [44:44<1:17:24,  5.03s/it]                                                    {'loss': 2.0696, 'grad_norm': 21.330852046353833, 'learning_rate': 3.665594827352908e-06, 'epoch': 1.46}
 37%|███▋      | 532/1456 [44:44<1:17:24,  5.03s/it] 37%|███▋      | 533/1456 [44:49<1:16:59,  5.01s/it]                                                    {'loss': 1.7566, 'grad_norm': 5.238311835760818, 'learning_rate': 3.6606711968220697e-06, 'epoch': 1.46}
 37%|███▋      | 533/1456 [44:49<1:16:59,  5.01s/it] 37%|███▋      | 534/1456 [44:54<1:17:26,  5.04s/it]                                                    {'loss': 2.221, 'grad_norm': 15.542523535185556, 'learning_rate': 3.6557418206384164e-06, 'epoch': 1.47}
 37%|███▋      | 534/1456 [44:54<1:17:26,  5.04s/it] 37%|███▋      | 535/1456 [44:59<1:17:02,  5.02s/it]                                                    {'loss': 2.3466, 'grad_norm': 7.367657643402727, 'learning_rate': 3.6508067232037624e-06, 'epoch': 1.47}
 37%|███▋      | 535/1456 [44:59<1:17:02,  5.02s/it] 37%|███▋      | 536/1456 [45:04<1:17:06,  5.03s/it]                                                    {'loss': 2.1238, 'grad_norm': 4.588825934355165, 'learning_rate': 3.6458659289482464e-06, 'epoch': 1.47}
 37%|███▋      | 536/1456 [45:04<1:17:06,  5.03s/it] 37%|███▋      | 537/1456 [45:09<1:17:04,  5.03s/it]                                                    {'loss': 1.6766, 'grad_norm': 4.452378166883669, 'learning_rate': 3.6409194623302046e-06, 'epoch': 1.48}
 37%|███▋      | 537/1456 [45:09<1:17:04,  5.03s/it] 37%|███▋      | 538/1456 [45:14<1:16:44,  5.02s/it]                                                    {'loss': 1.5017, 'grad_norm': 2.9771162504205417, 'learning_rate': 3.6359673478360556e-06, 'epoch': 1.48}
 37%|███▋      | 538/1456 [45:14<1:16:44,  5.02s/it] 37%|███▋      | 539/1456 [45:19<1:16:38,  5.02s/it]                                                    {'loss': 1.5596, 'grad_norm': 1.9707012497861804, 'learning_rate': 3.6310096099801756e-06, 'epoch': 1.48}
 37%|███▋      | 539/1456 [45:19<1:16:38,  5.02s/it] 37%|███▋      | 540/1456 [45:24<1:16:31,  5.01s/it]                                                    {'loss': 2.3296, 'grad_norm': 9.327412589263519, 'learning_rate': 3.626046273304779e-06, 'epoch': 1.48}
 37%|███▋      | 540/1456 [45:24<1:16:31,  5.01s/it] 37%|███▋      | 541/1456 [45:29<1:16:39,  5.03s/it]                                                    {'loss': 1.4138, 'grad_norm': 169.6917414294962, 'learning_rate': 3.6210773623797945e-06, 'epoch': 1.49}
 37%|███▋      | 541/1456 [45:29<1:16:39,  5.03s/it] 37%|███▋      | 542/1456 [45:34<1:16:27,  5.02s/it]                                                    {'loss': 1.3944, 'grad_norm': 5.369619470962486, 'learning_rate': 3.616102901802745e-06, 'epoch': 1.49}
 37%|███▋      | 542/1456 [45:34<1:16:27,  5.02s/it] 37%|███▋      | 543/1456 [45:39<1:16:35,  5.03s/it]                                                    {'loss': 1.8411, 'grad_norm': 7.947070742111646, 'learning_rate': 3.611122916198628e-06, 'epoch': 1.49}
 37%|███▋      | 543/1456 [45:39<1:16:35,  5.03s/it] 37%|███▋      | 544/1456 [45:44<1:16:33,  5.04s/it]                                                    {'loss': 0.9399, 'grad_norm': 4.083749918545061, 'learning_rate': 3.6061374302197882e-06, 'epoch': 1.49}
 37%|███▋      | 544/1456 [45:44<1:16:33,  5.04s/it] 37%|███▋      | 545/1456 [45:50<1:16:38,  5.05s/it]                                                    {'loss': 1.4839, 'grad_norm': 6.992747227945918, 'learning_rate': 3.6011464685458015e-06, 'epoch': 1.5}
 37%|███▋      | 545/1456 [45:50<1:16:38,  5.05s/it] 38%|███▊      | 546/1456 [45:54<1:16:10,  5.02s/it]                                                    {'loss': 1.4826, 'grad_norm': 4.161877486501313, 'learning_rate': 3.5961500558833484e-06, 'epoch': 1.5}
 38%|███▊      | 546/1456 [45:54<1:16:10,  5.02s/it] 38%|███▊      | 547/1456 [46:00<1:16:16,  5.03s/it]                                                    {'loss': 1.8984, 'grad_norm': 7.7399026865595735, 'learning_rate': 3.5911482169660934e-06, 'epoch': 1.5}
 38%|███▊      | 547/1456 [46:00<1:16:16,  5.03s/it] 38%|███▊      | 548/1456 [46:05<1:16:13,  5.04s/it]                                                    {'loss': 0.9749, 'grad_norm': 2.7318777833748564, 'learning_rate': 3.586140976554564e-06, 'epoch': 1.51}
 38%|███▊      | 548/1456 [46:05<1:16:13,  5.04s/it] 38%|███▊      | 549/1456 [46:10<1:16:00,  5.03s/it]                                                    {'loss': 1.748, 'grad_norm': 2.7992239523777274, 'learning_rate': 3.5811283594360237e-06, 'epoch': 1.51}
 38%|███▊      | 549/1456 [46:10<1:16:00,  5.03s/it]